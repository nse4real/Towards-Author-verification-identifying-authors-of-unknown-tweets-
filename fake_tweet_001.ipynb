{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nse4real/myrepo/blob/master/fake_tweet_001.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p0XnucR032yg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91234fc5-6b43-40dd-d516-96af18efd9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABb6jaUW_Ouo"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_m5HpQAQIOhQ"
      },
      "outputs": [],
      "source": [
        "#IMPORT NEEDED LIBRARIES\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re, string, unicodedata, math\n",
        "import collections as coll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ouZ0-MWRj-rt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b09528-b7ff-459e-b660-7915ce2a6d40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "#nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jd3fNCfB7Fws"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import words as nltk_words\n",
        "# Import other models needed for Classification models\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import Sequential\n",
        "#from keras.layers.core import Dense\n",
        "from sklearn.cluster import KMeans\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop\n",
        "from keras.utils import np_utils\n",
        "from imutils import paths\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import csv\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from tabulate import tabulate\n",
        "from matplotlib import style\n",
        "style.use(\"ggplot\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C9ystVcbJeUr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980a2c4c-810d-4d2d-f68e-b74cd8dbe786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/dataset.csv\n"
          ]
        }
      ],
      "source": [
        "#use glob to get all the csv files\n",
        "# in the folder\n",
        "#path = os.getcwd()\n",
        "path= '/content/drive/MyDrive/Colab Notebooks/'\n",
        "#csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
        "#print(path)\n",
        "\n",
        "filepath= '/content/drive/MyDrive/Colab Notebooks/dataset.csv'\n",
        "print(filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "w6J8sEQ6ektl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "dfe067da-3dac-43a8-8e52-62b2aaed5bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4560, 18)\n",
            "Content:\n",
            "Index(['input.access_token', 'input.exclude', 'input.tweet_fields',\n",
            "       'input.user_id', 'input.pagination_token',\n",
            "       'data.public_metrics.retweet_count', 'data.public_metrics.reply_count',\n",
            "       'data.public_metrics.like_count', 'data.public_metrics.quote_count',\n",
            "       'data.source', 'data.text', 'data.id', 'data.created_at',\n",
            "       'meta.oldest_id', 'meta.newest_id', 'meta.result_count',\n",
            "       'meta.next_token', 'meta.previous_token'],\n",
            "      dtype='object')\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  input.access_token     input.exclude  \\\n",
              "0  AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...  retweets,replies   \n",
              "1  AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...  retweets,replies   \n",
              "2  AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...  retweets,replies   \n",
              "3  AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...  retweets,replies   \n",
              "4  AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...  retweets,replies   \n",
              "\n",
              "                      input.tweet_fields  input.user_id  \\\n",
              "0  public_metrics,created_at,text,source       27699224   \n",
              "1  public_metrics,created_at,text,source       27699224   \n",
              "2  public_metrics,created_at,text,source       27699224   \n",
              "3  public_metrics,created_at,text,source       27699224   \n",
              "4  public_metrics,created_at,text,source       27699224   \n",
              "\n",
              "  input.pagination_token  data.public_metrics.retweet_count  \\\n",
              "0                    NaN                                  0   \n",
              "1                    NaN                                  2   \n",
              "2                    NaN                                  7   \n",
              "3                    NaN                                  0   \n",
              "4                    NaN                                  0   \n",
              "\n",
              "   data.public_metrics.reply_count  data.public_metrics.like_count  \\\n",
              "0                                1                              15   \n",
              "1                                4                              66   \n",
              "2                                3                              67   \n",
              "3                                1                              23   \n",
              "4                                0                              20   \n",
              "\n",
              "   data.public_metrics.quote_count         data.source  \\\n",
              "0                                0  Twitter for iPhone   \n",
              "1                                0  Twitter for iPhone   \n",
              "2                                1  Twitter for iPhone   \n",
              "3                                1     Twitter Web App   \n",
              "4                                0  Twitter for iPhone   \n",
              "\n",
              "                                           data.text              data.id  \\\n",
              "0  FYI for other authors…this raised $1,460 which...  1498672192766328838   \n",
              "1  Twenty years from now, this is gonna read like...  1498655705351479296   \n",
              "2  If you donate $20 or more to @WCKitchen and DM...  1498048242336120832   \n",
              "3  Our long international nightmare is just begin...  1496922333512351744   \n",
              "4                 Nostalgia. https://t.co/oh9hsNGL0U  1495551477057732609   \n",
              "\n",
              "            data.created_at       meta.oldest_id       meta.newest_id  \\\n",
              "0  2022-03-01T14:51:09.000Z  1396442583505805316  1498672192766328838   \n",
              "1  2022-03-01T13:45:38.000Z  1396442583505805316  1498672192766328838   \n",
              "2  2022-02-27T21:31:48.000Z  1396442583505805316  1498672192766328838   \n",
              "3  2022-02-24T18:57:50.000Z  1396442583505805316  1498672192766328838   \n",
              "4  2022-02-21T00:10:32.000Z  1396442583505805316  1498672192766328838   \n",
              "\n",
              "   meta.result_count                                meta.next_token  \\\n",
              "0                100  7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly   \n",
              "1                100  7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly   \n",
              "2                100  7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly   \n",
              "3                100  7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly   \n",
              "4                100  7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly   \n",
              "\n",
              "  meta.previous_token  \n",
              "0                 NaN  \n",
              "1                 NaN  \n",
              "2                 NaN  \n",
              "3                 NaN  \n",
              "4                 NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3758b1df-040a-4b05-9922-c576b25df60b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input.access_token</th>\n",
              "      <th>input.exclude</th>\n",
              "      <th>input.tweet_fields</th>\n",
              "      <th>input.user_id</th>\n",
              "      <th>input.pagination_token</th>\n",
              "      <th>data.public_metrics.retweet_count</th>\n",
              "      <th>data.public_metrics.reply_count</th>\n",
              "      <th>data.public_metrics.like_count</th>\n",
              "      <th>data.public_metrics.quote_count</th>\n",
              "      <th>data.source</th>\n",
              "      <th>data.text</th>\n",
              "      <th>data.id</th>\n",
              "      <th>data.created_at</th>\n",
              "      <th>meta.oldest_id</th>\n",
              "      <th>meta.newest_id</th>\n",
              "      <th>meta.result_count</th>\n",
              "      <th>meta.next_token</th>\n",
              "      <th>meta.previous_token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...</td>\n",
              "      <td>retweets,replies</td>\n",
              "      <td>public_metrics,created_at,text,source</td>\n",
              "      <td>27699224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>FYI for other authors…this raised $1,460 which...</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>2022-03-01T14:51:09.000Z</td>\n",
              "      <td>1396442583505805316</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>100</td>\n",
              "      <td>7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...</td>\n",
              "      <td>retweets,replies</td>\n",
              "      <td>public_metrics,created_at,text,source</td>\n",
              "      <td>27699224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Twenty years from now, this is gonna read like...</td>\n",
              "      <td>1498655705351479296</td>\n",
              "      <td>2022-03-01T13:45:38.000Z</td>\n",
              "      <td>1396442583505805316</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>100</td>\n",
              "      <td>7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...</td>\n",
              "      <td>retweets,replies</td>\n",
              "      <td>public_metrics,created_at,text,source</td>\n",
              "      <td>27699224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If you donate $20 or more to @WCKitchen and DM...</td>\n",
              "      <td>1498048242336120832</td>\n",
              "      <td>2022-02-27T21:31:48.000Z</td>\n",
              "      <td>1396442583505805316</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>100</td>\n",
              "      <td>7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...</td>\n",
              "      <td>retweets,replies</td>\n",
              "      <td>public_metrics,created_at,text,source</td>\n",
              "      <td>27699224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Our long international nightmare is just begin...</td>\n",
              "      <td>1496922333512351744</td>\n",
              "      <td>2022-02-24T18:57:50.000Z</td>\n",
              "      <td>1396442583505805316</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>100</td>\n",
              "      <td>7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AAAAAAAAAAAAAAAAAAAAAAyUYgEAAAAAYT3ZR%2Bw6cIB8...</td>\n",
              "      <td>retweets,replies</td>\n",
              "      <td>public_metrics,created_at,text,source</td>\n",
              "      <td>27699224</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Nostalgia. https://t.co/oh9hsNGL0U</td>\n",
              "      <td>1495551477057732609</td>\n",
              "      <td>2022-02-21T00:10:32.000Z</td>\n",
              "      <td>1396442583505805316</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>100</td>\n",
              "      <td>7140dibdnow9c7btw3w4sioouy7v4owjrs89d2hqa0yly</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3758b1df-040a-4b05-9922-c576b25df60b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3758b1df-040a-4b05-9922-c576b25df60b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3758b1df-040a-4b05-9922-c576b25df60b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# read the csv file\n",
        "df = pd.read_csv(filepath)\n",
        "\n",
        "# print number df rows and columns\n",
        "print(df.shape)\n",
        "  \n",
        "# print the content\n",
        "print('Content:')\n",
        "#display(df)\n",
        "\n",
        "#print the column names\n",
        "print(df.columns)\n",
        "print()\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yYQ2_Z6fN8qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c24575d3-0784-4952-ada2-83dbcf685885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['input.user_id', 'data.public_metrics.retweet_count',\n",
            "       'data.public_metrics.reply_count', 'data.public_metrics.like_count',\n",
            "       'data.public_metrics.quote_count', 'data.source', 'data.text',\n",
            "       'data.id', 'data.created_at'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    input.user_id  data.public_metrics.retweet_count  \\\n",
              "0        27699224                                  0   \n",
              "1        27699224                                  2   \n",
              "2        27699224                                  7   \n",
              "3        27699224                                  0   \n",
              "4        27699224                                  0   \n",
              "5        27699224                                  0   \n",
              "6        27699224                                  3   \n",
              "7        27699224                                  0   \n",
              "8        27699224                                  3   \n",
              "9        27699224                                  1   \n",
              "10       27699224                                  4   \n",
              "11       27699224                                  7   \n",
              "12       27699224                                  0   \n",
              "13       27699224                                  0   \n",
              "14       27699224                                  0   \n",
              "15       27699224                                  0   \n",
              "16       27699224                                  1   \n",
              "17       27699224                                  2   \n",
              "18       27699224                                  1   \n",
              "19       27699224                                146   \n",
              "20       27699224                                  0   \n",
              "21       27699224                                  0   \n",
              "22       27699224                                  0   \n",
              "23       27699224                                  0   \n",
              "24       27699224                                  5   \n",
              "25       27699224                                 69   \n",
              "26       27699224                                  5   \n",
              "27       27699224                                  1   \n",
              "28       27699224                                  1   \n",
              "29       27699224                                  6   \n",
              "30       27699224                                  5   \n",
              "31       27699224                                  1   \n",
              "32       27699224                                  0   \n",
              "33       27699224                                  1   \n",
              "34       27699224                                 55   \n",
              "35       27699224                                  6   \n",
              "36       27699224                                  1   \n",
              "37       27699224                                 16   \n",
              "38       27699224                                  2   \n",
              "39       27699224                                  0   \n",
              "40       27699224                                 18   \n",
              "41       27699224                                  0   \n",
              "\n",
              "    data.public_metrics.reply_count  data.public_metrics.like_count  \\\n",
              "0                                 1                              15   \n",
              "1                                 4                              66   \n",
              "2                                 3                              67   \n",
              "3                                 1                              23   \n",
              "4                                 0                              20   \n",
              "5                                 3                              24   \n",
              "6                                 0                              34   \n",
              "7                                 8                              70   \n",
              "8                                 5                             152   \n",
              "9                                 2                              57   \n",
              "10                                3                              53   \n",
              "11                                6                             141   \n",
              "12                                0                               7   \n",
              "13                                0                               6   \n",
              "14                                1                               8   \n",
              "15                                0                              11   \n",
              "16                                4                              29   \n",
              "17                                2                             164   \n",
              "18                                0                              43   \n",
              "19                               13                            1160   \n",
              "20                                0                               6   \n",
              "21                                0                              11   \n",
              "22                                1                              47   \n",
              "23                                2                              45   \n",
              "24                                4                              73   \n",
              "25                               11                             980   \n",
              "26                                4                              86   \n",
              "27                                7                              71   \n",
              "28                                4                             141   \n",
              "29                                4                             221   \n",
              "30                                2                              77   \n",
              "31                                0                              95   \n",
              "32                                7                              47   \n",
              "33                                1                              56   \n",
              "34                                5                             967   \n",
              "35                                1                             156   \n",
              "36                                1                              53   \n",
              "37                                9                             344   \n",
              "38                                0                              36   \n",
              "39                                1                              62   \n",
              "40                                2                             224   \n",
              "41                                4                             135   \n",
              "\n",
              "    data.public_metrics.quote_count         data.source  \\\n",
              "0                                 0  Twitter for iPhone   \n",
              "1                                 0  Twitter for iPhone   \n",
              "2                                 1  Twitter for iPhone   \n",
              "3                                 1     Twitter Web App   \n",
              "4                                 0  Twitter for iPhone   \n",
              "5                                 0  Twitter for iPhone   \n",
              "6                                 0  Twitter for iPhone   \n",
              "7                                 0  Twitter for iPhone   \n",
              "8                                 1  Twitter for iPhone   \n",
              "9                                 0  Twitter for iPhone   \n",
              "10                                0  Twitter for iPhone   \n",
              "11                                0  Twitter for iPhone   \n",
              "12                                0  Twitter for iPhone   \n",
              "13                                0  Twitter for iPhone   \n",
              "14                                0  Twitter for iPhone   \n",
              "15                                0  Twitter for iPhone   \n",
              "16                                0  Twitter for iPhone   \n",
              "17                                0  Twitter for iPhone   \n",
              "18                                0  Twitter for iPhone   \n",
              "19                                7  Twitter for iPhone   \n",
              "20                                0  Twitter for iPhone   \n",
              "21                                0  Twitter for iPhone   \n",
              "22                                0     Twitter Web App   \n",
              "23                                1     Twitter Web App   \n",
              "24                                0  Twitter for iPhone   \n",
              "25                                4     Twitter Web App   \n",
              "26                                1     Twitter Web App   \n",
              "27                                0  Twitter for iPhone   \n",
              "28                                0  Twitter for iPhone   \n",
              "29                                0  Twitter for iPhone   \n",
              "30                                0     Twitter Web App   \n",
              "31                                0  Twitter for iPhone   \n",
              "32                                1  Twitter for iPhone   \n",
              "33                                1  Twitter for iPhone   \n",
              "34                                6  Twitter for iPhone   \n",
              "35                                1  Twitter for iPhone   \n",
              "36                                0  Twitter for iPhone   \n",
              "37                                2     Twitter Web App   \n",
              "38                                0  Twitter for iPhone   \n",
              "39                                0  Twitter for iPhone   \n",
              "40                                2  Twitter for iPhone   \n",
              "41                                0     Twitter Web App   \n",
              "\n",
              "                                            data.text              data.id  \\\n",
              "0   FYI for other authors…this raised $1,460 which...  1498672192766328838   \n",
              "1   Twenty years from now, this is gonna read like...  1498655705351479296   \n",
              "2   If you donate $20 or more to @WCKitchen and DM...  1498048242336120832   \n",
              "3   Our long international nightmare is just begin...  1496922333512351744   \n",
              "4                  Nostalgia. https://t.co/oh9hsNGL0U  1495551477057732609   \n",
              "5   I don’t know what’s worth bragging about here,...  1495380686009733128   \n",
              "6   Congratulations to @xlorentzen and the cast of...  1493237197109145606   \n",
              "7   I have broken, had surgery on, sprained, broke...  1490821936070348801   \n",
              "8   The judgement is deafening. https://t.co/5uMsa...  1489834957115731969   \n",
              "9   If we insist on slicing American generations t...  1486802577522143234   \n",
              "10  Thank you to ⁦@TandCmag⁩ for this delightfully...  1485290465842839553   \n",
              "11  Michael Musto almost mowed me down in the midd...  1482134365542957064   \n",
              "12  I am currently reading Lost &amp; Found by Kat...  1482068580917207044   \n",
              "13               RIP Terry, you will be truly missed.  1481982151235100683   \n",
              "14  He taught me how to play Go, introduced me to ...  1481982052178268160   \n",
              "15  we wound up talking, mostly about Mencken, for...  1481981912818323457   \n",
              "16  This is deeply sad. A quick story about Terry:...  1481981764197396486   \n",
              "17  I don’t care if I’m engaged or married or have...  1481437203049943040   \n",
              "18  Consider it, sure, but don’t do anything rash....  1478588093829685249   \n",
              "19  “I'd like the pie heated and I don't want the ...  1478506041738510337   \n",
              "20                💜🕍 &amp; 🟢🍃 https://t.co/ddF4sMEN4h  1478483560604606465   \n",
              "21  And I *only* read with a Doberman present! Fee...  1478439023681150979   \n",
              "22  Are you living in a steam-heated New York apar...  1478340062047842304   \n",
              "23  I have started Yellowjackets and I notice it's...  1478238524730232833   \n",
              "24  This 2022, learn to ask for the things you wan...  1476783365604978695   \n",
              "25  Whenever you feel like the equilibrium of the ...  1476216733677543425   \n",
              "26  My New Year's resolution is to use paper, not ...  1475960287756967936   \n",
              "27  Everyday at 6PM, my hard-of-hearing downstairs...  1475614358097076224   \n",
              "28  My mother drew this, needle pointed it, “signe...  1474920991952613376   \n",
              "29  She couldn’t operate an air conditioning unit ...  1474107380220710917   \n",
              "30  The formula for cold fusion, where David Bowie...  1473790106247049220   \n",
              "31  My new favorite genre of social media post is ...  1473057537155117056   \n",
              "32  Who will aquire my anthology titled Over The P...  1471145463663542288   \n",
              "33  I was just feeling in love with love last nigh...  1470429739806605320   \n",
              "34  If you can’t sleep on a Sunday night, you shou...  1470302901163675649   \n",
              "35  I *tore* through the vampire chronicles when I...  1470070654330413056   \n",
              "36  Lotta enlightenment to be found in how the Jap...  1470056387736743942   \n",
              "37  I am proud to share this news from @fsgbooks &...  1467957746947481608   \n",
              "38  “I don’t identify as JAPy,” she said, blasting...  1466904422672388101   \n",
              "39                          💙 https://t.co/H4oXS6ER9R  1464456732890050568   \n",
              "40  There is a line around the block for Marie’s C...  1464373159587725314   \n",
              "41  I would be very interested in a “least watched...  1463716137317941253   \n",
              "\n",
              "             data.created_at  \n",
              "0   2022-03-01T14:51:09.000Z  \n",
              "1   2022-03-01T13:45:38.000Z  \n",
              "2   2022-02-27T21:31:48.000Z  \n",
              "3   2022-02-24T18:57:50.000Z  \n",
              "4   2022-02-21T00:10:32.000Z  \n",
              "5   2022-02-20T12:51:53.000Z  \n",
              "6   2022-02-14T14:54:25.000Z  \n",
              "7   2022-02-07T22:57:02.000Z  \n",
              "8   2022-02-05T05:35:08.000Z  \n",
              "9   2022-01-27T20:45:32.000Z  \n",
              "10  2022-01-23T16:36:57.000Z  \n",
              "11  2022-01-14T23:35:44.000Z  \n",
              "12  2022-01-14T19:14:19.000Z  \n",
              "13  2022-01-14T13:30:53.000Z  \n",
              "14  2022-01-14T13:30:29.000Z  \n",
              "15  2022-01-14T13:29:56.000Z  \n",
              "16  2022-01-14T13:29:21.000Z  \n",
              "17  2022-01-13T01:25:27.000Z  \n",
              "18  2022-01-05T04:44:07.000Z  \n",
              "19  2022-01-04T23:18:04.000Z  \n",
              "20  2022-01-04T21:48:44.000Z  \n",
              "21  2022-01-04T18:51:45.000Z  \n",
              "22  2022-01-04T12:18:31.000Z  \n",
              "23  2022-01-04T05:35:03.000Z  \n",
              "24  2021-12-31T05:12:46.000Z  \n",
              "25  2021-12-29T15:41:10.000Z  \n",
              "26  2021-12-28T22:42:09.000Z  \n",
              "27  2021-12-27T23:47:33.000Z  \n",
              "28  2021-12-26T01:52:21.000Z  \n",
              "29  2021-12-23T19:59:21.000Z  \n",
              "30  2021-12-22T22:58:37.000Z  \n",
              "31  2021-12-20T22:27:39.000Z  \n",
              "32  2021-12-15T15:49:45.000Z  \n",
              "33  2021-12-13T16:25:43.000Z  \n",
              "34  2021-12-13T08:01:43.000Z  \n",
              "35  2021-12-12T16:38:51.000Z  \n",
              "36  2021-12-12T15:42:09.000Z  \n",
              "37  2021-12-06T20:42:54.000Z  \n",
              "38  2021-12-03T22:57:22.000Z  \n",
              "39  2021-11-27T04:51:08.000Z  \n",
              "40  2021-11-26T23:19:02.000Z  \n",
              "41  2021-11-25T03:48:16.000Z  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7e4e64cc-7e9d-4315-90d1-4591af84d12a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input.user_id</th>\n",
              "      <th>data.public_metrics.retweet_count</th>\n",
              "      <th>data.public_metrics.reply_count</th>\n",
              "      <th>data.public_metrics.like_count</th>\n",
              "      <th>data.public_metrics.quote_count</th>\n",
              "      <th>data.source</th>\n",
              "      <th>data.text</th>\n",
              "      <th>data.id</th>\n",
              "      <th>data.created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>FYI for other authors…this raised $1,460 which...</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>2022-03-01T14:51:09.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Twenty years from now, this is gonna read like...</td>\n",
              "      <td>1498655705351479296</td>\n",
              "      <td>2022-03-01T13:45:38.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27699224</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If you donate $20 or more to @WCKitchen and DM...</td>\n",
              "      <td>1498048242336120832</td>\n",
              "      <td>2022-02-27T21:31:48.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Our long international nightmare is just begin...</td>\n",
              "      <td>1496922333512351744</td>\n",
              "      <td>2022-02-24T18:57:50.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Nostalgia. https://t.co/oh9hsNGL0U</td>\n",
              "      <td>1495551477057732609</td>\n",
              "      <td>2022-02-21T00:10:32.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I don’t know what’s worth bragging about here,...</td>\n",
              "      <td>1495380686009733128</td>\n",
              "      <td>2022-02-20T12:51:53.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27699224</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Congratulations to @xlorentzen and the cast of...</td>\n",
              "      <td>1493237197109145606</td>\n",
              "      <td>2022-02-14T14:54:25.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I have broken, had surgery on, sprained, broke...</td>\n",
              "      <td>1490821936070348801</td>\n",
              "      <td>2022-02-07T22:57:02.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27699224</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>152</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>The judgement is deafening. https://t.co/5uMsa...</td>\n",
              "      <td>1489834957115731969</td>\n",
              "      <td>2022-02-05T05:35:08.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If we insist on slicing American generations t...</td>\n",
              "      <td>1486802577522143234</td>\n",
              "      <td>2022-01-27T20:45:32.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>27699224</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Thank you to ⁦@TandCmag⁩ for this delightfully...</td>\n",
              "      <td>1485290465842839553</td>\n",
              "      <td>2022-01-23T16:36:57.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>27699224</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Michael Musto almost mowed me down in the midd...</td>\n",
              "      <td>1482134365542957064</td>\n",
              "      <td>2022-01-14T23:35:44.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I am currently reading Lost &amp;amp; Found by Kat...</td>\n",
              "      <td>1482068580917207044</td>\n",
              "      <td>2022-01-14T19:14:19.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>RIP Terry, you will be truly missed.</td>\n",
              "      <td>1481982151235100683</td>\n",
              "      <td>2022-01-14T13:30:53.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>He taught me how to play Go, introduced me to ...</td>\n",
              "      <td>1481982052178268160</td>\n",
              "      <td>2022-01-14T13:30:29.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>we wound up talking, mostly about Mencken, for...</td>\n",
              "      <td>1481981912818323457</td>\n",
              "      <td>2022-01-14T13:29:56.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>This is deeply sad. A quick story about Terry:...</td>\n",
              "      <td>1481981764197396486</td>\n",
              "      <td>2022-01-14T13:29:21.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I don’t care if I’m engaged or married or have...</td>\n",
              "      <td>1481437203049943040</td>\n",
              "      <td>2022-01-13T01:25:27.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Consider it, sure, but don’t do anything rash....</td>\n",
              "      <td>1478588093829685249</td>\n",
              "      <td>2022-01-05T04:44:07.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>27699224</td>\n",
              "      <td>146</td>\n",
              "      <td>13</td>\n",
              "      <td>1160</td>\n",
              "      <td>7</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>“I'd like the pie heated and I don't want the ...</td>\n",
              "      <td>1478506041738510337</td>\n",
              "      <td>2022-01-04T23:18:04.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>💜🕍 &amp;amp; 🟢🍃 https://t.co/ddF4sMEN4h</td>\n",
              "      <td>1478483560604606465</td>\n",
              "      <td>2022-01-04T21:48:44.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>And I *only* read with a Doberman present! Fee...</td>\n",
              "      <td>1478439023681150979</td>\n",
              "      <td>2022-01-04T18:51:45.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Are you living in a steam-heated New York apar...</td>\n",
              "      <td>1478340062047842304</td>\n",
              "      <td>2022-01-04T12:18:31.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>I have started Yellowjackets and I notice it's...</td>\n",
              "      <td>1478238524730232833</td>\n",
              "      <td>2022-01-04T05:35:03.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>27699224</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>This 2022, learn to ask for the things you wan...</td>\n",
              "      <td>1476783365604978695</td>\n",
              "      <td>2021-12-31T05:12:46.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>27699224</td>\n",
              "      <td>69</td>\n",
              "      <td>11</td>\n",
              "      <td>980</td>\n",
              "      <td>4</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Whenever you feel like the equilibrium of the ...</td>\n",
              "      <td>1476216733677543425</td>\n",
              "      <td>2021-12-29T15:41:10.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27699224</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>My New Year's resolution is to use paper, not ...</td>\n",
              "      <td>1475960287756967936</td>\n",
              "      <td>2021-12-28T22:42:09.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Everyday at 6PM, my hard-of-hearing downstairs...</td>\n",
              "      <td>1475614358097076224</td>\n",
              "      <td>2021-12-27T23:47:33.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>My mother drew this, needle pointed it, “signe...</td>\n",
              "      <td>1474920991952613376</td>\n",
              "      <td>2021-12-26T01:52:21.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>27699224</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>She couldn’t operate an air conditioning unit ...</td>\n",
              "      <td>1474107380220710917</td>\n",
              "      <td>2021-12-23T19:59:21.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>27699224</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>The formula for cold fusion, where David Bowie...</td>\n",
              "      <td>1473790106247049220</td>\n",
              "      <td>2021-12-22T22:58:37.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>My new favorite genre of social media post is ...</td>\n",
              "      <td>1473057537155117056</td>\n",
              "      <td>2021-12-20T22:27:39.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Who will aquire my anthology titled Over The P...</td>\n",
              "      <td>1471145463663542288</td>\n",
              "      <td>2021-12-15T15:49:45.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I was just feeling in love with love last nigh...</td>\n",
              "      <td>1470429739806605320</td>\n",
              "      <td>2021-12-13T16:25:43.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>27699224</td>\n",
              "      <td>55</td>\n",
              "      <td>5</td>\n",
              "      <td>967</td>\n",
              "      <td>6</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If you can’t sleep on a Sunday night, you shou...</td>\n",
              "      <td>1470302901163675649</td>\n",
              "      <td>2021-12-13T08:01:43.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>27699224</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I *tore* through the vampire chronicles when I...</td>\n",
              "      <td>1470070654330413056</td>\n",
              "      <td>2021-12-12T16:38:51.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Lotta enlightenment to be found in how the Jap...</td>\n",
              "      <td>1470056387736743942</td>\n",
              "      <td>2021-12-12T15:42:09.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>27699224</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>344</td>\n",
              "      <td>2</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>I am proud to share this news from @fsgbooks &amp;...</td>\n",
              "      <td>1467957746947481608</td>\n",
              "      <td>2021-12-06T20:42:54.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>“I don’t identify as JAPy,” she said, blasting...</td>\n",
              "      <td>1466904422672388101</td>\n",
              "      <td>2021-12-03T22:57:22.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>💙 https://t.co/H4oXS6ER9R</td>\n",
              "      <td>1464456732890050568</td>\n",
              "      <td>2021-11-27T04:51:08.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>27699224</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>224</td>\n",
              "      <td>2</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>There is a line around the block for Marie’s C...</td>\n",
              "      <td>1464373159587725314</td>\n",
              "      <td>2021-11-26T23:19:02.000Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>I would be very interested in a “least watched...</td>\n",
              "      <td>1463716137317941253</td>\n",
              "      <td>2021-11-25T03:48:16.000Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e4e64cc-7e9d-4315-90d1-4591af84d12a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e4e64cc-7e9d-4315-90d1-4591af84d12a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e4e64cc-7e9d-4315-90d1-4591af84d12a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#DROP UNNECCESSARY COLUMNS\n",
        "columns_to_drop = ['input.access_token', 'input.exclude',\n",
        "       'input.tweet_fields', 'input.pagination_token', 'meta.oldest_id',\n",
        "       'meta.newest_id', 'meta.result_count', 'meta.next_token',\n",
        "       'meta.previous_token']\n",
        "df=df.drop(columns=columns_to_drop)\n",
        "print(df.columns)\n",
        "df.head(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iquirhw8nBjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b0bab5-3a18-4f14-faf7-d9e7d3e59070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['user_id', 'retweet_count', 'reply_count', 'like_count', 'quote_count',\n",
            "       'tweet_device', 'tweet', 'tweet_id', 'tweet_time'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#RENAME THE COLUMNS NAMES TO SHORTER NAMES\n",
        "new_columns={'input.user_id':'user_id', 'data.public_metrics.retweet_count':'retweet_count',\n",
        "       'data.public_metrics.reply_count':'reply_count', 'data.public_metrics.like_count':'like_count',\n",
        "       'data.public_metrics.quote_count':'quote_count', 'data.source':'tweet_device', 'data.text':'tweet',\n",
        "       'data.id':'tweet_id', 'data.created_at':'tweet_time'}\n",
        "df=df.rename(columns=new_columns)\n",
        "# print(df.head())\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "uV4xk38nHpX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08f0c61-57dd-4f3a-be96-842b34cf9f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    user_id    username\n",
            "0  27699224  @askanyone\n",
            "1  27699224  @askanyone\n",
            "2  27699224  @askanyone\n",
            "3  27699224  @askanyone\n",
            "4  27699224  @askanyone\n",
            "(4560, 10)\n"
          ]
        }
      ],
      "source": [
        "#ADD NEW COLUMN CALLED USERNAME\n",
        "authors = {\n",
        "  426044697: \"@Shteyngart\",\n",
        "  18903971: \"@harlancoben \",\n",
        "  27699224: \"@askanyone\",\n",
        "  17790667: \"@megcabot\",\n",
        "  5520952: \"@paulocoelho\",\n",
        "  83876527: \"@tejucole\"\n",
        "}\n",
        "#print(authors)\n",
        "\n",
        "df['username'] = \"\" #Add an empty column\n",
        "#df.info()\n",
        "\n",
        "for id, username in authors.items():\n",
        "  #print(df[df.user_id==id]);\n",
        "  df.loc[df.user_id==id, ['username']] = username\n",
        "\n",
        "#print userid and username columns\n",
        "print(df[['user_id','username']].head())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvK8M8JswoQL"
      },
      "source": [
        "## DATA CLEANING\n",
        "- removal of links from tweets\n",
        "- removal of special characters from tweets\n",
        "- removal of numbers from tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zx2uzVYb1qCf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "e26dcaff-c277-487a-e1e2-47b3a6ccfd48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            user_id  retweet_count   reply_count     like_count   quote_count  \\\n",
              "count  4.560000e+03    4560.000000   4560.000000    4560.000000   4560.000000   \n",
              "mean   1.031864e+08     479.116667     38.814035    1893.208114     38.025219   \n",
              "std    1.555637e+08    3277.806502    265.834571   12704.063162    292.751279   \n",
              "min    5.520952e+06       0.000000      0.000000       0.000000      0.000000   \n",
              "25%    1.779067e+07       2.000000      2.000000      40.000000      0.000000   \n",
              "50%    2.769922e+07       9.000000      6.000000      97.000000      1.000000   \n",
              "75%    8.387653e+07      45.000000     19.000000     399.000000      3.000000   \n",
              "max    4.260447e+08  101649.000000  12418.000000  548082.000000  10586.000000   \n",
              "\n",
              "           tweet_id  \n",
              "count  4.560000e+03  \n",
              "mean   1.192169e+18  \n",
              "std    3.242729e+17  \n",
              "min    4.767467e+17  \n",
              "25%    1.125774e+18  \n",
              "50%    1.308792e+18  \n",
              "75%    1.418220e+18  \n",
              "max    1.499168e+18  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-270d07b6-0560-4dd4-8ac6-3dc6f64bddd0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>tweet_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.560000e+03</td>\n",
              "      <td>4560.000000</td>\n",
              "      <td>4560.000000</td>\n",
              "      <td>4560.000000</td>\n",
              "      <td>4560.000000</td>\n",
              "      <td>4.560000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.031864e+08</td>\n",
              "      <td>479.116667</td>\n",
              "      <td>38.814035</td>\n",
              "      <td>1893.208114</td>\n",
              "      <td>38.025219</td>\n",
              "      <td>1.192169e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.555637e+08</td>\n",
              "      <td>3277.806502</td>\n",
              "      <td>265.834571</td>\n",
              "      <td>12704.063162</td>\n",
              "      <td>292.751279</td>\n",
              "      <td>3.242729e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.520952e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.767467e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.779067e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125774e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.769922e+07</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.308792e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.387653e+07</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>399.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.418220e+18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.260447e+08</td>\n",
              "      <td>101649.000000</td>\n",
              "      <td>12418.000000</td>\n",
              "      <td>548082.000000</td>\n",
              "      <td>10586.000000</td>\n",
              "      <td>1.499168e+18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-270d07b6-0560-4dd4-8ac6-3dc6f64bddd0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-270d07b6-0560-4dd4-8ac6-3dc6f64bddd0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-270d07b6-0560-4dd4-8ac6-3dc6f64bddd0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0xU6sHit16Vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32f4905b-6ec1-4832-ac52-6ea9d8f85e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4560 entries, 0 to 4559\n",
            "Data columns (total 10 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   user_id        4560 non-null   int64 \n",
            " 1   retweet_count  4560 non-null   int64 \n",
            " 2   reply_count    4560 non-null   int64 \n",
            " 3   like_count     4560 non-null   int64 \n",
            " 4   quote_count    4560 non-null   int64 \n",
            " 5   tweet_device   4560 non-null   object\n",
            " 6   tweet          4560 non-null   object\n",
            " 7   tweet_id       4560 non-null   int64 \n",
            " 8   tweet_time     4560 non-null   object\n",
            " 9   username       4560 non-null   object\n",
            "dtypes: int64(6), object(4)\n",
            "memory usage: 356.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "D3mb2X5Z2fV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85baae1-d5dc-4d0f-f335-7572c1836ab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id          0\n",
              "retweet_count    0\n",
              "reply_count      0\n",
              "like_count       0\n",
              "quote_count      0\n",
              "tweet_device     0\n",
              "tweet            0\n",
              "tweet_id         0\n",
              "tweet_time       0\n",
              "username         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# CHECK FOR NAs\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnv8HMbJ2uKc"
      },
      "source": [
        "The dataset contains links and non-ASCII characters. There are no  NaN in the dataset but there exists empty tweets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZeXfwAtAysIj"
      },
      "outputs": [],
      "source": [
        "## preprocessing functions\n",
        "def remove_URL(tweet):\n",
        "    \"\"\"Remove URLs from a sample string\"\"\"\n",
        "    return re.sub(r\"http\\S+\", \"\", tweet)\n",
        "\n",
        "def remove_numbers(tweet):\n",
        "  \"\"\"Remove words with numbers\"\"\"\n",
        "  return re.sub(\"[0-9]\",\"\",tweet)   \n",
        "\n",
        "def remove_non_ascii(tweet):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    return unicodedata.normalize('NFKD', tweet.encode('ascii', 'ignore').decode('utf-8', 'ignore'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rG-PrE_C2Q_l"
      },
      "outputs": [],
      "source": [
        "# Use apply function to apply preprocessing\n",
        "df[\"tweet\"] = df[\"tweet\"].apply(lambda t: remove_URL(t)) #remove urls\n",
        "df[\"tweet\"] = df[\"tweet\"].apply(lambda t: remove_numbers(t))\n",
        "df[\"tweet\"] = df[\"tweet\"].apply(lambda t: remove_non_ascii(t))\n",
        "df[\"tweet\"] = df[\"tweet\"].apply(lambda t: t.strip())\n",
        "#print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UBy34VOXJ6bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f4d1102-c206-445d-f2a7-0d74785ee630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['@Shteyngart', '@askanyone', '@harlancoben ', '@megcabot',\n",
            "       '@paulocoelho', '@tejucole'],\n",
            "      dtype='object')\n",
            "[0 1 2 3 4 5]\n"
          ]
        }
      ],
      "source": [
        "## C0nvert tweet_device and username to categorical type\n",
        "df[\"tweet_device\"] = df[\"tweet_device\"].astype('category')\n",
        "df[\"username\"] = df[\"username\"].astype('category')\n",
        "df[\"tweet_device_code\"] = df[\"tweet_device\"].cat.codes\n",
        "df[\"username_code\"] = df[\"username\"].cat.codes\n",
        "ucat = df[\"username\"].values\n",
        "print(ucat.categories)\n",
        "print(np.unique(ucat.codes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qtp3vvzq2LTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6187f9bc-dedd-4b61-f087-c221d88d18fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of empty tweet: 159\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# CHECK FOR EMPTY TWEET\n",
        "df_empty_tweet = df[df['tweet'].str.len()<1]\n",
        "print(\"Number of empty tweet: \"+str(df_empty_tweet.shape[0]))\n",
        "df_empty_tweet.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gAbjM5eU8yJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79502cf5-8a80-4610-c6fc-43f904520528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset size: {0} 4401\n",
            "(4401, 12)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     user_id  retweet_count  reply_count  like_count  quote_count  \\\n",
              "0   27699224              0            1          15            0   \n",
              "1   27699224              2            4          66            0   \n",
              "2   27699224              7            3          67            1   \n",
              "3   27699224              0            1          23            1   \n",
              "4   27699224              0            0          20            0   \n",
              "5   27699224              0            3          24            0   \n",
              "6   27699224              3            0          34            0   \n",
              "7   27699224              0            8          70            0   \n",
              "8   27699224              3            5         152            1   \n",
              "9   27699224              1            2          57            0   \n",
              "10  27699224              4            3          53            0   \n",
              "11  27699224              7            6         141            0   \n",
              "12  27699224              0            0           7            0   \n",
              "13  27699224              0            0           6            0   \n",
              "14  27699224              0            1           8            0   \n",
              "15  27699224              0            0          11            0   \n",
              "16  27699224              1            4          29            0   \n",
              "17  27699224              2            2         164            0   \n",
              "18  27699224              1            0          43            0   \n",
              "19  27699224            146           13        1160            7   \n",
              "20  27699224              0            0           6            0   \n",
              "21  27699224              0            0          11            0   \n",
              "22  27699224              0            1          47            0   \n",
              "23  27699224              0            2          45            1   \n",
              "24  27699224              5            4          73            0   \n",
              "25  27699224             69           11         980            4   \n",
              "26  27699224              5            4          86            1   \n",
              "27  27699224              1            7          71            0   \n",
              "28  27699224              1            4         141            0   \n",
              "29  27699224              6            4         221            0   \n",
              "30  27699224              5            2          77            0   \n",
              "31  27699224              1            0          95            0   \n",
              "32  27699224              0            7          47            1   \n",
              "33  27699224              1            1          56            1   \n",
              "34  27699224             55            5         967            6   \n",
              "35  27699224              6            1         156            1   \n",
              "36  27699224              1            1          53            0   \n",
              "37  27699224             16            9         344            2   \n",
              "38  27699224              2            0          36            0   \n",
              "40  27699224             18            2         224            2   \n",
              "41  27699224              0            4         135            0   \n",
              "42  27699224              8            0          51            1   \n",
              "\n",
              "          tweet_device                                              tweet  \\\n",
              "0   Twitter for iPhone  FYI for other authorsthis raised $, which is a...   \n",
              "1   Twitter for iPhone  Twenty years from now, this is gonna read like...   \n",
              "2   Twitter for iPhone  If you donate $ or more to @WCKitchen and DM m...   \n",
              "3      Twitter Web App  Our long international nightmare is just begin...   \n",
              "4   Twitter for iPhone                                         Nostalgia.   \n",
              "5   Twitter for iPhone  I dont know whats worth bragging about here, b...   \n",
              "6   Twitter for iPhone  Congratulations to @xlorentzen and the cast of...   \n",
              "7   Twitter for iPhone  I have broken, had surgery on, sprained, broke...   \n",
              "8   Twitter for iPhone                        The judgement is deafening.   \n",
              "9   Twitter for iPhone  If we insist on slicing American generations t...   \n",
              "10  Twitter for iPhone  Thank you to @TandCmag for this delightfully d...   \n",
              "11  Twitter for iPhone  Michael Musto almost mowed me down in the midd...   \n",
              "12  Twitter for iPhone  I am currently reading Lost &amp; Found by Kat...   \n",
              "13  Twitter for iPhone               RIP Terry, you will be truly missed.   \n",
              "14  Twitter for iPhone  He taught me how to play Go, introduced me to ...   \n",
              "15  Twitter for iPhone  we wound up talking, mostly about Mencken, for...   \n",
              "16  Twitter for iPhone  This is deeply sad. A quick story about Terry:...   \n",
              "17  Twitter for iPhone  I dont care if Im engaged or married or have t...   \n",
              "18  Twitter for iPhone      Consider it, sure, but dont do anything rash.   \n",
              "19  Twitter for iPhone  I'd like the pie heated and I don't want the i...   \n",
              "20  Twitter for iPhone                                              &amp;   \n",
              "21  Twitter for iPhone  And I *only* read with a Doberman present! Fee...   \n",
              "22     Twitter Web App  Are you living in a steam-heated New York apar...   \n",
              "23     Twitter Web App  I have started Yellowjackets and I notice it's...   \n",
              "24  Twitter for iPhone       This , learn to ask for the things you want:   \n",
              "25     Twitter Web App  Whenever you feel like the equilibrium of the ...   \n",
              "26     Twitter Web App  My New Year's resolution is to use paper, not ...   \n",
              "27  Twitter for iPhone  Everyday at PM, my hard-of-hearing downstairs ...   \n",
              "28  Twitter for iPhone  My mother drew this, needle pointed it, signed...   \n",
              "29  Twitter for iPhone  She couldnt operate an air conditioning unit t...   \n",
              "30     Twitter Web App  The formula for cold fusion, where David Bowie...   \n",
              "31  Twitter for iPhone  My new favorite genre of social media post is ...   \n",
              "32  Twitter for iPhone  Who will aquire my anthology titled Over The P...   \n",
              "33  Twitter for iPhone  I was just feeling in love with love last nigh...   \n",
              "34  Twitter for iPhone  If you cant sleep on a Sunday night, you shoul...   \n",
              "35  Twitter for iPhone  I *tore* through the vampire chronicles when I...   \n",
              "36  Twitter for iPhone  Lotta enlightenment to be found in how the Jap...   \n",
              "37     Twitter Web App  I am proud to share this news from @fsgbooks &...   \n",
              "38  Twitter for iPhone  I dont identify as JAPy, she said, blasting dr...   \n",
              "40  Twitter for iPhone  There is a line around the block for Maries Cr...   \n",
              "41     Twitter Web App  I would be very interested in a least watched,...   \n",
              "42  Twitter for iPhone  I get all my automated email replies from Eyes...   \n",
              "\n",
              "               tweet_id                tweet_time    username  \\\n",
              "0   1498672192766328838  2022-03-01T14:51:09.000Z  @askanyone   \n",
              "1   1498655705351479296  2022-03-01T13:45:38.000Z  @askanyone   \n",
              "2   1498048242336120832  2022-02-27T21:31:48.000Z  @askanyone   \n",
              "3   1496922333512351744  2022-02-24T18:57:50.000Z  @askanyone   \n",
              "4   1495551477057732609  2022-02-21T00:10:32.000Z  @askanyone   \n",
              "5   1495380686009733128  2022-02-20T12:51:53.000Z  @askanyone   \n",
              "6   1493237197109145606  2022-02-14T14:54:25.000Z  @askanyone   \n",
              "7   1490821936070348801  2022-02-07T22:57:02.000Z  @askanyone   \n",
              "8   1489834957115731969  2022-02-05T05:35:08.000Z  @askanyone   \n",
              "9   1486802577522143234  2022-01-27T20:45:32.000Z  @askanyone   \n",
              "10  1485290465842839553  2022-01-23T16:36:57.000Z  @askanyone   \n",
              "11  1482134365542957064  2022-01-14T23:35:44.000Z  @askanyone   \n",
              "12  1482068580917207044  2022-01-14T19:14:19.000Z  @askanyone   \n",
              "13  1481982151235100683  2022-01-14T13:30:53.000Z  @askanyone   \n",
              "14  1481982052178268160  2022-01-14T13:30:29.000Z  @askanyone   \n",
              "15  1481981912818323457  2022-01-14T13:29:56.000Z  @askanyone   \n",
              "16  1481981764197396486  2022-01-14T13:29:21.000Z  @askanyone   \n",
              "17  1481437203049943040  2022-01-13T01:25:27.000Z  @askanyone   \n",
              "18  1478588093829685249  2022-01-05T04:44:07.000Z  @askanyone   \n",
              "19  1478506041738510337  2022-01-04T23:18:04.000Z  @askanyone   \n",
              "20  1478483560604606465  2022-01-04T21:48:44.000Z  @askanyone   \n",
              "21  1478439023681150979  2022-01-04T18:51:45.000Z  @askanyone   \n",
              "22  1478340062047842304  2022-01-04T12:18:31.000Z  @askanyone   \n",
              "23  1478238524730232833  2022-01-04T05:35:03.000Z  @askanyone   \n",
              "24  1476783365604978695  2021-12-31T05:12:46.000Z  @askanyone   \n",
              "25  1476216733677543425  2021-12-29T15:41:10.000Z  @askanyone   \n",
              "26  1475960287756967936  2021-12-28T22:42:09.000Z  @askanyone   \n",
              "27  1475614358097076224  2021-12-27T23:47:33.000Z  @askanyone   \n",
              "28  1474920991952613376  2021-12-26T01:52:21.000Z  @askanyone   \n",
              "29  1474107380220710917  2021-12-23T19:59:21.000Z  @askanyone   \n",
              "30  1473790106247049220  2021-12-22T22:58:37.000Z  @askanyone   \n",
              "31  1473057537155117056  2021-12-20T22:27:39.000Z  @askanyone   \n",
              "32  1471145463663542288  2021-12-15T15:49:45.000Z  @askanyone   \n",
              "33  1470429739806605320  2021-12-13T16:25:43.000Z  @askanyone   \n",
              "34  1470302901163675649  2021-12-13T08:01:43.000Z  @askanyone   \n",
              "35  1470070654330413056  2021-12-12T16:38:51.000Z  @askanyone   \n",
              "36  1470056387736743942  2021-12-12T15:42:09.000Z  @askanyone   \n",
              "37  1467957746947481608  2021-12-06T20:42:54.000Z  @askanyone   \n",
              "38  1466904422672388101  2021-12-03T22:57:22.000Z  @askanyone   \n",
              "40  1464373159587725314  2021-11-26T23:19:02.000Z  @askanyone   \n",
              "41  1463716137317941253  2021-11-25T03:48:16.000Z  @askanyone   \n",
              "42  1462620496986624003  2021-11-22T03:14:35.000Z  @askanyone   \n",
              "\n",
              "    tweet_device_code  username_code  \n",
              "0                   8              1  \n",
              "1                   8              1  \n",
              "2                   8              1  \n",
              "3                   4              1  \n",
              "4                   8              1  \n",
              "5                   8              1  \n",
              "6                   8              1  \n",
              "7                   8              1  \n",
              "8                   8              1  \n",
              "9                   8              1  \n",
              "10                  8              1  \n",
              "11                  8              1  \n",
              "12                  8              1  \n",
              "13                  8              1  \n",
              "14                  8              1  \n",
              "15                  8              1  \n",
              "16                  8              1  \n",
              "17                  8              1  \n",
              "18                  8              1  \n",
              "19                  8              1  \n",
              "20                  8              1  \n",
              "21                  8              1  \n",
              "22                  4              1  \n",
              "23                  4              1  \n",
              "24                  8              1  \n",
              "25                  4              1  \n",
              "26                  4              1  \n",
              "27                  8              1  \n",
              "28                  8              1  \n",
              "29                  8              1  \n",
              "30                  4              1  \n",
              "31                  8              1  \n",
              "32                  8              1  \n",
              "33                  8              1  \n",
              "34                  8              1  \n",
              "35                  8              1  \n",
              "36                  8              1  \n",
              "37                  4              1  \n",
              "38                  8              1  \n",
              "40                  8              1  \n",
              "41                  4              1  \n",
              "42                  8              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84164500-4624-4b21-a2ae-d876aaa98d0f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>tweet_device</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_time</th>\n",
              "      <th>username</th>\n",
              "      <th>tweet_device_code</th>\n",
              "      <th>username_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>FYI for other authorsthis raised $, which is a...</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>2022-03-01T14:51:09.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Twenty years from now, this is gonna read like...</td>\n",
              "      <td>1498655705351479296</td>\n",
              "      <td>2022-03-01T13:45:38.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27699224</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If you donate $ or more to @WCKitchen and DM m...</td>\n",
              "      <td>1498048242336120832</td>\n",
              "      <td>2022-02-27T21:31:48.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Our long international nightmare is just begin...</td>\n",
              "      <td>1496922333512351744</td>\n",
              "      <td>2022-02-24T18:57:50.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Nostalgia.</td>\n",
              "      <td>1495551477057732609</td>\n",
              "      <td>2022-02-21T00:10:32.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I dont know whats worth bragging about here, b...</td>\n",
              "      <td>1495380686009733128</td>\n",
              "      <td>2022-02-20T12:51:53.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27699224</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Congratulations to @xlorentzen and the cast of...</td>\n",
              "      <td>1493237197109145606</td>\n",
              "      <td>2022-02-14T14:54:25.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I have broken, had surgery on, sprained, broke...</td>\n",
              "      <td>1490821936070348801</td>\n",
              "      <td>2022-02-07T22:57:02.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>27699224</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>152</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>The judgement is deafening.</td>\n",
              "      <td>1489834957115731969</td>\n",
              "      <td>2022-02-05T05:35:08.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If we insist on slicing American generations t...</td>\n",
              "      <td>1486802577522143234</td>\n",
              "      <td>2022-01-27T20:45:32.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>27699224</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Thank you to @TandCmag for this delightfully d...</td>\n",
              "      <td>1485290465842839553</td>\n",
              "      <td>2022-01-23T16:36:57.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>27699224</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Michael Musto almost mowed me down in the midd...</td>\n",
              "      <td>1482134365542957064</td>\n",
              "      <td>2022-01-14T23:35:44.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I am currently reading Lost &amp;amp; Found by Kat...</td>\n",
              "      <td>1482068580917207044</td>\n",
              "      <td>2022-01-14T19:14:19.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>RIP Terry, you will be truly missed.</td>\n",
              "      <td>1481982151235100683</td>\n",
              "      <td>2022-01-14T13:30:53.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>He taught me how to play Go, introduced me to ...</td>\n",
              "      <td>1481982052178268160</td>\n",
              "      <td>2022-01-14T13:30:29.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>we wound up talking, mostly about Mencken, for...</td>\n",
              "      <td>1481981912818323457</td>\n",
              "      <td>2022-01-14T13:29:56.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>This is deeply sad. A quick story about Terry:...</td>\n",
              "      <td>1481981764197396486</td>\n",
              "      <td>2022-01-14T13:29:21.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>164</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I dont care if Im engaged or married or have t...</td>\n",
              "      <td>1481437203049943040</td>\n",
              "      <td>2022-01-13T01:25:27.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Consider it, sure, but dont do anything rash.</td>\n",
              "      <td>1478588093829685249</td>\n",
              "      <td>2022-01-05T04:44:07.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>27699224</td>\n",
              "      <td>146</td>\n",
              "      <td>13</td>\n",
              "      <td>1160</td>\n",
              "      <td>7</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I'd like the pie heated and I don't want the i...</td>\n",
              "      <td>1478506041738510337</td>\n",
              "      <td>2022-01-04T23:18:04.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>&amp;amp;</td>\n",
              "      <td>1478483560604606465</td>\n",
              "      <td>2022-01-04T21:48:44.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>And I *only* read with a Doberman present! Fee...</td>\n",
              "      <td>1478439023681150979</td>\n",
              "      <td>2022-01-04T18:51:45.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Are you living in a steam-heated New York apar...</td>\n",
              "      <td>1478340062047842304</td>\n",
              "      <td>2022-01-04T12:18:31.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>I have started Yellowjackets and I notice it's...</td>\n",
              "      <td>1478238524730232833</td>\n",
              "      <td>2022-01-04T05:35:03.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>27699224</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>73</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>This , learn to ask for the things you want:</td>\n",
              "      <td>1476783365604978695</td>\n",
              "      <td>2021-12-31T05:12:46.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>27699224</td>\n",
              "      <td>69</td>\n",
              "      <td>11</td>\n",
              "      <td>980</td>\n",
              "      <td>4</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Whenever you feel like the equilibrium of the ...</td>\n",
              "      <td>1476216733677543425</td>\n",
              "      <td>2021-12-29T15:41:10.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>27699224</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>My New Year's resolution is to use paper, not ...</td>\n",
              "      <td>1475960287756967936</td>\n",
              "      <td>2021-12-28T22:42:09.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>71</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Everyday at PM, my hard-of-hearing downstairs ...</td>\n",
              "      <td>1475614358097076224</td>\n",
              "      <td>2021-12-27T23:47:33.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>My mother drew this, needle pointed it, signed...</td>\n",
              "      <td>1474920991952613376</td>\n",
              "      <td>2021-12-26T01:52:21.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>27699224</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>She couldnt operate an air conditioning unit t...</td>\n",
              "      <td>1474107380220710917</td>\n",
              "      <td>2021-12-23T19:59:21.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>27699224</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>77</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>The formula for cold fusion, where David Bowie...</td>\n",
              "      <td>1473790106247049220</td>\n",
              "      <td>2021-12-22T22:58:37.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>My new favorite genre of social media post is ...</td>\n",
              "      <td>1473057537155117056</td>\n",
              "      <td>2021-12-20T22:27:39.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Who will aquire my anthology titled Over The P...</td>\n",
              "      <td>1471145463663542288</td>\n",
              "      <td>2021-12-15T15:49:45.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I was just feeling in love with love last nigh...</td>\n",
              "      <td>1470429739806605320</td>\n",
              "      <td>2021-12-13T16:25:43.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>27699224</td>\n",
              "      <td>55</td>\n",
              "      <td>5</td>\n",
              "      <td>967</td>\n",
              "      <td>6</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If you cant sleep on a Sunday night, you shoul...</td>\n",
              "      <td>1470302901163675649</td>\n",
              "      <td>2021-12-13T08:01:43.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>27699224</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>156</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I *tore* through the vampire chronicles when I...</td>\n",
              "      <td>1470070654330413056</td>\n",
              "      <td>2021-12-12T16:38:51.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>27699224</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Lotta enlightenment to be found in how the Jap...</td>\n",
              "      <td>1470056387736743942</td>\n",
              "      <td>2021-12-12T15:42:09.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>27699224</td>\n",
              "      <td>16</td>\n",
              "      <td>9</td>\n",
              "      <td>344</td>\n",
              "      <td>2</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>I am proud to share this news from @fsgbooks &amp;...</td>\n",
              "      <td>1467957746947481608</td>\n",
              "      <td>2021-12-06T20:42:54.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I dont identify as JAPy, she said, blasting dr...</td>\n",
              "      <td>1466904422672388101</td>\n",
              "      <td>2021-12-03T22:57:22.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>27699224</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>224</td>\n",
              "      <td>2</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>There is a line around the block for Maries Cr...</td>\n",
              "      <td>1464373159587725314</td>\n",
              "      <td>2021-11-26T23:19:02.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>135</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>I would be very interested in a least watched,...</td>\n",
              "      <td>1463716137317941253</td>\n",
              "      <td>2021-11-25T03:48:16.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>27699224</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>I get all my automated email replies from Eyes...</td>\n",
              "      <td>1462620496986624003</td>\n",
              "      <td>2021-11-22T03:14:35.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84164500-4624-4b21-a2ae-d876aaa98d0f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84164500-4624-4b21-a2ae-d876aaa98d0f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84164500-4624-4b21-a2ae-d876aaa98d0f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# REMOVE EMPTY TWEETS\n",
        "df2 = df[df['tweet'].str.len()>0]\n",
        "print(\"Cleaned dataset size: {0}\",df2.shape[0])\n",
        "print(df2.shape)\n",
        "df2.head(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4l60cK71THP"
      },
      "source": [
        "## DESCRIPTIVE DATA ANALYSIS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vz52-xwq18iV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "02b0409f-c4c7-41b6-f756-99b6752291fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            user_id  retweet_count   reply_count     like_count   quote_count  \\\n",
              "count  4.401000e+03    4401.000000   4401.000000    4401.000000   4401.000000   \n",
              "mean   1.062827e+08     487.416042     38.482618    1906.300386     38.383549   \n",
              "std    1.572219e+08    3329.984820    268.416740   12878.056611    297.275943   \n",
              "min    5.520952e+06       0.000000      0.000000       0.000000      0.000000   \n",
              "25%    1.779067e+07       2.000000      2.000000      39.000000      0.000000   \n",
              "50%    2.769922e+07       9.000000      6.000000      94.000000      0.000000   \n",
              "75%    8.387653e+07      42.000000     19.000000     371.000000      3.000000   \n",
              "max    4.260447e+08  101649.000000  12418.000000  548082.000000  10586.000000   \n",
              "\n",
              "           tweet_id  tweet_device_code  username_code  \n",
              "count  4.401000e+03        4401.000000    4401.000000  \n",
              "mean   1.189038e+18           5.497160       2.375369  \n",
              "std    3.282205e+17           2.250162       1.724416  \n",
              "min    4.767467e+17           0.000000       0.000000  \n",
              "25%    1.122850e+18           4.000000       1.000000  \n",
              "50%    1.308830e+18           5.000000       2.000000  \n",
              "75%    1.418273e+18           8.000000       4.000000  \n",
              "max    1.499168e+18           9.000000       5.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b55689a5-35ba-4bc5-a0c6-4650378f74f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_device_code</th>\n",
              "      <th>username_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.401000e+03</td>\n",
              "      <td>4401.000000</td>\n",
              "      <td>4401.000000</td>\n",
              "      <td>4401.000000</td>\n",
              "      <td>4401.000000</td>\n",
              "      <td>4.401000e+03</td>\n",
              "      <td>4401.000000</td>\n",
              "      <td>4401.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.062827e+08</td>\n",
              "      <td>487.416042</td>\n",
              "      <td>38.482618</td>\n",
              "      <td>1906.300386</td>\n",
              "      <td>38.383549</td>\n",
              "      <td>1.189038e+18</td>\n",
              "      <td>5.497160</td>\n",
              "      <td>2.375369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.572219e+08</td>\n",
              "      <td>3329.984820</td>\n",
              "      <td>268.416740</td>\n",
              "      <td>12878.056611</td>\n",
              "      <td>297.275943</td>\n",
              "      <td>3.282205e+17</td>\n",
              "      <td>2.250162</td>\n",
              "      <td>1.724416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.520952e+06</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.767467e+17</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.779067e+07</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.122850e+18</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.769922e+07</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.308830e+18</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.387653e+07</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>371.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.418273e+18</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.260447e+08</td>\n",
              "      <td>101649.000000</td>\n",
              "      <td>12418.000000</td>\n",
              "      <td>548082.000000</td>\n",
              "      <td>10586.000000</td>\n",
              "      <td>1.499168e+18</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b55689a5-35ba-4bc5-a0c6-4650378f74f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b55689a5-35ba-4bc5-a0c6-4650378f74f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b55689a5-35ba-4bc5-a0c6-4650378f74f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "oLWf4xZl44Ua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "937194f9-3a9f-4ad6-9a06-b36c3ef01651"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              retweet_count                                 reply_count      \\\n",
              "                      count min     max median          std       count min   \n",
              "username                                                                      \n",
              "@Shteyngart             840   0   10800    5.0   373.806324         840   0   \n",
              "@askanyone              761   0    1452    3.0    60.901864         761   0   \n",
              "@harlancoben            754   0  101649   13.0  3707.241653         754   0   \n",
              "@megcabot               697   0    1906    2.0   101.307085         697   0   \n",
              "@paulocoelho            651   5   90466  374.0  7191.707764         651   0   \n",
              "@tejucole               698   0    1526   30.0   113.402553         698   0   \n",
              "\n",
              "                                        like_count                      \\\n",
              "                 max median         std      count min     max  median   \n",
              "username                                                                 \n",
              "@Shteyngart     1000    7.0   37.155850        840   4   76026    81.0   \n",
              "@askanyone       128    2.0    8.067927        761   0   10062    66.0   \n",
              "@harlancoben    1821   18.5   93.360633        754   5  548082   353.0   \n",
              "@megcabot        119    1.0    8.420293        697   1   14197    49.0   \n",
              "@paulocoelho   12418   63.0  669.215480        651  71  261561  2829.0   \n",
              "@tejucole        103    5.0    8.465871        698   0    1294    39.0   \n",
              "\n",
              "                            quote_count                                \n",
              "                        std       count min    max median         std  \n",
              "username                                                               \n",
              "@Shteyngart     2636.328065         840   0    618    1.0   21.671458  \n",
              "@askanyone       573.915931         761   0    452    0.0   18.233827  \n",
              "@harlancoben   19960.701893         754   0   6537    2.0  240.334512  \n",
              "@megcabot        739.786860         697   0    345    0.0   22.211201  \n",
              "@paulocoelho   23654.010421         651   0  10586   39.0  696.641256  \n",
              "@tejucole         95.545226         698   0    104    0.0    3.988841  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e310b585-d57e-43fa-9c97-ac9c73e21840\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"5\" halign=\"left\">retweet_count</th>\n",
              "      <th colspan=\"5\" halign=\"left\">reply_count</th>\n",
              "      <th colspan=\"5\" halign=\"left\">like_count</th>\n",
              "      <th colspan=\"5\" halign=\"left\">quote_count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>median</th>\n",
              "      <th>std</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>median</th>\n",
              "      <th>std</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>median</th>\n",
              "      <th>std</th>\n",
              "      <th>count</th>\n",
              "      <th>min</th>\n",
              "      <th>max</th>\n",
              "      <th>median</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>username</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>@Shteyngart</th>\n",
              "      <td>840</td>\n",
              "      <td>0</td>\n",
              "      <td>10800</td>\n",
              "      <td>5.0</td>\n",
              "      <td>373.806324</td>\n",
              "      <td>840</td>\n",
              "      <td>0</td>\n",
              "      <td>1000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>37.155850</td>\n",
              "      <td>840</td>\n",
              "      <td>4</td>\n",
              "      <td>76026</td>\n",
              "      <td>81.0</td>\n",
              "      <td>2636.328065</td>\n",
              "      <td>840</td>\n",
              "      <td>0</td>\n",
              "      <td>618</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.671458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@askanyone</th>\n",
              "      <td>761</td>\n",
              "      <td>0</td>\n",
              "      <td>1452</td>\n",
              "      <td>3.0</td>\n",
              "      <td>60.901864</td>\n",
              "      <td>761</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.067927</td>\n",
              "      <td>761</td>\n",
              "      <td>0</td>\n",
              "      <td>10062</td>\n",
              "      <td>66.0</td>\n",
              "      <td>573.915931</td>\n",
              "      <td>761</td>\n",
              "      <td>0</td>\n",
              "      <td>452</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.233827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@harlancoben</th>\n",
              "      <td>754</td>\n",
              "      <td>0</td>\n",
              "      <td>101649</td>\n",
              "      <td>13.0</td>\n",
              "      <td>3707.241653</td>\n",
              "      <td>754</td>\n",
              "      <td>0</td>\n",
              "      <td>1821</td>\n",
              "      <td>18.5</td>\n",
              "      <td>93.360633</td>\n",
              "      <td>754</td>\n",
              "      <td>5</td>\n",
              "      <td>548082</td>\n",
              "      <td>353.0</td>\n",
              "      <td>19960.701893</td>\n",
              "      <td>754</td>\n",
              "      <td>0</td>\n",
              "      <td>6537</td>\n",
              "      <td>2.0</td>\n",
              "      <td>240.334512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@megcabot</th>\n",
              "      <td>697</td>\n",
              "      <td>0</td>\n",
              "      <td>1906</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.307085</td>\n",
              "      <td>697</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.420293</td>\n",
              "      <td>697</td>\n",
              "      <td>1</td>\n",
              "      <td>14197</td>\n",
              "      <td>49.0</td>\n",
              "      <td>739.786860</td>\n",
              "      <td>697</td>\n",
              "      <td>0</td>\n",
              "      <td>345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.211201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@paulocoelho</th>\n",
              "      <td>651</td>\n",
              "      <td>5</td>\n",
              "      <td>90466</td>\n",
              "      <td>374.0</td>\n",
              "      <td>7191.707764</td>\n",
              "      <td>651</td>\n",
              "      <td>0</td>\n",
              "      <td>12418</td>\n",
              "      <td>63.0</td>\n",
              "      <td>669.215480</td>\n",
              "      <td>651</td>\n",
              "      <td>71</td>\n",
              "      <td>261561</td>\n",
              "      <td>2829.0</td>\n",
              "      <td>23654.010421</td>\n",
              "      <td>651</td>\n",
              "      <td>0</td>\n",
              "      <td>10586</td>\n",
              "      <td>39.0</td>\n",
              "      <td>696.641256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>@tejucole</th>\n",
              "      <td>698</td>\n",
              "      <td>0</td>\n",
              "      <td>1526</td>\n",
              "      <td>30.0</td>\n",
              "      <td>113.402553</td>\n",
              "      <td>698</td>\n",
              "      <td>0</td>\n",
              "      <td>103</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.465871</td>\n",
              "      <td>698</td>\n",
              "      <td>0</td>\n",
              "      <td>1294</td>\n",
              "      <td>39.0</td>\n",
              "      <td>95.545226</td>\n",
              "      <td>698</td>\n",
              "      <td>0</td>\n",
              "      <td>104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.988841</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e310b585-d57e-43fa-9c97-ac9c73e21840')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e310b585-d57e-43fa-9c97-ac9c73e21840 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e310b585-d57e-43fa-9c97-ac9c73e21840');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df2.groupby(\"username\").agg({\n",
        "    \"retweet_count\": ['count','min', 'max', 'median', 'std'],\n",
        "    \"reply_count\": ['count','min', 'max', 'median', 'std'],\n",
        "    \"like_count\": ['count','min', 'max', 'median', 'std'],\n",
        "    \"quote_count\": ['count','min', 'max', 'median', 'std']\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tEdS_0Ag2QWG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "b07ecb41-e0aa-4062-d40b-c0e78fab3753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'@Shteyngart': 840, '@harlancoben ': 754, '@askanyone': 761, '@megcabot': 697, '@paulocoelho': 651, '@tejucole': 698}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# DISPLAY TOTAL NUMBER OF TWEETS PER AUTHOR\n",
        "data_dict =  {}\n",
        "for id, username in authors.items():\n",
        "  data_dict[username]=df2[df2.user_id==id]['tweet'].count()\n",
        "\n",
        "print(data_dict)\n",
        "x = list(data_dict.keys())\n",
        "y = list(data_dict.values())\n",
        "  \n",
        "fig = plt.figure(figsize = (10, 5))\n",
        " \n",
        "# # creating the bar plot\n",
        "plt.bar(x, y, color ='blue', width = 0.4)\n",
        " \n",
        "plt.xlabel(\"Authors\")\n",
        "plt.ylabel(\"No. of tweets\")\n",
        "plt.title(\"Number of tweets per author\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8Xkl2QpV2xOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9b7ff73e-60cf-4c33-f9e2-2efd01310c4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAQwCAYAAAATlK4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd1gU5/YH8O/ssoUOijSpggWJXbGLoLHGXDWJSSw/Ta4m5iY3mmrUGNNtyU3UxBSNRo0l5hqNiVeNvaOAICKCgBRFepO+7M75/UGYsNIVWMr5PA8P7DvtzGw7nJl5X4GICIwxxhhjjDHGGGPNmMzQATDGGGOMMcYYY4zVhgsYjDHGGGOMMcYYa/a4gMEYY4wxxhhjjLFmjwsYjDHGGGOMMcYYa/a4gMEYY4wxxhhjjLFmjwsYjDHGGGOMMcYYa/a4gMHqJD4+HoIg4Ny5c4YORc+9e/cwZcoUWFpaQhAExMfHGzqkJnHq1CkIgoA7d+4YOpR6mTNnDkaPHm3oMFg9jBw5EnPnzm3Qdf74448wMjJq0HUyxponzh+al+aYPzTG90xFbm5u+Pjjjxtt/Q+Kvwur9v7778PT07NB19lcP4fYg+ECRgswZ84cCIKAt99+W6/9zp07EAQBp06dMkxgzcA333yDixcv4ty5c0hOToazs3Olec6dO9dskpOW9Jzdu3cPa9aswfDhw+Hg4AB7e3sMGTIEq1atQl5eXqX5i4qKsGzZMnTu3BnGxsZo164dBgwYgHXr1tVrux9//DHc3NwaaC+an7lz52LkyJGGDsOgnn76aSQlJRk6DMZaPc4fqsf5Q+Opb/7AWGNzdnZGcnIyBg4caOhQWAPgAkYLoVarsW7dOiQkJBg6lAZXWlr6wMtGR0fD29sbPXr0gL29PeRyeQNG1nadOXMGXbt2xcGDBzF37lzs378ff/75JxYuXIjz58/Dy8sLV65c0VvmpZdewrZt27BmzRpERETg5MmTePnll5GTk2OgvWheRFGETqczdBjNIg5jY2PY2dkZNAbG2grOH6rG+UPjeJD8obFoNJom2Q6r3cO8VxuCXC6Hvb09FAqFQeNgDYRYszd79mzy9/cnHx8fmj59utR++/ZtAkAnT54kIqK4uDgCQGfPntVb3sPDg5YvXy49BkDr1q2jadOmkYmJCTk7O9Mvv/xCOTk5NH36dDIzMyN3d3f673//Ky1Tvu7t27eTv78/qdVqcnd3p127dultKyUlhWbPnk02NjZkZmZGQ4YModOnT0vTT548SQDojz/+oKFDh5JKpaINGzZUud8ajYYWLVpEjo6OpFAoyMvLi3bs2CFNd3V1JQDSj6+vb6V1lMd9/3wxMTEEgG7evKm3vo4dO0qPb968SQAoMjJSimf58uXk5uZGKpWKunfvTt9++63e9vLy8ujVV18lR0dHMjY2pt69e9PevXv1jn3FH1dXVyIqey6nTp1K7du3J5VKRe7u7rR69eoqj0vF43jgwAEaMGAAqVQq8vb2puPHjxMRkSiK5O7uTp988onecvn5+WRubk7btm2rdt1Xr16ldu3aVXpuK9qzZw/Z29tTQkKC1GZpaUnr16+vdhmistfyqFGj6LvvviMXFxcyNzenSZMmUUpKChERbdmypdIxKn/t1nb8Z8+eTY8++milbfr5+dHzzz9PRETLly8nDw8P2r9/P3Xt2pVMTEzI19dX73VARLRz507q1KkTqVQqGjx4MP3+++967y1RFGnu3LnUqVMn6b2wePFiKi4ultZRvq3du3dT165dSS6X07Rp0yrt35YtW6o8Vlu2bCG5XE5Hjx6l7t27k0qlIh8fHwoJCdGbLygoiB599FEyNTUlGxsbmjJlCsXHx9cYR0RERJXbjI+Pp7Fjx5JarSYnJydat24d+fr60j//+U9pntqeh+nTp1f5PIwbN45mzJiht2/378fYsWPJ3NycTE1NacCAARQQECBN//PPP2nIkCGkVqvJ0dGR5syZQxkZGVXuB2OsDOcPnD/crznmD+XfMx9++CHZ2dmRtbU1zZo1i/Ly8qR5goODady4cdShQwcyNTWl/v3706FDh/TW7erqSkuXLqWXXnqJ2rVrRz4+PlL7Rx99JM23Y8cO8vHxIQsLC2rfvj1NmDCBoqKipOnlz/3PP/9MEydOJGNjY3J3d6/0fZ2Xl0cLFiwgJycnUiqV5OrqqnfcIiMjacKECWRqakqmpqb02GOPUXR0tDS9ob/na8ttamOI92pRURHNnz+fLCwsyMrKiubPn0/vvPMOeXh46M23a9cu6tWrF6lUKnJ1daXXXnuN8vPziYjo+++/JwsLCyoqKtJbZuXKleTs7Ew6na7Kz7jU1FSaM2cO2drakkqloi5dutAPP/wgTY+OjqapU6eSpaUlWVlZ0aOPPkphYWH1OqascXABowUo/6fvzJkzJAgCBQYGEtHDJSB2dnb0448/UnR0NL300kukVqtp3LhxtGXLFoqOjqZXXnmFTExMpH8Qytft4OBAP/30E0VGRtLSpUtJJpPRlStXiIiosLCQvLy8aOrUqRQYGEjR0dH08ccfk1KplP5hKv9Q69q1Kx04cIBu3bpFt2/frnK/33zzTWrXrh3t2bOHoqKi6JNPPiFBEOjYsWNERJSWlkbTpk2j4cOHU3JyMmVmZlZah1arpd9++40A0OXLl/Xmc3FxkRKImJgYUqvVZGZmJn2Jffvtt3oJyezZs6lHjx505MgRunXrFu3evZssLS1p06ZNRFT2pT9y5Ejy9fWls2fPUmxsLH333XekUCikmK9cuUIAaO/evZScnExpaWlERDRp0iQaNWoUhYSEUFxcHJ04cYJ27txZ7Wui/Dh6enrS77//ThEREfT888+TiYkJ3b17l4iIPv30U+rUqROJoigtt2nTJrK2tq70IV/R8OHDae3atURU9uH+1FNPkZ2dHfXr14+2bt1K3bt3JyKixYsXS4UBIqJu3brRxIkTq3weKh5DCwsLeuaZZ+jatWt04cIFcnNzo5kzZxJR2Wto0aJF5OTkRMnJyZScnCwlMLUd/wsXLpAgCHTr1i1pe9HR0SQIgvSP8PLly8nExITGjh1LQUFBFBoaSn379qVhw4ZJywQFBZEgCLR06VKKjIykffv2kYeHh957S6fT0ZIlSyggIIDi4uLot99+I3t7e3rvvfek9SxfvpyMjY1pxIgRFBAQQFFRUXTv3j2aPn06DR48WNq/wsLCKo/Vli1bSBAE6tOnD506dYquXr1KEydOJEdHR2mZ69evk6mpKb333nt048YNCgsLoyeffJI6d+4sPcfVxXE/URSpT58+1L9/fwoICKCQkBAaPXo0mZub6xUwansejhw5QjKZjJKSkqRl7t69S3K5nI4cOSLtW8UCRnh4OJmYmNAzzzxDgYGBdPPmTdq5cydduHCBiIiOHz9OxsbGtG7dOrp58yZdvnyZRo4cSSNGjNB7fTPG9HH+wPnD/Zpj/uDr60uWlpa0cOFCunHjBh05coSsra3p3Xff1Yt7y5YtFB4eTlFRUbR06VJSKBR6hQdXV1cyNzen5cuXU1RUFF2/fl1qr1jA2Lx5Mx04cIBiYmLoypUrNGnSJPL09KSSkhIi+vs16+7uTj///DNFR0fT4sWLSS6XS9sTRZF8fX3J3d2d9u3bR7GxsXT69Gn6/vvviajsNe3i4kL+/v4UFBREQUFBNHLkSPLw8JC205Df87XlNnVhiPfqwoULqUOHDrR//366ceMGvfHGG2Rubq5XwNiyZQtZWVnRtm3bpOPco0cPKXfMyckhtVpNu3fv1lt39+7dafHixXr7Vv4ZV1hYSN26daM+ffrQ0aNHKTY2lo4cOSIVa1JSUsjOzo7mz59PYWFhFBkZSa+88gq1a9dOeu8xw+ECRgtQnoAQEU2ePFk6U/AwCciCBQukx2lpaQSAXnnlFaktKyuLANDvv/+ut+6KXyZERIMHD5Y+QLZs2UIdO3ak0tJSvXn8/Pyk7ZV/qNVUwSciKigoIKVSSV9//bVe++TJk8nPz6/KY1Ods2fPEgCKi4vTa589ezY99dRTRFRWvfX396fx48fTN998Q0RE06ZNk/bt1q1bJAgC3bhxQ28dH3zwAfXq1UvaN5VKRTk5OXrzPPfcc/SPf/yDiCo/Z+V69uyp9xzVpvw4lic/RESlpaXk4uIiPUcpKSmkUCjo6NGj0jyDBg2iV199tdr1xsbGkp2dHWk0GiIqO2s+duxYunz5Mh0+fJg8PT2lsz4xMTFkb28vLXvu3DlycXEhmUxGPXr0oHnz5tG+ffv0EqDZs2dThw4d9K5UWLlypd56PvroI2kb5epy/ImIevToQUuXLpUev/POO9SzZ0/p8fLly0kul+t9+ezevZsEQZASgenTp1f60v/mm2+qfG9V9J///Ic8PT31tiUIgt5ZJiKif/7zn1We7btf+dUo5ckrUdn70tTUVHreZ8+eTU8//bTecsXFxWRsbEz79u2rMY77HT16lADoJYNpaWmkVqulAkZdngedTkeOjo56ZwDXrFlDHTt2JJ1OJ+1bxQLGzJkzqWfPntL0+/n6+tKiRYv02hISEghApTNVjLG/cf7wN84fSNpWc8sffH199b6riYjmz59PgwYNqnFfevbsSR9//LH02NXVlfz9/SvNd38B436ZmZkEgM6dO0dEf79mP//8c2kerVZLZmZmUuHq2LFjBEAqCt5v06ZNZGxsTOnp6VJbSkoKqdVq2rp1KxE17Pd8bblNXTT1ezU/P59UKpVU9CnXr18/vQKGq6ur9N4qd/r0aQJAWVlZRET09NNP04QJE6TpgYGBeldB3f8Zt2nTJlKpVNUWVpYvX04DBw7UaxNFkTp16kRffPFFjfvFGh93fdvCrFq1Ct7e3jhw4AD69u37wOvp1auX9HeHDh0gl8vRs2dPqc3a2hpKpRJpaWl6yw0ePFjv8dChQ3H8+HEAQGBgIFJSUmBlZaU3T0lJCYyNjfXafHx8aowvJiYGGo0GI0aM0Gv39fXFihUratm7uvHz88Nbb70FIsKJEycwatQoKBQKnDhxAi+++CJOnTqFlStXAgCCgoJAROjfv7/eOrRarXTfbGBgIDQaDTp27Kg3j0ajQefOnWuMZeHChXjxxRdx6NAhjBw5EhMnTqy071Wp+HwYGRnBx8cH169fBwDY2dnhH//4BzZu3IjRo0cjPDwcAQEB2LhxY7Xru3r1KgYMGACFQoHCwkIcOXIEt2/flvbpvffew7JlywAADg4OyMrKkpYdOnQoYmNjcfnyZVy8eBFnzpzBk08+ifHjx+PAgQMQBAEA0K1bN6hUKmk5R0dHpKam1rifdTn+APDiiy/i008/xQcffAAiwo8//oilS5fqLePo6IgOHTroPSYipKWlwcXFBREREZVGSrn/dQ8AGzduxKZNmxAfH4+CggJotVqIoqg3j52dHVxcXGrct9pU3La1tTW8vLyk5zgwMBAxMTEwMzPTW6a4uBjR0dH1iiMiIgI2Njbo0qWL1NahQwd07dpVelyX50Emk2HmzJnYvn073nrrLQDA9u3bMWPGDMhkVXe7FBwcjHHjxlU7PTAwEAEBAfjqq68qTYuOjkbv3r1r3DfGGOcPnD/oa075A6D/ugLKvpuPHDkiPU5PT8fy5ctx4sQJpKSkQKvVori4uFLfLrW9PgAgNDQUH3zwAUJDQ5GRkQEiAgAkJCRg6NCh0nwVv1vkcjlsbW2lfCU4OBjW1taVntdy169fR/fu3WFjYyO12dnZoWvXrtJxLtcQ3/O15Tb10VTv1djYWJSUlGDIkCF67cOGDcMff/wBoOx5T0hIwOuvv44333xTmqf8OYuJicGAAQMwe/ZsPP7440hLS4OtrS22bdsGHx8fvRymouDgYHTv3h1OTk5VTg8MDERwcHCl415UVKR33JlhcAGjhenSpQtefPFFLFq0CIcOHdKbVp78l7+py1XVcU5Vndjc3yYIQqV/yGoiiiK8vLywb9++StNMTEz0HpuamtZ5vY3F398f6enpCAsLw8mTJ7FgwQIoFAqsWbMG165dQ1paGvz9/QFAOg4XLlyotC/l/5iLoghLS0sEBgZW2pZSqawxlueeew7jxo3D4cOHcfLkSYwfPx5TpkzBTz/99FD7OH/+fEyYMAEZGRnYtGkTBg8ejEceeaTa+bVarfQFpNFoQER6z5W5ubn095UrVyoNc2VkZIQhQ4ZgyJAheOONN/DTTz9h1qxZOHPmDHx9fQFUPhaCIFR6zd6vLscfAGbNmoVFixbh4MGDEEURubm5mDlzpt78VW2/4jbuX2dVfvnlF7z88stYuXIlfH19YWFhgV9++aVSsaSxX+eiKGLWrFl45513Kk1r3759g8dR1+fh//7v/7B69WqEhoYCAMLCwrBr166H2u6iRYswa9asStPs7e0feL2MtSWcPzQczh8qe9j8oarv5oqvoTlz5iAxMRGrV6+Gu7s7jI2N8cwzz1TqqLO210dhYSHGjBmDYcOGYcuWLVKH0t7e3pXWVVtMTaGu3/N1yW0aKp6mfK+Wx7927Vr4+flVml5egBgzZgxsbGywc+dOvPzyy9i9ezfef//9h9ruqFGjqjxxYmlp+cDrZQ2DCxgt0PLly7F9+3Z8//33eu3llde7d+9KbWlpaQ06XGFAQAAmTJggPb5w4QK6d+8OAOjfvz+2bdsGCwsL2NraPtR2PD09oVKpcObMGb0vzNOnT9f4BVqV8g/1+0decHZ2hoeHB9avX4+ioiIMGDAAgiBAq9Vi7dq16NSpE1xdXQEA/fr1AwAkJibiscceq3I7/fv3R05ODoqLi6uNsbpYgLIzEs899xyee+45TJgwAc8++yw2bNgACwuLavctICBAOv5arRaXL1/W+yfP398fLi4u+O6777B9+3Z89tln1a4LKDvu5f90WllZoVevXli+fLk09Nnnn38OoOzMwksvvSSdYa+Ol5cXAFQ6E1cTpVJZ6fjU5fgDgIWFBZ555hls3LgRoijiqaeeqnSWoDbdu3fHxYsX9doCAgL0Hp85cwZ9+vTB66+/LrXVdZi9qvavJgEBAVIinJOTgxs3buDFF18EUPaaCwsLg4eHR61Fl9p0794dGRkZiI6Ols74ZWRkICoqSjrDVNfnwdvbG/369cP27dtBROjXr5/0Oq1Kv379cPz4cYiiWOVVGP3798f169cbfFx4xtoazh84fyjX3POH+505cwarV6/G448/DgAoKCjArVu36v2c3rhxA+np6fjkk0+kHOXChQu1nki5X79+/ZCdnY2goKAqr8Lw9vbGt99+i4yMDOkqjNTUVERFReGNN97Qm7epvufrqqneqx4eHlAqlbhw4QK8vb2l9vPnz0t/29nZwdnZGVFRUZg3b16165LL5ZgxYwa2b9+OTp06ITc3F88880y18/fr1w+bN2/GnTt3qrwKo3///vjxxx/h5OQEtVr9gHvIGk1T37PC6q+q+zQ//fRTMjY2rnQ/5NChQ6lv374UGhoq9epvYmJS6R7W7du3661PLpdX6l1ZpVLRxo0biejve8ccHR1px44dFBUVRcuWLSNBECg4OJiIynoS9vb2pv79+9ORI0coLi6OAgIC6NNPP5Xu0yu/L666e84qeuutt2rshKu6Y3O/lJQUkslktG7dOkpNTdW7x3TevHlkZGREjz32mNQ2efJkMjIyorlz5+qt5/nnnyd7e3vatm0bRUdHU2hoKP3www+0cuVKIiq7N2706NHUuXNnqUOnoKAgWrdunXR/n06nIzMzM3r77bcpOTlZunfv5ZdfpoMHD1JMTAyFh4fTU089Rc7OztV2UFh+HDt37kwHDx6kiIgImjt3LhkbG+t1nkhEtHr1alIqlWRpaUkFBQU1HitRFMnT05P++OMPIiIKCQkhDw8PkslkZGZmRkuXLiUA5OTkRN99953esiNGjKBvvvmGAgMDKT4+no4dO0Y+Pj5kZWUl3QNa1fO1fft2qvhRtGfPHjIyMqILFy5Qenq6FHNtx7/c5cuXSS6Xk1wul+5nLVfeU3dF99/jXN6J57JlyygqKop+++036ty5s979sevXrydjY2Pav38/xcTE0Jdffknt27fX24+qtlX+fNjY2FB4eDilp6fr9QdSUXnnXv369aPTp09TWFgYTZo0iezt7aVjEhERQWZmZjR9+nS6dOkS3bp1i06cOEGvvvoqxcbG1hjH/URRpF69epGPjw9dunSJQkJCaMyYMZU68azr87B27Vqyt7cne3t7WrduXaV9q9gHRlhYGBkbG0udeMbExNCePXukTjxPnDhBRkZG9Nprr1FISAjFxMTQoUOH6Pnnn6+2E1TGGOcPnD9U1hzzh/tHuyKq3B9Wv379aOjQoRQWFkYhISE0adIksrCwoNmzZ0vzVNfXRcX29PR0UqlU9NJLL1FMTAwdO3aM+vfvT4IgSK/juvQJI4oiDR8+nDp16kT79++nW7du0blz56TXfcVOPIODg2vsxLMxvuer67+lJoZ4r7766qtka2tLv/32G0VGRtJbb71VqRPPbdu2kUKhoI8//piuXbsmdbD+wgsv6K3r6tWrBIB69+5NU6dOrXLfyp/TgoIC6tKli9SJ561bt+jYsWNSR6ApKSnk4OBAY8aMoTNnzlBcXBydPXuWlixZQufPn6/zMWWNgwsYLUBVX7JFRUXk7OxcKQGJioqiESNGkImJCXl6etLevXur7ITrQROQbdu2ka+vL6lUKnJzc9MbloyIKCMjg+bPny8NXebo6EiTJ0+Wei+uz4dabcOgVXdsqrJq1SpydHQkmUym14Hizp07CQD95z//kdrWrVtHACr14q3VamnVqlXUtWtXUigU1L59exoxYgTt2bNHmqd8FA03NzdSKBRkZ2dHY8eOlYYnIyLaunUrubm5kVwul76c//Wvf1Hnzp1JrVZTu3btaMKECRQeHl7t/pQfx99++4369u1LSqWSvLy86M8//6w0b3p6OikUCvrXv/5V63EiIjpw4ADZ2trqbf/u3btUVFREpaWl0pCn91uxYgUNGzaMOnToQCqVipydnWnGjBlSL+BEdStgaDQaevbZZ8na2lpvGNW6HP9yvXv3lno7r6iuX/Llw6gqlUoaNGgQ/fzzzwSAgoKCpBhfeOEFsra2JnNzc3r22Wdp/fr1dSpgZGZm0vjx48nCwqJOw6geOXKEunXrRkqlkgYMGCAlEeXCwsLo8ccfJysrK1Kr1eTh4UHz5s2TesuvawGDqOx9/uijj5JKpaKOHTvSl19+WSmxrOvzUP66UygUep2YVdy3ii5dukSjRo0iExMTMjMzo4EDB9KlS5ek6WfOnKFRo0aRmZkZmZiYULdu3WjBggWVOhJjjP2N8wfOH+7XHPOHuhQwwsLCaPDgwaRWq8nV1ZW+/vprGjVqVL0LGEREv/zyC3l6epJKpaLevXvTqVOn9F7Hde3U9t69e/TKK6+Qvb09KRQKcnNzoxUrVkjTIyMjafz48dIwqhMnTqxyGNXG+J5/mAJGU75XCwsL6YUXXiALCwuysLCgefPmVTmM6r59+2jQoEFkbGxM5ubm1KtXL/rggw8qra93794EgPbv31/lvlV8TpOTk2nWrFnSEMRdu3bV+yyLj4+n6dOnk42NDSmVSnJxcaEZM2bojXbHDEMgquc1U4yxFuX69et45JFHEBoaWqmTrOp88803WLx4MRYsWIAZM2ZItxRERETg66+/RkZGBvbs2dOYYT+w0tJSuLm54e2338aCBQsaZJ3btm3Dc889h8zMzHrfkvKgfvzxR8ydOxdarbZJtscYY4xV1Nbyh7YuPj4e7u7uOHv2LIYNG2bocBirVtVdvjPGWrySkhIkJSVh8eLF8PPzq3PyAQAvvfQSTp48ifDwcPTt2xcKhQIKhQL+/v5QKpVVdmpkaKIoIi0tDStXrkRBQQGee+65B17XZ599huDgYMTFxWHPnj1YtGjRA/WnwRhjjLU0bS1/YIy1LNyJJ2Ot1K5du/D888/D29sb//3vf+u9fJ8+fbB3715otVqkp6dDEATY2dk1WSdS9ZWYmAh3d3c4ODhg8+bNNXZeVpuwsDB8/vnnyMrKgrOzM2bOnIkPPvigAaNljDHGmqe2lj8wxloWvoWEMcYYY4wxxhhjzR7fQsIYY4wxxhhjjLFmjwsYjDHGGGOMMcYYa/a4gMEYY4wxxhhjjLFmjwsYjDHGGGOMMcYYa/a4gMEYY4wxxhhjjLFmjwsYjDHGGGOMMcYYa/aM6rsAESE9PR2lpaWNEQ9rxhQKBTp06MDjeDPGGGtQnFu0XZxbMMYYqw+BiKg+C6SlpUGr1UKhUDRWTKyZKi0thZGREWxtbQ0dCmOMsVaEc4u2i3MLxhhj9VHvW0hKS0s5wWijFAoFnx1jjDHW4Di3aLs4t2CMMVYf3AcGY4wxxhhjjDHGmj0uYDDGGGOMMcYYY6zZq3cnnvcrnjO+IeKQqH88VOs89vb28PLyAhFBLpdjxYoV8PHxQUpKCpYsWYLNmzfj2rVrSE1NxejRowEAu3fvRmhoKFauXNmg8TLGGGOsYXFuwRhjjLGqtMgrMNRqNU6ePIlTp05h6dKl+OSTTwCUJR+bN28GAFy/fh3Hjh0zZJiMMcYYayE4t2CMMcaavxZZwKgoPz8flpaWAIDExESMGDECGo0Gq1atwm+//QY/Pz/s379fb/7+/ftLHUbl5eXpPWaMMcZY28a5BWOMMdY8PfQtJIZQXFwMPz8/lJSUIDU1Fb/++qvedKVSiUWLFuld1rl7924AgJmZGYYMGYKjR49iwoQJ2LdvHyZMmMC9nzPGGGNtGOcWjDHGWPPXIq/AKL/M88KFC9i9ezdeeeUVEFGdl58xY4aUdOzatQvPPvtsY4XKGGOMsRaAcwvGGGOs+WuRBYyKBgwYgMzMTGRkZNR5mYEDByIxMRHnz5+HKIrw8vJqxAgZY4wx1pJwbsEYu1/evp9QeO4YxMJ8Q4fCWJvWIm8hqSg6OhqiKKJdu3ZISkqS2k1NTZGfX/0HzLRp0zB//ny8/vrrTREmY4wxxloIzi0YYxWJxcXI2boBKNUARkZQPdIXxoN8YTx4JIxs7PcwJbEAACAASURBVAwdHmNtykMXMOoyNFlDK79PFQCICOvXr4dcLtebZ9iwYVi/fj38/PywYMGCSut44oknsHLlSkydOrVJYmaspSBRA5TmA6X5IG0BQDoAwl9TBUAQ/vrrrzZB+Gu6ABgZAwpzQGEGQZBXsXbGGKsd5xaMseakJCyorHgBAFotSkIvoyT0MnK++wzKLt4wGT4a6jGToDC1NGygjLUBAtXnBk8ASUlJUCqVjRVPk/n9999x6NAhbNiwwdChtCgajQYdO3Y0dBisnogIKMkCFaUARSkgTU5ZkUL7V6Giwt8QNQ2wRQEwMvmrmGEO4a/ff/9tAcHYFjBxgGBk2gDbY4y1ZJxbtG2cW7DmLvub1cj/Y0+10wVjU1x4vSe83SbC23FcE0bGWNvT4m8heRCLFy/G8ePHsWvXLkOHwliDIl0xUJgCKkoGFaYARcmgwmSgKBUQS5oyEkBbUPZTlALSn6JPaQnBpGNZMcPEETB2hGDiCEFl1YTxMsbYw+HcgrHWqzj4Qo3TjQb44G5BKMZaL22iiBhru9pkAWPFihWGDoGxh0aiBrh3C3QvuuwnPxHQZBs6rPrT5II0uUBOhH5xw8gEMHaAYNIRgoUHBMuuEEwcDBUlY4zViHMLxlqn0qREaJPv1DhPqrc1HKy6w9LYXq+diCAIQjVLMcYeRJssYDDWElFpHig3GnTvJij3JpCfAJDW0GE1Hm0hkBcLyosFpZ4pa1NYQrDsUlbMsOwKmDpBEFr8YEqMMcZYiyASIbNAg9R7xUjJK0FWgQYFGi0KNbqyn1ItijQ6FGtFlOpElOoIWp2IUpGgEwkKuQC1Qg7jv35URjLpb7VC9tfvsh9LtQL2Fio4WKhhrlYYbJ9ru/pCZmGJcOt4PGL/mF47leZDF7wMQof+kNkNg2Dm2phhMtZmcAGDsWaKSrJA2RGge1Gg3GigKNnQIRleaS4oIxCUEVj22MgUgkXnvwsa5m7ceShjjDH2gAo0WtzJLkJqXglS7hUjNa8YqXklSMsrRsq9EqTnl0Ar1qv7vAZhqpTD3kINBws17P76XfFvGzMlZI10pUOtBQyfgcgoCkYXO1+9dkq/DGiyQEl/Qpf0J2DiBJndEAi2Q/k2WcYeAhcwGGtGKD8BlHkFYmZI2RUWrGbaAlBWKCgrtOyxXA3BugcEm34Q2vWCYGRi2PgYY4yxZiq7UIPI1DxEpeUhKjUfUal5uJNTVLmvqmagQKNDbEYBYjMKqpyuMpLBs4MZutmZw8vOHN3szOFhYwoj+cNdpUmaEpRcC65xnmQvU7i27wdjpf4IJGLaRf0ZC+9AjNsDxO+FYDMAMqexEMw7PVR8jLVFXMBgzICIRCD3JsSMQFDmFaAky9AhtWy64r+v0BDkECy7lRUzbPpDUPLQZowxxtqmlHvFiErN+6tgUVasSMtvys69G1eJVsT15Hu4nnxPalPKZfDsYAovOwt0sy8rbNS3qFEcFgwqqf44ydt3QJjZTQyyn63XTsUZwL3oqhciHSg9ALr0AMCiM2Qdx5blKnxLLGN18tAFjAk/XmuIOCT/m9Oj1nns7e3h5eUlPZ4yZQpeffXVKufdvXs3QkNDsXLlyjrHcODAAaxatQq2trbYt29fnZdjrC7+LlpcBmUEA5ocQ4fUOpEOlHMdlHMdiPkJglU3CB18INgMgKAwM3R0jLEacG7B2MPJLNDgUnwmLsZl4XJCNrIKG2KI9JZFoxMRkZKHiJQ84GpZW3lRo6+zNQa6WqO3kxXUiupvPS2+crHaaQAAn/7I14TAw3aIXjOlXUQV465Vdi8a4r1oQGUDWcdHIdj7QjAyrn05xtqwFnkFhlqtxsmTJxtt/Tt27MDnn3+OQYMGNdo2WNtDxZkQU06BUs5w0aLJiaCcCFBOBBCzHYJVdwh2w8vOeMha5McgY6yBcW7BWjKNVkRoUg4C4rIQEJ+FmPT8ZnkriKFVLGr8FJgIpVyGnh0tMdDNGlN7dYTFfZ2FFgedr3F9iV2V8LAdCoVcrdde6faR2pRkQLy1C0jYB8F+BGSOYyAYd6jfOhhrI1pV5h4SEoKlS5eisLAQKpUKe/fuBQCkpKTg6aefRnx8PCZMmIDly5cDAH799VesXbsWRITRo0fjvffew2effYZLly7htddew9ixY/HOO+/g7bffxtWrVyGXy/Hhhx9i2LBh2L17Nw4fPoyioqJK62WsHJEIygoDJZ8EZYUBEA0dEiMdKPsaKPsaoLSEYO8LmYMfBFU7Q0fGGGuGOLdgzVVcZgEuxmXhUnwWrtzJRnEp5xj1pdGJCErMRsidHDzZ20lvmjb5DrRJidUuK3dwQrg6AqPtX9Nrp/xEoDDpwQLSFf/V6edRCDb9IHP5BwQzlwdbF2OtVIssYBQXF8PPz096vGDBAkyYMAHz5s3Dxo0b0adPH+Tl5UGtLquGhoeH48SJE1AqlRgyZAjmzp0LuVyOjz76CEePHoWVlRWmTZuG//3vf3jzzTdx7tw5vP/+++jduzc2bNgAQRBw+vRpREdHY9q0abh48WK16+3YsaNBjglrXkiTC0o5DTH5NFCSYehwWHU0uaDEA9Al/gGhfR8IjqMgs/Y2dFSMMQPg3IK1BFGpefgzMhXHotJwN7fY0OG0Gj0dLWCm0v+3qKiW0Ud0Pr2hE6/BpX0/vfZ6X31RJQJlBEGXEQzBdhBkbk9AUPMVGYwBLbSAUdVlnhEREbCzs0OfPn0AAObm5tK0ESNGwMLCAgDQpUsX3L59G9nZ2RgyZAhsbGwAAE888QQuXryICRMm6K330qVLmDt3LgCgc+fOcHJyQmxsbLXr5SSjbROzI0DJJ8o65CSdocNhdSaCMoNBmcEQjR0gc/SHYDeMRzFhrA3h3II1V/FZBfjzRir+jExDQlahocNplQa7t6/UVhxccyEiobOALnZ+kFUYvp1IBKUFNGBkBEq7CF16IAQHP8hcHoegtGjA9TPW8rTIAkZ9KZVK6W+5XA6drmH+sWys9bKWhUgHSj0P8fb/gKJkQ4fDHlZRMsTYHUDcfyHYDi7rVMvUqfblGGNtCucWrDHdKy7FkRup+CM8uawTStaohtxXwKBSDUquBlY7v5GrB67LwvC4w8f6y+VGAZpGGFGOtKC7R6FLPQuZ0zgITuMh3NfvBmNtRasZr8fT0xOpqakICQkBAOTn50Or1VY7f9++fXHx4kVkZmZCp9Ph119/xZAhQyrNN2jQIOl+19jYWCQlJcHT07NxdoK1KEQ6iClnoAtcBPHmD1y8aG3EElDKKeiC34XuxgZQ4V1DR8QYa2KcW7CmpBMJ529lYvGBcIzfcB6rj93k4kUTsDFVoquduV5bSfgVUEn1t+hoBnhDKTeFg6WXXjs1yO0jNdAVQ0zYD93ltyAmHQWJ1X8eMdZaPfQVGHUZmqyh3X+fqr+/P5YtW4aNGzdiyZIlKCoqgrGxMX755Zdq12FnZ4d3330XU6dOlTraGj9+fKX5nnvuObz99tvw9fWFXC7HunXroFKpGmW/WMtAJJZdcZF4AChOM3Q4rNERKP1S2eWbtoMgc50MwdjO0EEx1qpxbsHakkKNFvvDkvHzldvcr4UBDHKv3Il3US23j9zy0KGrg79eG4mloIzqr9poUKX3IMb+BCQdgcztCchsBzfNdhlrBgQiqtcoS0lJSXqXN7K2RaPRtNl7ccsKFxf+KlykGjocZiiCHILd0LKewdU2ho6GsVaBc4u2ra3mFun5JdgdfBv7rt5FXgmfSTeUTyd549Fu+icmkuc/Be3tuCrnV3Tpjl8fz8WzPl/B2tRZahczgiBGrG/UWKsjWHWHrPMcPsHC2oQ20QcGYw+jrEOmCxATuHDBUDYMa8oZ6FLPl43V7vI4D8HKGGOszqLT8rEjKBFHbqRCK9brPCJrYEn/24jl+29jWyd3bN68GQqFAtq0ZGTfisGCq3Eo0OrQ09IUS72ccK9Uh3nBMUBcFp6f5A9rU2csW7YM//znP+Hm5tb4t4/UgHIioAt+t+wqUadxECp0LMpYa8NXYLB6aWtnScSsqxBjdwJFKYYOhTVXggKCw0juGZyxh8C5RdvWVnKLi3GZ2BGYiEsJ2YYOhQEovBuLksv7EHP+f/jkk08QEBCA0NBQFOfdg51YipmuHTDDpQOWhCcgNr8YwTkFKBUJCxdNhJWtO37fFYBr167Bx8cHv+/fg9WvjUdOfhFem+YNNwczw+2YqQvkXZ6HYO5uuBgYa0R8BQZjVaDiDIixO8qGQ2WsJlRa1jN42nnI3J6E4OAHQWg1/SMzxhh7CDqRcDgiBT8FJiImo8DQ4bAK8hOuY/SoUQCATp06YePGjfD19YVLSjx2XghElqbsth6ZIIAArO3ljrev30ZobAT6oytKS0sxc+ZMmJmZYcfGNcjNL4KVmdKwxQsAKEiELuRDCB3HQOY2FYKc+9dhrQtn2YxVQKIWYuLv0AUt5uIFqx9tIcSYbdCFfgTKizd0NIwxxgzsXGwGpm+9jPcP3eDiRTOkK8pDb3cHAMDNmzchCAIe9ffHMCqAqZEcJ9JyAQDnM+7BQa3EGDsrCAoj3IkshoOdEywtLXHt2jWcOHECv+4/gOISHV6b5m3IXapABCUdhi54KcTscEMHw1iD4gIGY38Rs8PLPujj/wuIGkOHw1qqvFvQhXwAXcxPIG2RoaNhjDHWxG6k3MNLP1/Ba7+G4RYXLpotcwsrWMhKAQBpaWlQKpUwzs2Eua4UdmoF0ktK8eylmyAAdmoFFEoF2tmbYejQIQgLC4O7uztiYmLg7OSAnOxsZOVrMGXJCcz55CzupDWT5704HeK1NdBFfgcqzTd0NIw1CC5gsDaPSrKgi/gK4rU13NcFayBi2W0lQe9ATLtk6GAYY4w1gbu5RXj3j+uYvT0IQYk5hg6H1WLEsCE4fvw4AOD27duws7NDVngo7ml1MJHL4GdriV0Du0ApE/CIhQmUPfuhWFsETb4S48aNw+eff44pU6bAzKgY9wpK0c5cic5OFrAyU+Gb/VEG3jt9lHYBuuBloNybhg6FsYf20H1g/PpTekPEIZk6s0Ot87i5uSE+Pl56vHv3boSGhmLlypXVLnP+/Hls2LABO3bsqDRt586d+O677wAARITFixdXOW57bc6fPw+FQgEfH596L8uaHolaUNKRsmFRdTzuOmsEmhyIkRtAKach6zybhzdjrI44t9DfBucWzdu94lL8cDEev4TcQamORxVpKaaOHopjiQEYPnw4zM3NYWZmhtV7D+ApOwvcK9UiKq8Yz1y6iUHtzBGdX4ycXh1R/A0hMyML06ZNgyAISEhIQHjoFcwZ54bE1AJodQSdSKjnGAlNQ5MFXdhKyNyegOA0AYIgGDoixh5Im+/E8+7du/jiiy9w/PhxWFhYID8/H5mZmQ+0rvPnz8PU1JSTjBaAClOgi/wGyI83dCisGqlZRXjy3VNQGMkglwnYtmwYToekYv3eG1Ar5Vj/2kB0d7PSW+aLn69j35lEmBkb4YfFQ+HQ3gTvfn8FJ66kYOn/9cTEIU64FpuNI5eS8Ob0R5psXyjnOnRBSyFzmQTBZRJ38slYK8e5Rdug0Yr4+cpt/HgpAfeKtYYOh9WDTAAGurXH2DVrpLY3XvkXQk4cw6b4NAxrb46OxirIBAHveTljYXgi+j73AbQaQklJCQ4fPowxY8bA0c4aDv1s8eHcPpi36gL+vHwHHazV+OGdoQbcuxqQDmLcHgi5UZB1fQGCwsAdjjL2AFpdAePf//43xowZg0mTJgHQP6OSl5eH6dOnIy4uDkOHDsXq1auRkZEBMzMzmJqaAgDMzMxgZlb2Zp48eTK8vb1x4cIF6HQ6fPnll+jbty+ys7OxYMECJCQkwMTEBJ999hnMzc2xdetWyOVy/Pe//8WKFSswaNAggxwDVjMx+VTZ0KhiiaFDYTWwsVTh9FfjIJMJ2HooBpt+j8aBc7dx4dsJSMsuxqtfXsLeT/yk+VMyi/C/i0k4/dU4BEZm4pOtYfjq9UG4efseTn81DnM+OYeJQ5zw1d4bWLtgYNPvEJVCTPgVyL4GebeXIKjbN30MjLEHwrkFu19AXCZWHI3C3Vy+grMl8ra3gJWxQq/tg8cexcK4y1XO/90LM7B/+G3MG/Ez5LK//33a/NE00G1jAMCm5lq0qAJlXYXuyjLIvV6GYOFp6HAYq5cWWcAoLi6Gn9/f/7jk5ORg7NixtS4XEhKCs2fPwtnZGU8//TQOHjyICRMmoEOHDujfvz+GDx+OiRMn6q2rqKgIJ0+exMWLF7Fw4UKcOXMGq1evRo8ePbBt2zacPXsWr7zyCk6ePInZs2fD1NQUL7/8cqPsN3s4VJoPMXoLKCPI0KGwOpDL/75KIa+wFF1dLNDRxgQKIxk6djBBVGKu3vwJqfno7mYJQRDQt3M7vLAqDQAgCICmVAelQoZjgXcxrKcd1Cp5k+6LnnvR0F15F7LOz0PWYYDh4mCM6eHcgtVFXnEp/nMyGn+Ec59ZLdlg98onEYqDLlQ7f2YPO3jauuoVLwCA0gMaPLYmU5IF3dVPIXN/CjKn+t/expihtMjrmNVqNU6ePCn9LFq0qE7L9enTB25ubpDL5Zg6dSouXboEuVyOn3/+GT/88AM8PDywbNkyrF69WlpmypQpAIDBgwcjLy8Pubm5uHTpEp566ikAwPDhw5GdnY28vLyG31HWYMScG2WdF3HxokUJjc7CkPn/wzf7ojCwewfcTi9Abr4G1+NyEJOUh1KtKM3r4WiO4KhMlGh0OB6cjOy8sitsHh/mgrkrL+DVJ72w61gcenpa4+XPA7DnRJyhdqtsyNUbX0F3czNIx1cCMdYccG7BanMqOh3TNl/i4kUrMKSTfgGDtFoUX6366gvBxBThtkno5jBKf5ncaKC4YfvraXKkg3hrN3TXvwSVNpORUxirRYssYNTEyMgIolj2T40oiigtLZWm3d9ZTfljQRDQt29fLFiwAN9//z0OHjxY6zKsZSBRC13cHohhqwBNlqHDYfXUu3M7XPh2At5/vjdW7QjHpy/0xdSlJ/HZrnD4eNlAYfT3R5iNlRov/qMrxr95DIcvJaGriyUAYMaYTtj1gS+u3crB9Efd8e3+KHy5wAdHLt011G5JKOU0dCHvg/ITDR0KY6wGnFu0bdmFGiw+EI639l9DRgEPs97SWRkr4GVvrtdWcuMqqLDqf+CN+g9Evi4bHa166LWLaRcbLcamRpkh0F15D5RnwJM7jNVRqytgODs74+rVqwCAw4cP6yUZISEhSEhIgCiK2L9/P3x8fJCSkoKwsDBpnvDwcDg5OUmP9+/fDwAICAiAhYUFLCwsMGjQIOzduxdAWeda7dq1k3ovzs/nMZabCypKgS70Y9DtgwCaYW/QrEaaUp30t6WZAiYqOcYO7Ijja8di8ayeeKSTdaVlZo3zwIl1YzF5uAt8e9tL7UUlWly4loZR/R2Rk1eWfObmN5MktPAudKEfQkw6auhIGGPV4Nyi7TpyIwXTNl/Csag0Q4fCGshAt3aQ3Vc0rOn2kVRvK3S199MrNBLpQBlVX7HRYpVkQHd1BcTMUENHwliNHroPjLoMTdaUZs6cidmzZ2PkyJHw9/eHiYmJNK13795YvHix1NHWxIkTkZSUhPfffx8pKSlQqVRo37491lTokVitVsPf3x9arRZffvklAOCtt97CggUL4OvrCxMTE6xfvx4AMHbsWDz//PM4fPgwd7RlYGLaJYg3f+COOluw0JhsLNoQBLlMgFopx8Z3huD19YG4FpuNdhZKfP162ftr66EYdHG2xOBHOmDGB2eQll0MFztTrH/t7446v94biZendgMATB/TCb6vHMaofg4G2a8qiaUQY38C5VyHrMtc7hWctXmcW3BuYWjp+SVYeTQKZ2IyDB0Ka2BDqur/IrjqqylkFla41i4e4xye1WunrGtAaSu8xUssgXh9LeD5f5A5+tU+P2MGIFA9BypOSkqCUqlsrHialcmTJ+P9999H7969DR1Ks6HRaNCxY0dDh1EtIoKYsB+UuN/QoTD2YFQ2kD/yGgRTp9rnZayV4NyibWtuucWhiBSsOXYTeSU8NGprIwA48vIwWJv8/Xmjy0zH3f+ruhNLo9FjcGxQOmYN3qjXrrvxLSi99dxCUhXB+THI3Z8ydBiMVdIiRyFhrCqk00C8uQmUfsnQoTD24EoyoAv9GDKvlyFr16P2+RljjDWI4lId1hy/iQPXkg0dCmskXvbmesULACgKrv72kbteZuhmr/9dTLoSUOaVRomvOaHbf0BXkgVZl39CkPG/jKz54FdjDcrvUWXNH2lyoLu+Fsi7ZehQGHt4uiKI178APGZC5uhv6GgYYw2Ic4vmKT6rAIt/C0dMBo/E0JrVZ/hUeXtbhJvfxBT7f+q1U0Zwm7lFmdIuQNTkQNb9VQhGxoYOhzEArbATT9b2UH4CdFc+4OIFa11IBzFmK3SxO0Ek1j4/Y4yxB3IoIgWztwVx8aINuL//C9LpUBxadWecNLAfjJXWsDC2029vRaOP1AXlREB39WNQCY/mx5oHLmCwFk3MCIYu9BMeIpW1WpR0BGLEOpCubZztYYyxpqLViVh9LArvHYxAYYWRr1jrZKk2wiOOFnptmshroIKqO+O83VWFbg6j9NpIcw+Uc73RYmy2Cu5AF/IhqOC2oSNhjAsYrOUSbx+EGLG+zVzGx9ouygyB7uonfPaDMcYaSEZ+CV76OQS/hCQZOhTWRKoaPrUo6HyV8xo5OOOG+ia62PnqtVP6JYDaaLFLkw3d1U9BefGGjoS1cVzAYC0OkQjdzR8gxu0BUK9BdBhrufITys5+5CcYOhLGGGvRwpJy8X/bAxGalGvoUFgTqrL/i2o68NT69EJ7M1eoFeZ67WIbu32kEm0hdNdWg/ITDR0Ja8MeuhPPzz//vCHikLzxxhu1zmNvbw8vLy/odDp07twZ69ev1xuTvSYpKSlYsmQJNm/e/LChMgMgEiFGfd/m7j9kDIB09kPu/RoEq26GjoaxRsO5BWssB67dxcqjUSjV8QmQtkRA5QKGLjsTpbduVjl/QhcZujn46bVRUSqQF9tYIbYc2gLorq2GvOc7POQ7M4gWeQWGWq3GyZMncebMGSgUCmzdurVOy2m1Wtjb23OC0UIR6SBGfsvFC9a26YqhC/8PKCfS0JEw1qpwbtH6bboQh48OR3Lxog3qameO9qb6w6cWB18EqPJrwcjVA9FGMehkM1ivndICGjXGFqU0r+xKjMIUQ0fC2qAWWcCoaNCgQYiLi0NBQQEWLFiAsWPHwt/fH4cOHQIA7N69G7NmzcLUqVPxxBNPIDExESNGjAAAREZGYuzYsfDz84Ovry9u3SobxeLnn3+Gr68vRo4ciX/9618AgMTEREydOhW+vr544okncOfOHQDAv//9b7z55pt49NFHMWjQIPz5558AAJ1Oh/fffx9jxoyBr69vnRMhVjUStRBvbCi795Cxtk4s4SIGY42Ic4vWRSTCqqNR+O58nKFDYQYyxL1dpbai4Kr7v9AMeASO1o/ASK5f8Gjzt4/cT5MLXdjKsitTGGtCD30LiSFptVqcOHECfn5++PLLLzFs2DCsXbsWubm5GDt2rJRMhIWF4dSpU7C2tkZi4t/3bG3duhXz5s3Dk08+CY1GA51Oh8jISHzxxRc4ePAg2rdvj+zsbADAkiVLMG3aNDzzzDPYuXMnlixZgm3btgEAbt++jSNHjiA+Ph5TpkzBiBEjsGfPHlhYWODPP/9ESUkJHnvsMYwcORKurq5Nf6BauLLixdegzCuGDoWx5uOvIob8kdf5dhLGGhDnFq2LRivivYPXcfxmuqFDYQZ0/+0jpNOhJKTq4VNveWjRzX6C/vx5cUBRcqPF12JpsqELWwV5ryUQ1DaGjoa1ES2ygFFcXAw/v7L70gYNGoQZM2Zg4sSJOHLkCDZs2AAAKCkpQVJSWc/Svr6+sLa2rrSe/v3748svv8Tdu3fx2GOPoVOnTjh37hwef/xxtG9f9kFXvlxQUBC2bNkCAHjqqafw4YcfSuv5xz/+AZlMhk6dOsHV1RXR0dE4deoUIiIi8PvvvwMA8vLycOvWLU4y6olELcSI9aCsUEOHwljzw0UMxhoM5xatT36JFm/uC0Pw7RxDh8IMyFxlhB6OlnptmpvXIeZV7sRV0aU7Eo0SMbJdH712vvqiBiWZ0IWtLCtiqCpf6cJYQ2uRBYzy+1QrIiJs3rwZnp6eeu1XrlypthOuJ554An379sWxY8fw7LPP4rPPPnugeIT7hmQSBAFEhE8//RT+/v4PtE4GkKiBeH09KDvM0KEw1nyJJdCFfw75I29wEYOxh8C5ReuSkV+CBXuv4mZavqFDYSgrItiYKWGmMoKRTAa5TIBcJsBIVvY614kk/WhFEUWlIjILSpBdWPrQ480NdGsHuUz//VQcVPXoI0X9usCtfTsIwt932ROJfAtzbYrTy4oYPZdAUFkZOhrWyrXIAkZV/Pz8sGnTJqxYsQKCIODatWvo0aNHjcvEx8fDzc0N8+bNw507dxAREQFfX1/MmTMH8+fPR7t27ZCdnQ1ra2sMGDAA+/btw7Rp07B3714MHDhQWs+BAwfw9NNPIyEhAQkJCfD09ISfnx9+/PFHDB8+HAqFArGxsbC3t4epqWljH4pWgXQaiBFrQdnhhg6FseZP1EAX/jlkj7wOmZWXoaNhrNXg3KJlSswuxL9/CcXd3GJDh9ImdLQyhrOVMWxMlbAxU8HGTAkb079/tzdVQq2QP9C6tToRWYWlyMgvQUZBCTIKNMjI10iPk+8VIy6jELoqOuMsN7jK/i+qKGDIZLjpVoTeDqP1minnBqDhq3hqVZQK3bU1kPd+F4KRsaGjYa3YQxcw6jI0WVN4/fXX8e6772LkyJEQRREuLi7YsWNHjcscOHAAv/zyC4yMjGBr7iVFNwAAIABJREFUa4uFCxfC2toaCxcuxOTJkyGTydCjRw+sX78en376KRYsWICvv/4aNjY2WLt2rbSejh07YuzYscjLy8OaNWugVqsxc+ZM3L59G6NHjwYRoX379tzZVh0R6cpuG+HiBWN1J2oghv8H4CIGawU4t+Dc4kFFpNzDwr1XkV1YauhQWiUnK2N42Zmjm705vOzM0dXOHBZqRaNtz0gug625CrbmqmrnKS7VISY9H5GpebiRmofI1DzEZhRAJ5YVNSoNn5qbjdKYG5XWo/TuhQyjTNhZdNFrp7Sqr9ZgVSi8AzHyG8i8F+pdxcJYQxKIaihZViEpKQlKpbL2GduIf//73xgzZgwmTZpk6FCahEajQceOHRt1G7qbW0Appxp1G4y1WnI15L2WQjBzMXQkjNUZ5xb6OLd4MNfu5uKVPaEoLNU1QFSsvakSfZ2tygoWdhboZmcG80YsVjSkEq0OsekFuHuvGKO72upNKzjxP2R9/l7lZWZNRYaPMwZ1miW1kaiB7uKrgK6o0WNuTQSncZB3etbQYbBWqtXcQsJaBzHxDy5eMPYwdMXQhX8BeZ/3IKgqdzDIGGOt0c20PCzce5WLFw+pi60ZhnvYYISHDbrZm0N2X18sLYXKSI7uDhbo7mBRaZo2PQWQyQGxwmvFyAiRLrkYZj9Hb17KDOXixQOgO4chmnSEzH6EoUNhrRBfgcHqpTGvwBDTAiBGfgs8dHdNjDGYuZZdiSGv/rJbxpoLzi3atofNLRKyCvHCrmBk8W0j9WYkEzDAxRrDPW0wrJMNHCzVhg6pSYj591AUfBHFl86gKOg8FN28cXqSEtMGfKE3n+76WlDmFQNF2cIJRpD3fBuCZVdDR8JaGb4CgzULlHsTYtQmcPHCgOQmgNKyrPdohSUgVwKCDBCMyn5DBkAESARIV/YjlgKaeyBNTlkHV9oCQ+8FK5efUHYfavdX+T5UxlirlZxbhJf3hHDxoh5URjL4d+mAkZ07YKBbO5gq296/AzIzC5j6joWp71iQVouirCQMVdzTm4dKC0BZPBLeAyMtdBHrIe+9HIJxB0NHw1qRtveJxZodKkyB7vqXAHHy0ahUNhDM3QBjOwhKK0BpJf2G0rJBztSTqAE0uUBJjlTUIE0OUJwGyksAilMffj9YnVFmCMRbuyD3mGHoUBhj7P/Zu/eAqup0/+PvtRZ3EBAQUQRBzUulooCApkCohfdLpcd0zGnSnGpsZmzS6TJmM2aeznjGY6U0Z452G6cMHE1TG6QyR8RMKivFxBveQUXul73X74/9cxcCymXDYm+e1z8j7r3X/iwm4dnfy/O1ufziCh57L5sLRRVGR7ELoR3dmRoRzNg7uuDjbh+9LFqD4uSER2B3bjwYWc/PAr3akEwOo6oI07cr0SKek5NJhM3IAIYwlF55DdOh/5KZe1tz64TiFYbiFQYdLP+rOHu1+Nsqqgu4dbK8fx2P69Ul6MWnoOgEevEJ9OLjUCaDGi1JP7MTs3sQatcko6MIIYTNFJZV8fj72Zy+Kv0JbkZTFEbcFsB9EcFEhXa0254WRlB870TpkoR+cQ+Y5EjeJis9IyeTCJuSHhiiUWzZA0M3VWL6ejkUHbPJ9dovBXx6o3bsDx16oHh1b5XBClvRq0uh+CR60Qn0K9+gFx62bE8RNqSi3vkkqt9Ao4MIUSepLdq3xtYWJZXV/PIfB/nufFELprJvAZ4uTB4YzKQBXW96BKm4Nb26DP3iXszndkHJaaPj2C05mUTYSrMHMDp+v9Cmga70e+Wmj1++fJmpU6cCcPHiRTRNw9/fcr7zjh076iyA1q1bh7u7O9OmTWPDhg0kJCQQFBQEwNq1a5k1axYeHjcuHGuYwsJChgwZwuHDh1EUhf379zN27Fiys7Pp2rUr165dIyoqisOHD6OqtUcd9+zZw2uvvXbLc+UBCgoK6N+/P8uWLeOhhx5qUt7msuUAhum71ej5+21yrXZHc0PpOADFPwLFb6BdDVjcil5din7lEHrBQfTLX8nqHFuR41VFGya1RU1SW9SvvMrErzZ+xcG8qy2cyj71DvRiTmwYCb0CcNJkttvW9MKjmPO2ohccNDqKXVJvfwI1IMroGMLO2d0WEj8/PzIyMgBYsWIFnp6ePPbYYzd9zU9/IW/YsIG+fftai4yUlBTuu+++RhUZJpMJTdMA8PHxoXPnzuTk5NCnTx/2799P//792b9/PxMnTuSLL75g0KBBdRYYjbV582YiIyNJS0szrMiwFXPedhm8aCzXAMuAhf8gFJ++KKrd/fNtEMXJA6XTEOg0BF03QeFRzJezLV3AZbtJ05nKLftQBy9Fce5gdBoh2hSpLeyjtjDrOos3H5LBizp083Vn/l09GNk3ULaJtCDF5zY0nyfRr/2A6fh7UHjE6Eh2xZzzNxSvcBQ3f6OjCDtm90OzZrOZkSNHAnDo0CECAwPJy8sDIDo6mtLSUlasWMGrr77Kli1byM7OZv78+SQmJpKSksL58+eZMmUKkydPBiAjI4Pk5GSSkpJ4+OGHKS4uBiAyMpKlS5eSlJTE5s2ba2SIjo5m/37Lh/H9+/czb968Gl8PGTIEk8nEkiVLGD16NPHx8axfv976+qKiImbMmEFcXBwLFy7EbDbXea9paWm88MILnDt3jrNnz1r/PiwsjOeee47hw4czdepU8vPzAZg0aRLPPPMMiYmJjBgxgi+/bBvHQOmFRzEff8/oGPbByQMl+B60wX/EKea/0HrNQu14p8MOXtxIUTQU375oPabjFL0CLWo5Ssh4cK59rrtogIrLmA+n0MiFd0K0O1JbtM3a4tXPjvF5bkGrvZ898Pd0YdGoPrz/8xhG9+ssgxetRPHuhdPA36Pe+VvwlJWNDVZdgunwGnS97p9HQjSE3Q9gqKpKRUUFRUVF7Nu3j4iICDIzMzl9+jQBAQE1Zj/Gjx9PREQEr7/+OhkZGcydO5egoCBSU1NJS0ujoKCAlStXsnHjRtLT0xk4cCBr1qyxvr5jx46kp6dbC5LrflpknDx5kgkTJpCdnQ1Yiozo6GjeeecdvL292blzJzt37uTtt9/m5MmTABw8eJBly5bx+eefc+LECbZu3VrrPs+cOcOFCxcYPHgwEydOZNOmTdbHSktLGThwILt37yYuLo5XXvlxqWxZWRkZGRm8/PLLPPnkkzb4jjePXlWE6fvXpMfBrXiFo/b+BVrMf6P1nIHiFWJ0ojZB8eiCFn4fWsxK1L7zQc4WbzT9ytfoeduMjiFEmya1RdurLXZ8f543s061ynvZgw6uTjw+oiebHoljakSwbBcxiOo3AG3wC5aaxC3Q6Dj24VoO5pObbv08IerhENO40dHRZGVlsXfvXhYsWMCuXbvQdZ3Y2NhGXefAgQPk5OQwbtw4AKqqqoiK+nGf1qRJk+p83ZAhQ1i1ahUnT54kJCQENzc3dF2nuLiYr7/+msGDB7Nu3Tq+++47tmzZAlhmRnJzc3FxcWHQoEGEhYUBMGXKFPbt28f48eNrvMemTZuYOHGiNceTTz7JL3/5S8BSaF3Pdt999zFnzhzr664XRHFxcRQVFVFYWIiPj0+jvi+2ous65sNrofKyIe/f5qnOKJ1iUbvejdKhh9Fp2jRFdUIJjEUNjEUvycN8dpd0CW8E84kPULxvQ/HpbXQUIdosqS3aTm1x5EIRL24/3GLXtyeuTir/ERnCrCGheLvJUahtgaKoKIGxKAFR6Oc/w3xqk+VIeVEv/dRmdN/bUXz7Gh1F2CGHGMCIjY0lMzOTvLw8kpOTWb16NYqiMGrUqEZdR9d14uPjWbt2bZ2P17eXtUePHhQWFrJz505rUTJw4EA2bNhASEgIXl5e6LrOsmXLuPvuu2u8ds+ePSg3LPe78WuwLPG8ePEiH3zwAQDnz58nNzeXHj1qf9D96esbcu3WoiiK5Yd74REwVxqWo81x74zaJQml8zCHasbZWhTPbmi3/Qw9/H7pEt5QugnT4dfRBr8o/80JUQ+pLWoyqra4UlrJwk1fU1EtS85H9Arg6ZF95FSRNkpRnVC63o3SeRjmk5vQ8z4CZMtm3XRMR95Ai/wjipO70WGEnXGI9WaxsbFs3LiR8PBwVFXF19eX9PR0YmJiaj3Xy8vLuvf0xq8jIyPJysoiNzcXgJKSEo4da9gRn5GRkaSkpBAdHQ1AVFQUa9euZciQIQAkJiaybt06qqqqADh27BglJZbTFQ4ePMjJkycxm81s2rTJ+prrrj/366+/5sCBAxw4cIBf/epXpKamApa9utdnX1JTU2vc9/XloJmZmXh7e+PtbWzvALVLAtqgJeDRzdAcbYJbJ9S+89CilqN2u0c+SDaT4uSO2vVunCL/iHr7AvCwzWk5DqviMuacvxmdQog2S2oL42uLarOZRZsPcf5aRYtc3154uznx4tjb+a/JA2Twwg4omitaj2loEc+BR1ej47RdFfmYj71rdAphh5q9AuNWR5O1htDQUHRdJy4uDoCYmBjOnj2Lr69vredOmzaNp556Cjc3N7Zt28asWbOYPn06QUFBpKWlsWrVKh599FEqKiy/LBcvXkzPnj1vmWHIkCHWva1gKTJOnjxpLTpmzpzJ6dOnGTlyJLqu4+/vb222FRERweLFizl+/DjDhg1j7NixNa6dmprKmDFjavzduHHjmDt3LgsXLsTDw4Mvv/ySlStXEhAQQEpKivV5bm5u3H333VRXV/Pf//3fDf2WtijFMxht8B8wH3sX/VyG0XFan7MPavcJKEEJ7aYZZ2tTAwaj+EegX/w35hOpUCFN3+qiFxzAfO5T1C7xRkcRogapLSzae22xctcPfHm6fZ84knBbAItG9cHfUwYu7I3i3RNt8AuYT/4T/fRWZDVGbfqFzzAHDEL1H2x0FGFHFL2R7ehvPKtdGC8sLIwTJ07U+vtJkyaxZMkSIiIibPZejTmrvSHMl/ZjPvo3qC612TXbLM0dNWQMSvBoFM3N6DTthm6uQj+XgfnUZqgqMjpO26O6okW+iOLe2egkoh2T2qLtMbq22PzN2Xbd98LH3ZnfJfVmdD/52ewI9KJcTEf+CqVnjI7S9jh7o0X+CcVFTpgTDeMQW0iE/VI7RaMNfhG8exkdpeUozijdktGGvIIaOkEGL1qZojqjBo9Gi/5P1O6TQb7/NZkr/v+RZnIykBCibfjmbCHLPz5idAzDJPbuxD/mxMjghQNROvRAG/yC5Sh4+fhVU9U1zMfeNjqFsCOyAkM0iq1XYFyn6ybMJ9LQT3+IIy2xUwLjUMMfQHH1MzqK+P/0ymuYT6ahn9tldJQ2Re0+BbX7RKNjiHZKaov27ae1xdXSSmasz+JScftr9u3t5sSiUX0Y1VcGLhyZXnQC05EUWY1xA3XAIlTffkbHEHZAhgBFm6AoGlr4faj9fwcutfcX2x0XX9Q7nkTr+6gMXrQxios32m2z0QYsArdORsdpM8yntqCXXTA6hhCinfvjjsPtcvCiZ4Anb86KlsGLdkDpEIY26HkU/0ijo7Qp5h/eRDdXGx1D2AEZwBBtitrxdsvRjh0HGB2lyZTOd6FFLkP1H2R0FHETim8/y57Lro07EtFh6VWYf3jT6BRCiHYs7aszfPpDvtExWl3CbQH874ORBPvKcZLthaK5od7+uGVrq7AoPYt+ZqfRKYQdkAEM0eYoLt6od/4Gtcd0UDSj4zScS0fUO36N1ucRFGdPo9OIBlA0V7ReM9EG/h7cAo2OYzj9yiHMl/YZHUMI0Q6dulLKyowfjI7R6n4xNIyXJ/bH00VOJWtvFEVF7T4J9fYnQDXulJnC4kri5m3F9953OZR7BYCV//iWEY99xJiFH3OuoHaj/UO5Vxiz8GNGLtjBmk2WfjXPpnzJ0Ee3sfXfeQB8c+wKr7x7qFFZzKf+iV5xpZl3JBydDGCINklRFNRuyZYztO3gg6USNAIt6k+o/rbryi5aj+LTBy3yjyjB9wCK0XEMZT72Lnp1mdExhBDtiFnXee7Dbymraj/NhN2cVV6eeCfzhvVAVdr37532Tg2IQhv0nGHbWj3cnNj8chJT4rsDcL6gjG17z/Dp6ntZ8vAg/rT+61qveTblIBteiOdff7mHRyf1ASDn9DU+XX0v736cC8DqD77n8amN7GlhKsec+/fm3ZBweM0e7n07e7otcljNjNhw08cvX77M1KlTAbh48SKapuHv7w/Ajh076mwCtm7dOtzd3Zk2bRobNmwgISGBoKAgANauXcusWbPw8PBoUt7CwkKGDBnC4cOHURSF/fv3M3bsWLKzs+natSvXrl0jKiqKw4cPo6q1x4v27NnDa6+9xjvvvHPT96mqqmL58uV8+OGHeHl54eLiwsKFC0lKSiIyMpKdO3fi7+/PmDFj2LZtW5Pu5cbvTVugdAhHG7wU89H16Jf2Gh2nNpeOqL1/jupnv1tehIWiuaL1nIEeEGU56qy8nfaDqLyK+WQqWs8HjU4i2jGpLdpXbXEsv4TvzrefY667+rjxyuQB3NbJy+gooo1QPEPQBv0B8/evol/9vlXf29lJpZPvjye0nbxQzO1hPiiKwuDb/Jj78sUaz889W0SVyczPXvycymoTf35iCH27+6AoUFllwsVZ5V/7z3LXgM64uTZ+JbV+aR/mLonS0FPUy+5WYPj5+ZGRkUFGRgazZ89m3rx51q/r62D+0EMPMW3aNMDyi/T8+fPWx1JSUigra9xso8n04wyBj48PnTt3JicnB4D9+/fTv39/9u/fD8AXX3zBoEGD6iwwGmP58uVcuHCBzz77jPT0dNavX09xcXGt5zW1wIDa35uW0LVrV5ycnPDy8qKwsND692VlZfj4+ODk5ESnTpYR6EOHDuHs7IyLuzc5xKP2/gXh93/Axl0nWjRjg3n3Rhv8ggxeOBjFpzfa4CUofgONjmIY/cy/0ItPGh1DiFYjtYVxtUV5lYljl2q/p6OKDPFl/cwoGbwQtSjOHVDvXIjSdaShOXp27cCBIwVUVJpIP3COK0UVNR6/cLmcb45dYf2zd7Hil1E89eoXAEy4K5RfLP83v7qvH3//13EG9OrIY/+VyXu7jjc6g/mHN+V4d1EvuxvAuJHZbGbkSMs/9EOHDhEYGEhenmXvVXR0NKWlpaxYsYJXX32VLVu2kJ2dzfz580lMTCQlJYXz588zZcoUJk+2NNHJyMggOTmZpKQkHn74Yesv8sjISJYuXUpSUhKbN2+ukSE6OtpaVOzfv5958+bV+HrIkCGYTCaWLFnC6NGjiY+PZ/369dbXFxUVMWPGDOLi4li4cCFms7nG9UtLS3n77bd56aWXcHW17JELDAxk4sTaRx6GhYVZ/7x69Wrr+7388ssAnDp1imHDhvGb3/yG4cOHc//991NWVlbre9PYwqshVqxYwbVr16iuriYoKIgHHnjA+tisWbPw9vamurqaqqoqnn76aZ555hkSEhJISEhg0aJFpO25CM4+3Dd+hM2zNZbSJQFtwNMoLj5GRxEtQHHyQL3jSZSQsUZHMYgZ09H16Lr51k8VwgFJbVFTS9UWuq5z9lo5Zsc5Pf2m7u3XmdX3R+DrIUcGi7opqhNar1moBq6CDPB1Y97EPiQv/Bfb952hT2jNWtfXy5nBvf3x8XLhzh4duXS1HIAHR/fg7y/E803uVWaMCmfNpiP894Ih7Nh3tvEhpKGnuAm7H8BQVZWKigqKiorYt28fERERZGZmcvr0aQICAmos3xw/fjwRERG8/vrrZGRkMHfuXIKCgkhNTSUtLY2CggJWrlzJxo0bSU9PZ+DAgaxZs8b6+o4dO5Kenm4tSK77aZFx8uRJJkyYQHZ2NmApMqKjo3nnnXfw9vZm586d7Ny5k7fffpuTJy0znAcPHmTZsmV8/vnnnDhxgq1bt9a4/vHjxwkODqZDhw4N/r5kZGRw/PhxduzYQUZGBl9//TV791q2YOTm5jJnzhx2796Nj48PH374Ya3vjbt78zthp351hqLyKuvX7733HlFRUQDMnj2bL774wvrYv//9b6ZMmQJAfHw8mzdvxtvbm7KyMoqLi/H19WXevHls3faR5egpo0anFQ2118/QbpuDokrDLUemKCpa+AOofR8F1dnoOK2v6Bj6uU+NTiGEIaS2qJuta4v8kkoq2knfiwn9u7BkzO04aXZfeotWoAaPRr1tDkb15Zp1b092rbqHScNDiY+ouf3rtm7e5BeWU1VtJu9iCT5eP9ZIZRXV/PubiyRFdeVqkeU45MImHotsPrkJveJq029COCyH+AQWHR1NVlYWe/fuZcGCBezatQtd14mNjW3UdQ4cOEBOTg7jxo0DLHtDr3/gBpg0aVKdrxsyZAirVq3i5MmThISE4Obmhq7rFBcX8/XXXzN48GDWrVvHd999x5YtWwDLzEhubi4uLi4MGjTIOrsxZcoU9u3bx/jx45vwnfjRJ598wieffMLdd98NQElJCbm5uQQHBxMaGkr//v0BGDBgAKdPn27We9Xl48MXeGnnEdZlnuTFcXcwMNiHwsJCune3NAjq3r075eXl1ueXlpbStWtXwDIDdODAAVavXk14eDiKopCQkECXLl2YM2cOx48f580332RM7ALMOX+F6hKb56+Tkxfa7Y+jyJ68dkUNjENx74Lpu79AxWWj47Qq84n3UQIiUVy8jY4iRKuT2qI2W9YW5VUm8pv4wcbe3D8omIVJvaVZp2gUtUsCqM6Yj7wBtOwypfG/S+erHy6Tc6qQRyb0ZmfWWS5eKSe0syf/8+sYAFa88w333x1GeJcO/PY/7mDkkzswmXT+/Ksh1uu8+sFhHpvSF4AZo3sQ//h2kiK7NC2UqRzz6c1ovX7W7PsTjsUhBjBiY2PJzMwkLy+P5ORkVq9ejaIojBo1qlHX0XWd+Ph41q5dW+fj9TXj6tGjB4WFhezcudNalAwcOJANGzYQEhKCl5cXuq6zbNky6y/96/bs2YNywy+0G78ODw/nzJkzFBUVNXimRNd1fvWrXzF79uwaf3/q1CnrUlEATdNqDCTYwrnCMpbttBypdO5aOfM2fMncoeF4e3tTUFAAWGaT3Nx+bBjk7u7O2bOWJWYXL16kQ4cO+Pj4cPmy5QOjj48PH3/8MWPGjCE1NZUHH3yQM2fOoHT4I6bDa6DwiE3voRbPELQ7FqAY1CFaGEvpEIY26A+YvlsN144aHaf1VJdgPr1FGnqKdklqi7rvxVa1xfmiclr6Q1lbMDM6hAUJtxkdQ9gptfMwyyDG968DLbetc8uKpBpfz07uVes5v3uwv/XPk0d0Z/KI7rWes3DGndY/jx8WwvhhIc3KpZ/7DD1kHIqrX7OuIxyLQ6xji42NZePGjYSHh6OqKr6+vqSnpxMTE1PruV5eXjUaVP3068jISLKyssjNtRz/U1JSwrFjxxqUITIykpSUFKKjowGIiopi7dq1DBliGZVMTExk3bp1VFVZtlQcO3aMkhLLyoGDBw9y8uRJzGYzmzZtsr7mOg8PD2bMmMEzzzxDZaVltiI/P7/WftmfSkxM5O9//7v13s6dO8elS5dueg83fm+awmTWeW7rdxRXVNf4u9c/z8W5zzDrtpE333yzxgzU0KFDSUtLA+DTTz9lwoQJ1semT5/O0KFDAcvMVXFxMRUVloZCiqsf2oBFKKGTaKlldkpAFFrEszJ40c4pLr6WvidB8UZHaVX6uQw5k120S1Jb1Gar2uJaWRVllY6/deQ/IrvJ4IVoNrXTEMt21vZ4zLtehfn0h0anEG1Ms1dg3OpostYQGhqKruvExcUBEBMTw9mzZ/H19a313GnTpvHUU0/h5ubGtm3bmDVrFtOnTycoKIi0tDRWrVrFo48+av2AvHjxYnr27HnLDEOGDLHubQVLkXHy5Elr0TFz5kxOnz7NyJEj0XUdf39/a7OtiIgIFi9ezPHjxxk2bBhjx9ZuHLh48WJeeukl7rrrLtzc3PDw8OB3v/tdvXkSExM5evSo9VoeHh689tpraFr9xxnd+L1pSh+Mvx84zVdnCut8zDRoElUfvoOmOeHm5sq+ffvo2LEjV65cYf369dYTSnx9fa2NwcrKyti2bRtXrlyxZp84cSLPPvus9bqKoqKFTUb37WdZjVFpuw9bSpe7UXvNQlEcYqxPNJOiOqP1/jlm146YT24yOk7rMFdZVmHIEk7RiqS2sHDE2sLVzY0LxRX1Pt9R3BcRzG/u7m10DOEg1MAY0KtbZTtJWyOrMMSNFF3XG/Wv4MyZM/UeKSYcX2VlJcHBwXU+lnellOnrsqiovvkSNwX4j6gQnhjR0+bNrPSqYsxH3kC/nN3saynB96L1/A8bpBKOyHzqQ8wn3jc6RutQnNGiX0Zx8zc6iXBQUlu0H5eKK8i/YQDjyLmrpHxV9+SHPZrYvwu/v6ev9LwQNmc+/ynmnL8ZHaPVKV1HovWaZXQM0UbItLKwCV3X+eOOw7ccvADLuPG7X5zm5+8eIO9KqU1zKM5eaHf+2nL8lNL0kyOU0AkyeCFuSg0dZ+gxZ61Kr8J8qv5l5UII0RBVJjMFJY7duDOpdycWj5bBC9Ey1KB41B4zjI7R6vRzn8p2VmElAxjCJtK+OsuB04076uj780XMfHM/H3133uZ51ODRaIOeA/egWz/5xtd2n4IWNtXmmYTjUYNHo/aafesnOgD9wm70spvvdRdCiJu5WFRBIxf+2pU+gV4sGXM7miqDF6LlqN3uaXf9uKQXhvgpGcAQzXahqJxVn/7QpNeWVJp4fut3LNn2nc0beile3dEGv4ASOKzhrwmdgNp9ok1zCMemdr0btedMo2O0PN2E+dQ/jU4hhLBTpZUmrpVXGR2jxfh7uvBfkwfg5lx/PxAhbEXt9TPwbl89VmQVhrhOBjBEsy3feYSSZg4+bP32PLPe2k/OxSIbpbJQNDe0vnNR+8wFze3mz+02RlZeiCZRg0eh9phudIwWp1/Yg17YffcMAAAgAElEQVR2wegYQgg7dKHItke2tyXOmsKKSf3p7H3zOkMIW1FUJ7TbnwDXdtSbSq/CfHqr0SlEGyADGKJZtn93ns9zC2xyrZOXS5nz9gH+8eVpm1zvp9TOw9AGLwWvsDofV4JHo/WYZvP3Fe2H2i0ZNew+o2O0MHP7OX1FCGEzV8uqKK9y3GNTfz+6LwO6+hgdQ7Qzios32h1Pgtp+GiDr5z+RVRhCBjBE05VVmpq8daQ+lSYzr6QfZWHa1xSW2XapqeLeGS3iOZTge/jpWdpKQBRqD2nYKZpPDR2P0iXR6BgtSr+4F730nNExhBB2wqzrXCpy3GNTH4wKYdydXYyOIdopxSsUte88o2O0HnMV5nO7jE4hDObU3At02v+lLXJYXYoefNPHL1++zNSplmX+Fy9eRNM0/P0ty6d27NhR5zFs69atw93dnWnTprFhwwYSEhIICrI0d1y7di2zZs3Cw8OjyZnz8/OZOXMmlZWVLFu2jNjY2CZdp7q6mv79+zNjxgyee+65Rr8+MjKSnTt3Wr8ft3L+/Hl+//vf87e/1T6OadKkSSxZsoSIiIh6X78u6ySXilumm/inP+Tz/fosXhx7O4NDOtrsuorqhNZzBmbf2zHn/BVcfFH7PIKiyFiesA2150xMpWeh8IjRUVqIjvnsv+Q4M9GipLZwnNriSmkV1WbLCWULfj6D+b9dTN87+jc6R1s0NNyPJ+J7GR1DtHNqQBR0n4z5ZJrRUVqFfv4z9O6TUBTpN9Ne2d2nNj8/PzIyMsjIyGD27NnMmzfP+nV9Z8g/9NBDTJtm2R6wYcMGzp//8dSLlJQUysrKGpXBZKq5DHL37t3069ePXbt2NbjAuPEaAJ9++ik9evRg8+bNNuvSres6ZnPdR5sGBQXVOXjREOevlfPO/lPNiXZLF4sq+OU/snljz3HMNu5arvpHoA3+I1r/p1Bu0RtDiMaw7kt1CzA6SovRL+xBNznujKpof6S2aJyG1ha6rnO51DGPTe3u58Efx90hJ46INkHtPgklYIjRMVpH5VX0fNsOcgv7YncDGDcym82MHDkSgEOHDhEYGEheXh4A0dHRlJaWsmLFCl599VW2bNlCdnY28+fPJzExkZSUFM6fP8+UKVOYPHkyABkZGSQnJ5OUlMTDDz9McXExYJmBWLp0KUlJSWzevNn6/t988w1Lly5l+/btJCYmUlZWRmpqKvHx8YwYMYKlS5danxsWFsbzzz9PQkIC+/fvr3UvqampzJ07l27dutV4PDIykpdffpmkpCTi4+M5evQoYJkxuv/++xk+fDi//vWvrYXJqVOniIuL47HHHmPEiBGcOXOGJUuWMGLECOLj49m0aZP1eSNGjACgrKyMuXPnMmzYMGbPnk15+c2bbf3Ppz9QUV138WJLJl0n5d/Hmf+Pg1y08RJUxdUXxUX2rArbU5w7WPalOurgmKkM/cK/jU4hRIuR2sI2tcX5K9d47rdPMGviPTzz5Hwqyh1j4NNFU1kxsT8d3JyNjiKEldrnF+DW2egYrUI/l2F0BGEgux/AUFWViooKioqK2LdvHxEREWRmZnL69GkCAgJqLN8cP348ERERvP7662RkZDB37lyCgoJITU0lLS2NgoICVq5cycaNG0lPT2fgwIGsWbPG+vqOHTuSnp5uLUgA+vfvz9NPP83EiRPJyMigsLCQF198kQ8++IBdu3aRnZ3Ntm3bACgtLSUyMpJPPvmk1mxKeXk5n332GaNHj2by5MmkpdVcBubv7096ejqzZ8/mtddeA+CVV14hJiaG3bt3M2bMGGtxBZCbm8ucOXPYvXs32dnZHDp0iIyMDN5//31eeOEFLlyoeZLA9aWwe/bs4Xe/+x1fffVVvd/zr88UsvPwxYb+X2QTX56+yoz1WXz2Q36rvq8QTaV4hqD2cdx9qbIHVTgyqS2aX1voOvz1f/8PVzd33vrnDn7+ywXkfH/IBv/vGG/eXeH0CPA0OoYQNSiaK1qfX/DTPm+OSr/6nZyK1o7Z/QAGWGZDsrKy2Lt3LwsWLGDv3r1kZmY2er/ogQMHyMnJYdy4cSQmJvLee+/V+MU9adKkW17j4MGDDB06lICAAJycnJg6dSp79+4FQNM0xo0bV+frPv74Y4YNG4a7uzvjxo3jo48+qrEUdOzYsQAMHDiQU6csWzf27t3LffdZTj0YNWoUvr6+1ueHhIQQFRUFQFZWFlOmTEHTNAIDA4mLi+PgwYM13v+n17rjjju4/fbb673HP2ccveX3oSUUllXx27SveSU9h8pWWP0hRHOpAYNRHfVo3pJT6IU5RqcQosVIbdG82uJaeRUHv8hi9NiJAPTs3Zcet/W59Tesjevf1ZsHo0KNjiFEnRSf3ijBo42O0Qp0zLIKo91qdhPPtiA2NpbMzEzy8vJITk5m9erVKIrCqFGjGnUdXdeJj49n7dq1dT7enGZcAK6urmha3Q1nUlNT2bdvH5GRkQBcuXKF3bt3k5CQAGDdg6tpWp17XG2dtT5nrpbx7blrLXLthvrHl3lk513lT+PvpLtfy9ynELaihk5ALzmDfinT6Cg2Zz67C82nt9ExhGgRUls0L2tBieP1vnDRVJ6/t5/0vRBtmho2FdPlbHDwFQr6hc/Rw6aiqLKVq71xiBUYsbGxbNy4kfDwcFRVxdfXl/T0dGJiYmo918vLy7r39MavIyMjycrKIjc3F4CSkhKOHTvWqCyDBw9m7969FBQUYDKZSE1NZejQoTd9zfUlqgcPHuTAgQMcOHCA5cuX11rqeaO4uDhSU1MBSE9P5+rVq3U+LyYmhk2bNmEymcjPzyczM5NBgwbVe63vv/+e7777rtZ1dF3n6KXiWn9vhCMXi/nZm/v58JAc5yjaPrX3z8Gjm9ExbE7P349eaeyAphAtRWqLptcWJrNORbWJAZHR/GubpbdH7tEcco/a9+lMvxzegzB/2Toi2jZFc0Xr/QgOv5Wkqgj9UpbRKYQBmr0C41ZHk7WG0NBQdF0nLi4OsPxSPXv2bI1lj9dNmzaNp556Cjc3N7Zt28asWbOYPn06QUFBpKWlsWrVKh599FEqKiyNphYvXkzPnj0bnKVz5848++yzTJkyBV3XGTlyJMnJyTd9zdatW7nrrrtwdXW1/t29997L0qVLrTnqsnDhQubNm8fw4cOJjo6mW7e6PyCNHTuWL774gsTERBRF4fnnn6dz587W5aJg6aa+YMEChg0bxm233cbAgQNrXaewvJrSylvP0LSW0ioTL3z0PVknL7NoVB88XBxiQZFwQJZ9qY9gOvgC4EDbn/Rq9POfooSONzqJcDBSW9Rkb7WFyWxp/DnpgQdZ/vzTzJp4D9179KR3vzsbfM9tzYBgH6ZHhhgdQ4gGUXxuQ+l2L3reR0ZHaVHmcxmonYcZHUO0MkVv5JlaZ86cqfdIMeG4dF3nWH4Jh/Iuk/JVodFxagnxdedP4++gX5C30VGEqJfpRCr6qX8aHcO2XP3RhryCojjEgj5hEKktHEdJRTWnrpQ26jVHzl1tk7XFda5OKu/MHiLbVoVd0U2VmL58Hsoce7WyFvknFE/HW+Uq6icVp2iQwvJqqkxtd+b49NUyHn73AO9+ccpm59wLYWtq6ATwdLAZvIoC9Mv1n1okhGhf8h2w98Vjw3vK4IWwO4rm0i5OJTGf3210BNHKZABD3JKuQ0FJ2z+7vcqkszLjB36T+jVXSx2vgBL2T1Gd0Po8AkrdDffslX5xr9ERhBBtQHm1idLKaqNj2FT/rt5Mi5TZXWGfFO9eKMH3GB2jRen5XxgdQbQyGcAQt3StvMquji39PLeAGeuz+OLUFaOjCFGL4tXdshLDgeiXv0I3VxkdQwhhsMJSx/s5sCChF6ri2DPYwrGpoRPAyYFXEFXkoxedMDqFaEUygCFuSgfy7WD1xY0uFVfypx3ft+ltL6L9UkLGgWeo0TFsx1SOfuUbo1MIIQyk6zqF5Y41gDGiVwADg2s3bRXCnijOnqghjt1s2yyrMNoVGcAQN1VkZ6svfurZe/rhrMl/4qLtccStJPolKR6EaM+KKqqtp484AlWBx4b3MDqGEDahdB0Jrn5Gx2gxesEBoyOIViSf7sRNXbbTXhKTB3YlMrSj0TGEqJfiFWpZieEg9MsH0c2OtfddCNFwV8sca/XF2Du60CPAy+gYQtiEormgdp9kdIyWU3oWvdSxT1sRP3Jq7gXKH7r5OeSN5bbu5ucVX758malTpwJw8eJFNE3D398fgB07dtR5DNu6detwd3dn2rRpbNiwgYSEBIKCggBYu3Yts2bNwsOj6XvD8vPzmTlzJpWVlSxbtozY2NhGX2P58uXExcURHx/PpEmTuHDhAq6urnh6evKXv/yFXr16Neg6TzzxBKNHj2b8+OYvFSuvMlFWaWr2dVqbm7PKvGHhRscQ4pbUbsmYzu2CqiKjozRfdSn61e9Q/AYYnUQ4AKkt7Ku2qDKZKamwv3qhPi6aylypI4SDUTrfBac/cthjVfX8L1BCHXurjLBo9gBGa/Pz8yMjIwOAFStW4OnpyWOPPXbT1zz00EPWP2/YsIG+fftai4yUlBTuu+++RhUZJpMJTftx6ffu3bvp168fK1eubPI1Fi1aVOPx119/nYiICN58801eeOEF3nrrrQZf21au2OnqiwejQvH3dDU6hhC3pDi5o4ZOxHzsbaOj2ISe/wXIAIawQ1JbNE9hWRWWrlmO4YHBwQR5uxkdQwibUhQNNfx+zN+tMjpKizAXHECVAYx2we63kJjNZkaOHAnAoUOHCAwMJC8vD4Do6GhKS0tZsWIFr776Klu2bCE7O5v58+eTmJhISkoK58+fZ8qUKUyePBmAjIwMkpOTSUpK4uGHH6a4uBiAyMhIli5dSlJSEps3b7a+/zfffMPSpUvZvn07iYmJlJWVkZqaSnx8PCNGjGDp0qXW54aFhfH888+TkJDA/v37a9zHE088wZYtW2rdX1xcHMePH+fUqVOMHz+epKQkkpKSyMrKAixNsxYtWkRcXBxTp04lPz/fJt9Xk1mnsNz+loP7uDszM9qBmiMKh6d0SQS3TkbHsAm94Et03T575gjxU1JbNK62cKTtI54uGrNjwoyOIUSLUAMiwbthK6/sTtEJ9PICo1OIVmD3AxiqqlJRUUFRURH79u0jIiKCzMxMTp8+TUBAQI3Zj/HjxxMREcHrr79ORkYGc+fOJSgoiNTUVNLS0igoKGDlypVs3LiR9PR0Bg4cyJo1a6yv79ixI+np6daCBKB///48/fTTTJw4kYyMDAoLC3nxxRf54IMP2LVrF9nZ2Wzbtg2A0tJSIiMj+eSTTxq8FHTHjh3069ePgIAA3n//fdLT03njjTd45plnANi6dSs//PADn3/+Oa+++mqt4qWprpZVoev2N5vycGwYXq52t7BItGOK6oQaNtXoGLZRVYR+9bDRKYRoNqktGl5blFRWO9SJX7NjuuPr7mx0DCFajBb+gNERWoguzTzbCYf4pBcdHU1WVhZ79+5lwYIF7Nq1C13XG71f9MCBA+Tk5DBunKWxXlVVFVFRUdbHJ026dfObgwcPMnToUAICAgCYOnUqe/fuZcyYMWiaZr32rcyfPx83NzdCQkJ46aWXqK6uZtGiRXz77beoqkpubi4AmZmZTJkyBU3TCAoK4q677mrUPddFxz63j3TxdmNqRLDRMYRoNKVTDJzeBiWnjI7SbHr+F9DxdqNjCNFsUls0rLYodKDVFz5uTkwfHGJ0DCFalOLTB8X3DvSr3xodxeb0/AMQPNroGKKFOcQARmxsLJmZmeTl5ZGcnMzq1atRFIVRo0Y16jq6rhMfH8/atWvrfLw5zbgAXF1da+xNvZnr+1SvW7FiBZ06dSIjIwOz2UxISMv9gi2psM/ZlEfv6oGLk90vKhLtkKKoqOEPYD70itFRmk2/nA38zOgYQjSb1Ba3ZtZ1rtnhdtP6TBjQFXcXxzneWoj6KMGjHHMA49pRdFMFiia98ByZQ3zai42NZePGjYSHh6OqKr6+vqSnpxMTE1PruV5eXta9pzd+HRkZSVZWlnUGoqSkhGPHjjUqy+DBg9m7dy8FBQWYTCZSU1MZOnRoM+7OoqioiM6dO6OqKu+//z4mk6Xbd2xsLJs2bcJkMnHhwgX27NnT7Peyx72svTp5ck+/zkbHEKLJVL/+KL79jI7RfBUF6OWXjE4hRLNJbXHr2qK4otout5vWRQGmDpRVnKJ9UPwGgqu/0TFsTzehX2vcz1dhf5q9AuNWR5O1htDQUHRdJy4uDoCYmBjOnj2Lr69vredOmzaNp556Cjc3N7Zt28asWbOYPn06QUFBpKWlsWrVKh599FEqKioAWLx4MT179mxwls6dO/Pss88yZcoUdF1n5MiRJCc3/zi4OXPmMGfOHN577z3uvvtu64zN2LFj+fzzz7nrrrsIDg6usSy1KUxmneIK+5tNeWx4TzRVMTqGEM2ihj+A6eALRsdoNr0wB8VBGpMKY0htUVNbrS2KHGj1xdAe/gT7uhsdQ4hWoSgqapdEzCc2Gh3F9q4dka2sDk7RGzl0fubMmTrPQxeO4WppFeeuldX7+JFzV0n5qrAVE91azwBPNsypPSMmhD0yff0y+tXvjI7RLEpQPFrvnxsdQ9gRqS3sj67r5FwsxmyDFRhtobZYOWUAd/UMMDSDEK1Jr7yGad+ToJuMjmJTiu8daAN+Z3QM0YIcYguJsJ3CcvvbPnLfIFnyKRyH0uVuoyM0m154xOgIQogWVlJpssngRVsQ7ONGXLgDLqcX4iYUF2+UTkOMjmFzetExdAcblBE1yQCGsKoymSmttK/loJ4uGsm3BxkdQwibUQIGg0tHo2M0T9l59Mq2tVJLCGFb9rjdtD5TIoJlG6pol9QuSUZHsD1TORTb/6luon4ygCGsrtnh6osxdwTh6eIQh+kIAYCiaKhdEoyO0Wx6YY7REYQQLchRBjBcNJUJd3YxOoYQhlB8bgPPUKNj2JysBHVsMoAhrArL7K8YuS+im9ERhLA5JSgBFPs+yk+KByEcV0W12S6PW6/L6L6B+HpI/xXRfqldHW8Vhn7tqNERRAuSAQwBWIqRimr72i8WGeJLjwBPo2MIYXOKqy9KQKTRMZpFBjCEcFyOsvoCYHKE9NES7ZsSGAeam9ExbEpWgTo2GcAQABTZ4faR+wfJ6gvhuNSuI42O0Dwlp9GrS41OIYRoASUOMoDRycuFAV19jI4hhKEUzRWl4wCjY9hW1TX00nNGpxAtpNnNA8as+8YWOay2PdT/po9fvnyZqVOnAnDx4kU0TcPf39I5eseOHXUew7Zu3Trc3d2ZNm0aGzZsICEhgaAgS+PHtWvXMmvWLOvZ502Rn5/PzJkzqaysZNmyZcTGxjb6GsuXLycuLo74+HgmTZrEhQsXcHV1xdPTk7/85S/06tWLyMhIdu7cab1fWyq2s+adAZ4uxPeS486E41J8+oBHMJSeMTpKE+nohTko/hFGBxF2SGqLtltbmHWd0ir7WrFZnxG9OhkdQYg2QfEfhJ6fZXQMm9ILc1A8pL+NI7K77od+fn5kZGQAsGLFCjw9PXnsscdu+pqHHnrI+ucNGzbQt29fa5GRkpLCfffd16giw2QyoWk/7k/fvXs3/fr1Y+XKlU2+xqJFi2o8/vrrrxMREcGbb77JCy+8wFtvvdXgazeWyaxTVmlfe1knDeyKkyYLiIRjU7smYf7hTaNjNF3JKZABDGEHpLZouNJKE7qDHJ86oqdMhAgBoPgNwLIw374+D9yMXiInkTgqu/8EaDabGTnSstT60KFDBAYGkpeXB0B0dDSlpaWsWLGCV199lS1btpCdnc38+fNJTEwkJSWF8+fPM2XKFCZPngxARkYGycnJJCUl8fDDD1NcXAxAZGQkS5cuJSkpic2bN1vf/5tvvmHp0qVs376dxMREysrKSE1NJT4+nhEjRrB06VLrc8PCwnj++edJSEhg//79Ne7jiSeeYMuWLbXuLy4ujuPHj1u//utf/0pSUhLx8fEcPWppUHPlyhV+9rOfER8fT3JyMt9++y1gKcIWLFjApEmTiIqK4o033rBe5/333+eee+4hMTGRX//mN5hM9rUCY3TfzkZHEKLFKQHRgP0e7aeXnjU6ghBNIrVF/bXFK//5nyx/fhELfj6D6cmJbHxnvfU6Oz/cxLwZU3j4/vG8svRZTKa2u1LD3VkjMtTX6BhCtAmKsxeKT2+jY9iWbCFxWHY/gKGqKhUVFRQVFbFv3z4iIiLIzMzk9OnTBAQE1Jj9GD9+PBEREbz++utkZGQwd+5cgoKCSE1NJS0tjYKCAlauXMnGjRtJT09n4MCBrFmzxvr6jh07kp6ebi1IAPr378/TTz/NxIkTycjIoLCwkBdffJEPPviAXbt2kZ2dzbZt2wAoLS0lMjKSTz75pMFLQXfs2EG/fv2sX/v7+5Oens7s2bN57bXXAMtARf/+/fn000/5/e9/z+OPP259/tGjR/nHP/7Bjh07eOWVV6iqqiInJ4d//vOffPjhh2RkZGBC4eOtm2u9d1sV4utOuL807xSOT3HxBu9eRsdoMhnAEPZKaov6a4sqs5lTx4/xn2v+jzXvfsD6Nf9DdVUVJ3J/YNf2rby6/h/87/tbUFW1TdcWseF+uDrZ92lPQtiS4j/Y6Ag2JT0wHJfdbSGpS3R0NFlZWezdu5cFCxawa9cudF1v9H7RAwcOkJOTw7hx4wCoqqoiKirK+vikSZNueY2DBw8ydOhQAgIsyxKnTp3K3r17GTNmDJqmWa99K/Pnz8fNzY2QkBBeeukl69+PHTsWgIEDB7J161YA9u3bx9/+9jcAhg8fzpUrVygqKgJg1KhRuLq64urqSkBAAJcuXWL37t189dVXjB49GoBrJaV4endsUK62IP42WfIp2g/VfxBmez0OrPQ8uq6jKPa7ikS0X1Jb1F1bVJt04oYn4uLiiouLK75+/lwuyOfLff8m5/tvmTdjCgAV5eV09LN9zy5bkT5aQtSk+A+C3HeNjmE7lVfQTeUoDnbCinCQAYzY2FgyMzPJy8sjOTmZ1atXoygKo0aNatR1dF0nPj6etWvX1vl4c5pxAbi6utbYm3oz1/ep3uh6IzFN0xq0NPOnjcc0TaO6uhpd15k2bRrPPvssZVUmThSUNPAO2obhPaXplmg/FP9BcPw9o2M0jbkCKi6DW9v9ECNEfaS2qK2i2oyu6zj/tLZQVUwmE7oO906YzNwFTzXyDlqfqsCwcPm5JMRPKe6Bdt48/Ea6ZRtJh3Cjgwgbs/stJGApMjZu3Eh4eDiqquLr60t6ejoxMTG1nuvl5WXde3rj15GRkWRlZZGbmwtASUkJx44da1SWwYMHs3fvXgoKCjCZTKSmpjJ06NBm3N2txcbG8sEHHwCwZ88e/Pz86NChQ73PHz58OFu2bOHSpUsUV1RzrfAq58/axw8rHzcnBgR7Gx1DiFajeHQFd/vt+SLbSIS9ktqidm3h7Fb/YEtkTByffLydKwUFAG26thgY7IuvR+2TZYRo7xT/QUZHsCnZRuKYmr0C41ZHk7WG0NBQdF0nLi4OgJiYGM6ePYuvb+3mTNOmTeOpp57Czc2Nbdu2MWvWLKZPn05QUBBpaWmsWrWKRx99lIqKCgAWL15Mz549G5ylc+fOPPvss0yZMgVd1xk5ciTJycm2udF6PPXUUyxYsID4+Hg8PDz4n//5n5s+v0+fPixevJgHHniAiioTqqbx5O+XENQ1uEVz2sKwngE4qQ4x7iZEgyn+g9HzPjI6RtOUngU/439PCPsitUVNbaW2KLvJ8alhPW/jF4//hoWPPoTZbMbJyanN1hYjZPuIEHVS/QdhOv2h0TFsRi+TAQxHpOiNPAvrzJkzdZ6HLuyPrsORi0WNOg7tyLmrpHxV2IKpbu7liXdyd+9Aw95fCCPohUcwfbXM6BhNogQloPWeY3QM0cZJbWEfjheUUH6TQYymau3a4p3Z0fQOrH+lqhDtla6bMf17PpjKjY5iE0pANNrtj9/6icKuyFR2O1ZRbV9nuTtrCjFhfkbHEKL1efcCJy+jUzSJzH4I4Rh0Xae8ymx0jGZz0VR6yElmQtRJUVQUrzCjY9iMbCFxTDKA0Y6VtsAsSkuKCumIp4tD9J0VolEURUPxH2h0jKaRHhhCOITyajNgP5Me9ekd6IWTJuWvEPVypKaXZRfQdfsfeBU1yU/wdqys0r4GMCJD7eeoVyFsTfHpZ3SEpqkqQq8qvvXzhBBtmr3VDPXpFyRbR4S4GUdagYFeBeWXjE4hbEwGMNqxmzXjaotul6JDtGNKhzCjIzRd5RWjEwghmsneaob69O0stYQQN+NQAxiAXnHZ6AjCxmQAo52qNpmpMtnXkqo+UnSI9syjK6j22eRQVmAIYf8q7axmqE+/IDmKXYibcg8Ezd3oFLZTVWR0AmFjMoDRTtlb/4tuvu54uzkbHUMIwyiKBl6hRsdoGikehLB7jjCA4eqkEu7vYXQMIdo0SyPP7kbHsB2pQRxOszsipr5t231FU2Z2uunjly9fZurUqQBcvHgRTdPw9/cHYMeOHY0+hm3JkiWkp6eTlJTE448/zsyZM6msrGTZsmXExsY27SbsQIWddRLvJ6svhEDxCkO/9oPRMRpPigfRSFJbtC0ms47Z7CANPFWZuxPiljqEQ+Fho1PYhqwCdTh2d6SDn58fGRkZAKxYsQJPT08ee+yxJl/vrbfeIicnB03TSEtLo1+/fqxcubLBrzeZTGia1uT3N0p5tX2twOgr/S+EsAxgGB2iKWQAQ7RxUlvcnL1tOa2P9L8QomHstt6ogy41iMOx+2Fos9nMyJEjATh06BCBgYHk5eUBEB0dTWlpKU888QRbtmyxviYsLAyAWbNmUVJSwsiRI1m1ahVLly5l+/btJCYmUlZWRkZGBsnJySQlJfHwwz0vByMAACAASURBVA9TXGwZwYuMjGTp0qUkJSWxefPm1r1hG6motq9ipF9n2bMqhGKnR5tJDwxhb6S2qMkRto+A1BJCNJRdNw6/kdQgDsfuVmDcSFVVKioqKCoqYt++fURERJCZmUlMTAwBAQF4eNS/1/Gtt94iLCzMOusSGBhIdnY2y5cvp6CggJUrV7Jx40Y8PT1ZtWoVa9asYeHChQB07NiR9PT0VrlHWzPrut3NpvTt7GV0BCGM59HF0sjTXGl0ksapumZ0AiEaRWqLmuytZqhPqJ8DNSYUoiW5BWKZ53aAf/vVsgLD0dj9AAZYZkOysrLYu3cvCxYsYNeuXei63qx9pgcOHCAnJ4dx48YBUFVVRVRUlPXxSZMmNTu3Uext9UU3X3c6SANPIX5s5GlvfTBk9kPYIaktflRZ7RiLyTt5uRodQQi7oCgquPg4xDHosoXE8TjEAEZsbCyZmZnk5eWRnJzM6tWrURSFUaNGAeDk5ITZbPnQbjabqaqquuU1dV0nPj6etWvX1vn4zWZf2rpKOxvAuC1QVl8IcZ3iGWp3jTyleBD2SGqLHznKCgx/T/s8iloIQ7j4OsQAhkyiOB6774EBliJj48aNhIeHo6oqvr6+pKenExMTA0BISAhfffUVANu3b29QkREZGUlWVha5ubkAlJSUcOzYsZa7iVZkb3tZgzrIjIkQ1ymufkZHaDwZwBB2SGqLH9lb3VAXHzcnXJ3aTmNUIdo6xdXX6Ai2ITWIw2n2CoxbHU3WGkJDQ9F1nbi4OABiYmI4e/Ysvr6Wf3gzZ85k9uzZJCQkcPfddzdohiMgIIBVq1bx6KOPUlFRAcDixYvp2bNny91IK7G3LSQBsuRTiB+52GFBUS2zH6JxpLZoO3Qdqkz2v4VEagkhGske6426mCvRTZUomqzAchSKruuN+q105syZRp+HLtqW4wUllFc17RjVI+eukvJVoY0T3dwLY25nzB1BrfqeQrRV5svfYD70itExGs1pxHqjI4g2TGqLtqvKZOaHSy07CNkatUVMmB+r749o0fcQwpGYT27CfDLN6Bg2ocX+BcVRBmSEY2whEY1TbWczKZ28pKgV4jp7XdKp6/a18ksIYeEIqy8AAqT/hRCN40gf+KUGcSgygNHO6LpOtdm+/hH7e8qyTyGs7LWg0Ju26ksIYSxz4xbqtllyAokQjWSv9UZdZADDocgARjtTbW5eIWJEHSMrMIT4keLcARQ7bEQnxYMQdqk1BjBao7YIkFpCiEZRXDsaHcF2pAZxKI0ewHB2dm5Qp23RNjVnAMNsquZMUaUN09yaq5NKBzfnVn1PIdo8FzssKqR4EDchtUXb1cx5j1tfv5VqiwBZzSlE47j4GJ3AhqQGcSSNPoWkU6dOXLp0icrK1v0gK2zj0rVyjpy72ujX6TqcKarko+NlLZCqftI1XIja1D6/gOoSo2M0jioDkaJ+Ulu0XReulnDkfMscQ9iatUUHt2YfvCdE++LkCc4djE4hRC2N/mmuKAqBgYEtkUW0gj0X8lr9FJHm6CRNt4SoRfXtZ3QEIWxKaou2a9vJ43ZVN9THSVWMjiCEXVFUZ5ziVtv0mi4uLlRVVaEoCmfOnKFLly4AFBYW0rFjR3RdR9M0qqur+fjjjxk9ejQAu3btIjExEVdXV5555hmef/55m+YS9kWGo9uZi8UVRkdoFJkxEUIIIYxTUlFtdASb0GQAQwhDPfjgg1RXV6PrOh4eHsTExHDq1CkAYmJicHZ2pqKiAlVVueeeezh27BjdunUD4JFHHmHOnDkAMnghpIlne3O5xL6W5zqp8p+oEC3NxcUFRVFQVZVz585Z/76wsBBVVVEUBScny2Dixx9/jKIoKIpCRkYGAK6urixdutSQ7EKIllVS6RgnCGmKDGAIYaSPPvqIzp07AzBmzBjOnDljfSw3N5fY2FgAevTowZ49e/D09KSyspKysjI6dOjAH/7wBzZt2mRIdtG2yKfDdqasyr4KEVnyKUTL+umMiJubGzExMdbHrs+I6LqO2WzmnnvuYf78+XTr1o1u3brxyCOP8Kc//QmQGREhHFVJpWOswHDSpOQVwkjl5eV4e3sD0LNnT/SfHD9UXV1NcHAwAH5+flRWVrJ9+3by8/O5cuUKQUFBeHh4MGPGDDRN489//rMh9yDaBvlp3s6U2tlMiiz5FKJlyYyIEOJm7K1uEEK0Ta6urly7dg2AY8eOofxkVZSTk5O1/rh8+TIuLi506dIFk8mEyWRix44d/N///R9FRUW88cYbLFq0yJB7EG2DDGC0M/a2AkMGMIRoWTIjIoS4GUfpgWFq6fNghRA3lZyczIULFwDYtm2btb4ACA8PJzMzE7BMngwbNsz62B133EFISAgAZrOZq1evYjbLsajtmQxgtDPldjaAIYRoWTIjIoS4mfJqx/igIAMYQhjr3XffRdM0FEWhvLyczz//HE3TANizZ4/1dBJVVdmxYwdg6cX1/fff88MPPzB16lQAfvvb3zJ27FjD7kMYT454aGdK7WwAQwoOIVpWcnIyGzZsAG49IzJq1CjrYzIjIkT74CjrIKulnhDCcFVVVTW+Npksn0sCAgLqrCF8fHxq/L3UGQJkAKPdsbctJDKAIUTLevfdd3n//fetJ4tcnxExmUzs2bOHwMBAFEVB07RaMyIVFRU4OzsDlhmRCRMmGHkrQogWoDrIVk6TfPARolFMZp2/HzhtdIw6JdzWiW6+7kbHEAaRAYx2xt62kMiMiRAtT2ZEhBD1cZDxC7ubwBHCaCWV1fzlkx+MjlGncH9PGcBox6QHRjtTXmVfHzSq5YOREEIIYRhVcYwRjIKSSqMjCGFX8ovb7r8ZzTF+LIkmkgEM0aYVlTtG93Px/9i77/Coyvxt4PfMZCaTSe+NhDQIAULvXRBExUKxryLqrmVtP1fXhqIra3ld+7o2FPsiKIougtJ7CSUECIQkpJLee5mZ5/0jZiRCIIQkz5wz9+e6uEim3mdyZuY53/MUIiJSIrUUMIrt+GCMyB6V1DbKjtAurlLo2DiExMHotBpAQb0oi3nGhOgM+7LKUGXHxb1ADyMGBHvIjkFEXUCvklOdJTX2ezBGZI+K7fg9o5a5eahzWMBwMEp7v7PBQXSm59ceR0FVg+wY7bosLhCLZw2QHYOIuoCzk052hC5hz2eTieyRfQ8hUdgBDXUpDiFxME4Kq2A0mq2obmg+/w2JHIi9F/YU9jFDROdg1KujqcghJEQXxp7bGgYndXwuUefwr+9glDhmjI0Oot9V1DXZ/eo8ahkzT0SAUS09MOz4YIzIHpXY8TBuLxe97AgkEQsYDkaJBYxSdvsksrHnBkUrFjCI1MNZJWc6y+qaYLHz4i+RPbHnOTBYwHBs6vhWog5T4oEFe2AQ/c6eGxStXPTqOGNLROp5P1sFUF7H9gRRR9nrCRNnJy1MBk7j6MhYwHAwSpsDA+DEW0SnK7XTBsXp3JzVccBDROo606mEAjCRvbDXYVeeRvV8JlHnsIDhYJRYsbTXD1AiGZTQAHdzVt7nDBGdnb+7s+wIXSav0n5XbyKyJ6W1TWg0W2XHOCtPFRVVqXNYwHAwni7KO7AoqLb/AzainlKkgPeDKwsYRKrh76aeAsbxwmrZEYgU4XhhlewI7VJTrzDqHBYwHIwSu12lFtXIjkBkN04U2X8D3J0FDCLV8HMzyI7QZVjAIOqY4wX2+17xMinvWIa6FgsYDkaJ3a5yK+pR1dAsOwaRdGarFSkKKOhxCAmRegSoqAfGsQL7PatMZE+S7bjY5+2inqIqdQ4LGA5GiQUMAEix4w9Sop6SWVpnt2NST8cCBpF6mAxOcDWoY2LeygYz8irrZccgsnt23QNDoccy1HVYwHAwShxCAgDHWMAgUkz3ZxYwiNSF82AQOY7S2kYU2fGE4Uo9GUtdhwUMB6PUN709V4KJesoxhbwPvBX6OUNEZ+enogKGUj5HiWSx9/eIjyuHkDg6FjAcjFK7XdnzWDyinnLMjmcFb2XUa+FlYuOCSE38VTSRJ3t0Ep2bvfdSCvNykR2BJGMBw8H4KrRqeYoTeZKDM1utOKGACTyD3I2yIxBRF1PTEBJO5El0bvbcA0MDoLePSXYMkowFDAcTquCqpb1XhIm6U4ZCJvAM8mABg0ht1FTAqGow41QFJ/Ikao899/YM8jDCqFfHpMLUeSxgOBgPox7uCp1gz54rwkTdTSnzwLCAQaQ+vRR88uNsDuZWyI5AZJdyK+pRXNMkO0a72PuCABYwHJJSGyL7s8tlRyCSZn+OMvb/YBYwiFQnxt9NdoQutTW9RHYEIru0Na1YdoRzivR1lR2B7AALGA5IqcNI9uWUo7bJLDsGUY8zW63YrpAGd5CHerqaE1GLIA8jPIzK7L15NrszytBotsiOQWR3tqbZd1sjgj0wCCxgOKQQT2WeIW22COzOKJMdg6jHJZ2qQmWDMop3HEJCpE5q6oVR32zB/mwOIyE6XWV9MxJzK2XHOKfevixgEAsYDkmpQ0gAdvskx7Qt3b67dJ4uxFO5ny9E1L4+KipgAGxPEP3RroxSWISQHeOcIn04hIRYwHBISh1CAgA70ktgttr/SgxEXWlLqjIa2u7OTuyBQaRSfQNUVsCw87H+RD1ti50PH/E0OsHH1SA7BtkBFjAcULi3crtfVTaYkXTKvru3EXWljNJa5Chkyb8Yf54ZIVIrNQ0hAYDimiYcK7Df5SKJelKT2YpdGaWyY5xTb/a+oN+wgOGAgjyM8HTRy47RafY+wRBRV1LS/q62Axwi+l20nyt0Go3sGF2Kw0iIWhzIrUBtk31PbBvB+S/oNyxgOKhYBXcFtfcubkRdSUkNbBYwiNTL2UmHcB/lDkE9GyUViIm6kxKGVPUP8pAdgewECxgOql+gu+wInZZbUY+TJbWyYxB1u9LaJhxW0JAptU3yR0Rtqe09fqKoBnmVyhiiR9RdrEIoopg3tJeX7AhkJ1jAcFCxCi5gAMC6lELZEYi63cYTRbDv+cB/pwEQ46eugxsiakuNvax+PJwvOwKRVHsyy1BY3Sg7xjl5uugRySEk9BsWMByUkntgAMAPh/JgtnA1ElK3bw+ekh2hw0K9XOBi0MmOQUTdSI1duH9IykMz2xPkwJTQ1hgS6gmNyubgoc5jAcNBhXm5wFXBBxsltU3YrIDubkSddSCnHCdLlTNUSm1LLBLRmQaHesKgU1fTsbS2CZtO2P/4f6LukFdZj20KmGtrCIeP0GnU9S1EHabRaBR/wLHiYK7sCETdZoUCzoicbnAoGxdEamfU6xAfor5eGGxPkKP6/lCeIoaqcv4LOh0LGA4sTuFdQQ/kVOBkSY3sGERdrrimEZtSlXVGcFgYGxdEjmBUbx/ZEbpc4qlKpBazPUGOpdFswQ9JebJjnJeLXofYQGWfdKWuxQKGA1PDAce3ico6S03UET8k5cFiVcI5kRauBp3ie3QRUceM6u0tO0K3+Ja9MMjBbDxRjIr6Ztkxzis+xANOWh6y0u+4Nziw4WHe0Cl8QpzVRwpQ22SWHYOoy5gtVnx/SFmFuUGhntAq/LOEiDomLsgD7s5OsmN0uTXJhahpZHuCHIdShk5x/gv6IxYwHJibsxP6KrxLVl2zBWuOFsiOQdRltqSVoLimSXaMC8KxqUSOQ6fVYLgKenD+UX2zBauPcklVcgzHC6txOK9KdowOYRuD/ogFDAc3Mlz5XUE5jITURIn78zA2LogcykgVzoMBKGM5SaKuoJQhU05aDQYGK3vOPup6LGA4uBEqKGCkl9QqYgkoovM5kleJfdnlsmNcEGcnLfqzcUHkUEZFKL/tcDaZZXXYkFIkOwZRt8qrrMfPycrovTyklxeMep3sGGRnWMBwcENCveCkVf7Y9Xe3pitq0kOis/n31nTZES5YfIgn9Dp+lRA5kggfVwS6O8uO0S3+sy0dZotVdgyibvPBjgw0W5TRZp7Sx092BLJDbHU6OBeDDgNUcPY0vaQWa48po5pMdDa7MkqxP6dCdowLNiHKV3YEIpJgpEpXI8kur8ePRzgXBqlTanGNouaOmxzjLzsC2SEWMEg1S6K9vz0DjWaL7BhEF8wqhCJ7XwDApBieHSFyRGMj1Vu8/GhHBhqa2Z4g9fnP1nQoo+8F0DfADUEeRtkxyA6xgEGYGK2OA5CCqgZ8p8AJEIl+PVaIE0U1smNcsEhfE8K8TbJjEJEEE6J84eykzmZkSW0Tlu3PkR2DqEsdyKnA9pOlsmN02BT2vqB2qPObhy5IXJAHAlQylvWT3Vlcx50UpclsxXvbT8qO0SlqKX4S0YUzGZwwTsW9MD7dk4WK+mbZMYi6zL+3psmOcEEmc/4LagcLGAQAmKySbuCV9c34Ym+27BhEHbby0CnkVTbIjtEpk3h2hMihXdovQHaEblPbZMFnezJlxyDqEptTi3E4r0p2jA4L9zahb4C77Bhkp1jAIADAlD7qORD5en82SmoaZccgOq/aJjM+2Z0pO0an+Jj0iA9R/gTARNR5E6P8YNSrtym5/MApFFQps8BM1MpsteI/25Q1z5aai6N08dT7rUMXZHiYN7xc9LJjdImGZis+3JEhOwbReX2xNxvldcrsojw+yg9ajfKXYCaiznMx6DAhSh09OM+myWLFBwod4kfU6n9HCpBRWic7xgWZHssCBrWPBQwCAOi0GlX1wvg+KQ8JWeWyYxC160RRNT7dkyU7Rqep6fOCiDpvZlyg7Ajd6n9HC5CQVSY7BlGnlNQ04p0typr7ItLXFTH+brJjkB1jAYNsLlVZtXPxL8dQ28QJPcn+NFuseH7NMVisSlnMrC0vFz3GRfrIjkFEdmB8lC88VdKDsz0vrD3O9gQp0kvrUlDVoKx9dzqHj9B5sIBBNiPCveFjUk8jJK+yAe9sUdaYP3IMn+zOVOSyqa0uiwuEk45fH0QEOOm0mKHyA478qga8vVlZZ7GJ1iQXYGtaiewYF0SrAa4aGCw7Btk5tkDJRqfV4PL+QbJjdKnvEk9hL7t+kh05XliNpbuVO3QEAGaxcUFEp7lCZW2Hs1l5KA97MtmeIGUormnEq+tPyI5xwcZH+SHIwyg7Btk5FjCojWsGhciO0OVeWHscNY3K6j5H6tQydCRZsUNHACDazxX9Arm0GRH9bmCIJ8K9TbJjdLsX1h5je4IU4aVfj6Nagfvq3CGhsiOQArCAQW1E+rpiUIin7BhdqqCqAW8rbAIjUqePd2UirbhWdoyLcuUA9r4gojNdq8ITIH9UWN2ItziUhOzc/47kY1t6qewYFyzU08j5tahDWMCgM1wzSH0HKN8fysNudv0kiZILqvCpwoeO6DQaXN5f3SsOEFHnXDsoGC56newY3e6HpDzsylDewSE5hqLqRry2MVV2jE6ZOyQUGi7PTh3AAgad4dLYAJhU2AhZvPYYKuubZccgB9TQbME/1hyDRSh36AgAjI7wgZ+bs+wYRGSH3I16h5l875+/cGgq2Sel7pvOTlpcFa/+XlzUNVjAoDOYDE6qXMKosLoRT/10BGaLVXYUcjD/WHMM6SXKHjoCANfEO8bBCRF1zo3De0HrACdQC6sb8cLaY7AqvChN6vL1vmzsVGjvoGl9A+Cl8uWYqeuwgEFnpcbJPAFgb1Y53uT4VepBH+/KxLqUItkxLlqIpxGT+/jLjkFEdizM24QJ0X6yY/SIjSeKsWRnpuwYRACAXRmlip6fZd5QTt5JHccCBp1VfIgn+ga4yY7RLb45kIsfDuXJjkEOYFNqMd7fflJ2jC5x/dBe0DnCqVUiuig3Dw+THaHHfLQzA+tVUKAmZcsqq8VTPx2FUhc4iw1wQ7zKFhCg7sUCBrXrTyPDZUfoNi+vT8GBnArZMUjFUotrsGh1suwYXcLVoFNtrywi6lrDw71VewLkbJ77ORkphdWyY5CDqmpoxt9WHlbkvBetuHQqXSgWMKhd0/sFIMhDnRP2WawCj686jLzKetlRSIXK65rwt5VJqG+2yI7SJa6KD4abs5PsGESkEI7UC6PRbMXfvk9CaW2T7CjkYMxWK57+6SiyyutkR+k0Txc9ZsYFyY5BCsMCBrXLSavFTcPV2wujor4Zj35/GHVNyq1ak/1ptljx+KojyK9qkB2lS2g1wA3DHOdghIgu3oy4QPi6GmTH6DGF1Y34+6rDaDJzknDqOW9vTsfuzDLZMS7KrSPD4WJQ38qH1L1YwKBzunZQMNxVfOY1tbgGi35O5kzi1GVeXX8CB3PVMzxpUrQfenm5yI5BRAqi12lxnYNNypd0qhIvr0uRHYMcxI+H8/Df/TmyY1wUb5Me1w/tJTsGKRALGHROJoOT6sembU4twesbU2XHIBX4eFcmvk9S1wSxN41g7wsiunBzB4fCRe9YZ1Z/OpKPr/dly45BKpeYW4GXflV+sezWkb3Z+4I6hQUMOq8bhvWCQafuXeWbA7mKXn6K5Ptib5ZqVhxpNSTUE8PCvGXHICIF8jIZcNNwxzu7+uamNPx8tEB2DFKpE0XVeGRlEsxKXXLkN76uBofrpUVdR91HpdQl/NycccUA9U+w82VCNv6zLV12DFKgZftz8PYW9e07d42LlB2BiBTs1lG94eWilx2jRwkAz69JxrrjhbKjkMqkF9fgvuWJqFbwiiOtbhvVG0YH66FFXYcFDOqQO8b0hl6nkR2j2y3dnYWPdmbIjkEK8u3BXLymwiFIQ0I9MTrCR3YMIlIwN2cnLBgTITtGj7MK4Jn/JWNTarHsKKQSmaW1uG/5QVTWN8uOctH83QyYO4RLs1PnsYBBHRLs6aL6uTBafbgjgz0xqEP+uy8Hr6w/ITtGt/jzePa+IKKLd93QUIR4GmXH6HEWIfDUj0ewLa1EdhRSuOzyOty3/CDK6pRfvACA20dHwNmJvS+o81jAoA67Y0wEXB1ksp2lu7M4sSed09LdmXh9kzr3kRHhXhjVm70viOji6XVa3O2gBVGzVeCxVYexIaVIdhRSqJMlNfjLfw+guKZJdpQuEejujGsHsfcFXRwWMKjDvE0G3OxAKxL8d38OXvr1OJdYpTO8v/0k/rNNXRN2nu6+idGyIxCRiszsH4Q+/m6yY0hhsQo89dMRrEnmxJ50YVIKq3H3soMorVVH8QIAFoyJgMGJh590cbgH0QW5ZWQ4vE2OMyHXykN5eHzVYdQ2KX/CJLp4TWYr/rHmGD7elSk7SreZFOOH+BBP2TGISEW0Gg3+OslxC6NWASxanYwfVLbMNnWfI3mVuPebg6hQwZwXrUI8jbgmPlh2DFIB3XPPPfec7BCkHAadFjqtFrszy2RH6TGZZXXYll6CsZG+8DA6TvGG2iqpacRD3x3CtvRS2VG6jU6rwctXD4SPySA7ChGpTLi3CQdyypFf1dDpx6jJOoqTy15Gyb5fkL/xKzSW5sNcV42s715D6YH1cA2Lhd7N64z7NZYX4tA/5sF74Hjo3byRu2YJTq39GHp3Hxj9w1CXfxIl+3+Be8TAi9nE89qWXgKNBhjaywsajfonRqfO2ZJajMd+OIzaJovsKF3qH1f2R4Svq+wYpALsgUEXbN6QUAR7ONaEXOkltZj/RQISssplRyEJkvOrMP+LfTicVyU7SreaNyQU0X6O2c2biLrfA5NjLur+br0HoN89r6PfPa/DrfcAeA8Yj8It3yD23jcRddOTOLX247Per2DzMrhFDLD93lCci9j73kLpwfUAgKId3yNw/JyLytZRH+7IwJM/HkEde3bSWXy8MwOP/nAYdc3qKl5MjvHDhGg/2TFIJVjAoAtmcNLigcmO1xW0ssGMB1Yk4psDObKjUA9ak1yAP//3AIpqGmVH6VY+Jj3umRAlOwYRqdiAYA9cGhtw0Y9jNTejNuc4jAFh0Hv6QatzgsHTHw1FZ34/N5blAxoNDF6/P69GAwhLM7ROelSe2Ae3yHho9T3X82zjiWLc9fUBnKqo77HnJPtW32TBE6sO4/0dGbKjdDmjXotHp/WVHYNUhAUM6pTp/QIxure37Bg9ziIE/rUhFYvXHkOT2So7DnUji1Xgrc1peHZ1Mpos6v9b/3VSNNycnWTHICKVe2Rqn4v+rKlKPQCPmGFwcvVCU0UxzPU1qC/IREPpKVgtbXs2FGxahqBJ17e5zGvAeGQufxWBE+aiLHEjTMHRyFr5JsoSN11UrguRWlyD+V/uw75s9ux0dHmV9bjz6/3YcKJYdpRucdfYSAQ5WM9t6l4sYFCn/X16LAw6x9yFVh3Ox73L1TUzNP2uuqEZj6w8hC8TsmVH6REDgj1w1UBOrEVE3c/fzfmie3GWH94C70GTodFq0euKu5D22bMo2LIMrmFx0Op+L440lLZMmunsE9Tm/r7DpiP6T8+iLv8kfIdOQ9GuVQi75n5Unki4qFwXqrK+GfcvT8SKg7k9+rxkPw7klGP+F/uQWlwjO0q3iPR1xS0OtIIh9QzHPPqkLhHubcKfRoXLjiFN0qlK/OmzvdieXiI7CnWhAzkVuPWLfdiZ4RgT1WoAPDatLyeUI6IeM3tQCIaFnTnZZkdYLWbU5qTA7bcJNz1jR6HfPa8jeOotMAVFtrltfV466gszcWLJE6hK3Y+slW/C2txy4sHa3IiazKPw6DMclvqWg8fW/3uSRQj8v/Un8OIvx9HsAL396HffJubivuWJqlpp5I8en94XTg56spO6j0YIIWSHIOVqNFtwwyd7cKqy87OKq8GsAUH4v6l9uEqJgtU3WfDutnR8c8CxzoRdHR+MZ2bGyY5BRA4mu7wON3+6F40XOByz8vgeVKYkIPya+1se58d3UZ9/Ek4md4TP+T/oXT1Rsm8tjP5hcOv9+8SdGd+8gqDJ18PltyJH/uZl8IwdBVNwFCqO7kT+xq/g3mcYes28s+s28gINDvXEC1cOQLAnu9urWV2TGW9sSlP9srqX9w/EP64ccP4bEl0gFjDoom1PL8H/sKZ8tQAAIABJREFUrUySHUM6P1cDnprRDxNjOMuy0uzPLscLvxx3uAnVPI1OWH7HGPi4ctlUIup5n+7JxLtbT8qOYVdMeh0euiQGcwaHyo5C3WBfdjkWrz2m+hN/7s5OWHHnGPiyfUHdgAUM6hKPfZ+EzWkcSgEAl/cPwt+m9oGnC3tj2Lu6JjP+vTUdKw6ekh1FisWz+uOyuKDz35CIqBuYrVbc/sU+pBSpc/z/xRgZ7o2nL+uHUC8X2VGoC9Q2mfHvLen4NtEx2huPTeuL64f1kh2DVIoFDOoSRdWNuHHpHlQ3cl1zAPB1NeCJ6bGY0sdfdhRqR0JWORb/cgx5Kj8L0p6pff3xyjXxsmMQkYM7XliN27/YBwubo2dw0evw4ORozBkSCi3nKVKshKwyvLD2OPKrHKO9ER/igSU3D+c+S92GBQzqMmuTC/DM6mTZMezKjH6BeGByNJePsiOltU34YMdJfH9I3WNPz8XbpMc3C0bD28SunUQk39ub0/CFg6z61BnDw7zwzMw49sZQmJpGM97ZkoaVDtTeMOl1+Gr+SPTyNsmOQirGAgZ1qad+OoJ1x4tkx7Arep0G1w3thQWje8OLB4zS1DSa8VVCNr7al4P6ZovsOFK9fPVATIsNkB2DiAgA0NBswc2f7kWOg81DdCGMei0emBSDeUPZG0MJ9mSWYfEvx1HgIL0uWi28rB+uGRQiOwapHAsY1KWqGppx49I9KK5pkh3F7rgadPjTyHDcNCIMrgan89+BukSj2YJvE09h6e4sVKp4qbKOmt4vAC9eNVB2DCKiNhJzK3DPsoMcSnIe/YPccf+kGIzs7S07Cp1FVlkt3tt2EhtOFMuO0uOm9PHHq9dyaCp1PxYwqMvtzijFg98eAness/M26XHHmAjMGRwKgxPXxu4uZqsVPx8twIc7MlBY3Sg7jl3wMRnwzR2j4cUJZonIDn28KwPvb8+QHUMRRkf44L6JUegf5CE7CgEorG7Akp2Z+OlwvkMW4XxdDVh2+yj2NKYewQIGdYtX15/A8oO5smPYtWAPI+6eEImZcUHQadkdtCttOlGE/2w7icyyOtlR7IYGwGtzBmFiNJf5JSL7ZBUC9y9PREJ2uewoinFpbADumRCJ3j6usqM4pIr6Zny2JwvLD+SiyWKVHUcKrQZ457ohGNXbR3YUchAsYFC3aGi24NbPE3gA2QG9vFwwd0goZg0M5pnxi1DTaMaa5AJ8l3gK6SW1suPYndtGheOByTGyYxARnVNJTSNu+Wwvyuo45K+jdBoNrooPxl3jIhDozknDe0J9kwX/3Z+Dz/dmobbJsefVumNMb9w7MVp2DHIgLGBQt0krrsGCr/ahodkxK9IXyqDTYnq/AMwbEoqBIZ6y4yjGiaJqfJd4CmuSCx1+cs72DO3lif/cMBROWg5ZIiL7tyezDA9+mwgrW6gXxKDT4vphvXDryHD4uLIrf3doaLbgpyP5+HhXJkprOd/b0F6eeO+GYexJTD2KBQzqVlxatXNiA9wwb2gvXNYvEC4Gnew4dqfJbMXGE0VYkXgKSacqZcexaz4mA76aPxJ+bs6yoxARddiHO07io52ZsmMokpNWg0tjAzB3SCiG9PKSHUcVcsrrsPLQKfx4OB9VDWbZceyCl4seX80fhQB3ti+oZ7GAQd3uXxtO4JsDnA+jM9ycnTBrQBBmDQxGbKC77DjSnSypxc9HC7DqcB4quKLIeWk1wL+vG4KRHJdKRAojhMD/rUzCjpOlsqMoWoy/K+YOCcXl/YO4AtoFMlut2J5eiu8ST2F3ZpnsOHZFqwFenzMI46M4rxb1PBYwqNuZLVbc+81BJPJM+UUJdHfGxGg/TIrxw/Awb4dYwcRsseJgbiW2pZdgW3oJcivqZUdSlHsmROLOsZGyYxARdUpVQzNu/TwBeZUNsqMonkmvwxUDgjB3SChi/N1kx7FrJTWNWJWUh++T8riKWTsenhKDW0aGy45BDooFDOoRJTWNuPXzBJRwvGCXcNHrMCbSB5Oi/TA+yhfeKlq2qqqhGbsyyrA1rQQ7M0pR08iump0xNtIHb80dDI2G41KJSLlSCqtx59f70WjmfFpdZUioJ64dHIIJUX7w5OThAIBGswX7ssux+kgBNqYWw8IJWNo1e1AInrqsn+wY5MBYwKAecyi3Avd8cxBmfil0KQ2A+FBPjIv0Rf8gd8QFuitqHe6qhmakFNbgWGEVdmWU4WBOhUOuod6VInxM+PiW4fAwsmFKRMq3NrkAz65OBr8ZupZOo8HgUE9MivHDhGg/9PYxyY7Uo8pqm7DjZCm2phdjT2Y5JwLvgFG9vfHWvMGcFJykYgGDetSKg7n4f+tPyI6hekEeRsQFuqNfoDviglr+t4deGlUNzTheWI1jBdUt/xdW4xSHhXQpb5Men9wyAr28XGRHISLqMp/tycK/t6bLjqFqvb1NmBjjh4nRfhgU6qHKg9STJTXYmtYyLPVwXhWLYhcg0teET24ZATdnzqVCcrGAQT3urc1p+DIhW3YMhxPo7oy4IHeEeZvg52qAn6sz/NwM8HNzhp+rAaYumNyrodmCktomFNc0oqSmEaW1TSipacKpynoWK3qAs5MW790wFPFchpeIVIiTgvccT6MTxkX5YUS4F/oFuiPK1xVOOuUVNHIr6nGsoApJp1rm0zrF+VQ6hSdHyJ6wgEE9TgiBZ1Yn45djhbKj0GlMep2toOHraoCzTgudVgMnnRY6jQY6LWCxAhYhYLEKmC1WNFkEyuqaUFLTiOKaRtQ2sfulLBoAL149EJfGBsiOQkTULaxC4Mkfj2DjiWLZURyOQadFnwA39Gvt3Rnojig/V+jtpKhhFQK5FfU4XtDSuzOlsKWnZzXn0bpoBp0W/7lhKAaH8uQI2QcWMEiKZosVD6xIxP6cCtlRiFThr5OicPvoCNkxiIi6VaPZggdWJOJgLlc2k02v06CPf0tRw9a787denX5uzl0+1KCh2dLSs7O2EcU1LSdPCqoacLywGilFNZz0u5u8cGV/zOwfJDsGkQ0LGCRNTaMZd329H+kltbKjECnaNYOCsfCyONkxiIh6RFVDM+76+gAyStl+sGfOTlr4n1bQ8HM1wM3ZCU5aDXS//XPSaqHRAGbrb707rQJmqxUNzVaU1jaipOb3ggULFD3vz+Mi8JfxUbJjELXBAgZJVVjdgDu+2o8irrNN1CkTon3x6rXxqpxsjYioPQVVDbjzq/0oqmH7gag7XB0fjGdm8uQI2R+2eEmqQHcj3po7GO6c0Zjogo2J8MErV7N4QUSOJ8jDiLfmDeaKCETdYNbAIDx9WT/ZMYjOiq1eki7G3w1vzxsMV4NOdhQixRge5oVXr42HwYkf40TkmGL83fCva+NhsJOJJInU4MoBQXhmZhy0Go3sKERnxU98sgsDQzzx1tzBMOlZxCA6n8GhnnhjzmAY+X4hIgc3PNwbr82OhzOLuUQX7Yr+QXj2chYvyL7x057sxuBeXnhj7iAY9dwtidrTP8gdb84dDBf2WCIiAgCMifTFW/N4EoToYsyMC8SiK1i8IPvHSTzJ7hzIKcf/fZeEumaL7ChEdqVvgBveu2EoPIx62VGIiOzO4bxKPPTtIVRztQqiC3JZXCCev6I/dFoWL8j+sYBBdikxtwIPf3cItU0sYhABQFygO96eNxheJoPsKEREdiulsBr3r0hERX2z7ChEijCjXwD+ceUAFi9IMVjAILuVdKoSD3/HMylEI8O98erseLgaONs+EdH5pJfU4K/LE1Fa2yQ7CpFduzQ2AItnsXhBysICBtm19JIaPPjtIRRVc513ckxT+/rjhSsHcLURIqILkF1eh/u+OYhCth+Izury/oF49vI4LsVOisMCBtm9wuoGPPTtIaSX1MqOQtSjZg8KwRMzYjmhFhFRJ+RX1uPebw7iVGWD7ChEduXP4yLwl/FRsmMQdQoLGKQI1Q3NePSHwziQUyE7ClGPuGNMb9w7MVp2DCIiRSuuacRflx9ERmmd7ChE0ul1Gjw9ox+uHBgsOwpRp7GAQYrRZLZi0c/JWJ9SJDsKUbfRAHj4kj64eUSY7ChERKpQ02jGUz8dwa6MMtlRiKTxMDrh/10Tj+Hh3rKjEF0UFjBIUYQQeGNTGv67P0d2FKIu52rQ4R9XDsCkGD/ZUYiIVMViFXh7Sxq+3sf2AzmeUE8j3pw7GBG+rrKjEF00FjBIkZYfyMUbm1JhtnL3JXUI83LBv2YPQpQfGxdERN3lf0fy8dKvKWiyWGVHIeoR8SEeeG32IHhzGXZSCRYwSLEO5lbgyR+PcJk0UrzRvb3x4tUD4WHUy45CRKR6h/Mq8dgPh9l+INW7NDYAz10RB2cnnewoRF2GBQxStOKaRjy+6jAO51XJjkLUKTcPD8ODU2K4BjsRUQ8qqm7Eoz8k4VhBtewoRN3itlHhuH9SNDRcyYxUhgUMUjyzxYrXNqbi28RTsqOcoSo9EfkbvgSsVgRMmAMnV0/k/vwhNBotwmc/BFNw2yWsMpa9jMqUvQi59DYEjL8WAJC7Zgmq0w4ieNqf4NV/LOryT6IyZS+Cp9woY5Ooixh0Wjw5IxazOBM4EZEUDc0WLP7lOH45Vig7ClGXcTXo8MzMOEyLDZAdhahbOMkOQHSxnHRaPD49Fv2DPfDKuhQ0mu1jXKu1uRGFW1egzx0vQevUMjTg+Hv/hz4LXoSlsQ5ZK99E3ztfanOf0MvvgnvMEFgbf1+zvqE4F7H3vYWMZS/Bq/9YFO34HuHXPNCj20Jdq5eXC168agDigjxkRyEiclhGvQ6LZw1AtJ8r3t9+EpxWi5QuNsANL109EGHeJtlRiLoNCxikGlcNDEYffzc8/dNRZJfLX++9JisZWr0z0j5dCK3eGeGzH4JGq4WTyR1OJndY6s/stmrwPHP1CY0GEJZmaJ30qDyxD26R8dDqORGTUl0WF4gnZ8TC1cCPXyIie7BgTAT6B3nguZ+TUcJ5MUih5g4OxSNT+8DgpJUdhahbcQ8nVekX6I6v5o/E3CGhsqOgubocjSWnEHP7YviNuhJ5v34GnfH3irhGq4PV3Hzex/EaMB6Zy19F4IS5KEvcCFNwNLJWvomyxE3dGZ+6mIteh2dm9sPiWQNYvCAisjOjI3zw39tHcRlrUhw3Zyf886oBeGJGLIsX5BC4l5PqGPU6PDE9Fm/OHQxfV3k9FZxcXOEWMRBaJz08+gxFXV4aLA2/9wwRVottaMm5+A6bjug/PYu6/JPwHToNRbtWIeya+1F5IqE741MXGhDsga/mj8TV8SGyoxARUTu8TAa8NnsQHr+0L5x5IEgKMCTUE1/PH4kZ/QJlRyHqMfx0JtUaH+WLZbePwpQ+/lKe3xTWD/VF2RBCoC4vHS6B4RBWC8z1NWiqKILOxb3Dj2VtbkRN5lF49BkOS30NANj+J/ul02hw59gILLl5GMejEhEpxLyhvfD5rSPRL7Dj39NEPUmn1eDu8ZF4/8ZhCPZ0kR2HqEdxFRJyCD8ezsPrG1NR22Tp0ect2vkDyg5tBqBBxPWPobmyBLlrPgKgQe/ZD8EUEo2SfWth9A+DW+8ByF2zBBXJOwGrFR6xoxB+9X0AgPzNy+AZOwqm4ChUHN2J/I1fwb3PMPSaeWePbg91XN8ANzx9WT/050SdRESKZLZa8cmuTHyyOwsWzvBJdiLc2wXPXdEf8SGesqMQScECBjmM/Mp6/L8NJ7A9vVR2FFIxZyct/jIuEjePDIOTlp3ciIiU7nhhNRb9nIyTJbWyo5ADM+i0mD86HLePjuBcF+TQWMAgh7M5tRj/2nAChdWNsqOQyozq7Y0nZ/RDLy925yQiUpMmsxUf7szAVwnZMLM3BvWwEeFeeHx6LCJ8XGVHIZKOBQxySPVNFny0MwNf789ht1C6aF4uejw8JQZXDgyWHYWIiLpRZlktXtuQit2ZZbKjkAPwNrW0L64YwPYFUSsWMMihpRXX4OV1KTh0qlJ2FFIgrQaYNTAYD0yKhpdJ3oo3RETUs7akFuONTak4VdkgOwqpkAbANYNC8MDkaHgYz79iHZEjYQGDHJ4QAj8dycf720+iuKZJdhxSiDERPnhwcgz6BLjJjkJERBI0ma34MiEbS/dkoqHZKjsOqUS0nyuenB6Lwb28ZEchskssYBD9pqHZgmUHcvD5nmxUN5plxyE7FePnigenxGBspK/sKEREZAcKqhrw9pY0rDteJDsKKZirQYcFYyJwy4gwOOk4SSdRe1jAIPqDyvpmfLonCysO5qLRzDMq1MLP1YB7JkThqvhgaDUa2XGIiMjO7M8px2sbUpFaXCM7CimIUa/F9UN74dZRveHlwuEiROfDAgZROwqqGvDhjgz8fLQAFr5NHJan0Qk3jQjDzcPD4WLQyY5DRER2zGIVWJWUh6V7MlFQxdXOqH16nQZzBofi9tG94efmLDsOkWKwgEF0HidLavHJ7kysP17EQoYD8XU14JYR4Zg7JAQmg5PsOEREpCBmixX/O1qAT3dncqJPakOn1WDWwCDcNTYSQR5G2XGIFIcFDKIOOlVRj6/35eDHI3mcrEvFgj2MuHVUOK6OD4azE3tcEBFR51msAr8cK8Anu7OQVVYnOw5JpNUAM/oF4i/jIxHmbZIdh0ixWMAgukAVdU1YfjAXyw+eQmV9s+w41EXCvU24fUxvXB4XyMmziIioS1mFwPqUInyyKxPpJbWy41AP0gCY0scfd0+IRLQfVy4julgsYBB1UkOzBasO5+HrfTnIY/dQRdJqgDERvpg7JBQTon05OScREXUrIQQ2p5bgk92ZOF5YLTsOdSNXgw6zBgZj3tBQRPi4yo5DpBosYBBdJKsQ2JVRhh+S8rAtvQQWK99S9s7bpMdVA4MxZ3AoQr1cZMchIiIHtONkKb49mIudGaVg00E9In1NmDekF64cGARXzqFF1OVYwCDqQqW1TfjfkXysSspDTkW97Dj0B0NCPTF3SCimxQZAz2EiRERkBwqrG/Dj4Xz8eDiPK5colE6jwYRoX1w/rBdG9faRHYdI1VjAIOoGQggcyKnA90l52JxajEYzJ/2UJcTTiOn9AjEzLhAx/hx7SkRE9ok9OpXH00WPa+KDMW9IKII92aOTqCewgEHUzWoazdiSWoz1KUXYnVkGMxsk3S7AzRnTYgMwo18ABoZ4yo5DRER0QUpqGvG/o/lYlZSPXPbotCs6jQbDw71wef8gTO8XwBXLiHoYCxhEPaiqoRlb0kqwObUYezLL2DOjC3mb9Jjat6VoMbSXFzSckJOIiBROCIF92eX46Ug+tqaVoLbJIjuSw4oP8cBlcYG4NDYQvq4G2XGIHBYLGESS1DdZsCuzFNvSS5CQVY7Cao57vRA6jQYDgj0wNtIHYyN9ERfkzlVEiIhItZotVuzNKsOmE8XYklaCCi7l3q00AAYGe+CSvv6Y2jeAk34T2QkWMIjsRFZZHRKyypCQXY792eWobDDLjmR3At2dMSbSB2MjfDGqtzfcjXrZkYiIiHqcxSpwMLcC29JKsP1kCbLLOcykK+i0Ggzr5YVL+vpjSh9/+Ls5y45ERH/AAgaRHbIKgZTCaiRklWN/TgWOFVahvM6xzrToNBpE+bliQLAH4kM8MCjEExG+XEediIjoj7LL67A9vRQ7TpbgYG4Fmi1s3neETqNB3wA3DAvzwvBwbwzt5QU3Zy59SmTPWMAgUoiCqgYcK6jG8cIqJBdU43hhtaq6j/q5GjAw2AMDQzwxMNgDcUHuMHH9dCIiogvS0GzBscJqJJ2qxOG8ln9lDnYSpD0sWBApHwsYRAqWX1mPlKIaZJfVIaeiHrkVdcgpr0dRdSPs8Y2t1QBBHkaEebmgt48rovxcEelrQpSvK7xMnBCLiIioO+SW1yEprxJJeVU4nFeJ9OJaWBzgEMCo1yLazw1De3lheJgXhrBgQaR4LGAQqVCj2YJTFQ3IqajDqYp6lNQ0oaK+GeX1Taioa275ua6pS2czN+l18HU1wM/NAF9XZ/i6Gmz//NycEexhRKinCwxO2i57TiIiIrpwdU1mHM2vwpH8KmSV1SG7vOUEiFJ7djo7adHbp+WESLS/K6J83RDl54pQTyNXJSNSGRYwiBxYs8WKivpm1Daa0WwRaLZaYT79f4sVZquA1SrgrNfC2UkHZyctjE66335v+dn423VERESkXNUNzcgub+nRmV1ej5zfChs55XXSJxc36XXwcTXAx2RAkIczovxaChXR/q4I9XSBTstCBZEjYAGDiIiIiIjOqbK+GaW1TahuaEZ1oxlVDWZUNza3/P/bz9UNv13e0Iy6ZgvOdpSh1QB6nRZ6nRZOOg0Mv/3saXSyFSh8XA3w/e1/H1NLb06jnidKiIgFDCIiIiIiIiJSAA5GJyIiIiIiIiK7xwIGEREREREREdk9FjCIiIiIiIiIyO6xgEFEREREREREdo8FDCIiIiIiIiKyeyxgEBEREREREZHdYwGDiIiIiIiIiOweCxhEREREREREZPdYwCAiIiIiIiIiu8cCBhERERERERHZPRYwiIiIiIiIiMjusYBBRERERERERHaPBQwiIiIiIiIisnssYBARERERERGR3WMBg4iIiIiIiIjsHgsYRERERERERGT3WMAgIiIiIiIiIrvHAgYRERERERER2T0WMIiIiIiIiIjI7rGAQURERERERER2jwUMIiIiIiIiIrJ7LGAQERERERERkd1jAYOIiIiIiIiI7B4LGERERERERERk91jAICIiIiIiIiK7xwIGEREREREREdk9FjCowzIzM6HRaLB9+3bZUdqoqqrC7Nmz4enpCY1Gg8zMTNmResTmzZuh0WiQm5srO0qX+fTTT+Hk5CQ7Bv0mIiICixcv7tLHfO655xATE9Olj0lE6sB2hn1RYztDNkd9TW+//XZceumlXfqYjvpaEgsYinH77bdDo9Hg73//e5vLc3NzodFosHnzZjnB7MB7772HXbt2Yfv27cjPz0dYWNgZt9m+fbvdNDqU9DerqqrCq6++iokTJyI4OBhBQUEYN24cXnnlFVRXV8uORwr06KOPYvfu3bJjENEfsJ3RPrYzug/bGZ2zePFiREREyI4h1bhx45Cfn4+QkBDZUaiHsYChIEajEW+//TaysrJkR+lyzc3Nnb5vamoqBgwYgPj4eAQFBUGn03VhMse1detWxMbGYvXq1bjrrrvwww8/4Ndff8XDDz+MHTt2IC4uDgcOHJAdky7AxbzPuoqbmxv8/PxkxyCis2A74+zYzugebGcolxBCepvCYDAgKCgIWi0PZx0N/+IKMm7cOAwePBhPPfVUu7dpr/tlTEwMnnvuOdvvGo0G77zzDm644Qa4uroiPDwc3377LSorK3HLLbfA3d0dUVFR+O677876HNOmTYOLiwuioqKwbNmyNtcXFhbi9ttvh7+/P9zd3TF+/Hhs3brVdn1rl6/Vq1djwoQJMBqNWLJkyVm3p7m5GU888QRCQ0NhMBjQv39/fP3117brIyIi8PHHH2Pjxo3QaDSYMmXKWfNOnDgRABAZGWm7XXp6OjQaDVJTU9s8Xq9evWy/p6amQqPRICUlxZbnueeeQ2RkJIxGIwYMGIAPPvigzfPV1NTgoYceQmhoKEwmE4YOHYqVK1farm89c3PJJZdAo9HYKui5ubmYO3cu/Pz8YDQaERUVhVdfffWsr8vpDh48iFGjRsFoNGLgwIHYuHEjgJYvl6ioKLz44ottbl9bWwsPDw988cUX7T5mUlISZs+ejTfeeAObN2/G/PnzMXr0aAwaNAjXX389fvzxR7zxxhu48sorkZ2dbbvfunXrMGXKFPj4+MDT0xOTJ0/G3r172zz2kiVLEBcXB6PRCB8fH0yaNKnd7n8NDQ2YM2cO4uPjcerUKQgh8Oc//xnR0dG2/e+pp55CY2Oj7T6tQxRWrVqFfv36wdXVFVOmTLH9naurq+Hu7t5mPwJa9hOtVott27bZbnf33XfD398fzs7OGDFiBH799dc2t9doNFi+fDlmzZoFk8mEqKgofPrpp20e93z7w9m0bsPXX3+NqKgoGI1GTJ8+/Ywze+vWrcP48ePh4uKC0NBQLFiwAKWlpbbrW7tsvvPOO4iIiICzszPq6+vP+pyHDh3CuHHj4OzsjD59+mD58uVn3OZ82zJ+/Hj85S9/OeN+cXFxWLhwYZttO9369esxceJEmEwm236Tnp5uu37ZsmUYMmQIjEYjIiIi8Mgjj6C2tvacryERXTi2M9jOOBt7amdMmTIFd955JxYuXIiAgAB4eXnh6aefhtVqxT/+8Q8EBgbC398fTz/9dJvn68jrmpGRgRkzZsBoNCIsLAzvvvsupkyZgrvuust2G7PZjOeffx7R0dFwdnZGaGgoHnjgAdv1b731FoYMGQI3NzcEBQXhxhtvRH5+fodf01a7d+/GpEmT4OLiAm9vb9x8880oKioC0DLc9plnnkFWVhY0Gg00Gk2b997pWt8LP/300zmfLy0tDXPnzoWXlxe8vb0xY8YMHD582HZ96xDfTZs2YejQoXB2dsb69evP+pxlZWW2931gYCAWLlwIIcQZt3vnnXfQr18/GI1G9OnTB//85z9hNpsBAE8//TRiY2PPuM+9996LCRMmtNm209uQ6enpmDdvHnx8fGAymTBo0CD873//s12/f/9+zJgxA25ubvD398ecOXNUWbBVPUGKMH/+fDFt2jSxdetWodFoREJCghBCiJycHAFAbNq0SQghREZGhgAgtm3b1ub+0dHRYtGiRbbfAYjAwEDx6aefitTUVHHvvfcKo9EoZs6cKZYuXSpSU1PF/fffL0wmkygpKWnz2MHBweLLL78Ux48fF08//bTQarXiwIEDQggh6urqRFxcnJgzZ45ISEgQqampYvHixcJgMIjk5GQhhBCbNm0SAERsbKz48ccfxcmTJ0VOTs5Zt/vRRx8VPj4gvbmwAAAgAElEQVQ+Yvny5SIlJUX885//FBqNRqxfv14IIURRUZG4/vrrxcSJE0V+fr4oLS094zHMZrNYtWqVACD27t3b5nbh4eHi/fffF0IIkZaWJoxGo3BzcxMpKSlCCCHef/99ERoa2ubvEB8fL3755Rdx8uRJsWzZMuHp6SmWLFkihBDCarWKKVOmiMmTJ4tt27aJ9PR08cEHHwi9Xm/LfODAAQFAfPfddyI/P18UFRUJIYS46qqrxLRp08TBgwdFRkaG2Lhxo/j666/b3SdaX8eYmBjx008/ieTkZHHHHXcIk8kk8vLyhBBCvPjiiyIqKkpYrVbb/ZYsWSK8vb1FfX19u489ceJE8dZbbwkhhCgsLBTXXXedCAwMFMOHDxefffaZ6N+/vxBCiCeffFLccccdtvutXLlSfPPNN+L48ePiyJEj4s477xTe3t62fWjfvn1Cp9OJzz77TGRmZoqkpCTx0Ucf2f7+S5cuFTqdTgghRFlZmRg/fryYNGmSKC8vF0IIYbFYxFNPPSV2794tMjIyxKpVq0RQUJB49tlnbRkWLVokTCaTuOyyy8S+fftEYmKiGDZsmJgwYYLtNn/5y1/ElClT2mzzwoULRVxcnO33efPmid69e4u1a9eK5ORk8eCDDwq9Xi+OHTsmhPj9/RAZGSm++eYbkZqaKp588kmh0+ls+09H9oezad2G8ePHi4SEBLF3714xatQoMXToUNvfcsOGDcLFxUW8/fbb4sSJE2Lv3r1iypQpYtKkSbbbzJ8/X7i7u4trr71WJCYmiqSkJGE2m894vrq6OhESEiIuv/xykZiYKHbu3ClGjBghXFxcxAsvvNDhbfnggw+El5eXaGhosD32nj17BADba7Jo0SIRHR1tu37dunVCq9WKhx56SCQmJopjx46JJUuW2F7npUuXCi8vL/H555+L9PR0sWXLFhEfHy/+9Kc/tfv6EdGFYzuD7Yw/ssd2xuTJk4WHh4f4+9//LlJSUsTHH38sAIiZM2eKxx57TKSkpIhPP/1UABA///zzBb2ugwcPFqNGjRJ79uwRBw8eFJdffrnw8PAQd955p+1xbrvtNuHv7y8+//xzkZaWJnbt2iVef/112/VvvvmmWLdunTh58qTYuXOnGDt2rJg0adIFvab5+fnC3d1d3HTTTSIpKUls27ZNxMfHi4kTJwohWt4Djz/+uOjVq5fIz88X+fn5orq6utN/w4KCAhEYGCjuuecekZSUJI4fPy7uv/9+4ePjY9t3li5dKjQajRg5cqTYuHGjSE9Pt133R9dee62Ijo4WGzZsEEeOHBG33HKLcHd3F9OmTbPdZtGiRSI8PFysXLlSnDx5UqxevVqEhYWJhQsXCiGESElJEQDE7t27bfdpaGgQ3t7e4oMPPmizba3v7fz8fBEQECCmTZsmtm3bJtLS0sQPP/wgVq9eLYQQ4ujRo8LV1VU8++yz4tixYyIpKUnMmzdP9OnT55z7KtkfFjAUorVhIUTLB8PkyZOFEBfXsHjooYdsvxcVFQkA4v7777ddVlZWJgCIn376qc1jt364tBo7dqztYGLp0qUiNDRUNDc3t7nNJZdcYnu+1g+czz///JzbXFtbKwwGg3j33XfbXH7ttdeKSy655KyvTXu2bdsmAIiMjIw2l8+fP19cd911QgghPvzwQzF16lRx+eWXi/fee08IIcT1119v27aTJ08KjUZjO7Bq9fzzz4vBgwfbts3Z2VlUVFS0uc2CBQvENddcI4Q482/WatCgQW3+RufT+jq2fvkKIURzc7MIDw+3/Y0KCgqEXq8X69ats91mzJgx4sEHH2z3cdPT00VgYKBoamoSQggxc+ZMcdlll4m9e/eKtWvXipiYGNG7d28hREtjLCgoqN3HslgswsvLS3z55ZdCiJYCh4eHh6isrDzr7VsLGNnZ2aJ///5i9uzZ5/1Sef3110VMTIzt90WLFgmdTtfmi3XZsmVCo9HYHmv//v0CgDhx4oQQoqXxGRoaamuEpKamCgC2L71WQ4cOFQsWLBBC/P5+eO2112zXm81m4ebmZmusdmR/OJtFixYJACI1NdV2WeuXeWsDdfLkyeLxxx9vc7+srCwBQBw8eFAI0bJ/e3p6ttuwafXRRx8JV1dXUVZWZrvs8OHDAoCtgNGRbSkvLxdGo1EsX77cdv1f//pXMWbMmDbbdnoBY8KECeLKK69sN1vv3r1t78dWW7ZsEQDa5CWii8N2xu/YzhC257K3dsbkyZNtr0Wr/v37i4EDB56xrX/729+EEB17XX/99dczvndLS0uFi4uLrYDR2jZYsWLFOV61tlqLSbm5uUKIjr2mCxcuFKGhoaKxsdF2m8TERAFAbNmyRQghxAsvvGB7jc6lI8+3aNEiMXr06Db3s1qtIioqSrzxxhtCiJb3HQCxdevWcz5f62v066+/2i5rbGwUISEhtvdQbW2tcHFxEWvWrGlz388++0x4enrafh89erS47777bL+vWLFCGI1G20mtPxYwFi5cKAIDA0VNTc1Zs82fP1/ccMMNbS5raGgQLi4u4vvvvz/ndpF94XT/CvTKK69gwIAB+PHHHzFs2LBOP87gwYNtP/v7+0On02HQoEG2y7y9vWEwGGxd1lqNHTu2ze/jx4/Hhg0bAAAJCQkoKCiAl5dXm9s0NjbCxcWlzWWjRo06Z760tDQ0NTVh0qRJbS6fPHkyXnrppfNsXcdccskleOyxxyCEwMaNGzFt2jTo9Xps3LgRd999NzZv3oyXX34ZALBv3z4IITBixIg2j2E2m23jYRMSEtDU1ITQ0NA2t2lqakKfPn3OmeXhhx/G3XffjTVr1mDKlCm48sorz9j2szn97+Hk5IRRo0bh6NGjAIDAwEBcc801+Oijj3DppZfiyJEj2L17Nz766KN2H+/QoUMYOXIk9Ho96urq8MsvvyAnJ8e2Tc8++yyeeeYZAEBwcDDKysps983IyMCzzz6LXbt2oaioCFarFXV1dbbuedOnT0dUVBQiIyMxffp0TJ06FXPmzGkzJ4LVasXYsWMxfvx4/Pe//z1jbONHH32EJUuWIDMzE7W1tTCbzbBarW1uExISAn9//za/CyFQVFSE8PBwDBs2DCNGjMCSJUvwyiuvYM2aNSgpKcFtt90GAEhOTgaAM17/SZMmYdeuXW0uGzJkiO1nnU6HgIAAFBYWAri4/cHf37/NUIu+ffvCz88PR48exbRp05CQkIDdu3fj3//+9xn3TU1NteWKi4uDm5vbOZ8rOTkZcXFx8Pb2tl02cOBAeHp62n7vyLZ4eXnh6quvxhdffIHrrrsOzc3NWLZsGV544YV2n3v//v2299gfFRcXIysrC4888ggeffRR2+Xit66oaWlpGDly5Dm3jYguHNsZbGeczp7aGUDb/QoAgoKCEBQUdMZlrftVR17X5ORk+Pn5tfne9fHxaTOMoXU+jhkzZrS7bZs3b8ZLL72E5ORkVFRU2NonWVlZbf5m53pNjx49ijFjxsBgMLTZZk9PTxw9erRDf7M/OtfzJSQkYP/+/We0Ferr69sMfwJw3u/c1vbTuHHjbJcZDAaMHDkSNTU1tu2rr6/H3LlzodFobLezWCxoaGhAcXEx/P39MX/+fDzzzDN48803odfr8fnnn+Pqq68+473fav/+/Rg3bhxcXV3Pen1CQgLS0tLO2M6GhoYztpPsGwsYCtS3b1/cfffdePzxx7FmzZo217Ue7LU28FudbaIdvV5/3ss0Gs0ZB4fnYrVaERcXh++///6M60wmU5vf2/uA6UlTp05FcXExkpKSsGnTJjz00EPQ6/V49dVXcfjwYRQVFWHq1KkAYHsddu7ceca2tH4AW61WeHp6IiEh4YznOv2L6GwWLFiAmTNnYu3atdi0aRMuv/xyzJ49G19++eVFbeM999yDK664AiUlJViyZAnGjh2LgQMHtnt7s9lsawQ2NTVBCNHmb+Xu7m77+cCBA22+7GfNmgU/Pz+8++67CAsLg8FgwIQJE9DU1ASgZQLHffv2YceOHVi/fj3ef/99/P3vf8eGDRswfPhwAC378KxZs7By5UocPXoU8fHxtsdfsWIF/vrXv+Lll1/G5MmT4eHhgRUrVpwx1vWPr/Xpf5/TX5ennnoKixcvxpIlSzBnzhz4+vp27EU9z3O1Ps/F7A/nY7Va8fjjj+PWW28947rTG3Jd9T7r6LbcdtttmD17NoqLi7Fjxw7U1NTgxhtv7PRzAi1jii+55JIzrj99HDkRdR22M7oO2xlnuph2BnD2fehc+1VHXtc//twZ2dnZuOKKK3Drrbfi2WefhZ+fH3Jzc3HppZfa2kH2yGq1Ytq0aWc9IXL6iQydTgej0dglzwe0tOn69u17xvU+Pj4AgBtvvBEPP/wwVq9ejfHjx2Pt2rX44YcfLup5b731VjzxxBNnXNeZ9h/JwwKGQi1atAhffPEFPvzwwzaXt551zsvLs11WVFSEU6dOddlz7969G1dccYXt9507d6J///4AgBEjRuDzzz+Hh4cHAgICLup5YmJi4OzsjK1bt7b5ItyyZcs5vxjPpvVL3WKxtLk8LCwM0dHReOedd1BfX4+RI0dCo9HAbDbjrbfeQlRUFHr37g0AtgPs7OxszJo166zPM2LECFRUVKChoaHdjO1lAVrONCxYsAALFizAFVdcgZtuugn/+c9/4OHh0e627d692/b6m81m7N27t81B7dSpUxEeHo4PPvgAX3zxBf71r3+1+1hAy+uemJgIoOWM+uDBg7Fo0SLbkmavvfYagJYK+r333ovHHnsMAFBaWork5GT8/PPPuOyyywC0TBj2xzNrOp0OkyZNwqRJk/D888/bJkxrfX2BliXr9Ho9LrnkEqxfv97Wm2Dr1q0YOnQoHnnkEdttO7tk3Y033ohHHvn/7N13fFRV+vjxz51Jr6SHmkDoiPQQQAgBFAVFisIqsnZ31VVcFwu6fn8s66Kiu7qiuOCuCooiCkEQkCgEKQIGSOgB0gukh/Qy5fz+iIzEkJBAkkl53q9XXsnMbc+d3Enueeac5zzLihUr2LJlS7UCnQMGDLAc7/Jr/dLx66s+10NtsrOziY+PJygoCICzZ8+Sk5NT7b128uTJGjd216J///6sXLmSixcvWj7ZOHnyJAUFBQ0+l8mTJ+Pp6cnatWuJjIzk9ttvr9az47eGDRtGREQETz/9dI1lfn5+dO3alTNnzvDoo49exxkKIRpK7jPkPuOSlnKfca3q87r279+/xv/d/Px8zp49a9n+Um+kiIgI7rrrrhr7iIqKoqysjHfeeceSoDl8+PAVj1fXazpgwAA+/vhjKisrLb/Lo0ePUlBQYPmd29nZXfH3W5u6jjd8+HA++eQTunTpct0JikvH+Omnn7j55puBqiRVVFQU/fr1s5yfg4MDCQkJ1d7nv+Xh4cEdd9zBp59+SkpKCp6enpb7yysZNmwYH374ISUlJVdMXg4fPpxjx44RFBR03ckqYWVWGroiGuhK4y+XLFmiHB0da4xzHDNmjBo6dKiKiYlRhw4dUpMnT1ZOTk41xqZ++umn1fan1+vVxx9/XO05e3t79eGHHyqlfh2b2qlTJ7VmzRp15swZ9corryhN09Thw4eVUkqVlZWpAQMGqOHDh6vt27erxMREdeDAAbVkyRLL+LLfjlmry3PPPVdnca3aXpvfysjIUDqdTr377rsqMzOz2tjRRx99VNnY2Kjbb7/d8tz06dOVjY2NeuSRR6rt56GHHlL+/v5q9erV6ty5cyomJkb973//U6+//rpSqmrM4KRJk1SvXr1UeHi4io+PV4cOHVLvvvuuWrlypVKqqi6Ei4uLev7559WFCxcs4/iffPJJtWXLFhUXF6dOnDih7r77btW1a9dqhbEud+l17NWrl9qyZYs6deqUeuSRR5Sjo6NKT0+vtu7SpUuVnZ2dcnd3VyUlJXW+VmazWfXs2VN9++23SimloqOjVVBQkNLpdMrFxUW9/PLLClBdunSxFFK6dF4+Pj5qxowZ6syZM+qnn35SN910U7Vrb+PGjepf//qXOnTokEpOTlYbNmxQzs7OlrGZlxfxVEqpZ599Vnl4eFiKyS1btkw5OjqqjRs3qri4OPXOO+8oLy8vdfmfst/WWFCq9rHJTzzxhLKzs1O9evWq8TrcfffdliKep0+frrWIZ13jwOtzPVzJpSKeY8eOVVFRUSoqKkqFhISowYMHW66HnTt3KhsbG/XnP/9ZRUdHq7i4OLVt2zb10EMPqdLSUqVU/d4bSlWNR/X391dTp05VMTExav/+/So4OLhGEc/6nsuf//xn1a9fP2VnZ6c2bdpU49wu//1s377dUsTz6NGjKjY2Vn388ccqNjZWKaXU6tWrla2trXr11VfV8ePHVWxsrAoPD1ePPfbYVc9LCFF/cp8h9xm/1dLuM5SqqoFxeVFNpZSaOHGiuv/++6s9N3nyZDV37twGva6DBg1So0aNUj///LOKiYlRU6dOVW5ubtV+R3PnzlU+Pj7q008/VXFxcernn39W77zzjlJKqaNHjypN09Tf//53lZCQoMLDw1WfPn2qvX/q85pmZGRYingeP368RhFPpZRat26dsrGxUT/99JPKzs6u9TWv7/E6duyobrnlFrV7926VmJio9uzZo1566SW1b98+pVTN+7O6TJs2TfXq1Uvt3LlTnTx5Us2bN69GEc/FixcrV1dX9d5771kKv3/xxRfq+eefr7avb775RtnZ2al+/fqpZ5999orndul9fv78eeXj46MmTpyo9u7dqxISEtTmzZstxVxPnTqlXFxc1L333qsOHjyoEhIS1M6dO9XTTz+t4uPj63VuomWQBEYrcaV/nmVlZapr1641bizOnDmjxo0bp5ycnFTPnj3V+vXrr1hc61pvLFavXq1CQ0OVvb29CgwMVGvWrKm2TU5OjvrjH/+oOnXqpGxtbVWnTp3U9OnTLRXEG3JjUVlZqV544QXLvvr161fjePVtpL3xxhuqU6dOSqfTWYqTKaXU559/roBqVaTfffddBdSozm00GtUbb7yh+vTpo2xtbZWXl5caN25ctaKFl6pDBwYGKltbW+Xn56cmT56sduzYYVln1apVKjAwUOn1eksRpieeeEL16tVLOTg4KE9PTzVlyhR14sSJWs/n0uv4zTffqKFDh1r+wF9eOOmS7OxsZWtrW60YUl02bdqkfH19qx3//PnzqqysTBkMBpWRkXHF7Xbt2qVuvPFGZW9vr3r37q2+/vrratfejz/+qMLCwpS3t7eyt7dXPXv2VK+99ppl+yv9g3zxxReVu7u72r9/v6qsrFSPPfaY8vDwsPxzX7Zs2TUnMC4VxVq6dGmNcykoKFCPPfaY8vb2VnZ2dmrYsGFq+/btluX1LWRXn+vhty6dw6effqoCAgKUvb29mjBhgkpISKi23u7du9XEiROVi4uLcnJyUn379lXz58+3FLer73tDqapCYyEhIcrOzk716NFDffHFFyogIMCSwGjIuVx6XX18fGoU2rvS7+e7775TISEhysHBQbm5uanx48dXu5kIDw9XISEhytHRUbm6uqpBgwapv/3tb/U6LyFE/ch9htxn/FZLvM+41gRGfV7XhIQENWnSJGVvb6+6dOmi3nvvPTVixIhqhWcrKyvVX//6VxUQEKBsbW1V586dqxWrfe+991SXLl2Ug4ODGjNmjNq2bdsVExhXe03379+vxo4dqxwcHJS7u7u65557VGZmZrU47rnnHuXh4aGAWouz1vd4SUlJ6t5777Xc83Tr1k3NnTvXct/RkARGTk6Ouvvuu5WTk5Py9vZWL774ovr9739f4z304YcfqkGDBil7e3vVoUMHFRwcrJYvX15tncrKSuXj46MAFRMTc8Vzu/x9fubMGTV9+nTl5uamHB0d1Y033litIPuxY8fUtGnTVIcOHZSDg4MKCgpSjz766BVnFxItl6bUFSbmFUK0KSdPnuSGG24gJiamRvGr2nzwwQcsXLiQ+fPnM3fuXEtxsFOnTvH++++Tk5PDunXrmjLsJrd161ZmzJhBamrqdXdFbkyLFi3is88+Iy4uztqhCCGEEFfVFu8zioqK6NKlC6+++ipPPfWU1eK4Hrt27SIsLIzU1FSpGyXaDN3VVxFCtFYVFRWkp6ezcOFCwsLC6n1TAfD4448TGRnJiRMnGDp0KLa2ttja2jJhwgTs7OyuWOyptSgtLSUpKYlFixYxd+7cFpW8EEIIIVqLtnSfsWnTJrZu3UpiYiIHDx5kzpw5aJrG7NmzmzUOIUTdpIinEG3YF198wUMPPcSAAQP4+uuvG7z9kCFDWL9+PUajkezsbDRNw8/Pr9UXP1q6dCmvvvoqwcHBvPHGG9YORwghhGiV2tJ9RmlpKYsXLyYpKQlnZ2eGDRvG3r178fPza/ZYhBC1kyEkQgghhBBCCCGEaPFkCIkQQgghhBBCCCFaPElgCCGEEEIIIYQQosWTBIYQQgghhBBCCCFaPElgCCGEEEIIIYQQosWTBIYQQgghhBBCCCFaPElgCCGEEEIIIYQQosWzaegGSimys7MxGAxNEY9owWxtbfHx8bHK3NxCCCGEEEKItkfal+1bQ9uYmlJKNeQAWVlZGI1GbG1trylA0XoZDAZsbGzw9fW1dihCCCGEEEKINkDal+1bQ9uYDR5CYjAY5OJqp2xtbSUzKoQQQgghhGg00r5s3xraxpQaGEIIIYQQQgghhGjxJIEhhBBCCCGEEEKIFq/BRTx/q/yB2xojDguHT7ZddR1/f3/69euHUgq9Xs9rr71GcHAwGRkZvPTSS3z00UccP36czMxMJk2aBMDatWuJiYnh9ddfb9R4hRBCCCGEEEI0Dmlfirq0yh4YDg4OREZGsmvXLl5++WX+8Y9/AFUX3kcffQTAyZMn+eGHH6wZphBCCCGEEEKIFk7al61Hq0xgXK64uBh3d3cAUlJSGDduHJWVlbzxxht88803hIWFsXHjxmrrDx8+3FIopKioqNpjIYQQQgghhBDtk7QvW7brHkJiDeXl5YSFhVFRUUFmZiYbNmyottzOzo4XXnihWpeetWvXAuDi4sLo0aP5/vvvmTJlCuHh4UyZMkUq3wohhBBCCCFEOyTty9ajVfbAuNTF56effmLt2rX86U9/QilV7+3nzp1rueC++OIL7rnnnqYKVQghhBBCCCFECybty9ajVfbAuNyIESPIzc0lJyen3tuMHDmSF154gX379mE2m+nXr18TRiiEEEIIIUTrZzSaKS4yUFxooLjIQGWlGaPBjMFgxmhQv3w3V/tuMJgxGhUaoNNpVV/6qp/1eg0bGx02djpsbX/9cnDU4+xqi7OLDS4utji72qLXa9Y+fdFOSPuyZWv1CYxz585hNpvx9PQkPT3d8ryzszPFxcW1bjd79mz++Mc/8uyzzzZHmEK0eMpsBGMxmMrBWA6mcpSpHExlVc+ZKqq+UIAGmq7q69LPaKBpoLMDG2ewcUazdQYbF7BxQrNxtO4JCiGEEKJOlRUmigoNFP2SoCgqvJSsqKSo0EBZqclqsTk46nH5Janh7GKLs2tVcsPdww5PbwdsbVtlx3LRAkn7smW77gRGfaalaWyXxigBKKVYtmwZer2+2jo33XQTy5YtIywsjPnz59fYx6xZs3j99deZOXNms8QshLWp8lyoyEVV5EJFPqoiDyryUJVV36kspCo50UQ0Pdg4ga0rmp0HOHih2XtXfXfwAQc/NPsOTXd8IYQQQlhUlJvIziwjJ6uc7MxysjPLKCpsuUUHy8tMlJeZyMmquUzTwK2DHV4+Dnj7OODlY4+3ryNOzq3+s9p2SdqXoi6aasjgHiA9PR07O7umiqfZbN68mW3btrF8+XJrh9KqVFZW0rlzZ2uHIeqgKgtQJWlQmo4qSfvl5/NVPSlaOp09OPqgOXVCcw4AlwA0lwA0OzdrRyaEEEK0WuXlJnIyy8jOLCcnq+p7S05WNBZHJz1ePg6WxIZfJydc3aSwYksj7UvRkDZmu0xLLly4kB07dvDFF19YOxQhrosylKAKz6EKz0JhAqo0DQxF1g7r2pkr4Jeki8r++dfn7TqguVyW0HAJRHPwtl6cQgghRAtWVmYkPaWE9JQSzqeWUFjQ9pMVV1JWaiItuYS05BLLc+4d7Ogc4EyXbs506uqMvb2+jj0IUT/Svmw+7bYHhrg20gPDulRZNqrwLKrgLKrwXFXPiqYc9tGS2XujdeiL1qEfmns/NAcva0ckhBBCWIXJpMhILyU1uZj0lBJyssqtHVKroGng4+9Il25VCQ3fjk5SLNQKpH0pGtLGlASGaBBJYDQvZSxF5R9H5R5FXTwFlfnWDqnlcvD9JZnxS1LD3sPaEQkhhBBNpqzUSEpiMSmJRaQll1BZabZ2SK2era2Ojl2c6NLNmcAgV1zdpc3THKR9KSSBIZqMJDCanirLQOXGVH0VngVlvYrfrZpLIDrvYWjew9GcOlk7GiGEEOK6VZSbiDtTwLnTBWReaAW1rVo5X38Hgnq706O3Gy6uUjujqUj7UkgCQzQZSWA0PqUUFJ7FnHMElRcDZRnWDqntceyI5j0MnfdwNNfu1o5GCCGEqDeTSZGSWMTZ0wWkJBZjNrXToaNW5tfRkZ593Qnq44ajY7ssI9hkpH0pJIEhmowkMBqPKk7BnLUflX0QKnKtHU77Ye9VlczwHS3JDCGEEC1W5oVSzp4uIOFMIeXl0huzpdDpoGugC737dyCgh6vUzGgE0r4UzToLyZRPjl/vLqrZ+sDAq67j7+9Pv379LI9nzJjB008/fcV1165dS0xMDK+//nq9Y9i0aRNvvPEGvr6+hIeH13s7ISqMJZzN2IWHc1e6eNxY63qqJB3TkVeaMTJhUZGLSo/AlB4Bzl3R+Y9D8x2NZuti7ciEEEK0c0UFlZyLLeDs6QIK8iutHY64ArMZkmSwNKQAACAASURBVBOKSU4oxt5BT88+btwwxJMOHvbWDq3NkPalqEur7P/k4OBAZGRkk+1/zZo1/POf/yQkJKTJjiHaDqUUqfkxnDz/HXGZezGaywnyGV1nAkNz7gzOXaEktRkjFTWUpGKOXwMJ69C8h6D5jUPzGICm6awdmRBCiHbkfFoJRw/lkpJYbO1QRANUlJs4eTSfk0fz6dbdhYFDPenSTT4QaY2kfdl6tKm79OjoaKZMmcL48eOZPHkyxcVV/wQyMjKYM2cOI0eO5G9/+5tl/Q0bNhAaGsq4ceNYvHgxAG+99RYHDx7kz3/+M4sWLaK8vJynn36a0NBQJkyYwN69e4GqzNsDDzxwxf2K9qHCWMKhpHV8tG8e6w8vIPbCDxjNVdOWJeb8TFllQZ3b63xHN0eYoj6UAZX9M+YTb2H6eQGmpA2oiovWjkoIIUQbZjYr4s8WEv5FApu/SpbkRSuXkljMlvUpfPVpPLEnL2IyyqwwbYG0L1ueVtkDo7y8nLCwMMvj+fPnM2XKFB599FE+/PBDhgwZQlFREQ4ODgCcOHGCnTt3Ymdnx+jRo3nkkUfQ6/X8/e9/5/vvv6dDhw7Mnj2brVu3smDBAvbu3cuiRYsYPHgwy5cvR9M0fvzxR86dO8fs2bPZv39/rfuV+hBtX1F5NtEpGzievoVKY8kV1zErI2cyIhncbXqt+9H8RkPiV4D8g2tRKnJRKd9gSt2C5jsaXdfbZBYTIYQQjcZgMHPmxEWOR+dSWGCwdjiikeXlVPBjxHl+3ptJ/xs9GTDIA0enVtnkalekfdl6tMp305W6+Jw6dQo/Pz+GDBkCgKurq2XZuHHjcHNzA6B3796kpqaSn5/P6NGj8fb2BmDWrFns37+fKVOmVNvvwYMHeeSRRwDo1asXXbp0IT4+vtb9ygXWdmUXxXM4+SvOZERiVsarrn/qQkTdCQy7DmgeA1D5jTvOTzQSZURl7saUuQfN80Z0Xaagdehr7aiEEEK0UqUlRk7E5HHqWD4VUpSzzSsrNXH4QDYxUTn07OvOjUM98fR2sHZYohbSvmw9WmUCo6Eur2qr1+sxmRrnn0ZT7Ve0LMm5hziUtI6UvMMN2i6z8Ax5JSl4OnerdR3Nb4wkMFo8hco7iinvKLh2R9flNjTvEVInQwghRL0UFlQS/XMO504XYJIpUNsdk0lx5uRFzpy8SFAfN0aM9sW9g8y40dpJ+9J62swdeM+ePcnMzCQ6OhqA4uJijMbaPyUfOnQo+/fvJzc3F5PJxIYNGxg9umZNgpCQENavXw9AfHw86enp9OzZs2lOQrQYZmXi9IXv+Wz/Y2w48kKDkxeXnDofUedyzWsY6B2vad/CCooSMZ9ejinqxaopcBs2C7UQQoh2pLzcxE8/ZvDlqnhiT1yU5IUg/kwh61bFsXfnBUpLrt6bV1iXtC9bpuvugVGfaWka22/HKE2YMIFXXnmFDz/8kJdeeomysjIcHR356quvat2Hn58ff/3rX5k5cyZKKSZNmsRtt91WY70HH3yQ559/ntDQUPR6Pe+++y729jJNUluWmH2QPedWkluSdN37is3YwZieD9X6ab2mt0PzGYHK2H3dxxLNqDwTc+x/IHUrusBZ6LwGWzsiIYQQLYTJaOZETB7RP+dQUSF1rkR1ZjOcPJrP2VMFDBzqyaDhXtjZ6a0dVosi7UtRF0018CPE9PT0al1bRPtSWVnZZsdhZRaeZc+5laTmRTfqfmcNfZNuXkNrXa4uxmI69lqjHlM0M7fe6Lvfjebe29qRCCGEsBKlFPFnCvl5XxZFhVKcU9SPg6OeocHe9B/kiV6vWTscq5D2pWhIG7Nd1MAQoi6FZZnsi/sfsRk7gcbv3nnqQkSdCQzc+4CDD5RnN/qxRTMpPIvp6D/QPAehC7wLzaX2uidCCCHanvNpJRzYnUl2Zrm1QxGtTHmZiZ9+zOR4dB7DR/nQq587mtY+ExlC1IckMES7VW4o5ufENcSkhmMyN90nJXFZezCY5mNbS60LTdPQfEejUr5pshhE86gq9nkMzX8cuu6z0WxdrB2SEEKIJpSfW8HBvZkkJxRbOxTRyhUVGojcfp7j0XmMm9QRHz+pkSbElUgCQ7Q7JrOBo6mbOJj4GeWGwiY/nsFUzrnMPfTvdEut6+j8xmCSBEYboVAZP2LKPYIu8G40/3HySYoQQrQxRqOZQ/uzOX4kF7OUuRCNKCernPAvEhk4xJPho32xtW0zcy4I0SgkgSHalfMXT/L9qbfIK0lp1uOeuvB9nQkMzdEP3HpCYVwzRiWalKEI87mPIHM3+p73y7ASIYRoI9JSitnzwwUKC6TOhWgaSsGxI3kkxhUxblJHugRIj04hLpEEhmgXDKYy9p77H0dTv0HR/B+VpOXFUFSejauDT63r6HxvwiwJjLanMA5T9CK0TpPQBcxAs5EuoUII0RqVl5vY/2MGZ08VWDsU0U4UFRrYsiGFXv3cGR3qh4OjNN2EkD5Jos1LyYtm9f5HiUkNt0ryAkBh5vSFH+pcR/MNBs22mSISzUqZUOnbMR16EXPOIWtHI4QQooES4wpZtypOkhfCKs6dLuDLVfGci5XrT4jrTuNt+KxxZ06YeV/tn1BfEhgYSFJSkuXx2rVriYmJ4fXXX691m3379rF8+XLWrFlTY9nnn3/OihUrgKopsBYuXHjFOXuvZt++fdja2hIcHNzgbUXjqzCWsPvsCk6kb7F2KACcvhBBcPd7al2u2TijeQ1G5UQ1Y1SiWVVexHxqGcpnFLqe89Bsna0dkRBCiDpUlJvYG5lBnDQchZWVl5nYuS2dc6cLGDuxI65ubfdDL2lfVj+GtC+ra/f9kM6fP8/bb7/Njh07cHNzo7i4mNzc3Gva1759+3B2dpYLrAVIyD7AjtPvUFzRcqYmzStJIaMgFn/3vrWuo/ndJAmMdkBl78dUcBpd74fQeQ6ydjhCCCGuIDmhiN0/XKC0xGjtUISwSE0q5qvV8Ywe70ffGzysHY64AmlfNq02N4TkqaeeYvPmzZbHgYGBlp+Lioq49957GTVqFAsWLMBsNpOTk4OLiwvOzlWfhLq4uBAQEADA9OnTefnllwkLC2PcuHEcOXIEgPz8fH7/+98TGhrKbbfdxsmTJ0lJSWHVqlWsWLGCsLAwDhw40HwnLSzKDYVsO/Ea38S83KKSF5ecvvB9ncs1z4Fg69ZM0QirqryI+cS/MJ37BGWqtHY0QgghfmEyKfbsuMB336RK8kK0SAaDmR+/v8CObWlUVpqsHU6bJ+3LlqVV9sAoLy8nLCzM8vjixYtMnjz5qttFR0ezZ88eunbtypw5c9iyZQtTpkzBx8eH4cOHM3bsWKZOnVptX2VlZURGRrJ//36eeeYZdu/ezdKlSxk4cCCrV69mz549/OlPfyIyMpL7778fZ2dnnnzyySY5b1G3tLyjbD3xD0oqri3D2RzOZEQyrvfj6HVXfutpmh7NNwSVHtHMkQlrURciMRWcQd/3j2guAdYORwgh2rWiwkq+/zaN7Mxya4cixFXFxRaSdaGMSVO64OMvRcKvh7QvW49W2QPDwcGByMhIy9cLL7xQr+2GDBlCYGAger2emTNncvDgQfR6PV9++SX/+9//CAoK4pVXXmHp0qWWbWbMmAHAqFGjKCoqoqCggIMHD3L33XcDMHbsWPLz8ykqKmr8ExX1opSZgwmf8fWRBS06eQFQZiggMafu7KnOd0wzRSNajNLzmKIXY077ztqRCCFEu5WaVMyGNYmSvBCtSmGBgY1fJnLscMu+B27ppH3ZerTKBEZdbGxsMJurZpowm80YDL/O0a1pWrV1Lz3WNI2hQ4cyf/58Vq5cyZYtW666jWgZSisvEh69kJ/iP0Yp68ww0lBXHUbiGghOXZonGNFyKCPmhC8wnV6OMlVYOxohhGg3lFIc2p/Fto0plJdLd3zR+pjNsH93JhGbU2VISROQ9mXL0uYSGF27duXo0aMAfPfdd9UusOjoaJKTkzGbzWzcuJHg4GAyMjI4duyYZZ0TJ07QpcuvjceNGzcCcODAAdzc3HBzcyMkJIT169cDVYVVPD09cXV1xcXFheLi4uY4TQGcv3iSzw48RnJu65qWMjH7IOWGwjrX0flJL4z2SmUfxBS9GFWWae1QhBCizSsvM7I1PIXDB3JQytrRCHF9EuOK2PB5Ink50ouoMUn7smW57hoY9ZmWpjndd9993H///YwfP54JEybg5ORkWTZ48GAWLlxIYmIiY8aMYerUqaSnp7No0SIyMjKwt7fHy8uLN99807KNg4MDEyZMwGg08s477wDw3HPPMX/+fEJDQ3FycmLZsmUATJ48mYceeojvvvuO1157jZCQkOY9+XbkaOomdp15H7NqfcW1TMrAmYxIBnW9s9Z1NN/RkPgV0Dp6lYhGVpqG6cgidH3/gM5rsLWjEUKINikro4zvv02juMhw9ZWFaCUK8isJX5vIuEmd6NXX3drhXBNpX0r7si6aUg3LN6enp2NnZ9dU8bQo06dPZ9GiRQweLA2ISyorK+ncubPVjm80VbIz9t+cPN+6awX4u/XlnpHv17mO6fibqPwTzRSRaJk0tG7T0AXMkO6FQgjRiE4ezeOnHzMxm6TbhWi7ho70ZsRoX2uHcVXSvhQNaWO2uSEkou0qKs/my6j5rT55AZBRGEteSWqd62hSzFOgUCnfYD75NspYau1ghBCi1VNKsXfnBfbuzJDkhWjzjhzMIXJ7Oia51kUbIj0wRINYqwdGbnESG468SHFFdrMfu6kEd7+XMT0frnW5MlVgOvA0mGQcowCcu6K/4S9o9h7WjkQIIVolk9HMzu/SSTgnlf1F+9KlmzM339EFOzu9tUO5ImlfCumBIdqU9Isn+DLqmTaVvAA4feEH6sofanp7NO8RzRiRaNFKUjHF/B1Vkm7tSIQQotWpqDCxNTxFkheiXUpLKWHTuiRKiqXei2j9JIEhWrT4rH2sP/wcFca2d8NRVJ5FWn5MnetoMhuJuFxFLqaj/0AVnLV2JEII0WqUFBvYtC6J82kyFE+0X7nZFWxcm0R+rkzVLlo3SWCIFut42hY2H1uEyVxp7VCazKnzEXUu19z7gr13M0UjWgVjCabjSzFnR1k7EiGEaPEu5lfwzZdJ5OVIo02I4iIDG79M5HxaibVDEeKaSQJDtEgH4lfzw+l/oVTbnkb0XNYeDHXUuNA0Dc13VDNGJFoFswHz6fcxp39v7UiEEKLFysoo45svkygqlG7zQlxSWWFmy4YU4s4UWDsUIa6JzfXu4J///GdjxGHxl7/85arr+Pv7069fP0wmE7169WLZsmXV5uOtS0ZGBi+99BIfffTR9YYqmoBSZnbGvsuxtM3WDqVZGExlxGXtoV/Hm2tdR+d3E6bU9vF6iIZQmOM/QxkK0QfOsnYwQgjRoqQkFvH9ljSMBpl9QYjfMpsUO7amU15m4obBntYOpwZpX4q6tMoeGA4ODkRGRrJ7925sbW1ZtWpVvbYzGo34+/vLxdVCGc2VfHtscbtJXlxy6nzdn6JrTv7gGtRM0YjLZeaVMfaJbUx4ejs3PxPBhdxS9h7LZOwT2wj90zaOx+fX2CYtq4QZC3cyaf52/vZRVY2TD8JjGfP4VlZ8c8ay3+eXH2qUGFXKJkyJXzfKvoQQoi2Iiy1g+6ZUSV4IcRX7IjM4dazmvUx7JO3L1qNVJjAuFxISQmJiIiUlJcyfP5/JkyczYcIEtm3bBsDatWuZN28eM2fOZNasWaSkpDBu3DgAYmNjmTx5MmFhYYSGhpKQkADAl19+SWhoKOPHj+eJJ54AICUlhZkzZxIaGsqsWbNIS0sD4KmnnmLBggXcfPPNhISEEBFRVdPAZDKxaNEibrnlFkJDQ+v9JmivTGYDm2P+H3FZe6wdSrNLzYumuLzuGVZ0UszTKrzd7fnxvVvZ+e5k7pvcg4+3xPF//41h0xsT+PSVsby04kiNbV784DDvPRvCD/+ezP97aDAAkUcy2PfBFH6IugDAP9ee5C+/G9BocarUzZiS1jfa/oQQorVKjCskcns65rY9AlWIRrNnxwXOnLxo7TBaFGlftmzXPYTEmoxGIzt37iQsLIx33nmHm266iX//+98UFBQwefJky4V07Ngxdu3ahYeHBykpKZbtV61axaOPPspdd91FZWUlJpOJ2NhY3n77bbZs2YKXlxf5+VVZyZdeeonZs2fzu9/9js8//5yXXnqJ1atXA5Camsr27dtJSkpixowZjBs3jnXr1uHm5kZERAQVFRXcfvvtjB8/noCAgOZ/oVo4szKx9fg/SMr92dqhWIXCzOkLPzCi+z21rqP5hED856CMzRiZ0Ot/zfEWlRro0ckVvS4DD1d7PFztySuqXhTOYDSTlFHM88sPkZVfzt8eGczoG3zR6zSMRjN6ncbppIt4utrj5+nYqLGqlE2Y0NAHzmzU/QohRGuRmlTMD1sleSFEQ/34/Xl0eo1efd2tHYrVSfuy5WuVCYzy8nLCwsKAqgzZ3LlzmTp1Ktu3b2f58uUAVFRUkJ6eDkBoaCgeHh419jN8+HDeeecdzp8/z+23306PHj3Yu3cv06ZNw8vLC8Cy3aFDh/j4448BuPvuu1m8eLFlP3feeSc6nY4ePXoQEBDAuXPn2LVrF6dOnWLz5qrhEEVFRSQkJLS7C+xqlFJEnHyzUXpemE2Kz988RUFuBV7+jtz9TB9LA7SywsTqV09QXmpCr9e4b+EAnN1s+WjRMUqLjNy3sD+efo7s25RG556uBPZv3j/gV01g2DqjeQ1G5TTOsANRfzHn8njinwcoKK5k61uT+CoyybLMRq9RaTBhZ6sHIKegnKNx+Xy+aBx2NnqmL9zJgZVTeej2Xty3eA+P3dmbZetjmX93P/70rwMM6N6Bx2f0bbRYVco3vyQxZjTaPoUQojW4kFZCxOZUzCYZNiJEQykFkd+lo9dp9OjtZu1wrELal61Hq0xgXBqjdDmlFB999BE9e/as9vyRI0dqLcAya9Yshg4dyg8//MA999zDW2+9dU3xaJpW47FSiiVLljBhwoRr2md7sTP2XU5faJyZFI7vy8bL35H7XhzAznXJHN+bzeBQPwBio3LxD3Th9oeDOPTDBQ5+d54+wzwJ7O9O0I0eHNuTTchtnchILmHMtC6NEk9D5JYkkVl4Fj+33rWuo/mNkQSGFQzu5clP/5nCVzuTeO3T4xSW/FrN3mhSluQFQAcXO4I6u9LNzwUAWxsdRqOZm0d04uYRndgdk8GwPl6s2hbHKw8M4rVPj1NcasDFybbR4lUpGzFroAuQJIYQon3Izijju29SMRoleSHEtVIKdmxLQ6fvSmCQq7XDaXbSvmw9Wn0NjEvCwsL473//i1JV/7yOHz9+1W2SkpIIDAzk0Ucf5dZbb+XUqVPcdNNNbNq0iby8PABLF58RI0YQHh4OwPr16xk5cqRlP5s2bcJsNpOYmEhycjI9e/YkLCyMTz75BIOhqrETHx9PSYnMuXy53WdXcCxtU6PtL+dCGZ2CqhqOXXq6En/81/F83p2cqCw3AVBaZMTZzRY7Bz2GSjOV5SbsHPT8uCGVcTO7Nlo8DXXqfESdyzWPG8G2/f1DsaZKg8nys7uLLS6ONhhNZi4WVZKaVYKnq3219R3tbfByt+diUSUlZQYqDCZsbKr+zCqlWLUtngduC6KkzIjBaKa0wkjFZcdoLObkjZhT2lcxXCFE+5SXU86W8BQqK2XciBDXy2yG77ekkZJYZO1QWgRpX7ZM190Doz7T0jSHZ599lr/+9a+MHz8es9lMt27dWLNmTZ3bbNq0ia+++gobGxt8fX155pln8PDw4JlnnmH69OnodDoGDhzIsmXLWLJkCfPnz+f999/H29ubf//735b9dO7cmcmTJ1NUVMSbb76Jg4MD9913H6mpqUyaNAmlFF5eXu220MqVHIhfzeHkdY26T/9uzsQeymXQWF/ORudRVvRrvQjvzo5kppTwxqMHQSmeWTYce0cbzCbFkcgMwu7qxqEdmaSdK2LX1ymMmdaFTt1dGjW+qzmTEcm43n9Er7vy21LT2aD5hKCuMmuJaDwxcfm8sPwQep2Gg52eD18cTVxaEXe8sANNg2V/rvpHs2pbHL27ujPqBh/+/ugQpi/cSaXRzP97cLBlX1/uSOKusAD0eh33TQ5i9v/9SP9Ad7zcHZokdnPS12Dvgc7vpibZvxBCWFtBfgVb1qdQUd74iWAh2iuzSRGxOY1b7+xKl4DmvRe+RNqX0r6si6YupZTqKT09HTs7u6aKp9V56qmnuOWWW7jjjjusHUqzqKyspHPnzte1jyPJX/Pj2Q8aKaJfKaXYtDKO9Lgi/ANd0Nto3PmHXgD89G06hXkV3Pr7HhzdnUXK2ULueOTX7mDhH5zl5nsD2fxhHLOf6cv6984y+5nGq01QX9MG/Z0g39G1LldFiZiiFzVfQKJ10/TobvgLOo/Gm/FECCFagqJCA5vWJVFcZLj6yqJZOTjocXK2qfpysfn1Z2dbHBz06HSg6TR0Og2dDqCqa7zZrDCbQZkVBoOZslIjpSVVXyXFv/5cWmKQQq3NwMZG4467A/H1b9yi41ci7cvq2lv7EhrWxmyVNTBE63U8bUuTJC+gamzYpYTFd6sT6DX418I6Simc3av+MDq721Je8mvvjPMJxbh72ePibkdZcdXzly9vTqcuRNSZwNBcu4NTJyg93zQBaDZg1wHs3EBni6bpQdOBpqdqxJkZlAmUCaXMYKoEQwFUFlQ9L1oWZcJ8ahnaoJfQXLpZOxohhGgUZaVGvl2fLMkLK9LrNbx8HPD2dcDHzwEPT/uqZIWTDXqbph2hrpSivNxEaYmR4kIDOVnlZGeWkZ1ZTqmV7t/aIqNRsf2bVGbc2x0X18ar1SXE9ZIeGKJBrqcHRnLuIcKjF1Y1fJtAYV4Fn752Ep2m0WuIB5PuCWTdO7HMfqYvZSVGVv/jBMZKM2azYs6z/fDtUlV858u3TzPzyd7Y2unZ+nE8Z4/kM+neAG4Y5dMkcdZFr7PlsXFf4VBHrQtz6hbMidcw/EazBZeuaA7eYNcBza7DL8kKdzQ7j6rvttfWVVApMxhLoPIiquIiVF6EygJU5UWozEeVZUFpuiQ5rMWuA/rB/4fm4GXtSIQQ4rqYjGa+XZ9Mxvkya4fSbuj1Gt6+l5IVjnj7OtDB0x69Xrv6xs2stMRIdmaZJamRk1VOSbEkNa6Ht68D02YHYmvbdIkpaV+KhrQxJYEhGuRaExgXS9P5/OCTVBilKNDVTOg7n0Fdp9W6XFXkYTr4LFDHW1dnC87d0FwC0VwD0VwCwakTWi31NZqDMhugJA1VnIQqSkIVJ0FJqiQ1motTZ/SDX0azcbZ2JEIIcc0iv0vn7OkCa4fR5vl3ciSghytdA13w8LJHp2t5yYr6Ki0xciG9lOSEIlISi6VmyjXo3tOVm2/vUmNmjMYi7UshQ0hEi1JpLOWbmL9K8qKeTl+IqDOBodl7onXoj7p48tcnHf3QOtyA5tr9l2RFR6smK65E09mCa/eqYTAdq56rSmqk/5LUSETlH4eKXOsG2laVpmM6+S76gc+1uGtDCCHqI/rnHEleNBEbW42uAS4EBLnSLdAFR6e283/CydmGoN5uBPV2w2xWZF4oIzmhiOT4Ii7mV1o7vFYhMa6IQ/uzGTHa19qhCCEJDNG0lFJsO76EvJIUa4fSalwoOE1+SRoezl1qXUfzG4NSRnSeg9G8hqA5dWzGCBtPVVKjqpcIHccDoIpTUXnRmHOjoSjBqvG1OQWxmOPXoO91v7UjEUKIBkmKL+LnfVnWDqNNcXG1IaCHKwE9XOnUxanJa1e0BDqdRsfOTnTs7ETIWD8u5leQnFBMckIRGemlNKxfevty5GAOHp729Ozrbu1QRDsnQ0hEgzR0CMm+uI/4ObHu6YZETSO738fong/Wulwp1WTd+FoSVXERlXcUlReNyj8JZvmkpDHo+jwq06sKIVqN/NwKwtcmYqiUqSeul06vEdTbjf43euDfycna4bQoZWVGzp4s4NSxPAoLpEDslej1GtNmN/7MJNK+FM1aA8Pj9IKGRXcV+f3eqnN5Xl4es2bNAiArKwu9Xo+XV1Vhuu3bt1/x4v/kk09wdHRkzpw5rF27lvHjx+Pv7w/AihUrmDdvHk5O1/ZHvKCggODgYGJjY9E0jaioKKZOnUpMTAydOnWisLCQ4cOHExsbi05XM7O9b98+li9fftU5hQFyc3MZOHAgS5Ys4YEHHrimeK9XQy6uMxm72Hr8700cUdvk5uDHQzetaRdJivpSpgrUxVOorP2onENSO+N66OzQD35FZiYRQrR4lRUmNnyRSIF09b8uru629L/Rgz79O7Sp4SFNQSlFWnIJJ4/mkZJYLL0yfsPJ2YYZ9zTuzCTSvqyuvbUvoWFtzFbXV8zT05PIyEgiIyO5//77+cMf/mB5XFvm7oEHHmDOnDkArF27loyMDMuylStXUlbWsErWJtOvDSd3d3f8/Pw4e/YsAFFRUQwcOJCoqCgADh06xJAhQ654cTXUpk2bGDZsGOHh4de9r6aWXRRPxMk3rR1Gq6XT2VBckW3tMFoUTW+PzmsI+n5PoB/5L3SBs8De09phtU7mSkyn3kUZS6wdiRBC1Eopxc7v0iV5cY00DQJ6uHDb9G7c82BPBg/3luRFPWiaRtdAF269sxv3PNSLIcHeODrprR1Wi1FaYmT7plQMhrbTI0ral62jfXlJq0tg/JbZbGbSpEkAnDhxAl9fX9LS0gAYMWIEpaWlLF26lPfff5/NmzcTExPD448/TlhYGCtXriQjI4OZM2cyY8YMACIjI7ntttuYOHEiDz/8MMXFxQAMGzaMxYsXM3HiRDZt2lQthhEjRlguqKioKP7whz9UexwcHIzJZGLRokXccssthIaGsmrVKsv2RUVFBpA/xQAAIABJREFU3HvvvYwaNYoFCxZgNl/5D0J4eDh/+9vfuHDhAufPn7c8HxgYyCuvvMLYsWOZNWsWOTk5AEyfPp2XX36ZsLAwxo0bx5EjR6779a6P0sqLbIp5BaO5vFmO11Zo6AjyGcPMoUt5YPQnuDpIoaTaaHYd0HWbhj74LXQDnkHzGGjtkFqf8mzMsStoYCc8IYRoNkcO5pCcUGztMFodB0c9Q4K9ueehntx6Zze6dXeRHp3XyNXNluAxvsx9pDeTpnSmY2cZdgOQk1XOvsiMq6/YSkn7suW1Ly/X6hMYOp2OiooKioqKOHjwIIMHD+bAgQOkpqbi7e1drevOHXfcweDBg/nggw+IjIzksccew9/fnw0bNhAeHk5ubi5vv/02X3/9NTt27GDQoEH85z//sWzv4eHBjh07LBfjJZdfYMnJyUybNo2YmBig6gIbMWIEa9aswc3NjYiICCIiIvjss89ITk4GIDo6miVLlrB3716SkpLYsmVLjfNMT08nMzOToUOHcuedd7Jx40bLstLSUgYNGsSePXsYNWoUb731azepsrIyIiMjeeONN3jmmWca4RWvm1Jmth5/lcLyzCY/VlvhbOfJyB7zeHjsGqYNXkyA1zA0rdW/NZuFpumremUMXIB+xFK0LreBTBNabyrvKCrlG2uHIYQQNaSlFHP4gPREbAg7Ox0jRvtw78O9CB7ji6ub1BRoLHq9RlAfd6bNDuSOuwLw69i4NSBaozMnLxJ3pm3OCiTty5bVvvytNtFKGjFiBD///DP79+9n/vz57N+/nwMHDhASEtKg/Rw+fJizZ89y++23ExYWxrp16yzZNqjKOF1JcHAwUVFRJCcn07VrVxwcHFBKUVxczLFjxxg6dCi7du1i3bp1hIWFceutt5Kfn09CQtUMC0OGDCEwMBC9Xs/MmTM5ePBgjWNs3LiRO++80xLH5d18dDqdJba77rqr2vaX3gyjRo2iqKiIgoKm/UMTlfQlqXnRTXqMtsLF3oeb+y/g4bFfMDroAelxcZ00Rz/0PX6HfuQ76ILmgq2rtUNqFczJGzHnn7B2GEIIYVFRbmLX9vNSe6Ce9HqNQcO8uOehngwd6YOtbZu4vW+xOnV1ZvrvujN5Wlc8vOytHY5V7fnhAoUX2+YQL2lftpz25W+1iYFwISEhHDhwgLS0NG677Tbee+89NE3j5ptvbtB+lFKEhoayYsWKKy6vrRBLjx49KCgoICIiguHDhwMwaNAg1q5dS9euXXFxcUEpxZIlS5gwYUK1bfft21ejW9+VuvmFh4eTlZXF+vXrAcjIyCAhIYEePXrUWPfy7euz78aSUXCG/fGfNNn+2woHWzeCu89lUJdp2Ojl05HGpunt0DrfguY3FpW+HXPaNjDJcKbaKcxn/os27B9ottJ7RQhhfXsjL1BSbLR2GC2epkGfAR0YFuLTqAUVRf0EBrnSrbsL52ILOPRTNsVF7W/mkspKMzu2pTFtdnf0+rY1TEnal9VZq315JW0iRRsSEsLXX39N9+7d0el0dOjQgR07djBy5Mga67q4uFjGHf328bBhw/j5558tmauSkhLi4+PrFcOwYcNYuXIlI0aMAGD48OGsWLGC4OBgAMLCwvjkk08wGKr+uMXHx1NSUlVALzo6muTkZMxmMxs3brRsc8mldY8dO8bhw4c5fPgwTz/9NBs2bACqxmlt3rwZgA0bNlQ770tdgQ4cOICbmxtubm71Op+GMpjK+O7EEsxKbjhqY6t3YGSPeTw05lOGBdwlyYsmptk4oguYjn7Em2idJ4PWJvK1TaMyH3PcamtHIYQQxJ8pIC620NphtHg9erly9++DCL25kyQvrEin0+jTvwO/eyCI0eP9cHBsf8U+szLKObQ/y9phNDppX1q/fVmb676jv9q0NM2hW7duKKUYNWoUACNHjuT8+fN06NChxrpz5szhueeew8HBga1btzJv3jx+97vf4e/vT3h4OO+++y5//OMfqaioAGDhwoUEBQVdNYbg4GDLuCaousCSk5MtF9x9991HamoqkyZNQimFl5eXpdDK4MGDWbhwIYmJiYwZM4apU6dW2/eGDRuYMmVKteduv/12HnvsMRYsWICTkxNHjhzh7bffxtvbm5UrV1rWc3BwYMKECRiNRt555536vqQNti/uI/JL066+Yjuk02y4scvtBHe/D2d7D2uH0+5odm7og+5Fdb4Fc/JGVOZeQPol/5bKPoDZeyg6n5r/mIUQojmUFBvYs7PtFgZsDH4dHRk93h9ff6nB0JLobXQMHOJFnwEdOHool5ioHGqpmdgmHT2US7furo1W5FTal1Xae/uyNppqYAn6387TK6wvMDCQpKSkGs9Pnz6dRYsWMXjw4EY7Vm1z9BaX5/D9qbdIyo1qtGO1BX38JzAm6EHcnTpZOxTxC1WSjjlxHSovxtqhtDw2LuiH/QPNvuY/ZyGEaGpbNiSTlizTO1+JXq8RPMaXG4Z4otO1ra76bVFudjm7Is6Tk9V+hrC6udty131B2No1vIO/tC9bnuZsX0LtbcwrkT7VolG4OHgzY+jrHEvbzO6z/8HQzmsOuNh7M6n/X+juHXz1lUWz0pw7o7/hz5izDmCO+xSMMkWfhbEY87mP0N/wrLUjEUK0MyeP5jU4eZGQFEP4lqpP/woKs7ih3zh6dh/K9p3/RdN0jBx2B2Fj51bb5ov1r3L+wjkqDWXcMuFhhg2azNETO9n2w0r69xnNtNuexmCoYO2GfzBvzuJGO7/r4d/JkdBbOtHBo30XjGxNvHwcmP677hw7nMuh/VntojdGYYGBn37MIPRm+dBONC3pgSEapD7ZsYul59l+8g3OX2yfMxvc0HkK43r9AXtbF2uHIq5CVRZgjluNyjlk7VBaFF2vB9B1DLN2GEKIduJifgXrP0vAaLz24X2ffPESo0fMYP3mN3nm8Y+wt3PiH/+cxct/WY9O9+snwkZjJTY2dpSXl/DWe/P464IN/Hf1Ah6c+xofrl7AHx/8NxE7P6J/3zF06dSnMU7vmtnYaATf5MuAQdLrojXLy6nqjZGd2T4+3Lv1zq4E9GjYTHDSvhQN6YHRJop4ipalg1MnZg9/m5t6PYpe134KS7nY+zBjyOvc3P8vkrxoJTQ7d/T9n0LX70mZdvUy5oS1qPIca4chhGgHzGZF5Hfp15W8MBorSUo5Ts8ew/Dz6U55eTFGYwW2tvbVkhcANjZVjaRKQxkd/arGoOttbDGZTGhAcXE+FwuzrJ686NjZibvmBTFwiJckL1o5T++q3hjBN/mia2MzdVzJ7h8uYKhsB11OhNXoFy1atKghGxQVFaHXt78Ku6KKyWSqV6VZTdPo3OEGgnxGc+HiKUor85shOusZ2Pl2pg1ejLdLoLVDEddAc+6M5ncTVORCabq1w7E+ZYTyHHS+DZvrXAghGio6Kodzp69v1pGTsftQyszA/qHo9TZ88NFT/LhvLRPGziOg64Aa6/939QI2fPsvxo2ZQ9fOffHy6MzXm95k6I03E3P8B0YHz2BrxH9ISTtJr6Dh1xVbQ9nYaIwa589NE/1xcJSR3m2Fpml07OxEj55uZGeWt+lpgg0GMyazomtA/T/Mk/alqG8bE6QHhmhi3q49uGfkcoK734umtb3LzdXBl5lDlzKp/5+xt3G2djjiOmh2buj7PYmu35/Atnmng2qJVO4RzHlHrR2GEKINKy4yEH3w+nt7HTm6nWGDJgMQ/u3bvPLcRha/tI2DhzdRUlpQY/1Hfv8Wi17czLYfVmI2m+nWpR+P3f8vArregK2tA3EJhwkedjt6nQ0ZWYnXHV99uXewY+a9PbhhiCea1vY/qW+PPLzsuXNOIDcO9bR2KE3qRHQu+bkV1g5DtFFtr0UpWhy9zoYxPR9mzvB/08GpfmObWoPu3iHMC/mQAK9h1g5FNCKdzwj0w14Ft97WDsXqzHGfosyV1g5DCNFGHdideV1DRwBMJgPJqScI6j4UABsbWxzsnbC1sUOns8ForP43zPDLYzs7RxzsnasNMfnhx1VMCr2fisoyTCYDJrORiorS64qvvroGODPjnu54eEmhzrZOp9MYFerP+Mmd2uyQErMZ9kZesHYYoo267r5pn8X8rjHisLhv8No6l+fl5TFr1iwAsrKy0Ov1eHl5AbB9+/YrFoD55JNPcHR0ZM6cOaxdu5bx48fj7+8PwIoVK5g3bx5OTtc2b3FBQQHBwcHExsaiaRpRUVFMnTqVmJgYOnXqRGFhIcOHDyc2NrbGOEyAffv2sXz5ctasWVPncQwGA6+//jrffvstLi4u2NnZsWDBAiZOnMiwYcOIiIjAy8uLKVOmsHXr1ms6l9++No2tY4f+3Beykj3nVnI0dRNwfTct1jQi8F5G93wAnSbd3doizc4d/Y0vYI7/FHVhl7XDsZ7ybFTqFrSAGdaORAjRxpxPKyH+7PUNHQE4ffYAfXqOtNxjTQy9nzeXzUOn09Ov9yjc3Xw4eXoPlYYKhtw4if+u/gulZUWYTAZum/SYZT/xidF07tgbBwdnhtx4Mx999jzOTu7cOvHR647xagYN86qqjyC1LtqVPv070MHDnojNqZSWtL0hJedTS4k7U0DPPu4N3lbal9K+rEurG1zn6elJZGQkAEuXLsXZ2Zknn3yyzm0eeOABy89r166lb9++lhdx5cqV3HXXXQ26wEwmk2Wclru7O35+fpw9e5Y+ffoQFRXFwIEDiYqK4s477+TQoUMMGTLkihdXQ7z++utkZmaye/du7O3tycrKYv/+/TXWu9aLC2q+Nk3BVu/AhL5PE+QzmoiTb1Fckd1kx2oKNjp7bhnwHH38ZYaGtk7T2aDv9SBm526Y49eAMlk7JKswp25B8x2D5uhr7VCEEG2E2az4aVdGo+zrhn5juaHfWMvjkOHTCBk+rdo6Ay5b/vhDy664n6DuQwjqPgQAb8/OPP903Tf+jUGv1xh3c0d69+vQ5McSLZNfR0dm3tudiM1pZGWUWTucRndgdyYB3V2xtWvZnf6lfdm62pct+2qqB7PZzKRJkwA4ceIEvr6+pKWlATBixAhKS0tZunQp77//Pps3byYmJobHH3+csLAwVq5cSUZGBjNnzmTGjKpPGCMjI7ntttuYOHEiDz/8MMXFxQAMGzaMxYsXM3HiRDZt2lQthhEjRhAVFQVAVFQUf/jDH6o9Dg4OxmQysWjRIm655RZCQ0NZtWqVZfuioiLuvfdeRo0axYIFCzD/ZrLo0tJSPvvsM1577TXs7au6Fvr6+nLnnXfWeD0CAwMtP7/33nuW473xxhsApKSkMGbMGJ599lnGjh3L3XffTVlZWY3Xpqysaf+IBngNZ96o/9K346QmPU5jcrH3YfaIf0vyop3RdZqIfuBzYNNOZ5YxGzDHf2btKIQQbUjs8Xxys9v3+HgnZxumzQ6U5IXA2cWWO+4OoFe/hvdUaOlKio0cOtC6PqwEaV/+VktrX7b6BIZOp6OiooKioiIOHjzI4MGDOXDgAKmpqXh7e1fLfN1xxx0MHjyYDz74gMjISB577DH8/f3ZsGED4eHh5Obm8vbbb/P111+zY8cOBg0axH/+8x/L9h4eHuzYscNyMV5y+QWWnJzMtGnTiImJAaousBEjRrBmzRrc3NyIiIggIiKCzz77jOTkZACio6NZsmQJe/fuJSkpiS1btlTbf2JiIp07d8bVtf7TPEZGRpKYmMj27duJjIzk2LFjloxaQkICDz74IHv27MHd3Z1vv/22xmvj6OjYgN9C3UaOHIm7uzs9evSgtPTXsaQ6Zcf8mR/zf/+fvTsPj6pM8z7+PVVZKivZyEIIhEUhIBIJmASVEFnsILQItjgKTTtOu7Tj8Pa0ttI6tuKM2owzjLQb2IutM9O0INigCDohKNJAEAFBkGDYshCy76n9vH9Eo5AAWapy6py6P9fl1Z1U1cmvSFXlPPd5nvuZv5v//Nk+AOoqrfzq1k94fN4n1Fe175f925/v48QhbXcxGRR1FXdmvkpC5BWa5hDaUKLSME94CsJStI6iCbX2IO6az7WOIYQwAJvVxd6/6W9A40kJSSHMu2sY8YmeO9cS+hYQYOLGHySTPSUBo/Vv1WNDTxlfds1Xxpe6W0LSlUmTJlFYWMiuXbtYsmQJ27ZtQ1VVsrJ6tgXgvn37KCoqYvbs2UD7uqCJE7/bPmvu3LldPu7aa69l5cqVnD59mpSUFCwWC6qq0tzczBdffMGECRN44403OHLkCJs2bQLaq2InTpwgKCiIa665pqOyNW/ePPbs2cOcOXN68S/xne3bt7N9+3ZuvPFGAFpaWjhx4gTJyckMGTKEcePGAXD11VdTUlLSp591KW+//TaVlZU0NDQwY8YMHn30UX772/bpm0899RTx8fEUFRVx5agrOP5xMEePHWfCjQkAfLKhhKuuGwjA8HHRXst4OeOSbyZ39EOYTYGaZRDaUywDMac/gfvY66jVn2kdp9+5T7yNEpNuyN2EhBD9Z++uSqxW/1ySBzDiykim3jSIgAD5LBWdXZ0RS1RMMB+9V9LnBre+4tuGnnNuS9U6So/I+LIzXxlfGqKAkZWVxe7duyktLSUvL4+XXnoJRVGYMWNGj46jqio5OTmsWrWqy9svto5p+PDhNDQ08OGHH3a8IMePH8+aNWtISUkhPDwcVVV59tlnO37h39q5c2enrbIu/HrYsGGUlZXR1NTU7SqZqqr80z/9E4sXLz7v+2fOnOmYJgRgNpuxWq3dOublOF1unvvoGD++dihDY9r/rTZs2NDxe1i8eDHLly/vuH9+fj4LFy4E4JYfzuXogaOMHZ3DvsPbcTgdRMaE8s7KY9yz7GqP5OuNG664l4mpCzT7+cK3KGYLprQHcZ9ci1ra+/WAutR2FrXiY5QkWUIlhOid2morRw5qO6NSS6PGDGDKjEHSrFNc0pBh4cy6dQgfvFuCw+G+/AN0oLykleKiRkZcqZ9t6mV82fVz6e/xZVcMUf7Nyspi3bp1DBs2DJPJRFRUFPn5+WRmZna6b3h4eMe6owu/zsjIoLCwkBMnTgDtVaXi4uJuZcjIyGD16tVMmjQJgIkTJ7Jq1SquvfZaAHJzc3njjTdwOBwAFBcX09LSArRP8Tl9+jRut5t333234zHfCg0N5c477+Txxx/Hbm/f/qu6urrTWqnvy83N5c9//nPHczt79ixVVZeesnnhv01P/W7XKTYeOsvCNwv5y+clqKpKTU1NRxffpKQkGhu/6zje2NhIfHx7Y8CBAwdSW1vL8mWrqD8TRuUpJxExQcQmhfDe74r5zU/3cOarznu5e9ONo/9JiheiE0UxYR6+AJMf7szhPv0uqku2VRVC9M7O7RWoxrio3GNjro4mZ6YUL0T3JA0O4+b5QwkKNsRQDYDPdlWi6ugDQMaXnWkxvuxKn2dgXG5bmv4wZMgQVFUlOzsbaO+5UF5eTlRU58ZICxYs4JFHHsFisbB582YWLVrEHXfcQWJiIhs2bGDlypXcf//92Gzta7WWLl3KiBEjLpvh2muv7VjXBO0vsNOnT3e84BYuXEhJSQnTp09HVVViY2M7Gq2kp6ezdOlSTp48yXXXXcfNN9/c6fhLly7lueee4/rrr8disRAaGsovf/nLi+bJzc3l+PHjHccKDQ3llVde6ehu25UL/216sk7pSEUjb+xpX3Nldbh5If84n3xdTUjEAGpqaoD2F3lk5HeV14iICCorKwGoqqoiJiaG0NBQjh75ClVVSR2RzI9/ncbvn97Pj381lrf/6yuWvDix8w/3OIWZYx5mbPIP+uFnCb0yDZ0LpkDcJ9/WOkr/sdejln2IMmS21kmEEDpz5lQz5SWtl7+jAV09IYbsHO/t8CaMKSEphDm3DeX9d84YYtlVfa2dr481csXoyzcrlfFlO38fX16MovawFFZWVtblXrjCP9jtdpKTk8/7nsPl5q4/7eVkTUun+7cc/pjabW9QUXKamTNnMmrUqI4eGEuXLmXnzp188sknpKWl8fOf/5x7723fk/3JJ5+koaGBu+6+lVtumcsdD4/kLyu+4pFVnauenqRg4gfjljI68cbL31kIwF32kX/t0hEQhvna/0AJkOZzQojue3fNSc6dNd42kZczbkIMk6V4IfqgpsrKprWnsNn0v5wkKiaI2388otNyBhlfiq7GmBdjnHlJQjNvFZ7psngBEHZVDk2EEBwazlfHinjuuedIS0sD4Ne//jXl5eUMGDCAoKCgjuKF3W7nz3/+MytWrODa9KmEBw3ktccOk3vbUC8/E4WbrnpUiheiR0zJMzANv1PrGP3H2YJatlXrFEIIHSkrafHL4sXY8dFSvBB9FjvQ0r6cJEj/w7ZvZ2EI0RcyA0P0yIXVsfKGNm7/wx5szstXhWNCA/nVTaPJGTmwVz+7ouEYW798ntqWM716/OXMGPMwVyXneeXYwvjcJe/7z3IScyjma19ACQzTOokQQgc2rTvld8tHRl8VxZTpSZ2uNAvRW+fKW3l//RndN/bsahaGjC+FzMAQ/ebf84u6VbwAqG118PCGQzz9wRGabc4e/6zEAaO4K3MV1wyZD3j2hGBa2v+T4oXoE1PKzf7T2NPVirvsQ61TCCF0oKK81e+KFyNHRXLDNCleCM9KGBRK3twUTGZ9v67qa+0UyywM0QdSwBC99vHxKj4trunx4947XMGdbxSy70zPt1ILMAcxddTPuC3jBSItCT1+fFcmj/h7rh7ct32RhYD2xp7KoJ5tr6VX6tl8VLfsSCKEuLTP91RrHaFfxSeGyG4jwmuSBocxZXqS1jH6bN+eKl3tSCJ8ixQwRK9YHS7+Y9vxXj/+bKOVB/6yn//YVoTN2fPOyikx6SzMfp2xg/q2U8ioxBvJHH5Xn44hxPeZRvwdSvRVWsfwPkcT6rmdWqcQQviwqnNtlJzy7PZ5viw0LICZPxxMQICcXgvvGTUmiqsnxGgdo09kFoboC/mEFb3yu12nONto7dMxVGDNvlIWvbmXIxU9/xALDghj5thH+OH4ZwgNiu7x4xMiRzFzzMM9fpwQl6IoZkyjfwYhnpkh5MvcpVvlCooQ4qL8afaF2azwg1tSCAsL1DqK8AOZNySQkhqudYw+kVkYorf63MRz4N7PPRqoatKES95eW1vL/PnzAaisrMRsNhMbGwvA1q1bu2wA88YbbxASEsKCBQtYs2YNU6dOJTGxvSv0qlWrWLRoEaGhob3OXF1dzcKFC7Hb7Tz77LNkZWX16jhOp5Nx48Zx55138i//8i89fnxGRgYffvhhx7/H5VRUVPCrX/2KP/zhD51umzt3Lk899RTp6ennfd9ut+MIieLv/liI0+25Dx2zSeHuzKHcMzmVAFPP62pt9gb+7+gKvq7c0a37hwXFcGfmq4Rb4nr8s4ToDrW1HNf+ZeAydud909ifY4pNv/wdhRB+pbbaytq3Tmgdo99My0tm5OgBWscQfsRmdfHumpPU1+l3Oef0WcmMGDVAxpdd8KfxJRi8iWdMTAwFBQUUFBSwePFi7rvvvo6vL9a99ic/+QkLFiwAYM2aNVRUVHTctnr1atraejbAcLnOX/KwY8cO0tLS2LZtW7dfXBceA+Djjz9m+PDhbNy40WMVSVVVcbu7brKZmJjY5Yvrcl7+5IRHixcALrfK73ad4u//e99Ft2S9lJCgAcwZ/xQ3jX2M4IBL74xgNgUyJ32ZFC+EVymhgzCl/QxPN5z1NWrpB1pHEEL4oM8L/Wf2xTXXxknxQvS7YIuZm25JIShYd8O5DocP9rwfnjfI+LJnvDG+7An9vuK/4Xa7mT59OgCHDx8mPj6e0tJSACZNmkRrayvLly/n5ZdfZtOmTRw4cIAHHniA3NxcVq9eTUVFBfPmzePWW9t3DygoKCAvL49p06Zxzz330NzcvnYzIyODZcuWMW3aNDZu3Njx8w8dOsSyZcvYsmULubm5tLW1sX79enJycpgyZQrLli3ruG9qaipPPvkkU6dOZe/evZ2ey/r167n33nsZPHjwebdnZGTwm9/8hmnTppGTk8Px4+29J2pra/nRj37EDTfcwM9//vOOF+WZM2fIzs7mwQcfZMqUKZSVlfHUU08xZcoUcnJyePfddzvuN2XKFADa2tq49957ue6661i8eDFWa9fLQ+rbHGw/XtWL31T3HD3XxKI39/I/e8/06k02ZtAMFmX/niExF6+0zhjzMEkD0voSU4huMcVcjWn4Aq1jeJXa8BVq0ymtYwghfEhTo4MTRf6xvj11RASTJvdue3gh+ioqOpjpNw9GrxveVJS1UlvdtyXp3iDjy/4dX/aU7gsYJpMJm81GU1MTe/bsIT09nd27d1NSUkJcXNx5U3fmzJlDeno6r776KgUFBdx7770kJiayfv16NmzYQE1NDStWrGDdunXk5+czfvx4XnvttY7HR0dHk5+f3/FiBBg3bhyPPvoot9xyCwUFBTQ0NPDMM8/wzjvvsG3bNg4cOMDmzZsBaG1tJSMjg+3bt3eqpFmtVj755BNmzpzJrbfeyoYNG867PTY2lvz8fBYvXswrr7wCwAsvvEBmZiY7duxg1qxZHW8sgBMnTnD33XezY8cODhw4wOHDhykoKGDt2rU8/fTTnDt37rzjfzsNaufOnfzyl7/k4MGDXf57HzvX1JNfT6/YnG7+a/vXPPCX/Zxt6Pn0+wjLQOZNWE7uqIcIMFnOu21i6h2kJU33VFQhLss0OA8l4XqtY3iVu3SL1hGEED7k6KE6/GFpe0xsMLk/GCTbpQpNpQwNJztHv323jhzyjVkY3yfjy/4dX/aU7gsY0F4JKywsZNeuXSxZsoRdu3axe/fuHq8V2rdvH0VFRcyePZvc3Fzefvvt835pc+fOvewx9u/fz+TJk4mLiyMgIID58+eza9cuAMxmM7Nnz+7ycR999BHXXXcdISEhzJ49mw8++OC8aUA333wzAOPmDES4AAAgAElEQVTHj+fMmTMA7Nq1i9tuuw2AGTNmEBUV1XH/lJQUJk6cCEBhYSHz5s3DbDYTHx9PdnY2+/fvP+/nf/9YY8eOZcyYMZ0yNtuc1LT03zq7fSX1/N0bhWw8VN7jxyqKQvqQuSzMWtUx2yI17lquG/n3no4pxGWZrlgMESO0juE1anUhqt0/rrYKIS7N5VI5drhe6xheFxCoMPOHKQQFmbWOIgTjrollxKhIrWP0yvGjDbg9vDTdE2R82T/jy94I8MhRNJaVlcXu3bspLS0lLy+Pl156CUVRmDFjRo+Oo6oqOTk5rFq1qsvb+9KIBSA4OBizues/dOvXr2fPnj1kZGQAUFdXx44dO5g6dSpAx/ors9nc5fomT2ftSlWzzePHvJwWu4tntnzF9uPVPH7TaGLDul6HdjHRYYO5fdKL7D+9gbRB0zEpcqIh+p9iCsI8+j5c+54At36bbV2U6kKt/BvK4L5tayyE0L9TxU20tjq1juF1WTckMCCqZ+ckQnjT9bmJlJe00NZ6+XGCL7Hb3DQ1OrBYgrWOch4ZX3o+q6cYYgZGVlYW69atY9iwYZhMJqKiosjPzyczM7PTfcPDwzvWHV34dUZGBoWFhZw40d41u6WlheLi4h5lmTBhArt27aKmpgaXy8X69euZPHnyJR/z7fSk/fv3s2/fPvbt28fzzz/faZrPhbKzs1m/fj0A+fn51Nd3fcUjMzOTd999F5fLRXV1Nbt37+aaa6656LGOHj3KkSNHzru90erA6tDuA3FHcTV3/HEP245V9vixJsVMRupthAZFXf7OQniJEpKAaZhx+2G4z3VvByAhhLEd+aJW6wheNygllDFX93z7diG8yRISwJTpg7SO0SsNPriTiowvvT++7K0+z8C43LY0/WHIkCGoqkp2djbQ/g9aXl5+3pSXby1YsIBHHnkEi8XC5s2bWbRoEXfccQeJiYls2LCBlStXcv/992Oztc82WLp0KSNGdH/qd0JCAk888QTz5s1DVVWmT59OXl7eJR/z/vvvc/311xMc/F3l8Qc/+AHLli3ryNGVhx9+mPvuu48bbriBSZMmMXjw4C7vd/PNN/PZZ5+Rm5uLoig8+eSTJCQkdEwVgvZOukuWLOG6667jiiuuYPz48R23qaqqyeyLC9W3OXh042F+kJbAL6dfSYRF9loX+qIMuhGlei9qw1daR/G8llLUppMoEcO0TiKE0EhDvZ3yklatY3hVYKCJqTOk74XwTakjIrgibQDHjzZoHaVHrFYXToebgMD2a+syvjyfEceXfaGoPdzq4cJ9eoXxNbQ5KP+mmeaxs/WsPqj9h2J8RDBP/iCNzNQYraMI0SNqW+U3S0m0Lwp6mjJoGuaRP9Y6hhBCI4U7K9lv8O1Tb5iWyJir5dxD+C6r1cXaN4tpbdHPUq4rx8HQYVFERMrFSX9lt9tJTk7u1n0NsYREeFd/Nu7srsomGw+tPcBvPjqm6dIWIXpKCYk37NaqauVuVLdD6xhCCA2oqkrREWM370weEibFC+HzLBYzU6YnaR2jx2xWp0828xS+RwoY4pKabU5sTt8sEKjAugNl3PWnQg6Vaz8rRIjuUpJyUaI804nZpzhbUGs+1zqFEEIDpWdaaGnWzxXfngoMMpEzQ3+DQuGfhg6P4MoxA7SO0SOqCjarb445hG+RAoa4JF+cfXGhM3Vt/PR/P+eVHcU4XW6t4whxWYpiwnTl34PZonUUj1MrpJmnEP7o2JfGnn2RPSWBiEhZQi30Y3JOIqFh+tpw0ioFDNENUsAQF2V1uGi16+NqiktV+ePu0yz+78/4uqr58g8QQmOKZaAhdyVR675Edch7UAh/Yre7OPV1k9YxvCY5JYy0cbLriNCXYIuZG6bpa9aQ0+HG5ZJlJOLSpIAhLkoPsy8uVFTZzMqPv9Y6hhDdoiRNhbAUrWN4mBu15oDWIYQQ/ajkZLOhBx1ZU+K1jiBEr6SOiCBpcKjWMXpElpGIy5EChuiSw+Wm0aqP2RcXuv/64VpHEKJbFMWEadiPtI7hcWrNPq0jCCH60akTxp19MWJUJHHxIVrHEKLXMq/XVwHOZpMChri0Pi+Msv7k0nvQ9pTljQ8ueXttbS3z588HoLKyErPZTGxsLABbt27tcovXN954g5CQEBYsWMCaNWuYOnUqiYmJAKxatYpFixYRGtr76mR1dTULFy7Ebrfz7LPPkpWV1eNjPP/882RnZ5OTk8PcuXM5d+4cwcHBhIWF8eKLLzJy5MhuHeehhx5i5syZzJkzp8cZvq+2xU57m0x9mTEqnjGJkVrHEKLbTDHjUQeMRm34SusoHqPWHUZ12VHMsl5cCKNzu1VKThpz2ZjJBJMm62vwJ8SFEpJCGTYygpM6WebldLhlfIkxx5eeoq/OLkBMTAwFBQUALF++nLCwMB588MFLPuYnP/lJx/9fs2YNo0eP7niBrV69mttuu61HLzCXy4XZbO74eseOHaSlpbFixYpeH+Oxxx477/ZXX32V9PR03nzzTZ5++mneeuutbh+7r1RVpcGqv60QzSaF+2+Q2RdCf0zDfoTrwDNax/Actx21/jBK7AStkwghvOxsaSs2mzEbaKeNi2ZAlBRihf5Nui6eU8VNqPq7NtkvZHypL7pfQuJ2u5k+fToAhw8fJj4+ntLSUgAmTZpEa2sry5cv5+WXX2bTpk0cOHCABx54gNzcXFavXk1FRQXz5s3j1ltvBaCgoIC8vDymTZvGPffcQ3Nz+1WFjIwMli1bxrRp09i4cWPHzz906BDLli1jy5Yt5Obm0tbWxvr168nJyWHKlCksW7as476pqak8+eSTTJ06lb179573PB566CE2bdrU6fllZ2dz8uRJzpw5w5w5c5g2bRrTpk2jsLAQaC82PPbYY2RnZzN//nyqq6v7/G/aZHXi0uE+zHOvHsSQaH2t8xMCQIkciRKboXUMj1KrZTtVIfyBUZePBAQqTMgcqHUMITwiOiaYUWOjtI6hGzK+9Pz40pN0X8AwmUzYbDaamprYs2cP6enp7N69m5KSEuLi4s6rfM2ZM4f09HReffVVCgoKuPfee0lMTGT9+vVs2LCBmpoaVqxYwbp168jPz2f8+PG89tprHY+Pjo4mPz+/48UIMG7cOB599FFuueUWCgoKaGho4JlnnuGdd95h27ZtHDhwgM2bNwPQ2tpKRkYG27dv7/Y0oK1bt5KWlkZcXBxr164lPz+f119/nccffxyA999/n6+//ppPP/2Ul19+udMLtzfq2vQ3+8ISaOIfslO1jiFEr5mG3QYoWsfwGLX2AKpqzKuyQojvnC42ZgFjfEas7ragFOJSJmYPxGw2znmGN8n40vPjS08yxCfzpEmTKCwsZNeuXSxZsoRt27ahqmqP1wrt27ePoqIiZs+eDYDD4WDixIkdt8+dO/eyx9i/fz+TJ08mLi4OgPnz57Nr1y5mzZqF2WzuOPblPPDAA1gsFlJSUnjuuedwOp089thjfPnll5hMJk6cOAHA7t27mTdvHmazmcTERK6//voePecL2V1u3Wyd+n13ZgwhLjxY6xhC9JoSOgglcQpqxcdaR/EMRxM0HocBo7ROIoTwkppqK02N+rvocTmWEDNXT4jVOoYQHhUWHsi4CTEc2FujdRRdkPGl58aXnmaIAkZWVha7d++mtLSUvLw8XnrpJRRFYcaMGT06jqqq5OTksGrVqi5v70sjFoDg4ODz1iVdyrdrlL61fPlyBg4cSEFBAW63m5QU72y92KDD2RcDQgJZdO0QrWMI0WemobfiqvwbuPX3PuyKu/YLzFLAEMKwjDr7YkJmHEHB3TtfE0JP0ifGceSLOuwG7VvjSTK+9F26X0IC7S+wdevWMWzYMEwmE1FRUeTn55OZmdnpvuHh4R3rji78OiMjg8LCwo7qU0tLC8XFxT3KMmHCBHbt2kVNTQ0ul4v169czefLkPjy7dk1NTSQkJGAymVi7di0uV/sWQ1lZWbz77ru4XC7OnTvHzp07e/0zVBXqdVjAWDgxhfBgQ9TihJ9TgqNRkm7UOobHGGlnFSFEZ6cMWMAICTUzZly01jGE8Ipgi8wu6i4ZX3pmfOkNfR71XW5bmv4wZMgQVFUlOzsbgMzMTMrLy4mK6tysZsGCBTzyyCNYLBY2b97MokWLuOOOO0hMTGTDhg2sXLmS+++/H5vNBsDSpUsZMWJEt7MkJCTwxBNPMG/ePFRVZfr06eTl9X0roLvvvpu7776bt99+mxtvvLGjWnfzzTfz6aefcv3115OcnHzelKSearE7cbr0VZENMpuYe/UgrWMI4TGmQTfiKtuqdQzPaDqJ6rKhmGV5lxBG09LsoOqcVesYHpc2LhpzgCGu7wnRpbRx0Xy+pwq3D5/yN/1mPdDefDQgUJv3o4wvPTO+9AZFVXu2oU5ZWVmXe+EK/Surb6PxMtunHjtbz+qDDf2U6PJuHpvIU7PGaB1DCI9yHXoBte6Q1jE8wjTul5iix2odQwjhYUVH6inYWq51DI9SFLjznisIjwjUOooQXvV/75dSXNSodYwOV46DhMTwTt8PiwgkNFRmWfsDu91OcnJyt+4rJWYBgFtVabbpr3nnbende6ELoSfKoGlaR/AYteGY1hGEEF5QUd6mdQSPSx0RIcUL4RfGpsdoHaFbnHYfniYiNCMFDAFAi82Fu2eTcTSXlhDBVYMGaB1DCI9TYsZDsDHWqEoBQwhjOne2VesIHjd2vD4GdUL0VVJyKDFxvr+80+GQAoboTAoYAoAmm/6ad952jcy+EMakKCZMRmnm2VSMapBdVYQQ7ex2F3U1Nq1jeFRUdBDJQ8K0jiFEvxk73veb1brdKi6nFDHE+aSAIVBVlSarvpaPRFoCmDk6QesYQniNkjgFFAOs+3Q7oLFn3baFEL6t8mwbOpu0eVljdDCYE8KTrhgdRVCQ7w8FZRaGuJDvv2qF17XY9bd8ZM5VSVgCZY92YVxKUCTKwGu1juERauNxrSMIITzo3Flj9b8ICFC4ckznnQWEMLLAIJMuXvcO6YMhLiAFDKG72RcA86V5p/ADJoM081SbT2sdQQjhQUYrYFyRNoDgYLkoIvzPmKt9f+aRzMAQF+rz/ORZb3h2q7/NPxl3ydtra2uZP38+AJWVlZjNZmJj25vdbd26tcstXt944w1CQkJYsGABa9asYerUqSQmJgKwatUqFi1a1LHvbW9UV1ezcOFC7HY7zz77LFlZWT0+xvPPP092djY5OTnMnTuXc+fOERwcTFhYGC+++CIjR44kIyODDz/8sOP5eoKq6q//xYSUKFKie//7EkIvlMiREDoIWvW9VaHaUqJ1BCGEh6iqSqXBGnimjfP9QZwQ3hAdG0xScihny3zrPb34g689ejwZX/bv+NLbdLfAOiYmhoKCAgCWL19OWFgYDz744CUf85Of/KTj/69Zs4bRo0d3vMBWr17Nbbfd1qMXmMvlwmz+rlK/Y8cO0tLSWLFiRa+P8dhjj513+6uvvkp6ejpvvvkmTz/9NG+99Va3j90TVqcLl1tfy0emjhyodQQh+o0SOwFV5wUM2s6humwoZt/veC6EuLT6Wjs2m3GuiIZHBDAwIUTrGEJoJnVkhM8VMPqbjC/1RfdLSNxuN9OnTwfg8OHDxMfHU1paCsCkSZNobW1l+fLlvPzyy2zatIkDBw7wwAMPkJuby+rVq6moqGDevHnceuutABQUFJCXl8e0adO45557aG5uBiAjI4Nly5Yxbdo0Nm7c2PHzDx06xLJly9iyZQu5ubm0tbWxfv16cnJymDJlCsuWLeu4b2pqKk8++SRTp05l79695z2Phx56iE2bNnV6ftnZ2Zw8ebLj69/97ndMmzaNnJwcjh9vX1deV1fHj3/8Y3JycsjLy+PLL78E2t+AS5YsYe7cuUycOJHXX3+94zhr167lpptuYub0abyw7AlcLlfvfwn97IaRcVpHEKLfmGKv0TqCB6jQUqp1CCGEBxht+9ShwyO0jiCEpuQ90JmML/s2vszNzeUXv/iF18aXui9gmEwmbDYbTU1N7Nmzh/T0dHbv3k1JSQlxcXHnVb7mzJlDeno6r776KgUFBdx7770kJiayfv16NmzYQE1NDStWrGDdunXk5+czfvx4XnvttY7HR0dHk5+f3/FiBBg3bhyPPvoot9xyCwUFBTQ0NPDMM8/wzjvvsG3bNg4cOMDmzZsBaG1tJSMjg+3bt3d7GtDWrVtJS0vr+Do2Npb8/HwWL17MK6+8ArS/kMaNG8fHH3/Mr371K/7xH/+x4/7Hjx/nL3/5C1u3buWFF17A4XBQVFTEX//6V9577z3+e8NmTCYTH72/sdPP9kUj4sIYHCVXSoQfiRgOgZFap+gzWUYihDEYrf/F0BEyeBP+bUBUENGxMkPy+2R82bfxZUFBAWazmXXr1vXuF3AZultC0pVJkyZRWFjIrl27WLJkCdu2bUNV1R6vFdq3bx9FRUXMnj0bAIfDwcSJEztunzt37mWPsX//fiZPnkxcXPssgfnz57Nr1y5mzZqF2WzuOPblPPDAA1gsFlJSUnjuuec6vn/zzTcDMH78eN5//30A9uzZwx/+8AcAbrjhBurq6mhqagJgxowZBAcHExwcTFxcHFVVVezYsYODBw8yc+ZMbE43NquV6Bh9rHuaIrMvhJ9RFBNK7DWoFR9rHaVP1JYzWkcQQnhATZVV6wgeExhkYlCy9NQSYujwcOpqbFrH8Ckyvuz9+BLAarV25PU0QxQwsrKy2L17N6WlpeTl5fHSSy+hKAozZszo0XFUVSUnJ4dVq1Z1eXtfGrEABAcHn7cu6VK+XaN0oW+byJjN5m5Ny/l+0xmz2YzT6URVVRYsWMDPH3mMM3X6mgo6ZYQUMIT/MUQBo1lmYAhhBA31dq0jeMyQ1HDMAbqfjCxEn6UOj+DA3hqtY/gUGV9e3KXGl0888UQ3k/eeIT61s7KyWLduHcOGDcNkMhEVFUV+fj6ZmZmd7hseHt6x7ujCrzMyMigsLOTEiRMAtLS0UFxc3KMsEyZMYNeuXdTU1OByuVi/fj2TJ0/uw7O7vKysLN555x0Adu7cSUxMDBERF58SecMNN7Bp0ybOlJ8DoLGhnoryMq9m9ITYsCDGJOl/Kr0QPaVEjQFToNYx+kaWkAihe22tTuwGauApa/+FaDcwMYSQUNlK+PtkfNm78WVVVRXQ3kOjpMQ75359noFxuW1p+sOQIUNQVZXs7GwAMjMzKS8vJyoqqtN9FyxYwCOPPILFYmHz5s0sWrSIO+64g8TERDZs2MDKlSu5//77sdnap1EtXbqUESNGdDtLQkICTzzxBPPmzUNVVaZPn05eXp5nnuhFPPLIIyxZsoScnBxCQ0P57W9/e8n7jxo1iqVLl/IPi+/E5XITEBDA//vVUyQOSvZqzr66YUQcJkXROoYQ/U4xB6NEXYVau1/rKL3nakN1NKEEyoBBCL0y0uwLRYGUYeFaxxDCJ5hMCkOHR/DV4XqtowDwp7yRnb4XOSCIYEv/FVlkfNm78eXtt9+O2+0mMDCQ559/npSUFI9nU1RV7dEemmVlZV3uhSv0xeVWKapsBnq2heqxs/WsPtjgnVCX8Z+3Xi07kAi/5T77Me7jf9A6Rp+Yr3kKJWKY1jGEEL1UdKSegq0639b5G4NSQplzW6rWMYTwGaeKm9i6UZvZkleOg4TESxcUQ8MCCQs3RPcD0QW73U5ycvcuphtiCYnoOavDRU+LF1oKNCtMGhqtdQwhNKPEjNc6Qp+pNllfK4SeGWkGhiwfEeJ8yUPCMJt9d6azy2Wc5Wuib6SA4aesTu/sy+stVwwMxxIoa/OE/1KCoyA4RusYfWOt1jqBEKIPGuqMU8BIkt1HhDhPYKCJ+MQQrWNclMupnwuvwrukgOGn2hz6qmKOTpArJUIo4fpefiEzMITQN6PMwDCZFWLiLFrHEMLnxMX77vtCZmCIb0kBw0+1LyHRj7RE2X1ECCUiVesIfSMzMITQNaMUMGLign16qrwQWhmY4LszMFQVXC6ZhSGkgOGXXG4Vh86qmGkyA0MICE/VOkGfyAwMIfSrtcWJw66vc4eL8eVBmhBaikvw3RkYAG4pYAikgOGX9Db7IshsYnhcmNYxhNCcovMChszAEEK/jDL7AmCgD0+TF0JLUdFBBAb67vDQ7ZYChoA+70Wz/r+rPJGjw7yFAy95e21tLfPnzwegsrISs9lMbGwsAFu3bu3xFq9PPfUU+fn5TJs2jX/8x39k4cKF2O12nn32WbKysnr3JHyc1amvKygjB4YRaPbdD1Mh+osSFAnBsaDXmQzOFlS3A8UUqHUSIUQPtTQ5tI7gMb68zl8ILSmKQly8hbNlrZrm2PFRs0ePJ+NLY9HdZroxMTEUFBQAsHz5csLCwnjwwQd7fby33nqLoqIizGYzGzZsIC0tjRUrVnT78S6XC7NZX7tj6G0GxhjpfyFEByVimL6XYjjbIEgKGELoTVubU+sIHiENPIW4tIEJ2hcw+puML/VF95e13W4306dPB+Dw4cPEx8dTWloKwKRJk2htbeWhhx5i06ZNHY9JTU0FYNGiRbS0tDB9+nRWrlzJsmXL2LJlC7m5ubS1tVFQUEBeXh7Tpk3jnnvuobm5vRqYkZHBsmXLmDZtGhs3buzfJ+wBNp3NwJAdSIT4ju6XkTj966RICKOwtunr4sfFxEoDTyEuKU56xMj40sfpbgbGhUwmEzabjaamJvbs2UN6ejq7d+8mMzOTuLg4QkMvvs/3W2+9RWpqakfFLT4+ngMHDvD8889TU1PDihUrWLduHWFhYaxcuZLXXnuNhx9+GIDo6Gjy8/P75Tl6kgrY9dbAM1EKGEJ00HsBwyUFDCH0yCgFDGngKcSlDfTxRp79QcaXvk33BQxor4QVFhaya9culixZwrZt21BVtU9rjPbt20dRURGzZ88GwOFwMHHixI7b586d2+fcWnC43KiqvhrgDIm++IeEEP5GCU3SOkKfqM5W5NqnEPpjlAKG9L8Q4tIGRLU38nQ49HXB09NkfOm7DFHAyMrKYvfu3ZSWlpKXl8dLL72EoijMmDEDgICAANzu9jeh2+3G4bh8IypVVcnJyWHVqlVd3n6pypsvs+ts+UhEcACWQFkDJkSHoAFaJ+gbZ5vWCYQQvWC1GqMHRniE9OAR4lIURSEsIoD6WuPsPNQbMr70XbrvgQHtL7B169YxbNgwTCYTUVFR5Ofnk5mZCUBKSgoHDx4EYMuWLd16gWVkZFBYWMiJEycAaGlpobi42HtPop/obfnIwPBgrSMI4VMUUyAEhGsdo/ecLVonEEL0gt2mr/OHiwkNN8S1OyG8KixcCn0yvvRdff4Uv9y2NP1hyJAhqKpKdnY2AJmZmZSXlxMVFQXAwoULWbx4MVOnTuXGG2/sVnUrLi6OlStXcv/992Oz2QBYunQpI0aM8N4T6QcOnRUw4sJ7tm2REH4hKAqcnt1irN+4ZAaGEHrksOvr/OFiQsOkgCHE5Wj9PrlhRtcXahQF4uL7p4+NjC99l6L2sCFCWVlZj/fCFb6jtL6NJmvv93I/drae1QcbPJjo0maNTeTpWWP67ecJoQeuQ/+OWndY6xi9ogy5BXPqPK1jCCF66K1VRbS26nsZickEP10i5xRCXM7uHec4+Fn/bdl+5ThISOze7NK4eAuKIt20jMZut5OcnNyt+xpiCYnoPt3NwAiTYpkQnQRFaZ2g91R9D4CE8Fd2h/6beIaGybR4IbojzIdnKqn6GsoIL5AChp/RWwFDemAI0QVdFzD0tQuSEKK98ZzTof/3bpj0vxCiW3y5V4z+P4lEX0kBw4+ogMvdt7d9f489YmUGhhCdKHouYKCvIqoQApxOYwwZtF7XL4Re9PtsJbm4IXqgx5/kgYGBOBwOAgNlGp7euPtYvHC7nJQ19e+WSjIDQ4guhCS2/6dDSkCE1hGEED1kMshycylgCNE9/f1eaW5SiY13EmDuxs9VVcAgH0oCoMe1hR6/OgcOHEhVVRV2u3/vDaxHzTYnx87W9+qxqgplTXY+ONm/OwjIDAwhOjPFjMMU8xutYwgh/IRikAqGFDCE6J7+fq+Un1aAVsIjlPatRi4hJBSCgs39E0z0i8DAQAYO7P7Opj1+dSqKQnx8fE8fJnzAwdJ6Vh/U117DIYHyASWEEEJoySgN/0NCpYAhRHcEBpoIDDL14/bJyjdFjMsbnx5PTJzFy3mEL5NPcj9S39b77VO1YjbIVR8hfFlQUBAOhwNFUSgrKyMpKQmAhoYGoqOjUVUVs9mM0+nko48+YubMmQBs27aN3NxcgoODefzxx3nyySe1fBpCCC8xypaFAQHS+k2I7rrzniu0jtCloCB5H/s7eQX4ESlgCCEudNddd+F0OlFVFYvFQmZmZsdtmZmZBAYGoqoqbrebm266iQceeIDBgwczePBgfvrTn/Jv//ZvAFK8EMLgTAY4YzTJpE4hus1iMXv0v+HDUwgPDyYubgA2W3PH91XVTkJCDOHhwaSkJGKxmPn666NERFiIiLBw8mQRFouZK68cxqZN6zHJ2MDvGeDPkeiuBilgCCEu8MEHH5CQkADArFmzKCsr67jtxIkTZGVlATB8+HB27txJWFgYdrudtrY2IiIi+PWvf827776rSXYhRP8xwiwMkwGegxB6tHz5chobG3E6nSQmJnL77bd33LZo0SIiIyNxOp04HA4effRRHn/8caZOncrUqVN57LHHeOeddwD40Y9+pNVTED5EChh+pMGqwwKGnGwI4VVWq5XIyEgARowYgfq9rcycTifJyckAxMTEYLfb2bJlC9XV1dTV1ZGYmEhoaCh33nknZrOZ//zP/9TkOQghvM8If46N0oxUCL15++23mThxIgCLFy/ms88+67jtb3/7G/PmzQMgJyeHjRs3EhkZSVtbG83NzURFRXHffffx3vyv1UEAACAASURBVHvvaZJd+B4pYPgRm7O/GvF4jmwLLYR3BQcH09jYCEBxcfF5V1kDAgI6ZmTU1tYSFBREUlISLpcLl8vF1q1b+eMf/0hTUxOvv/46jz32mCbPQQjhfUYY/BthGYwQetTQ0EBsbCwAQ4cOxWq1dtzW2trKoEGDAIiPj6epqYmXXnqJI0eOUFRUxKBBg0hKSuLuu+8mJiZGChlCmnj6E6dbf9UAp9sNyKJVIbwlLy+PNWvWALB58+aOGRcAw4YNY/fu3UD7cpIZM2Z03DZ27FhSUlIAcLvd1NfX43brr0gqhOgeI8zAkIsiQnTfXX8qpLzBevk7dkOF1UTVFyfIXfkJp7Z8jJ0Acld+AkCr28xvN+9lS8gnHNp1hFZnAHP/dJDxT7UvT/33R/O4+mf/wRerHmPs3U8zf+FPmLxsfY9+/tq/zyQuPNgjz0VoTwoYfsSlwwKGHjMLoSf/+7//y9q1a1EUBUVR+PTTTzGbzbhcLnbu3El8fDyKomA2m9m6dSvQfiXl6NGj2Gw2AgMDAfjFL37BD3/4Qy2fihDCi4zQP8It5xRCdFuT1UmzzemRYw0YN4Wz+f9Ds83J2cIthCRf2XHssCFjqDy4g6TZP6Ou+CDxWbM7biv+n2cIGzKWNrsbt9NBc3MzLofDY7mEPslkOj/i1OHVUZdcLhHC6xwOR8dOI0OGDMHlcgEQFxeH2+1GVVWczu9OFgYMGIDb7e4oXnx7n7/+9a+a5BdCeJ85wAgFDK0TCKEfnhw3JOX+HaYgC589OgNHUy3D/u5X7H/yFgCG3f4YLmsTnz06A8VkZvCsewFw2dto+GoPI+7+N8KHjAag+E//QvzkW3r882VTAGORGRh+xOnSXzHA7tRfZiGEEMJoQkIDaGnW91VPmYEhRPd5ehZ0+pPrzvv6mmXtFz3MISFMeKZzXwtz0Pnfn/DMpl7/bCPsoiS+IzMw/Igee2DUtdq1jiCEEEL4PUuI/vtRuXV4IUcIrXhy3OBsa+bIb3/G50/cTFvFyfNuc1lbOP7HJzj22j9T8t6qjvsfe+2fObbqF7isLQCUbf0jttqKXv38AJmBYSgyA8OP6LGfRFWzTesIQvicz0vq2Pxl7/6I95c5VyUxfnCU1jGEEB4SGqr/U0Zrm0vrCELogtPlptHquRlXpiALV9z9LKXvr+p0W9We94kaO5mB187i9IYXaT7zFY6GSuIybwag8fg+QgePAiA4JrFXPz8kUP8FWPEd/f81Et2mxxkY1S0yA0OIC+0rqeevh85qHeOS0gdHSQFDCAMJMUABo6XFoXUEIXShxsPn3yZzAKbwrs8JbDXlxF07C4DQQSNpPvkFIQlDcVlbUN1uAkIjOPfx2wy66e5e/ezgAJP0wDAYWULiR8w6fO9WywwMITrRw8wkI+xYIIT4TkiY/gsYrS367uEhRH/pzwuIloShNH29H4DGrz/H2dZExBUZtJQW0Xq2GLMlnODYQdTuz+f0hhex11f16PhhQTL7wmikgOFHLDqcPiUzMITorKbZ998XcrFDCGMJCdXfOcSFWnXehFSI/tKfF0oGXjuLtsozHFv9COagEAIjYjCZAxh66xKGzv0nqgvfJ3bCdKxVJQyavojKXT3b8Sw0SP/FV3E++Y36ET0WMPRwpVmI/qaH94VM1xTCWIywhERmYAjRPdUt/XeeYQoMZtjtjwBwau0LRKVlddxWf2QXkVdMBMBtt6K6XLhtbT06fkSw/j+7xPnkN+pHLIH6m3AjS0iE6Kw/Tyx6S654CGEsRmjiKT0whOieai/M9Cz6/VLayouxVpUwMGs2zaePkDr/n2kt/5ozG19BURRiJ8wgOCYJANXtou7wDlJ/9AiKoqCqKsVvPcWQuQ/16OdGWvT/2SXOJ79RP6LHDryyhESI87ncqseba3mDXPEQwliMMAPD6VCx210EyZp4IS4pZ2QcEcEBVDRZqWiwcrbRSkWTjYa23hcBr7znufO+jpv4A6C9cefo+/+z0/0Vk5lht/+y4+tvZ2n0VGRIYK8eJ3yX/v8aiW6zBOjvD3Ztix2n202ASX+zR4Twhvo2O3rYUChcChhCGIolxIyigKqDz59LaW12EhSjv/MhIfpTWmIkaYmRnb7fandS0Wg7v7DxzX9nG61UN9txdfEhcfCZH+ForscUGMTVj/+FgJBwAFz2Ng4+cztuuxVzaATX/Ho9rWdPcuTFewGFsT9/nZCEoRz8tztIufl+YtKn9vi5RFqkgGE0cobpR/S4hEQFzjXaSI4K0TqKED6hrMGqdYRukQKGEMZiMimEhATQ2qrvPhKtLU6iYoK1jiGELoUGBTA8LoDhcWFd3u50u6lqsn2vsGHjL79/CdXexm2v7+S9R+dT/N/PMOqnvwHg5JrfYA4OZcIzm/j8yR9Sunk1befOEDH8GgBKN79O7MSZAL0qXgDEhgb16nHCd+lvRCt6TY9NPAG+OtekdQQhfMYxnbwfwoP1+XkjhLi4qFj9DwRamqUPhhDeEmAykTQghAkp0cwam8TfZ6dSc2A712Vdy9p7svjVkvsJqDnBm4sm8ptbroKzx8iclsfUKwaSNHoCjUd3Y7aE4nZacdlbMYeEcfqdFYy8+996nSk+QgqWRiMFDD+i1yuiRyv0MWAToj/o4f1gVhRp4imEAUXH6n8gUFPt+02QhdCSqrpRVbfHjtfQ0EBsbCwAQ4cOxWa1kpYYyY1XxqM6bczOHMu/zx1H3sRRRAc4+XLr2wTUlxHQWEFO+ijiExKp2/RffPH0rXDqM8xKz3Y5S5AChuHIGaYfiQvT55WTo+catY4ghM/Qw/shTGZfCGFIMQZYelF1rmdbMArhb9Tag7iP/BaCosEShxIcC5bYb/73m6+DY1HM3RtXREZGUlNTA8Dp06exWCwdt4WEhFBeXg5AZWUlERERJA6Mob6uDoABAwbw0UcfMWvWLLa+91fuuusuzpSUUtVsO7//RoO1vS/HN704rI7vCjDxERaEsUgBw48MDNfniYcsIRGindXh4kR1i9YxLkuvs72EEJdmhBkY1ZX66CMkhGaaT4HqAls12Kr5tiVnp9acgZHthQxLLATHffO/sSiWuPb/DWxv1Hn77bfzr//6rwC8+eabTJw4seMQkydPZsOGDbz44ot8/PHH3HfffR233XHHHUyePBkAh8NBc3MzNpsNs0khMdJCYuTFCxP1rXYqmmycbbCSHCUFDKORs0w/EhemzxOPRquTsvo2aeQp/F5RVbMudiDR62eNEOLSouP0PxCw29w01NsZEKXPWalCeJvadLJ7d3Q0gqMRtbn9/p1OT8wWCI7h4VmxrHjBRIDZTLAliN0f/g/RUQOoravjT3/6E4MGDSIgIICoqCh+85v25p5tbW1s3ryZuro6zOb2WZ233HILTzzxRLeiRYUGERUaxOiEiO49F6ErUsDwIyFBZsKCzLTYXVpH6bEjFY1SwBB+72iF7y8fAUiMlAKGEEZksZgJDdX/TiRV59qkgCHERajNpzxzIJcVWstRW8spfWfud98veZmqjXNxffoPWIKiqd3xWMeyFPfZ7RAci8USS0NdNco3xYuGhgbPZBKGIAUMPxMXHkxLbavWMXrsq3NNzBidoHUMITT1lQ4aeAKXnNYphNC36Nhg3Rcwqs9ZGTlqgNYxhPA5qq0O7P1ULOjWMpWI85elWOIgOAYlOK69H8c3y1SEf5EChp+JCwvitE4LGEL4u6M6eR8kSMMsIQwrOjaYshLf78VzKVWV0shTiK54bPaFpziawNHUkatTgcMU/F2D0fMKHbEQMQLFJENdI5Lfqp+J02kjzyMVTbhVFVMPt04Swija7C5O1uhj0JA0QAoYQhiVIRp5nrOiqiqKnFMIcZ5u97/wFW5bxzIVOL/AYc76LQRFapNLeJVJ6wCif+l1L+Rmm5MjZ/Wx/l8Ib9h7plYXDTwBEmUGhhCGFWOAAobd7qax3q51DCF8j6/NwOgtswVFiheGJQUMPzM0JlTrCL32SXG11hGE0MwnX+vn9S9NPIUwrug4Y7y/K87KMhIhvk9V3aiNxVrH8AxLvNYJhBdJAcPPpMaEaR2h1/Q0gBPCk9yqyg6dFPDCgsxEWAK1jiGE8JLgYLMhZmGcOdmsdQQhfEtjMTiN8b5QLAO1jiC8SAoYfmZYrH5nYBRXt1BWL1dMhP/58mwjta0OrWN0y5Bo/X7GCCG6JzFZ/+/zkpPNuJxurWMI4TPctfu1juA5IVLAMDIpYPiZCEsgsWH63ftcL1ehhfAkPc0+GjlQtjQTwugSB+m/gOFwuCkv1d+ubEJ4i1pjnAKGYknUOoLwIilg+KFUHffB+FhHAzkhPEUKGEIIX5I4KETrCB5x+oQ+tqYWwtvUtgr4ZicPI1AihmodQXiRFDD8UGqsfvtg7C+pp9Gqj6n0QnhCSV0rJ3SyfSrAyIH6/XwRQnRPxIAgwsIDtI7RZ6eKpYAhBBhr9gWKGcJStE4hvEgKGH5Iz30wXKrK307UaB1DiH6jt2VTV8oMDCH8wqDB+i9WtjQ7qTonvbWEcBupgBE2GMUkzcSNTAoYfmiYjmdggGynKvyLnpaPxIYFERWq3x47QojuSx6i73OJb50+YYxdF4ToLdXRDA1FWsfwGCU8VesIwsukgOGHxiRGomgdog92FFfTJMtIhB+oaLSyv7Re6xjdNjLOGAMaIcTlGaeAIctIhH9Taw8CqtYxPEYJH6Z1BOFlUsDwQ+HBAbrug2F1uHn/ywqtYwjhde8cKMOto3MKaeAphP8IjwhkQLT+Z1xVV1ppapSLIsJ/qTWfax3Bo5SIVK0jCC+TAoafGjcoUusIfbJuf5nWEYTwKrvTzV8P6asj+JhEfX+uCCF6JjlFvxdDvq/oiH5mugnhSaqjCbXmgNYxPEcJkAaefkAKGH5q3KABWkfok9N1rRSertU6hhBes62okrpWfV0VTB8cpXUEIUQ/Skk1xqyro4fqcOtpupsQHqJWfAKqU+sYnhM2GMWk/x2SxKVJAcNPXZWk/yulMgtDGNnaA/p6fQ8aYCE+IljrGEKIfpQyNIygIP2fSrY0OzktW6oKP6Oqbtzl27SO4VHSwNM/6P+vjuiV4XFhhAWZtY7RJx9/XcW5RqvWMYTwuKLKJr4oa9A6Ro9cI7MvhPA75gATQ4ZHaB3DI748WKd1BCH6lVr7Bdj0s9NZdygR0sDTH0gBw0+ZFIWxOp+F4VZhwxf66hEgRHfocXaRFDCE8E8jrtT3ucS3ykpaqKuxaR1DiH6jludrHcHjlIjhWkcQ/UAKGH7sap33wQB494tyHC631jGE8Jgmq4MPjupvlx3pfyGEfxo8NIxAAywjATjyhczCEP5BbatErftC6xieFThAGnj6CWP8xRG9cm1qjNYR+qymxc62oiqtYwjhMe9/WYHVoa+iXExoEENjQrWOIYTQQECAiaHDjdHMs+hIPQ67vj5/hegN91lj9b4AUGLGoSiK1jFEP5AChh8bNyiS8GD9d+p9Y88pXNI9XBiA1eHiv/ee0TpGj10zWP+zuYQQvTfiSmN8Btjtbo5/pa/+Q0L0lOqyte8+YjBK9NVaRxD9RAoYfizAZOLaodFax+izr6ta2Hr0nNYxhOizdQfKONekvzXYk4bqfzaXEKL3jLSM5MuDskW7MDa1qhCcLVrH8DATSvRYrUOIfmKMvzai17KHxWodwSNe+/QEdqdM+xT61WR18Mfdp7SO0SvXjzDG54gQoneMtIykttrG6ROypaowJlV14S55X+sYnhc5HCXQGJ9B4vKkgOHnsocZ48rp2UYr7xzQ384NQnzrzcIzNFqdWsfosVHx4SREWLSOIYTQ2PArjLEbCUDhp5W4ZWmqMCC1Yge0ndU6hseZZPmIX5EChp9LiLAwPC5M6xge8fvdp2i26W8AKERlk40/7yvROkavTBkZp3UEIYQPSEkNN8wyktoaG19LLwxhMKrLhvv0u1rH8AolRgoY/sQYf2lEn2QbYDcSgIY2hy4bIArxu7+dxKbTJVA3jJAChhCifRnJFaON0cwTYO/fqnDq9HNZiK6o5f8HdgNuFRwYAeGpWqcQ/UgKGILrhhtn/fr/fHaGmhb9NUEU/utUTQsbD+lzOmd8eDBpicaZNi6E6Jux4/XfGPxbzU0OjnxhwMGe8Euqoxn3mfe0juEVSrRsn+pvpIAhmJASTVRIoNYxPMLqcPO7v53SOoYQ3fbKpydwqfpcay3NO4UQ3xcTZyFpcKjWMTxm/55qbDaX1jGE6DN3yfvgatU6hlfI8hH/IwUMgdmkkHvFQK1jeMyGL8o5UW207aGEER0oraegqErrGL0my0eEEBcaO94Yy1IBrFYXX+yr0TqGEH2i2mpRyz/SOoZ3KAEo0eO0TiH6mRQwBADTR8drHcFjXG6VZVuO4nTL2lXhu6wOF89sOap1jF6LtARw7VDjDFSEEJ4xbGQEYeEBWsfwmC/21dDaIg3ChX65T78LbofWMbxCiblatk/1Q1LAEABkpEQTExqkdQyP+fJsI/+zV5+7Ogj/8OqnJzhT16Z1jF6bPiqeoAD5EyKEOJ/JpJA2zji9MJxOlX279TtTTvg3taUMteITrWN4jZJwvdYRhAbk7FMA7ctIZhhoFgbAqp0nOFHdrHUMITrZX1rPnz/Td4Ft1tgkrSMIIXxU2rhoTGbjNNU78kUdZ8uM2T9AGJequnEV/R7QZ5+tywqMQIkZr3UKoQEpYIgOeWMStY7gUQ6XytMfyFIS4Vva7C6e+eCork8nUqJCGJ9snO0ShRCeFRoWwPCREVrH8KjtH5bjcMj5hNAPtXQLNBVrHcNrlIFZKCbjLFcT3ScFDNFhbFIkQ2OM0z0c4EhFE28VntE6hhAdXtlRTEm9fpeOAOSNNVaxUwjheUZq5gnQWG9n785KrWMI0S1qaznuU+u1juFVpoTrtI4gNCIFDHGeWQabhQGweudJvq6SpSRCe5+X1LHm81KtY/SJgjE/J4QQnpWYHEpcvEXrGB51aH8tZ0tllzPh21TVhevY66Aas3EnAKHJKBHDtE4hNCIFDHGeH45LIsBknHWrAE73N0tJXDL1U2inze5i2ZavtI7RZ+mDB5AcFaJ1DCGEDozPiNU6gsfJUhLh69qXjpzQOoZXyewL/yYFDHGeuPBgpl4xUOsYHvfVuSZ+v/uU1jGEH/uv7ccp0/nSEYCbpXmnEKKbRoyKJDo2WOsYHtXY4GDPp+e0jiFEl9SWMsMvHQETSvxkrUMIDUkBQ3Tyo2uStY7gFb/72ym2H5et0ET/e/dgOesPlmsdo88iLQHMHJ2gdQwhhE4oisLEbONdFPnyQB1lJbKURPiW75aOOLWO4lVK9FiUYONs1Sx6TgoYopMJKdGMiAvTOoZXPPn+EY5LPwzRjz4vqef5/zumdQyPuGXcIEKCzFrHEELoyLCREYbrhQHw8YflOOyylET4DrVkMzSf1DqG1ymyfMTvSQFDdGl+ujFnYbQ5XPxi/RfUtdq1jiL8QHlDG4/+9RAut543TW1nVhRunzBY6xhCCJ0x6iyMpkYHH3+k/5l1whjU+q9wn96gdQzvC4pCiZukdQqhMSlgiC7NGptImEGvtJ5ttPLYXw/jkKaewota7U4e3nCI+jZjdAGfekUciZHGu4oqhPC+ocMjiE8yXvPf4qJGPt8jS1OFtlRrFa4jvwXVpXUUrzMlz0QxBWgdQ2hMChiiS2FBAfzAwFslfl5az7/nF2kdQxiUW1X59WZjLVf6u4wUrSMIIXRskgFnYQDs/VsVJ79u1DqG8FOqsw3X4f8Cp3HONy7KHIKSdKPWKYQPkAKGuKg7MgZjsB1Vz7PhYDlr95dqHUMY0Os7T7L9eLXWMTwmLTGC8YOjtI4hhNCxwUPDSRocqnUMr9i2pYyaKqvWMYSfUVU37mOrodU/zmWVpFyUAOPN5BI9JwUMcVGpMWHceGW81jG86j/yj7P3dK3WMYSBfPTVOX6365TWMTzqjgky+0II0XdGnYXhdKhs2VhCW6uxd38QvsV9egNqzedax+gfSgCm5JlapxA+QgoY4pLuyU7FwJMwcKkqv/zrYb4616R1FGEAe0/X8fQHR7WO4VHx4cHMGG3sQqYQon8kDQ5j8FBj7nLW3Ojgo/dKcbn037RZ/H/27js+ijr9A/hndrMl2fROeocQIDRBSugCIipNENBDEE9BTznv7P13ZzvPE8V6chZQQBRULCgqRWnSW4CQEJCWTkhI3WT3+f0Rs7IkpECS2SSf9+sFyc7Ozj4z+e7ud5+Z7/N1fNbsrZATq9QOo8Uo/v04dSrZMIFBdYrxc8WgGF+1w2hWReWVuGf57jZVr4Ba3u5T53D/53tRXtm2isP+qW8YdFp+VBBR07g6KQBKGz0zknG6BJvWZagdBrVxcv44rEcWqh1GC1KgCR2jdhDkQNgrpXrN6hehdgjNrqCsEncv34303GK1Q6FWaP+ZAsz7bC/KKtpW8sLXpMe4bkFqh0FEbYiPnxEJid5qh9FsDu0/h/2789QOg9ooKc+HJXk+YG0bM5w1hOKdCMWFfRH6AxMYVK/Oge64OqLtdjaq5ZdUYO7y3fjtLJMY1HAHMwtx72d7UVLR9qYv+1PfcBic2uZ0ykSknt79/eDs0nbfWzavz0LKwXNqh0FtjJgLYdn/L8Ccr3YoLUoTep3aIZCDYQKDGmR2O7gKAwDyis24c9luHOVwEmqAfacLMPeT3Sgqb3uF2/xc9ZiQyDMeRNT0DAYt+g4MUDuMZrVhzRmkpRSoHQa1EVJRVJW8KDmjdigtyz0Gikec2lGQg2ECgxokMcQTvcPaR/GcvGIz7vxkNwt7Up12nMjHPZ/uQbG57V15AQCzro7g1RdE1GziOnsgMKjtTokoAqxdfRrpqYVqh0KtnFQWw7L/JaD4pNqhtDhN+AS1QyAHxAQGNdi9g6Pb9IwkFyoorcCcT3Zj/xmePaGathzLw7wVe1HaBoeNAECQh5G1L4ioWSmKgqThHaBpwz1REeCnb0/hWBqTGHR5pKIYlv3/BoqOqx1Ki1O8E6HxSlA7DHJAbfhjg5pafKA7ru0cqHYYLaaovBJzl+/GjynZaodCDuTzvadx/8p9bW62kQv9uX8knDjzCBE1M29fIxJ7t+2ZzqxW4IevT3E4CTWamAth2fcCcD5d7VBanqKFJupmtaMgB8UeKjXK3EFRMDi1n2ZTVmHFI6sO4J2N6bAK53ZvzyotVvzrxxQ8tyYFlda22xbiA9xwbUL7SVQSkbp69fWFh5de7TCaVdWVGKeRkszCntQwUn6uKnlRfELtUFShBA7mzCN0Se3nmyg1iQA3I6ZfFaZ2GC1u4ZbjePCL/Sg2t71ijVS//BIz7v50Dz7dfVrtUJrd34bHQaO0l8FiRKQ2rZMGg4Z3UDuMFrF+zRkk7z2rdhjk4KQ8D5Z9zwElbb/PUSutMzTh49WOghwYExjUaDP6hMHH1LbPltRmQ1oubv94J06dK1U7FGpBR7LPY8biHdh1su2fORsdH4DEYA+1wyCidiYo1IROXTzVDqNFbFybiS0bMmFtw1fy0eWTwjRYdj8DlGapHYpqNKFjoejd1Q6DHBgTGNRoLnon3DkgUu0wVHE0txgzFm/Htt94BqU9WHskG7cv2YmMwjK1Q2l2Ljot7h0So3YYRNRO9R8SCM82PpSk2r5dZ7H6ixMoL2ubhaDp8lgzf4Fl7/OAuR3XSzH4QgkZqXYU5OCYwKDLcmO3IMT6uaodhioKyypx76d7sWxn+5vOqr2wiuCdjel46MsDKKtou8U6LzSzXzj8XA1qh0FE7ZROp8HwMSHQatvHELZTvxVj5dJjyM8rVzsUUpmIBZajH8N6ZCEg7XuosiZyEhRN+0hk0uVjAoMui0ZR8PA1HaFpH/2MGiwieHltKh796gDOlZjVDoeaUNb5Mvx1xT4s3HJc7VBaTKinM6b3bn+1bYjIsfj6G9FnoL/aYbSYwnNmfL7sGH5LP692KKQSqSiCdf/LkNNr1A5FfW6RUPyuVjsKagWYwKDL1i3YAxO7B6sdhqp+OJyNKe//irVHONVqW7Bq/xlMee9XbD6Wp3YoLWre0FjoOG0qETmAbj19EBbZfq7wrDBb8d2XJ7F7W67aoVALk+LTsOx+BnIuWe1QHII2ahoUFhGnBlBEODckXb5icyWmvPcrss7zEshrOvrjgRFx8HLhpW+tTVZhGZ79/jC2HG9/tU2GxvrhX+O6qh0GEZFNaWklPlucjpLi9nU5fXScOwaPDIJOx4RyW2fN3QVryjuApe3X2GoIJXAwtHGz1A6DWgkmMOiK/XI0F/ev3Kd2GA7By0WHB0d0xIiO7ecS2Nbui31nMH9dKorN7a+YmqezDp/M7AvvdjirEBE5ttMnivHNyt/Q3nqp3r4GDB0VBF9/Z7VDoWYgFjOsv62EnFqtdiiOw+ADba9noTixzVPDMIFBTeKRVQfwYwqHUVQbHueHB0d05BdDB5ZZWIZ/fn8Yv7bDqy6qPTs2ASPjA9QOg4ioVr9uzMKe7e1rSB8AaDRA96t80bOvX7spatoeSEEqLEcWAqWZaofiUDRd/g6NN68EpYZjAoOaxNliMya/txUFZe3rcs+6eDjr8NehMbi2cyA0HNPnMCotVny+7wze+Plou7zqohqHjhCRo7NaBV8uP47sjFK1Q1GFt68BQ0YGwS+AZ6ZbM7GUw3p8JeT09wD4tetCHDpCl4OD7KhJeJv0uG9orNphOJSC0go8/e0h3PLhdmw8yuJcarOKYM2hLEx+71f868cj7Tp54eGsw8PXdFQ7DCKiOmk0CkZcGwyDUat2KKo4m1uOz5cew7ZN2bBUto8pvdsaKTgCy64nIKe/Q0smLwqKzOh35zfwHL0EB9LzAQCvfJKMQXevxpi//4CMvJIaj3n8v7swYM63GDDnW2zcl2Vb1v+ub/HN5lMAPrXO1wAAIABJREFUgP1H8/HvJQeaJkiDNzRRU5tmW9SuMIFBTeb6Lh0wLM5P7TAcTmpOEf66ch/uWLITe06dUzucdmnLsTzcumg7Hvs6GSfPtc8zeRd6cHgchzcRUavg5qHHyOtDoGmnPVYRYPe2XKxYcgw5Wfz8ai3EUg7L0SWw7H0OKM1q8ed3MTph1YvDMWFwOAAgM68U3245jQ2vj8bTt/fAsx/a1647W1iO9bszsemtMVj2zGDb/UdOFmLD66Ox5Id0AMDrKw7hnonxTRKjJnYW617QZWmnHwfUXB4b1QkBbga1w3BIe04X4I6lu/DXFXuRmlOkdjjtwr4zBbhz2S7c+9leHMnmMQeqho6w7gURtSZBISYMGhGkdhiqys+ruhrj141ZqKjg1RiOzHruECw7H1d1yIjOSQM/T6Pt9m9ZRegc4QFFUdAz1hsb99nXrXNz0cHb3YCKSivyz5vh61HVl1cUwFxhgV6nwY/bz2BgtwAYDVd+RZQSOIh1L+iyOakdALUt7kYd/jE2AXOW7YaF5VVqtTE9D5vS8zC6cwDuHBCFYE9mn5taem4R3vwlHRvSOHTnQgFuBjw6qpPaYRARNVrHBE8UnDNj97b2+74uAuzZnoeU5HPodbUfOnXxYpFPByJFv8F67DNIvuPNzBcd5IadKXkoN1uwfncm8s+X292vc9KgW7QXOk//AmVmC1a9OAwAcMPAMMx+YTMenN4Fr684jHtvisfdL2/F4B4BmDws8vKCMXhDEzXtSneJ2jHt008//bTaQVDb0sHdCKsIdp3kcIm6pOUU47M9p3EivwTeJj0C3Y31P4guySqC7Sfy8eqGNLy8NhXHz9Yc39meaTUKXpmYiAhvF7VDISK6LEGhLsg/a0Z+Xnn9K7dhlRWCE8eKkHa4AEZnJ3j7GKCwWLhqpDQL1rTFsB5dDJS1/HCRuny58ST6dfFDRAc36Jw0+PsbO1BUWgGrALeOjratd/i3Avzvm1RseWcMJg+PxNyXt2LGtTHoFu2FSUMj8MP2DAzo6odF3x3Fq/P64tXlh3BjUthlxaSJvxsaU3AT7SG1R7wCg5rF7f0isf23fOw5XaB2KA6t0ipYfTALqw9mIdbPFRO7B2N05wCY9HxpNlRhWQW+PpCBlXvO4Ld8Ji0u5e6kaCQGe6gdBhHRZVMUBUNHBaHofEW7nZnkQoUFFVi7+jT2bM9F34H+CIt0UzukdkXK82E9sQqSuQEQxy8MfuvoaNw6OhobdmfC18P+pJmIwNNVD61WA09XPYpK/5hVsLS8Epv3Z+PtB/ph4VepAKqKhF4OJegaDh2hK8ZpVKnZZBaWYfqH21DIqVUbxaTXYkxCICYmBiPaz1XtcBzWwcxCfLb7NNYczkI5q7PXKSnaFy+P78ozdETUJpSWVOLzpcdwvrBC7VAcSodgF/QZ6I/AIF5p15ykohjWU99CTq8BrJf3Rb4lXP/gT9ibdhZhASbccUMc1mw7g+z8MoQFmLDgr33hYnTCvz7ej5uGRSCygxvmvboNu47koaLSiodv6Wq7wuLfSw5gVN9gdI32wlebTuL5xfsxvFcH/OOOHo0LyD0W2m4PQ9HwJB1dGSYwqFmtT83Bg1/s56zXl6lHiCcmdQ/GoBhfGHXtcxq5CxWbK7E2JQef7TmFg5nn1Q6nVejgbsRHM66Cu1GndihERE0mP68cX3xyDOZyJrAvFhbpiq49vBEcZmLiuglJeT6sGeshZ9YAlbzis1H0HtD2+D8oBk+1I6E2gAkManb/3ZSOdzcfVzuMVs3gpEHfCG8kRfsiKdoHPqb2M9NLVmEZfjmai5/TcrHjZD4qLHzLaignjYJ3p/ZElyAOHSGitufUb0VY/cUJWJnDqJWHpx6du3khLsETRiNPglwua34yJGMtJHcXADa2RlO00HZ9EIoni4hT02ACg5qdiOChLw9gXWqO2qG0GQkd3DEo2hdJMb6IbWPDTKwiOJx5vippcTSX059egb8Pj8WUnqFqh0FE1GzSUgqwdvVpsDd7aVqtgpiO7uic6A3/QM581hBSUQzJ2ghrxlqgNFPtcFo1TdQ0aEJGqR0GtSFMYFCLKDVbcPuSnUjN4ZfRptbB3YikaF/0jfBCfKA7/Fxb39UZGQVlOJRViK3HzuKXo7nILXbcMaWtxcTuwXj4mo5qh0FE1OxSDxdg3XdMYjSEb4ARCd28EN3RAzqdRu1wHI6cPw5rxk+Q7K0OXd+itVD8+kIbP1ftMKiNYQKDWsyZglLMWLwD50pZdKs5+Zj0iA9wQ6fqf4FuCHBznClazxSU4nDWeRzKPI/DWVX/2Caa1tUR3nhlYjc4adg5JaL2IfVQAdZ9zyRGQ+kNGoRHuSEi2g0h4Sbo9e13iImcPw45uwfW3J1A8Qm1w2k7XEKg7fEkFG3rO7FGjo0JDGpRO0/m457le1BpZbNrSd4uOnQKcEenADcEeRjh66qHr8kAX1cDvFx00DRhkS+LVZBfYkZOUTlyi83IKzLj1LlSHMoqRErWeRRwVppmFeVrwv+m9YKrgVW+iah9YRLj8mg0QFCoCeFRbgiPcoWbu17tkJqVWM2Qc4chebshZ/cA5WfVDqnt0TpD2/NpKM6BakdCbRATGNTiVu45jed/SFE7DPqdVlHgbdLBz9UAX5MBPq56+LjooXfSQKtRqv4pVT8tVoFFBJUWgcUqMFusyCs2I/f3ZEVOUTnyS8xgfkod3i46vH9LbwR5cIwzEbVPRw6ew/o1Z5jEuALevgZERLshPMoNfgHGNjGTiVjKIDnbq5IW+QcAa7naIbVhCjSd74XGt6fagVAbxQQGqeKNn4/ig19/UzsMojbD4KTBm5N7oFswZxwhovaNSYymYzRq4RtghJ+/8+8/jXDzaH1XaFjzdsOaPF/tMNoFTcQkaMKuVzsMasN4jTGp4u5B0SgorcDn+86oHQpRq6cAeHJ0PJMXREQA4jp7QgTY8AOTGFeqrMyCU78V49RvxbZlBqMWfv7GqoRGgDN8/Y1wVympYTZbkJ9XjoAOLnWup7hFtVBE7ZsSNJzJC2p2TGCQah4e2RGFZRX46QinVyW6En8fHoeR8QFqh0FE5DA6JngCYBKjOZSXWXDqRDFOnfgjqaHVKnBxdYKLyQkmkxNcTDq4mJxsy6r/GY3aBg1Jqay0oqS40vavuKjC7nZJUdXPsjILAGD67Fi4uukuuT1F7wEYfIHy3Cs/AFQrxbc3NNG3qB0GtQNMYJBqNIqCf4xNwPkVe7Htt3y1wyFqlf4yKBqTe4aoHQYRkcPpmOAJnU6Dtd+dhsXCLEZzslgE5wsqcL6g/lnFFAVQNAo0CqDRKIACiBWwWgUiAqu18c+fnVlaZwIDABT3KEgOExjNwj0Omk53QlE4+xk1P7YyUpVOq8FL47oioYO72qEQtTqz+0XgT33D1Q6DiMhhRcW547qJ4TAY2+80oY5GBLBaBJWVArPZCnO5FRUVVlgsl5e8AKoSGPVR3KIvb+NUN1MotF3mQdG0vtoo1DoxgUGqc9E7Yf7ERET6mNQOhajVmN47FHcO5JheIqL6dAh2wY1TIuDmXvcZemq9GpbA4Gdmk3MOhLbrA1Cc2IenlsMEBjkET2cd3pzcHRHedRdhIiJgYvdgzBsaq3YYRESthpe3AeNujoSvv1HtUKgZ5GSVwlrfHO6uEYDCK3GajMEH2q4PVtUXIWpBTGCQw/B1NeDtm3vySgyiOlyXEIiHRsSpHQYRUavjYnLCDZMjEBnjpnYo1MQqKwT5Z8vrXEfR6gETa0Y1CZ0HtN0ehGL0UTsSaoeYwCCH4mPS452beyDGl0kMootN7B6MJ6+Nb1AFdyIiqkmn0+CasSHo0cdX7VCoiWVncBhJi9C5Q9vtASjOgWpHQu0UExjkcLxc9Hjr5p6ID+QZEqJqs64Ox8PXdISGyQsioiuiKAr6DPDH0FFB0Gr5ntpWsA5GCzD4QNv9MSimULUjoXaMCQxySJ7OOrw1pQd6hHiqHQqRqhQA84bEYE4Sq6cTETWluM6euP6mcLiyuGebwJlImplzB2i7P84rL0h1TGCQwzLpnfDapEQMiOL4OmqftIqCx0d3wvSrwtQOhYioTQro4IJJ06NYF6MNyM8rR0VFPfOwunQAtM4tE1Bb4hpRdeWFwVvtSIiYwCDHZtRp8e/xXTEhMUjtUIhalF6rwXM3JOCGrmz7RETNyWDUYuT1oRg4LJBDSloxkarZSOqiKBoobpEtFFEb4dEJ2m4PQ9ExyUeOgQkMcnhOGg0eGdkJ9w6OgYb9CmoH3AxOeGViNwyL81c7FCKidiMh0Rvjp0bC01uvdih0mRpSyBOsg9Fgind3aLv+DYoTr1ohx8EEBrUat/YJwws3dIVRx2ZLbVeYlwveu6UX+oTzMk0iopbm42fEhGlRiOvsoXYodBlYB6PpKP79oEm4F4qGCT1yLPwmSK3K0Dg/vD2lJ3xMfDOltqdvuBc+uKUXIrw5jTARkVp0Og2GjgrGsNHB0PGkSavSoASGO6/AqI8SNByajndCUbRqh0JUA9+VqdVJ6OCOD27pjWhffsmjtmNKzxC8Oqk73Iyshk9E5Ahi4z0wcXokfP2NaodCDVRcVIniooo611H0noCBBeJrp4Emcgq0MX+CwmnbyUExgUGtUqC7Ef+b3gvD4/zUDoXoijhpFDw6siP+PjwOWhZ5ISJyKB5eBoyfGom+A/3h5MT36NagYcNIeBVGDU6u0HT9OzShY9SOhKhOioiI2kEQXYllO0/i1fVpqLQ6ZlMuP5uJQwvmwhgQAQCIvuVJ5O1cg/wDG6E1OCNi8oPQu9ufCSjNPIaTX78NqayAV+IQ+Pe7AadWL8T5tN3oMPwWeHbuh5KMdBSkbEOHITersFfUFLxcdHjhhi7oGeqldihERFSP8wVmbFyXiRPHitQOherQvbcP+iYF1LmO9eS3sB77pIUiagVcw6HtfC8Uo6/akRDVy0ntAIiu1M29QtGlgzse+eoAMgvL1Q6nVm5R3RB969MAgIrzZ1Fw+Fd0mvsqik+mIOOnjxA+/j679U+tXojoW56E1vjHMJmynFPoOPdVHFv2PDw790P2ps8RduNfWnI3qAn1DPXEP8cmwM/VoHYoRETUAG4eelw7LgzpRwqxaX0mSoor1Q6JapFdz1SqAKC4s5BnNcW/PzSxM6FoWV+OWgcOIaE2oUuQBz76Ux8MiHLMMY1Fx5Nx+M37cGr1QpTnZ8E5IAKKosAUHIuiY/vt1i3POwOxWJC+9DkcWfgQSrNPAAAUBRBLBTROOhQc2QHXyK7Q6Phh09poFGBWvwi8ObkHkxdERK1QVJw7psyIRkJ3L7BMgOPJySpDvReYu0YA7b1ApaKFJno6tJ3uZPKCWhUmMKjN8HDW4ZUJ3TA3KQpaB+pR6Ny90eWhReg4Zz4qi87BfDYTxadSYK00ozBtJypLCu3WryjKR2lGOiJvfgShY+/Cya/eAgB4JgzA8eUvIWDgRJzdsxYuHaLx28r5OLtnnRq7RZfB16THa5O6Y87AKNa7ICJqxfQGLQYO7YBxN7PIp6OpMFuRn1f3FbmK1gC4BLdQRA5I5w5t1wehCR6pdiREjcYEBrUpiqJg5tUReOfmHgj1dFY7HACAxkkPrd4ZiqLAs0sSSrOOw6/fDTjy7kMoOLwNRv8wu/W1Rle4hMTCydkVzoGRqCwuAAD49LwG0bc8iZKMdPj0GI7sLV8i9MZ7UHBkuxq7RY00KMYXS2/rg74R3mqHQkRETcQ/0Bnjp0ai3+AA6PTsVjsKFvKsg1sktD2fgeLZSe1IiC4L32mpTUoM8cSS2/pgco8QqH2e21JWYvu96Ph+GHyD4dtrJDrNeQWeXQbCLSrRbn2jbwgqiwtgtVTCfC7Hrg6GtaIcRceT4R7bC5bSqiJi1T/JMTnrtHhwRBxeHt8Nni68RJOIqK3RaBR06+mDqbNi0K2XD2crcQBZGayDUZMCJeRaaBMfg2LgyRRqvVjEk9oso06LB0bEYVicH/7vu0M4U1CmShxFx/fj9PfvQ6MzwODdAcEjZ+Lox/9AZdE56L0CEDbuXgBAxrql8E4cAoN3BwQOnoIj7/wNYrUg9IZ7bNvK2vQ5/AeMAwD49BiBlDfvg1tsT1X2i+rXN9wLj47qhCAPx7gaiIiImo+zsxP6DQpAt57e2PVrLg4fyIfVqnZU7VNOQwp5tqcrMIwB0HacDcUjTu1IiK4Yp1GldqHEXInX1h/Fyr2nwQZPzc3d6IR5Q2NxfZcOaodCREQqKSwwY+eWHKQeLgB72y1LUYCZd3eCTnfpi81FrLBsngNY1DnB1TIUKEHDoImcUlX3g6gNYAKD2pVfj5/Fs98fRkZhW/6wIjUNj/PDAyM6wsfE4SJERATk55Vjx5ZspKeeVzuUNm3lVy8j/fge+HgH4083/wPjbo5BUIgJFosFd9xxB1JTU9GrVy/Mnz8fBQUFGDduHFB8Aiue6QN3kx5P/W83Zo6JRUQHV7V3pWkYfKGJux0ar85qR0LUpLRPP/3002oHQdRSQjydMT4xCBpFwcHMQliszN9R0/A16fHMdZ0xu38kXPTtfGo2IiKycXZxQnScB8KjXFF0vhKF58xqh9TmnDp9GMmHN+HuO95ERtZRFBbmIKFLFwQGueCrr77C+fPn8dFHH2HFihXw8/PD3r17kZiYiB5RLvjt+FG4GJ2wO/Usxg8KV3tXmoQSOAjahPugMQWpHQpRk2MRT2p3jDot7hoYhU9m9sWgGF+1w6FWzkmjYFrvUHx6+9UYEuundjhEROSg/AKcMWZ8GCZOj0RsJw9o2AtvMkeP70Hnjv0BAAmdBiLt2G7k/D4TyebNmzFyZNV0oaNHj8amTZvg4uKCsrIyFIs7TEYn/GdZMv46OUG1+JuM3hOaLvdDG3c7FCfW36K2iW+d1G4Fezrj5fHd8OqkRIR5uagdDrVCQ2J8sXxWX/x1aCxcDayJTERE9fP1d8awa4Mx7fZY9OjjC4ORV+1dqZLSQhiNVUM/nI2uKCkpsE2lmp+fD3d3dwCAh4cHzp49ixEjRmDHjh3YdyQLHq56RAW7YemP6bjnP1txKrtYtf24fAqUwMHQ9noOGu/E+lcnasXY46Z2r3+kD66a6YUlO07ivS3HUVJhUTskcnBx/q64f2gseoV5qR0KERG1UiZXHfoM8EePPr5IO1yA5L35yMthja7L4ezshrKyqmnlS8uK4OLigaLzlSguqoCnpycKCwsBAAUFBfD29oZOp8Obb74JAJh5fRe88OcE/OODfXjitkS89tkhPPvn1jPDm+LRCZroaVBc28bwF6L68AoMIgA6rQYz+oZj5R39cHOvEOi1fGlQTT4mPZ4Y3QmL/3QVkxdERNQkdDoN4rt6YdItUbhxSgRi4z2g1Spqh9WqREd0x6HUrQCAgymbEBPZAwCQnVmK/v3748cffwQAfP/99xgwYIDtcV9//TVGDrkKAFBSXomKSiuKSipaOPrLZPSHpvNfoE18hMkLalf4LY3oAj4mPf42LA4r77gaExKD4KRhB4IAD2cd5gyMwsrZV+OGrlVFYImIiJpaYJALho0OxvQ7YtFvcAD8A1nHoCFCg+Ph7uqDfy+4FWcy09Cj2zX4ePnTyM4sxdixY3HixAkkJSXBaDSiX79+AACLxYIVK1Zg8k2T4ONhhNUqmPzkBtwyKlrlvamH1hmayCnQ9n4eGt/eakdD1OI4jSpRHU6fK8XCLcewOjkLFr5U2h0vFx2m9w7DTT2C4aLniDsiImp55wvMOHqkEEePFCI3m0NMGiMo1AXXT4qocx05dxiWfc+3TEBXRAOlw2BowidA0burHQyRapjAIGqA386W4N3Nx/Dj4WwmMtoBH5Met1wVhkndg2HUsbgaERE5hoJzZhw9UoCjKYU4m1uudjgOT6fXYObcjlDquHJSLOWwbLoLgLXlAmskxbNzVZ0LU6jaoRCpjgkMokY4U1CKZTtPYdX+Myg2s9hnW+PnqsetfcIxvlsQExdEROTQ8s+W42hKIdKPFCL/LJMZl3LTrVHw9jXWuU7lzseB4pMtFFHDKV5doISOhcYzXu1QiBwGExhEl6GovBJf7juDT3adQkYhL+ds7RKDPTC5RwiGxfnBiQVciYiolTlfaMbpkyU4c7IYZ04Wo7ioUu2QHMbgkUHolOBZ5zqWI+9BMje0UET1UaD49oYmdCwUtwi1gyFyOExgEF0Bi1WwLjUHS7afwP6MQrXDoUYw6jQYFR+AyT1CEOfvpnY4RERETaYgv/yPhMapYpSWtN+rRuO7emHQiA51rmPNWA9r6vstFNElKE5QAvpDE3IdFJdAdWMhcmBMYBA1keSMQnx1IAM/HM5CYRnPfDiqYA8jJvUIwQ1dO8DdqFM7HCIiomZ3NrcMZ06W4PSpYuRml6GosJVMFdoEQsJNuG5C3dOMSvFJWHY+3kIRXURjgNJhCDQho6EYvNWJgagVYQKDqImZK63YkJaDrw9k4tfjZ1n00wGY9FoMjfPD6PhAXBXuxWlQiYioXTOXW3A2rxxnc8txNrfM9rO83HELWTaEq5sOvv5G+AUYf//pDGeX+mcRE7HCsnkOYGnBYcE6N2iChkMJugaKzrXlnpeolWMCg6gZ5RaV49vkTHydnIFjeSVqh9Ou6LQKBkT6YHTnQAyM9oHBiUU5iYiI6lJcVIG835MZ+bnlKCysQPH5ChQXV8JqUf8rg06ngZuHDu4eettPdw8d3Dz0cHPXwcnp8utYWfY+Dyk43ITR1kLRQvHqCiUwCYp3dygaTtFO1FhMYBC1kJSs81ibmoN1R3JwLK9Y7XDaJI0C9AjxxOjOgRge5wc3DhEhIiK6YiKC0hKLLZlRWlL9z4Ky0qqfFRVWWK0Cq0VgtQosv//8Y1lV7TCrRaDRADq9Fnq9Bjq9BnpD1e/633/XVf+u18LorLUlKxpyNcXlsqR/Ajn1bfNs3CUImoAkKAH9oejrLihKRHVjAoNIBcfzirEhLRe/HM3F/jMFsPJVeNk8nHW4OsIbA6J80C/SB57OTFoQERFR41hzd8B6cEHTbVDrDMWvDzSBg6C4xzTddonaOSYwiFR2rrQCm9NzseXYWew6dQ7Z5zmXe306+rtiQJQP+kf5omuQO2taEBER0RWR8rOw/PrXK9yKBopHx6ohIr69oWgNTRIbEf2BCQwiB3MqvwS7Tp3DrpNV/zIKW7CglAPSKgpi/EzoFuyBbkEe6BXmBT9XdgiIiIioaVVunQeY8xv3ICcTFK9uUHwSq+pbsCAnUbNiAoPIwZ0pKMWuk+ew73QBjuQUIS2nCOWVrbtKeF3cDE7oEuSObkEe6BbsgS4d3OGiZ5ErIiIial6W5NcgeTvrX9EUAsU7ERrv7oB7DBTl8ouHElHjMIFB1MpYrIKT+SU4kl2EIzlFOJJ9HqnZRcgtNqsdWqNoFQXBnkZE+boixteEWD9XRPu5IszLGQqHhBAREVELs578BtZjy2veodFD8YyH4p1YNXuI0aflgyMiAExgELUZ50orcKagFBkFZThTUIozBWXIKKz6PaOwDGUVLXvVhkYBfEx6+LsZ4edqQICbAf6uBoR4OSPC24RQL2fotDxjQURERI7Beu4QrPteAPQeUNxioLhX/YNbJBQNi4QTOQImMIjaifwSM86VVqCwrBLnyypQWFb9eyUKyytQWFoJs8UKq/w+5Rnw+++//xSBRlFg0mvhrNfCpHeCs04LF331PyeY9Fr4uRrg72aAj0kPJw0TFERERNQ6iLUCKM+H4uyvdihEdAlMYBARERERERGRw+PpUSIiIiIiIiJyeExgEBEREREREZHDYwKDiIiIiIiIiBweExhERERERERE5PCYwCAiIiIiIiIih8cEBhERERERERE5PCYwiIiIiIiIiMjhMYFBRERERERERA6PCQwiIiIiIiIicnhMYBARERERERGRw2MCg4iIiIiIiIgcHhMYREREREREROTwmMAgIiIiIiIiIofHBAYREREREREROTwmMIiIiIiIiIjI4TGBQUREREREREQOjwkMIiIiIiIiInJ4TGAQERERERERkcNjAoOIiIiIiIiIHB4TGERERERERETk8JjAICIiIiIiIiKHxwQGERERERERETk8JjCIiIiIiIiIyOExgUFEREREREREDo8JDCIiIiIiIiJyeExgEBEREREREZHDYwKDiIiIiIiIiBweExhUq+PHj0NRFGzcuFHtUOwUFhZi/Pjx8PDwgKIoOH78uNohtYj169dDURScOnVK7VBUMWTIEMyePVvtMGr44IMP4OTkdMnbbU1ztcOIiAj885//bNJtElHbwn6JY2lL/RK12haPYf0ctf9H6mICwwHddtttUBQFDz74oN3yU6dOQVEUrF+/Xp3AHMBbb72FLVu2YOPGjcjIyEBoaGiNdTZu3OgwnYjW9DcrLCzESy+9hKSkJHTo0AGBgYHo378/XnzxRZw/f17t8KgN2759O/7617+qHQYRXQL7JZfGfknzaWy/ZMSIEbjtttsa/TyhoaHIyMhA3759myBqakorV67Ef/7zH7XDIAfDBIaDMhqNeO211/Dbb7+pHUqTq6iouOzHpqamIiEhAV27dkVgYCC0Wm0TRtZ+/fzzz+jYsSO++eYbzJ49G1988QXWrFmDefPmYdOmTYiPj8euXbvUDpOagdlsVjsE+Pn5wWQyqR0GEdWB/ZLasV/SPFqyX6LVahEYGAidTtck22srHKF/4O3tDXd3d7XDIAfDBIaD6t+/PxITE/Hoo49ecp1LXa4VExODp59+2nZbURQsWLAAU6ZMgclkQlhYGD777DMUFBRg+vTpcHNzQ1RUFFasWFHrcwwfPhzOzs6IiorCsmXL7O7PysrCbbfdBj8/P7i5uWHAgAH4+eefbfdXXx73zTffYODAgTAajVi4cGGt+1NRUYGHH34YwcGJ9G09AAAgAElEQVTB0Ov16Ny5M5YsWWK7PyIiAv/73/+wdu1aKIqCIUOG1BpvUlISACAyMtK23tGjR6EoClJTU+22FxISYrudmpoKRVGQkpJii+fpp59GZGQkjEYjEhIS8M4779g9X1FREe677z4EBwfDxcUFPXr0wMqVK233V5+JGTp0KBRFQUREBICqMyATJ06Er68vjEYjoqKi8NJLL9V6XC60e/du9OnTB0ajEV26dMHatWsBACKCqKgoPPfcc3brFxcXw93dHYsXL77kNvft24fx48fjlVdewfr16zFjxgz07dsX3bp1w+TJk7Fq1Sq88soruO6663DixAnb44YMGYJZs2bh4Ycfhq+vL9zd3fHnP/8ZZWVltnV++OEHDBkyBN7e3vDw8MDgwYOxbds2u+dXFAUfffSR3bL6zqLU11aAqr/NvHnzEBoaCoPBgIiICLvjk5KSguuuuw6urq5wdXXF9ddfj7S0NLtt7Ny5EyNHjoSrqyv8/PwwYcKEBnXeN23ahJ49e8LFxQW9evXC9u3b7e7funUrBg0aBGdnZ3h5eWHatGnIzs6uc5sRERF47LHHMHv2bLi7u8PX1xePPvoorFar3XGpr80qioLXXnsN06ZNg4eHB2699dZLPueCBQsQEhICFxcXjBo1yu7v35BjVP2a2rx5s91jfv31V7vX48VDSCorK/HMM88gOjoaBoMBwcHB+Mtf/mK7v77XHRE1PfZL2C+pjaP0S2677Tb89NNP+PDDD6Eoit1VJvW1iYvbbUPbcVP0My6WlpaGiRMnwtPTE15eXhg5ciT2799f52Ma0h8Dqj7TO3XqBKPRiNjYWDz77LOorKy03R8REYHHH38cc+fOhY+Pj63d1mb58uWIiYmB0WhE//79sW/fvkbtS2FhIVxcXGr03c6cOQMnJyf8+OOPtn27eAjJG2+8gc6dO8NgMMDf3x8TJ0603deQ1wi1AUIOZ8aMGTJ8+HD5+eefRVEU2b59u4iInDx5UgDIunXrRETk2LFjAkB++eUXu8dHR0fLU089ZbsNQAICAuSDDz6Q1NRUmTNnjhiNRhk9erS8//77kpqaKvfcc4+4uLhIbm6u3bY7dOggH330kRw+fFgee+wx0Wg0smvXLhERKSkpkfj4eJkwYYJs375dUlNT5Z///Kfo9Xo5ePCgiIisW7dOAEjHjh1l1apVkp6eLidPnqx1v//+97+Lt7e3LF++XFJSUuTZZ58VRVHkxx9/FBGR7OxsmTx5siQlJUlGRobk5eXV2EZlZaV8+eWXAkC2bdtmt15YWJi8/fbbIiKSlpYmRqNRXF1dJSUlRURE3n77bQkODrb7O3Tt2lW+//57SU9Pl2XLlomHh4csXLhQRESsVqsMGTJEBg8eLL/88oscPXpU3nnnHdHpdLaYd+3aJQBkxYoVkpGRIdnZ2SIicv3118vw4cNl9+7dcuzYMVm7dq0sWbLkkm2i+jjGxMTIV199JQcPHpRZs2aJi4uLnDlzRkREnnvuOYmKihKr1Wp73MKFC8XLy0tKS0svue2kpCR59dVXRUQkKytLbrrpJgkICJBevXrJhx9+KJ07dxYRkUceeURmzZple9zgwYPFzc1NZs+eLQcPHpRVq1aJn5+fzJs3z7bOypUr5ZNPPpHDhw/LgQMH5PbbbxcvLy9bOxOpap+LFy+2i2n48OEyY8YMu+e6/fbbbbfraytWq1UGDx4skZGR8vnnn8vRo0dlw4YN8t///ldEqtpuWFiYDBs2THbs2CE7duyQIUOGSHR0tJSXl4uISHJysphMJnnyySfl0KFDsm/fPpk0aZLExsbajuf7778vWq3WFtf7778viqJIUlKS/Pzzz3Lo0CEZPXq0RERESEVFhYiIZGRkiJubm0ydOlX27dsnv/zyi3Tt2lWSkpIu+TcSEQkPDxc3Nzd54okn5PDhw7Jo0SJxcXGR+fPn29apr81WH29vb29ZsGCBpKWlyZEjR2p9vi+++EK0Wq28/PLLkpKSIgsXLhR/f38BYHsNN+QY9evXT+666y67bc+ZM0f69etnt2//+Mc/bLf/9Kc/iZ+fnyxatEjS0tJky5Yt8p///Mf2t63vdUdETYv9EvZLLuZo/ZJz585JUlKSTJ48WTIyMiQjI0PKy8sb1CYubrcNacdN0c+oPobV7S8zM1MCAgLkrrvukn379snhw4flnnvuEW9vb9vfqTYN6Y899dRTEhYWJitXrpT09HT55ptvJDQ0VB5//HHbOtX9jKeeekpSUlIkOTm51ufbtWuXaDQaefjhh+Xw4cOyYsUKiYiIsDtmDdmXqVOnyujRo+22/eKLL0pISIhYLBbbvl3Y/3vyySfFZDLJggULJCUlRXbu3Cn//Oc/bfc3pB9ErR8TGA6ouqMgIjJu3DgZPHiwiFxZR+G+++6z3c7OzhYAcs8999iWnT17VgDIV199ZbftC9/YRKq+jNxyyy0iUvVlLTg42PbFrNrQoUNtz1f95rxo0aI697m4uFj0er288cYbdsvHjRsnQ4cOrfXYXMovv/wiAOTYsWN2y2fMmCE33XSTiIj897//lWHDhsm1114rb731loiITJ482bZv6enpoiiKHDp0yG4bzzzzjCQmJtr2zWAwyLlz5+zWmTlzptx4440iUvNvVq1bt252f6P6VB/HC9+AKyoqJCwszPY3yszMFJ1OJz/88INtnauvvlruvffeS2736NGjEhAQIGazWURERo8eLaNGjZJt27bJd999JzExMRIeHi4iVZ2rwMBA22MHDx4s4eHhUllZaVv2zjvviMFgkKKiolqfz2KxiKenp3z00Ue2ZY1NYDSkrfz4448CwNbJvtjChQvF2dlZcnJybMsyMzPFaDTKhx9+KCJV7WXKlCl2jysrKxNnZ2f5/PPPRaT2BAYA2blzp23Z1q1bBYAcPnxYREQef/xxCQ4OtnVgRET27NkjAGTDhg21xitS1bEYOHCg3bJHHnlEQkJCRKRhbVak6nhfmIi6lAEDBsi0adPslv3tb3+z62w15Bi99dZb4uXlZdvf8vJy8fb2tnXaq/etOoGRmpoqAOTTTz+tNa6GvO6IqGmxX/IH9kvE9lyO1i+5uO8g0rA2cTkJjKboZ1ycwHjqqaekb9++dtuxWq0SFRUlr7zyyiWPWX39seLiYnF2dpbVq1fbPe7DDz8UDw8P2+3w8HAZNmzYJZ+n2vTp06V///52yxYsWGB3zBqyL6tXrxatVisZGRm2dbp06SIPP/yw3b5V9/+KiorEaDTKSy+9VGtcDe0HUevXdsvltxEvvvgiEhISsGrVKvTs2fOyt5OYmGj73c/PD1qtFt26dbMt8/Lygl6vr3EZe79+/exuDxgwAD/99BOAqsJ7mZmZ8PT0tFunvLwczs7Odsv69OlTZ3xpaWkwm80YNGiQ3fLBgwfj+eefr2fvGmbo0KF44IEHICJYu3Ythg8fDp1Oh7Vr1+LOO+/E+vXr8cILLwAAduzYARFB79697bZRWVlpG9+6fft2mM1mBAcH261jNpsRGxtbZyzz5s3DnXfeidWrV2PIkCG47rrraux7bS78ezg5OaFPnz5ITk4GAAQEBODGG2/Eu+++ixEjRuDAgQPYunUr3n333Utub+/evbjqqqug0+lQUlKC77//HidPnrTt05NPPoknnngCANChQwecPXvW7vF9+vSxG+87YMAAlJeX4+jRo+jWrRuOHTuGJ598Elu2bEF2djasVitKSkquaAx1Q9rKzp074eXlVePvVy05ORmdO3eGr6+vbVlAQAA6duxoO57bt29HWloaXF1d7R5bVlZmd8nvxRRFsXu9BQUFAai6hLV6+1dffTX0er1tncTERHh4eCA5ObnOdlDb6/H5559HYWFhg9pstfpejwBw8OBBTJ061W7ZwIED8fLLL9tuN+QYTZkyBfPmzcPXX3+NCRMm4Ouvv0ZxcTGmTJlS6/NWj2keOXJkrfdfyeuOiK4c+yXsl1zI0folF2tMm2iMpuhn1Bbrzp07a3ymlpaW1tnvAOruj5WXl6O0tBQTJ06Eoii2dSwWC8rKypCTkwM/Pz/bdupz8OBBDB8+3G7ZwIEDG70v11xzDfz9/bFkyRLcf//92LVrFw4cOIDly5fX+rzJyckoKyu7ZP+gMf0gat2YwHBwcXFxuPPOO/HQQw9h9erVdvdpNFUlTETEbnltxahqK0x08TJFUezG09fHarUiPj4en3/+eY37XFxc7G47QoG+YcOGIScnB/v27cO6detw3333QafT4aWXXsL+/fuRnZ2NYcOGAYDtOGzevLnGvlS/+VutVnh4eNSobwDA7stpbWbOnInRo0fju+++w7p163Dttddi/PjxNWpBNNZdd92FMWPGIDc3FwsXLkS/fv3QpUuXS65fWVlp+wA3m80QEbu/lZubm+33Xbt2ISYmplHxjB07Fr6+vnjjjTcQGhoKvV6PgQMH2hWGUhSlQW24pVmtVtx66614+OGHa9zn4+NzycdpNBq7D8oL20tzakibrdZUr8eGHCMvLy9cf/31WLRoESZMmIBFixbhhhtuqNGZbMxzXu7rjoiuHPslTYf9kpqaul/SmDZRrTHtuClZrVYMHz4cr7/+eo37PDw8rmi7APDpp58iLi6uxv3e3t6235uyf1Dfvmi1WkyfPh2LFi3C/fffj0WLFuGqq65CfHz8ZT8n0LB+ELVuTGC0Ak899RQWL16M//73v3bLq7OlZ86csS3Lzs7G6dOnm+y5t27dijFjxthub968GZ07dwYA9O7dG4sWLYK7uzv8/f2v6HliYmJgMBjw888/232wbdiwoc4PutpUf0hbLBa75aGhoYiOjsaCBQtQWlqKq666CoqioLKyEq+++iqioqIQHh4OAOjVqxcA4MSJExg7dmytz9O7d2+cO3cOZWVll4zxUrEAVWcOZs6ciZkzZ2LMmDGYOnUq3nzzzTqrLW/dutV2/CsrK7Ft2za7IozDhg1DWFgY3nnnHSxevBj//ve/L7ktoOq479mzBwDg6emJxMREPPXUU7YpyqrPticnJ2POnDl44IEH7B6/fft2WCwW2xf2zZs3w2AwIDo6Gnl5eTh48CC+/fZbjBo1CkBVkbCLz6b5+/vbteHy8nIcPHgQkZGRl4y5vrbSq1cv5OfnY8eOHbWeHUlISMDbb7+N3Nxc29mRrKwspKSk4G9/+xuAqr/vvn37EB0d3aQffAkJCXj//fdhNptt7WPv3r0oKCiot61v3brV7vbmzZsRHBwMd3f3BrXZxujcuTM2b96Mu+++27Zs06ZNdus09BjNmDEDEyZMQEpKCr799ts6C25Wn9Fds2YNJk2aVOP+hrzuiKh5sV/Cfkk1R+qX6PX6Gvt1OW2iIe24KfoZF+vduzc++OADhISEwGg0NijWanX1x0QERqMR6enpdq+dy1XdP7hQbf2DhuzLjBkz8O9//xu7d+/G0qVLbVfXXOp5jUYj1qxZY3e1VrWm7geRA1Nl4ArVqbbxlM8995w4OzvXGLc4YMAA6dmzp+zZs0d27Ngho0aNEhcXlxpjTS+uMaDVauX999+3W2YwGOTdd98VkT/G/wUFBcnHH38sKSkp8sQTT4iiKLbx/aWlpZKQkCC9e/eW77//Xo4dOyZbt26V5557zjb+/eLxfXV54IEH6iyWdaljc7HMzEzRaDTy2muvSVZWlt1Y0DvuuEOcnJxk7NixtmXjxo0TJycnmT17tt12Zs2aJYGBgbJo0SJJTU2VPXv2yP/+9z954YUXRKRqLN+IESMkNjbWVsBpx44d8tprr9mKOFksFnF1dZUHH3xQMjIy5OzZsyIicvfdd8s333wjaWlpcuDAAbnpppskNDTUrtDVhaqPY2xsrHzzzTdy8OBBmT17tjg7O8vp06ft1v3Xv/4ler1ePDw8pLi4uM5jZbVaJSYmRr7++msREdm9e7dER0eLRqMRV1dXeeyxxwSAhISEyDvvvGP32OqiUXfeeaccPHhQvv76awkICLCNbbVYLOLn5yfjx4+XlJQU2bx5swwcOLBG+5w+fbpERETI5s2bZf/+/XLzzTeLu7t7nUU862srVqtVkpKSJCoqSr744gtJT0+XjRs32tr3hcW1du7cWWtxrYMHD4qrq6tMmzZNfv31V0lPT5e1a9fKvffeK0ePHhWR2mtgXHhbpOZ448zMTFsRz/379ze6iGd1ca2PP/5YTCaTrbilSP1tVqT294ParFy5UrRarcyfP1+OHDki7733ngQEBNi9nhtyjESqxkX7+/tL9+7dxd/fv8ZY5IuLeE6fPl38/Pxk8eLFkpaWJtu2bbMVK23I646Imhb7JeyXXMwR+yVz586V+Ph4SUtLk5ycHDGbzQ1qE7XVvKivHTdFP6O2Ip4dOnSQkSNHys8//yzHjh2TX375RR599FHZtGnTJY9Zff0xEZH/+7//Ezc3N3n99ddthdWXLl0qDz74oG2diz+LL2XHjh2iKIo8+uijkpKSIitXrpTIyMgaRTwbui89evSQ7t27i16vtyvyXr1vF/b/HnvsMTGZTPL6669LSkqK7NmzR5577jnb/Q3pB1HrxwSGA6rtw7C0tFRCQ0NrdBRSUlJk0KBB4uLiIjExMbJixYpai2Vdbkdh0aJFMnjwYDEYDBIRESEff/yx3WNyc3PlrrvukqCgINHpdBIUFCTjxo2zVQRvTEfBbDbLQw89ZNtWfHx8jedrSEdBpKqKcVBQkGg0GluxMRGRJUuWCAC7L32vvfaaAKhRbbuyslJefPFF6dixo+h0OvHx8ZFBgwbJ8uXLbeuUlJTIQw89JBEREaLT6SQgIEBGjRolP/30k22dDz/8UCIiIkSr1doKT82dO1diY2PFaDSKt7e3jBkzRg4cOHDJ/ak+jl9++aX07NlT9Hq9xMfHy5o1a2qsm5OTIzqdTubOnVvvcRIRWbVqlfj7+9s9/5kzZ6S0tFQqKiokMzOz1scNHjxYZs6caavS7urqKrfffruUlJTY1lm/fr1069ZNDAaDxMXFyWeffVajfWZkZMjYsWPFzc1NQkJC5M0336x3FpKGtJXCwkK55557JDAwUHQ6nURERMjzzz9vu//w4cNy7bXXislkEpPJJNddd52kpqbabWPfvn1yww03iKenpxiNRomOjpY77rjDVkH+chIYIiJbtmyRpKQkMRqN4uHhIVOnTpWsrKxaj3O18PBwefTRR+W2224TNzc38fb2loceeshWqVukYW22oQkMEZH58+dLUFCQGI1GGT58uHzwwQc1Xs/1HaNq8+bNEwB2VdEv3LcLO01ms1kef/xxCQ8PF51OJ8HBwXYF/xryuiOipsN+CfslF3PEfsnRo0clKSlJTCaTXbusr03UlsBoSDu+0n5GbW3x+PHjMm3aNPH19RW9Xi9hYWEyffp0SU9Pv+Txakh/TETk3XfflcTERDEYDOLp6Sl9+vSRN99803Z/QxMYIiJLly6VqKgo0ev10qdPH/niiy9qHMOG7sv8+fMFgIwbN67Wfbuw/2e1WmX+/PkSFxcnOp1O/P39ZdKkSbb7G/IaodZPEblogBcRtWrJycno0qUL9uzZY1ckrS5vvfUWHnnkEdx3332YPn26rdjXwYMH8cYbbyA3N7dGUaUhQ4YgJiYGCxcubPJ9oJoiIiIwe/ZsPP7442qHQkRE1GAt1S+5XCkpKejUqRN2796N7t27N8k2WxL7Y9TeaNQOgIiaRnl5OU6fPo1HHnkEQ4cObXAnAQDmzJmDdevW4cCBA+jZsyd0Oh10Oh2GDRsGvV5faxEmIiIioktpDf2S3NxcfPrpp3BxcUF0dHSTbJOImheLeBK1EUuXLsWsWbOQkJCAzz77rNGP79GjB1asWIHKykrk5ORAURQEBASwcjMRERE1Wmvol0yePBlpaWl4++237WY4ISLHxSEkREREREREROTwOISEiIiIiIiIiBweExhERERERERE5PCYwCAiIiIiIiIih8cEBhERERERERE5PCYwiIiIiIiIiMjhMYFBRERERERERA7PqbEPEBHk5OSgoqKiOeIhB6bT6eDn59ek828TERGxb9F+sW9BRESNoYiINOYB2dnZqKyshE6na66YyEFVVFTAyckJ/v7+aodCRERtCPsW7Rf7FkRE1BiNHkJSUVHBDkY7pdPpeHaMiIiaHPsW7Rf7FkRE1BisgUFEREREREREDo8JDCIiIiIiIiJyeI0u4nmxstuubYo4bIwfrK53ncDAQMTHx0NEoNVq8fzzz6NPnz7IzMzEo48+ivfeew/79+9HVlYWRowYAQBYtmwZ9uzZgxdeeKFJ4yUiIqKmxb4FERER1aZVXoFhNBqxbt06rF+/Ho899hieffZZAFWdj/feew8AkJycjB9//FHNMImIiKiVYN+CiIjI8bXKBMaFioqK4OHhAQA4ceIEBg0aBLPZjBdffBFffvklhg4dii+++MJu/d69e9sKRp0/f97uNhEREbVv7FsQERE5piseQqKGsrIyDB06FOXl5cjKysLKlSvt7tfr9XjooYfsLutctmwZAMDV1RX9+/fHDz/8gDFjxuDzzz/HmDFjWP2ciIioHWPfgoiIyPG1yiswqi/z3Lx5M5YtW4Z77rkHItLgx0+fPt3W6Vi6dCmmTp3aXKESERFRK8C+BRERkeNrlQmMC1111VXIy8tDbm5ugx/Tt29fnDhxAps2bYLVakV8fHwzRkhEREStCfsWREREjqlVDiG5UGpqKqxWK7y9vXH69GnbcpPJhKKioks+bvLkybjrrrtw//33t0SYRERE1Eqwb0Fkr9JiRok5/4J/51BiPodS2+9VP82VxRDYX7n0x5VM8vv/8sdNBdBpjDDoXGHUucPo5Aqjzq3qd707THpvmAw+tp96J+eW22kickhXnMBoyNRkTa16nCpQ9aa4YMECaLVau3UGDhyIBQsWYOjQobjvvvtqbGPixIl44YUXMGHChBaJmcgRicUMVJwHKgohFeftfzdX/Q5LGUSsAKyAXPTvwmUaJ0DrDMXJGdA6A07OgNYFipMR0LpU3XZygaL3Aox+UPTuau8+ETko9i2IWl6puQC5RceQW3QMeUXHcLb4BIrK81BizkeFpbSZn7xhq+m0Rrga/OBtCoWPawR8TJHwcQ2HlykUThp988ZIRA5BkcYM8ARw+vRp6PWt/w3iq6++wur/Z+/O46Kq9z+Ov84MO6hsIi4o7kupKKKYC+KSuZRbZfnTa93Ktlu2WF3rWmb3Z7bvlnYXvb/skql4NU3tIuYSKiK448IOAioi27DOOb8/KIoUBQQOM/N5Ph4+BOacM++hhM98znf5/nuWL1+udxSLUlZWRvv27fWOIepAqyiG4iw0UyZacSaYMtGKs6DkIphL9AtmcAAnbxSn1pV/O3pXNjacWoNzaxQ7V/2yCSGalNQWtk1qi6ZVVlFMTlEylwoSK/8uTCanMAlTWa7e0epNUQy4O7evbGq4+ePl6o+3mz/uLh0wGix+wLkQ4jds8l/0woULiYiI4N///rfeUYRoMJpaAYUpaAWJaKYMMGVVNizKrugd7drUMjCdRzOdB+CqTqqjN0oLfxQ3f3DzR2nRGcXeralTCiFErUhtIZojs1pOZt4pMnKPkpUXz6XCJPJLsrnGb12LpmkquaY0ck1pnLuwp+rrBsUOD5cO+LbqhZ9nAH4eA3Bz8tYxqRDiZtnsCAxRP3KXpPnQyvLR8s+h5Z9Fyz8HhcmVTQFrdlVTowuKvYzUEMLSSW1h26S2aDgVahmZV06SnnuUjNwjZOadokIt1TtWs+Lh0gE/zwGVfzwCcHZopXckIUQd2OQIDCEskWbKRLsS/2vDoiRb70hNr/QSWukltEuHfv6CAm4dUdxvQXHvg9KqB4rRUdeIQgghRFPKKUwmJSeGlJxo0nOPSsPiBnJN6eSa0jmavhlQ8HbrXNXM6ODRD0cZ7SlEsyYjMESdyF2SpqOZy9DyTqFdPoJ2+WjlmhXi+hQ7lJbdUDz7oXj2R3HtoHciIUQtSG1h26S2qBuzWk7ypYMkXowi5XIMBSUX9I5kNRTFgE+L7vh7BdHTdzRebp30jiSE+B1pYIg6kSKjcWnlBWg5sWiXYtCunLT+KSGNzdETxaMvincQisctKIpB70RCiGuQ2sK2SW1xY5qmkZ57hPisnZzN3k1pRYHekWxCa7eu9Gw7mp5tQmnp3EbvOEIIpIEh6kiKjIanleWhXTyAeukQ5J0FVL0jWSf7ViitgzD4DEVp2U3vNEKI35DawrZJbVGziwUJnMr8L6ezIikslZGY+lFo534LvXxH06PNKFk3Qwgd3XQDY+KqYw0aaOsDfW94jK+vL7179676fNq0aTz99NPXPDYsLIy4uDiWLVtW6wybNm3irbfewsfHh/Dw8FqfZwukyGgYmlpROTUke0/l9BDNrHck2+LUGqV1MAafYJlmIkQzILWFbZPaorq84ixOZ0UQn7mTnKJkveOI3zEoRjp6DqSn7xi6+QzDwc5F70hC2BSLXMTTycmJyMjIRrv+mjVreO+99wgODm605xC2SStKQ83ag3bhJyiX4Z+6KbmIlrYZc9pmcO2AofVQlDa3oTh66p1MCKETqS2EnkrKCzidFUl8VgTnr5zA2rY5tSaqZiY5J5rknGgiTjnSuXUwfdreTmfvISiKonc8IayeRTYwahIbG8srr7yCyWTC0dGR9evXA5CVlcXMmTNJTk5m4sSJvPbaawBs2LCBjz76CE3TGDt2LK+++irvvvsuBw4c4Nlnn2X8+PH8+c9/5sUXX+TIkSMYjUaWLFnC8OHDCQsLY9u2bRQXF191XSF+SysvQrsYhZq1p3KrU9G8FKWjFn0LKRtQvAMxtBuH0qqH3qmEEM2E1BaiMV0xnSc2dT0nzm+j3FyidxxRRxVqKWezf+Rs9o+4O7enf8cp3NLuDhztZBGoGvAAACAASURBVIt3IRqLRTYwSkpKCA0Nrfp8/vz5TJw4kUceeYQvv/ySAQMGUFBQgJOTEwDHjx9n586dODg4cNttt/Hwww9jNBp54403+OGHH3B3d+fee+9l69atLFiwgL1797J48WICAgJYvnw5iqLw448/cvbsWe69916ioqJqvK4MgRS/0EyZqOlb0bKjQCvXO464Ec2MdvEg5osHwa0zhvbjUFoPQTFY5I9JIUQdSW0hmlJm3ikOJX9DwoV9aLL2lVW4UpzBj6eXE3VuFX3ajSfAbyoeMk1ViAZnkZX5tYZ5njx5kjZt2jBgwAAAWrRoUfXYyJEjadmyJQA9evQgLS2N3NxcbrvtNry9vQGYMWMGUVFRTJw4sdp1Dxw4wMMPPwxA9+7d6dChAwkJCTVeV4oMoeWfQ03bgpYTiwwBtVCFSainV0LiNyhtR2FoNxrFwV3vVEKIRiS1hWhsmqaScPEnYlK+5fyV43rHEY2kzGwiLi2cuLSNdGk9lCD/+2jnfovesYSwGhbZwKir3y4MZjQaMZsbZsHExrqusDyapqFdPoKatgXyz+gdRzSU8jy01P9gTttSuYNJhwkosie8EAKpLUTtVZhLOXF+B7Gp68g1pesdRzQZjcSLP5F48Sfaud9KkP99dPYOlnUyhLhJBr0DNJRu3bqRnZ1NbGwsAIWFhVRUVNR4/MCBA4mKiiInJwez2cyGDRu47bbbrjouODi4ar5rQkICGRkZdOsmWzCKSppagZq1B3PMK6gnPpDmhbXSKtAuRGE+/Brmk5+imc7rnUgI0QSkthA3w1R2hZ8SVvG3PfezM/5DaV7YsPNXjvOfuL/wf1EPc/L8DlTZfU6IervpERi12Zqsof1+nuro0aNZtGgRX375JS+//DLFxcU4Ozvz7bff1niNNm3a8Je//IXp06dXLbQ1YcKEq4578MEHefHFFwkJCcFoNPLxxx/j6OjYKK9LWA5NU9GydqOm/AfKLusdRzQZDe1SNOZLh1B8hmLoNA3F2UfvUEJYHakthCUrqyjmUHIYMSnrqFBlYU7xq5yiZLafeIvo5DBGdJ9Hl9ayK5EQdaVomlanSfq/36td2BbZqx3UnDjUpLVgytA7itCbYkRpMwJDpymyBasQN0FqC9tmLbWFqpk5kbGNnxJWYZKbG6IW/DwHMrLHo/i0kBFYQtSWNDBEnVhLkVEfWkESauI3aHmn9I4imhvFvnKxz453oji00juNEBZHagvbZg21RUrOIXaf+YJLhUl6RxEWRsFAr7ZjGNbtIVo4tdY7jhDNnjQwRJ1YQ5FRV1rJJdSkdWgX9yO7iojrMjhi6DgZpcNE2X5ViDqQ2sK2WXJtcakwmT1nviA5J1rvKMLC2RkcGdhpBkH+9+Ng56J3HCGaLWlgiDqx5CKjrrSKItTUzWgZ/wWtXO84wpI4t8XQbQ4GD9k2TYjakNrCtllibVFUepmohFUcP/89mqbqHUdYERcHd4K7/IG+7SdjMBj1jiNEsyMNDFEnllhk1Id6IQo1YQ2UF+gdRVgwpfUQDF1moTi66x1FiGZNagvbZkm1RYW5lMOp64hOCqPMbNI7jrBinq4dGd79Ebq2vnonIyFsmTQwRJ1YUpFRH1rpZdSzq9AuH9E7irAWRufK3Uraj0NRrGbnaiEalNQWts1SaoukiweIiP+QgpILekcRNqRr62GM6f0MrrJYuBBAA2yjKoQ10DQNLXNn5e4iZtnyTA/Zl4u5+y+7sLczYDQo/GvRcGYv2YPZrGE0Kjw4sRuzx3etds7y8Hj+b1sCAC/MupXpIZ34PDyer3Yk8oc7uvLolJ5kXy7mvbATvP3EID1eFpiLURO/huy9GLvPRWkpK40LIYQlKSnPJ/L0Z8Rn/lfvKMIGJVzcR8aVY4zu9RQ9fUfrHUcI3d30CIwNX11s0EDTZ9949V1/f3+Sk5OrPg8LCyMuLo5ly5bVeM6+fftYvnw5a9asueqxr7/+mhUrVgCVb2QXLlx4zX3bb2Tfvn3Y29szePDgOp9rKSzlLkldaKZMzGf+Afln9I5i08xmFUVRMBgUVn9/joyLJiJiMvnPm6Nxc7G/5jn95/6HmL/fSVmFyqintnHwy8ncu2gXa98YxT1/2cW3fx3Fi8sP8fx9t9DG07mJX9G1KChtQzF0uQ/F6Kh3GCGaDaktaia1hb7OZu9hZ/xHmMpy9Y4iBN19RjK693xcHGRqqrBdNj8C4/z583zwwQdERETQsmVLCgsLycnJqde19u3bh6urq1UXGdZE08xoaVtQUzbJIp3NgNH46/SKAlM5ffzdiTycxZ0vReDu5sCH8wfTydet2jmd27aguMyMqaQCd7fKNz9Gg0JFhYrRoHAq+QqeLRybSfMCoHKkj/nKKYy9HkNp4a93ICFEI5DawvKZyq6w89RHnL2wW+8oQlQ5e2E36blHGd37aXq0CdE7jhC6sLoJ2U899RSbN2+u+tzf37/q44KCAmbNmsXQoUNZsGABqqpy6dIl3NzccHV1BcDNzY1OnToBMHXqVF555RVCQ0MZOXIkhw8fBiA3N5c//OEPhISEMGHCBE6cOEFqaiqrV69mxYoVhIaGsn///qZ70aLONFMm5sOLUZPXS/OiGYk7e5nbHtvK5+GnGdDDk7DXRxL5yR08O7MPz3x08KrjJwxtT98//IdBD33HszP7APDHyd2ZvWQP86b04JP18UwL6cif3t/P5+HxTf1yalaciTluCWraFlm9XggLILWFbUm8GMX/RT0kzQvRLBWXX2HL0SVsOfoGxWV5escRoslZ5AiMkpISQkNDqz6/cuUK48ePv+F5sbGx7NmzBz8/P2bOnMmWLVuYOHEirVu3ZtCgQYwYMYJJkyZVu1ZxcTGRkZFERUXxzDPPsHv3bt5++2369u3Lv/71L/bs2cOf/vQnIiMjmTt3Lq6urjz55JON8rpFw1Cz96GeXQ1qqd5RxO8EdPfkpy8m8u3OZN5ac5zlzwcDMDLAlxeWx1Q7Nr+ojBX/OcOpNVMpK1cZ9+wO7hjSnnFB7RgX1I7dcVkE9vRi9ffnWPRAf978v2MUmsprnI7S5DQzatJalMtHMfSch+LkpXciIWya1Bai3FzMrtOfczxji95RhLihM9m7SM89wpjez9DNZ7jecYRoMhY5AsPJyYnIyMiqPy+99FKtzhswYAD+/v4YjUamT5/OgQMHMBqNfPPNN/z973+na9euLFq0iLfffrvqnGnTpgEwdOhQCgoKyMvL48CBA9xzzz0AjBgxgtzcXAoKZLvN5k4zl2E+/TfU0yuledEMlZWbqz5u5WaPi6OR/KIyAE4mX8HDrfoOBQZFwdnRiJODEVcnO8rKVX5Z0UfTNFZ/n8ADE7pSVFxBeYWKqbSC0t88R3Oh5cVjPvwX1IsH9I4ihE2T2sK2ZV45yVdRj0rzQlgUU1kum4+8xtZj/0tJeb7ecYRoEhY5AuN67OzsUNXKIdmqqlJe/uv0AEVRqh37y+eKojBw4EAGDhxISEgI8+fP58UXX7zuOcKyaKbzmE9+BqZ0vaOIGsSdy+Wl5YcwGhScHIx8+efbGPfsDzg7GAH4+NkhAKz+/hw9/Fox9NbWTBvRkeFPfI+qajw+rScGQ+W/z28ikrk7tBNGo4HZ47ty76s/0se/FV6tnHR7fddVYUI9tRwt5wiGbnNQ7JrLmh1CCJDawpppmkZ08tf8lLBKpvQJi3U6ayfnrxznzv6v06ZlD73jCNGorK6B4efnx5EjR5gyZQrbtm2rVmTExsaSkpKCn58fGzduZM6cOWRlZXHhwgX69esHwPHjx+nQoUPVORs3bmT48OHs37+fli1b0rJlS4KDg1m/fj3PP/88+/btw9PTkxYtWuDm5iZ3S5ohNXsv6tl/yaiLZm5wb28iP7mj2tcOrJx01XFzJ/y6DemCWbeyYNatVx1z39jOVR8H9fbmpy8mNmDSxqNd2Ie5IBHjLc+guPjqHUcI8TOpLaxTubmYbcff4tyFPXpHEeKmFZRc4Jvo+Yzt/Rx92o3TO44QjeamGxi12ZqsKc2ePZu5c+cyatQoRo8ejYuLS9VjAQEBLFy4kKSkJIYNG8akSZPIyMhg8eLFZGVl4ejoiJeXF++8807VOU5OTowePZqKigo+/PBDAF544QXmz59PSEgILi4ufPLJJwCMHz+eP/7xj2zbto0333yT4ODgpn3xohrNXIp67l9o2Xv1jiJE7RVnYo57HUOvJzB49tU7jRC6kNpCaovGllecyaa4RVwqTNI7ihANxqyWsf3EMrLzTxPS43EMBqPekYRocIqm/TJrvHZ+v1e7NZs6dSqLFy8mICBA7yjNRnPeq/23tJIczCfehyKZMiIslQFDl3sxdJigdxAhGp3UFratqWuL1JzDbDm2hJJyGdkirFcHj/5M7vcazg6t9I4iRIOyyEU8hbgerSAJc9zr0rwQFk5FTQzDfPpLNFW2+hVCiIZwOGUdG2JfkuaFsHrpuUdYc+AxsvPP6B1FiAYlIzBEnTT3ERhqzmHUU1/IehfCurToivGWp1Ec3PVOIkSjkNrCtjVFbVFhLuO/p97nVOYPjfo8QjQ3dgZHxvZ5lt5tZV0MYR1kBIawGmrGDtQTH0vzQlifggTMhxejFchcbSGEqKuCkousPfSMNC+ETapQS9l2fBk/nl6OqjXcdvJHMvIoaYbb0wvrJw0MYfE0TcV87ivUhDVAnQYUCWE5ynIxH1mKmnNY7yRCCGExMnKP8fWBx8nOP613FCF0dTh1PRtiXqS4LO+mr3Uw5TJPro3lmfVHKC6TJoZoWtLAEBZNM5einvwY7bzcVRE2QC1DPfkp6oUovZMIIUSzF58ZwbqYBZjKcvWOIkSzkJYbxzfRT5NfnF3va8SlX2FB+DFKK1Ri0q7w1Lo4CksrGjClENcnDQxhsbSyfMxH3kTLidU7ihBNRzOjxq9AzdyldxIhhGi2jqVvYdvxZaiavLES4rdyTel8Ez2fnMKUOp97IjO/ctTFb6aOHMnI4+l1cZjK5N+aaBo3vYjne++916CBnn/++Rse4+vrS+/evTGbzXTv3p1PPvmk2p7s15OVlcXLL7/MP/7xj5uNapOayyKeWlk+5qPLwJShdxQhdGPocp9ssyqsgtQWtq2ha4vY1A3sOr0cmVYqRM2c7FsybcCb+LbqVavjz1wo4PFvYskvuXajYlBHDz6c0Q9HO2NDxhTiKhY5AsPJyYnIyEh2796Nvb09q1evrtV5FRUV+Pr6SoFh4bSyPMxH35TmhbB5amIY5uQNescQwipIbWEdDib9m12nP0OaF0JcX0l5PutiFpB6+cYjmZNyivjTt3E1Ni8ADqXm8udNx6kwqw0ZU4irWGQD47eCg4NJSkqiqKiI+fPnM378eEaPHs33338PQFhYGHPmzGH69OnMmDGD1NRURo4cCUB8fDzjx48nNDSUkJAQEhMTAfjmm28ICQlh1KhRPPHEEwCkpqYyffp0QkJCmDFjBunp6QA89dRTLFiwgHHjxhEcHMyOHTsAMJvNLF68mNtvv52QkJBaF0Li+rSyKz+PvDivdxQhmgUt9T+YE77WO4YQVkVqC8v007l/su/c3/SOIWpgUOxwc/SmlXM7PF074uXWmdYtutGmZQ98WnTH260LXq6dcHfpQEsnXxztWugd2eqVm4s5cX7bdY9JzzXx5NpYck3lN7ze3oQcFm05iVq3Af5C1Imd3gFuRkVFBTt37iQ0NJQPP/yQ4cOH89FHH5GXl8f48eOriomjR4+ya9cuPDw8SE1NrTp/9erVPPLII9x9992UlZVhNpuJj4/ngw8+YMuWLXh5eZGbW7nw08svv8y9997Lfffdx9dff83LL7/Mv/71LwDS0tLYvn07ycnJTJs2jZEjR7J27VpatmzJjh07KC0tZfLkyYwaNYpOnTo1/TfKSmhlVzAfWQbFmXpHEaJZ0TK2YzaXYOj+AIpi8X1pIXQltYVl+vH05xxOXad3DJvV0qkNbo7euDp64ero+fPfXrg6eOL288dO9i3q/DuqwlxKUdllikpzKCq9TGFpTtXHRWU5FJbmkF+cSbm5pJFemXXr4j2U2/u8UOPjWfklPLE2jouFZbW+5n9PX8DZ3siiO3qhKEpDxBSiGotsYJSUlBAaGgpU3iX5n//5HyZNmsT27dtZvnw5AKWlpWRkVE4xCAkJwcPD46rrDBo0iA8//JDz588zefJkunTpwt69e7nrrrvw8vICqDrv0KFD/POf/wTgnnvuYcmSJVXXmTJlCgaDgS5dutCpUyfOnj3Lrl27OHnyJJs3bwagoKCAxMREKTLqSSv9eeSFNC+EuCYt60dUTcXQ4yEpGISoB6ktLJOmaeyM/5ij6Zv0jmIjFDxcOlSOmmjZA58W3fBp0Q1He7dGeTY7oyOtnNvSyrltjcdomkquKZ3s/DNcKDjHhfwzXMg/S5nZ1CiZrEVHz0Am9X8Vo+HabwcvFZbyxDexZObXvTm0+Xgmro5Gnh/d42ZjCnEVi2xg/DJP9bc0TeMf//gH3bp1q/b1w4cP17gI14wZMxg4cCD//e9/uf/++3n33Xfrlef3bxYURUHTNJYuXcro0aPrdU3xK6009+fmRZbeUYRo1rTsPah2zhi7/o/eUYSwOFJbWB5VM/PDiXc5mblD7yhWy8PFjzYte9KmZfeqhoWDXe0Wt20qimLA07Ujnq4d6d12LFDZ1LhiOk92wRku5J8hO/8s2fnxMlLjZ+3d+3FXwBLsDA7XfDzXVMYTa2NJu1Jc7+cIi0mnXStn7g/0q/c1hLgWqxlrHBoayt/+9jd+2VTl2LFjNzwnOTkZf39/HnnkEe644w5OnjzJ8OHD2bRpE5cvXwaoGuYZFBREeHg4AOvXr2fIkCFV19m0aROqqpKUlERKSgrdunUjNDSUVatWUV5eOV8sISGBoqKiBn3NtqBqzQtpXghRK1rGDszJ4XrHEMIqSG3RfJnVCr4/tlSaFw3MqNjTySuI0F5P89Dwr3lg2Com9F3IwE5308GjX7NrXtREUQx4uHagl+9oRvZ4jHsGvcdjo8KZNmAZ/f2m0MLJR++Ijeq1+/by/B07+fNduyj+zfSPsmIzr0zbw6yhn9DOt7KxcPz4cezt7bG3t+fUqVPkl5TT3s+PmIitN53jw8iz/Hju4k1fR4jfuukRGLXZmqwpPPfcc/zlL39h1KhRqKpKx44dWbNmzXXP2bRpE99++y12dnb4+PjwzDPP4OHhwTPPPMPUqVMxGAz07duXTz75hKVLlzJ//nw+++wzvL29+eijj6qu0759e8aPH09BQQHvvPMOTk5OzJ49m7S0NMaOHYumaXh5ecliW3WkVRRjPv6+NC+EqCMtdSOqnTOGDnfoHUWIepHaQmqL69E0jR0n3uZM9i69o1gFJ/uWdPEeSpfWwXTyGmQxTYq6sjM44O8dhL93EKN7Pc3FggQSL0aReDGKrPx4veM1mIi1KZSaKnhv22j+d+5PrP7rCR5bNgCA9R+k4unhQ3paOu7u7rz00kvEx8czatQoABa8+CJFnUdQYdbwDBh101lUDRZ9d5KV9w+kVxtZlFU0DEXT6rZM7O/3ard1Tz31FLfffjt33nmn3lGaREPv1V4TTa1APf4+2pUTjf5cQlgnBUOvRzH4DNU7iBA3JLVFdVJbXN/es38jOvnfjZjI+rm7dKCbz3C6th6Kb6veGBSj3pF0VVSaQ+KlAyRe/ImUS4cwazfecaO5ev/Jgzg6G3ny3UB2fJXI7vB0/rp+JJ6unfjzjK3ce+9MPvroI6ZMmcKZM2cYNGgQSUlJlFdUcNnBi6SYvfSY9y6u7bo2WKbWbg78c/Yg2rRwarBrCttlkWtgCOumaRrqmb9J80KIm6Khnv4S7Ftg8LhV7zBCCNEgjqRtluZFPRkUI918RtDf7y46ePTXO06z4uroRd/2E+nbfiKmsiucyNjG0fTN5JdY3ijg4qIKPHwqGwXuPs6Ul6m4u7Tn7sB3mV+8gXbt2gHg4+NDTEwMn376KZ07d8ZUruIxaAL2Lb1IXvsOZblZ+M98CY8+N38j5GJhGc+uP8qXswbi6iBvP8XNkf+DbtInn3yidwTrU5qDlivNi2ZBMYLRCRQ7UAyVn/+yBZqmgmb+9U+FCZB9v5sVzYx68hOUfgtRWvjrnUYIUUtSW1xbwsWfiDz9sd4xLI6bY2v6dZjMre0n4uroqXecZs/FwZ2gzvcR6H8PKTmHOJK2iaRLB7CUGsfZxQ5TQeUIkisXinFwtOPuwHdxdfTE2dmZ8+fPA3DhwgVatGiBq1sL5v4tkr0JORxedCc9HnmHs/9YSNc5i0kKW9ogDQyAsxcL+ct3J3h/Wj/ZLU3cFGlgiGZHcfLGGPAq5uPvybapjcnRExw8UBzcwdEDxaEVOLiDg3vl1xzcwd6t1nu2a5oZygqg7Apa2RX4+Y9W9XcelOZAWV4jvzBRjbkE8/H3MQ5cjCKFqxDCQmXlxbP16P+iaareUSxGJ69B9O9wF529gzEYbHuKSH0YFCOdvYfQ2XsIecWZHEvfwvGMrRSXN+86pn+IDz+sSQYgJuIig4OGVi1aettttxEeHs5HH33Ejz/+yLxHH2XRlpPsTcghYc0buHW6BQDNXIG5rBi1omGn0uxNyOGf+1P441D/Br2usC2yBoaok6ZaAwNAKy9CPfkxWp71LKykGycflBb+KG7+4Fb5t2LvqksUrSwPrTAZCpLRCiv/UHpZlyw2pUVnjP1fQTHY651EiKtIbWHbblRbXDGd55vopzCVXWnCVJbJ3uhM3w6T6ddhMh4uHfSOY3Uq1DLOZe/hcOp6svNP6x2nRq/N3ENhXjnOTs6kpaXTtWtXcnNzKSwspF27dphMJtzd3Xly9W62nszCXFbMkTfuof/i/2A0Gjm86E7UsmLajplN+9sfaNBsBgU+vjuAIf5yU0XUjzQwRJ00ZQMDfl7M88zf0S781GTPafEc3FFa9axsVrTwR3HrhGKnT7OitrSy/MpGRmEyWkFyZdOqwja3BmxMSpuRGHs+pHcMIa4itYVtu15tUVyWxzfRT5NrSm/iVJbFqNjTz+8uBneehYuDu95xbELChX3sO/d3copS9I5yFSf7Ftwd+B6tW9S8EOfS7fGEHz3fhKl+5eFiz//9IUgW9RT1Ig0MUSdN3cD4hTk5HC11Y5M/r8Vw64TiOQCDV0Dlx7Wc9tFcaZoZ8s+h5sSi5cTKVroNyNDtDxjajdE7hhDVSG1h22qqLSrMZayLWUBmnqyLVRMFA73bjWNol7m0dG6jdxybo2pm4jMj+CnhnxSUXNA7DgAOdq7MGPgOvq161njMezvPEBajb1Pw1rYtWXn/QOyNll2ziqZ30w0Mj1MLGjRQbu93r/v45cuXmTFjBlC5+IzRaMTLywuA7du3X7MAWrVqFc7OzsycOZOwsDBGjRqFr68vACtWrGDOnDm4uNRvz+u8vDwGDx5MfHw8iqIQHR3NpEmTiIuLo127duTn5zNo0CDi4+MxGK7+B7pv3z6WL19+w33lAXJycujbty9Lly7lgQceqFfem3WzDYz84mwc7Jxxsm9Z53PV7L2oZ/4JWkW9n99qKHYo7n1QvAagePVHcfTSO1Gj0kyZaDlxqJdjIe8MlrKQVrOkGDH2W4jSqrveSYSoIrVFdVJbgKapfHd0Cecu7NElkyXo2noYw7r9ES83f72j2LwKtYxj6d9xIPErXdfIsDc6MW3gW7R3r3n3sc92J7DqQPMYNXLPgPa8OLbmRosQ12Jxi3h6enoSGRkJwNtvv42rqytPPvnkdc/57S/ksLAwevXqVVVkrFy5krvvvrtORYbZbMZorFwMqVWrVrRp04YzZ87Qs2dPoqOj6du3L9HR0UyZMoVDhw4xYMCAaxYYdbVp0yYCAwMJDw/Xrci4GaXlhYTHLkTTzEwd8CbuLu3qdL6hzXBw9EI9+fHPO17YGMWI4h2E0joIxf0WFDtnvRM1GcWlLYpLWwx+E9DKC9EuH0W7uB/t8lGkmVFHmhnzqU8xDngdxVGGGQsBUls0x9pi95kV0ryoQQePAIZ3e4i27n30jiJ+ZmdwYEDH6dzS7g4Op6zjUMpays3FTZrBaHDgroC/Xrd58feopGbTvAD4NjaDQD8PxvT00TuKsCAWP2ZHVVXGjh0LwPHjx/Hx8SE9vXJIVFBQECaTibfffpvPPvuMzZs3ExcXx+OPP05oaCgrV64kKyuL6dOnM23aNAAiIyOZMGECY8aM4aGHHqKwsBCAwMBAlixZwpgxY9i0aVO1DEFBQURHRwMQHR3No48+Wu3zwYMHYzabWbx4MbfffjshISGsXr266vyCggJmzZrF0KFDWbBgAap67RW2w8PDef3118nMzKzaAgnA39+fRYsWMWLECGbMmMGlS5cAmDp1Kq+88gqhoaGMHDmSw4cP3/T3u75U1cx3R5dwuSiFXFM6YQf/xPkrdR8SanDvjTFgETi1boSUzZSjNwb/ezAO+QBj78cxeA+yqebF7yn2bhja3Ibx1ucwDn4HxW8y2LfQO5ZlKbuC+dQnaKqMZhLiWqS20Le2OJP9I4dT1zX4dS2du0sHpg1Yxj2D3pPmRTPlYOdCcNc/8MfhX9G/w5Qme16jYs+d/RbT0XNAjcesiU7li71JTZaptt784TSXCkv1jiEsiMU3MAwGA6WlpRQUFHDgwAECAgLYv38/aWlpeHt7V7v7ceeddxIQEMDnn39OZGQk8+bNw9fXlw0bNhAeHk5OTg4ffPAB69atIyIigv79+/PFF19Une/h4UFERERVQfKL3xYZKSkp3HXXXcTFxQGVRUZQUBBr1qyhZcuW7Nixgx07dvDVV1+RklLZAY2NjWXp0qXs3buX5ORktmzZctXrzMjIIDs7m4EDBzJlyhQ2bvx1PQiTyUT//v3Zs2cPQ4cO5d13fx0qW1xcGjHa2AAAIABJREFUTGRkJG+99RbPPPNMA3zH62dn/EekXo75NVd5HutiFnAm+8c6X0txaYcx4FVo0aUhIzYzCopHPwy3PItx8DsYOk6u3OZUVKM4tcbYubK5Y+j1GLTsoXcky5F/DjXhK71TCNEsSW2hX22RW5TODyffa9BrWj6FwE73MCd4Jf7eQXqHEbXg4uDO6N5Pc8+g92nl3LZRn0tRDEzo+wqdWw+p8Zh1sel8uOtco+aor7zicpZsO6V3DGFBLL6BAZW/5A8ePEhUVBTz588nKiqK/fv3ExwcXKfrxMTEcObMGSZPnkxoaChr166tuuMClXcdrmXw4MFER0eTkpKCn58fTk5OaJpGYWEhR48eZeDAgezatYu1a9cSGhrKHXfcQW5uLomJiQAMGDAAf39/jEYj06dP58CBA1c9x8aNG5kyZUpVjvDw8KrHDAZDVba777672vm/FERDhw6loKCAvLymn5d3NH0zxzKuLpzMahlbjr5BdHJYna+pOLSsnMfvPaghIjYf9i1QOkzEGPQ2xr7PY/AKsPgFOZuCYrDH4DMUu4BXMA78K0rb0WCUla1vRMuMRL1w9c8bIYTUFnrUFhXmUr47+jplsgtVFQ8XP2YGfcTIHo9hZ3TUO46oow4e/Zkz9EsGdJwOKA1+fQUD4295ie5tRtR4zHfHM3n7v2ca/LkbUlTSZdYelp2GRO1Y3BoY1xIcHMz+/ftJT09nwoQJfPrppyiKwrhx4+p0HU3TCAkJYcWKFdd8vKa5rF26dCEvL48dO3YwaFDlG+r+/fsTFhaGn58fbm5uaJrG0qVLGT16dLVz9+3bh6JU/4H2+8+hcojnhQsXWL9+PQBZWVkkJibSpcvVoxB+e35trt2YsvPPsOv0Z9c5QmPv2S/JM51ndK/5GAzGWl9bMTpg6P0kauI3aBnbbj6snhzcMXScguI7HMUgK/HfDMXND2P3uWid70U7H4GatgXMNrhmSi2p51ZXbrsr62EIUY3UFtU1RW2xM/5jLhUmNsi1LJ2CgcBO9zC061xpXFg4e6Mzo3o+SXefkew4+Q5XTBkNdGWFMb2foXfbsTUesSM+m79ui7eI1cI+2X2Owf4e+Hu66h1FNHNWcWs3ODiYdevW0blzZwwGA+7u7kRERDBkyNVDqdzc3Krmnv7+88DAQA4ePFh196KoqIiEhIRaZQgMDGTlypUEBVUO7Rs0aBArVqxg8ODBAISGhrJq1SrKy8sBSEhIoKio8g5DbGwsKSkpqKrKxo0bq875xS/HHj16lJiYGGJiYnj66afZsGEDUDlXd/PmzQBs2LCh2uv+ZTjo/v37admyJS1b1n33j/oqKS/guyOvY1bLb3jssYwt/CfuFcrquDinohgwdr0fQ7c/YJH/O9u5YOh8L8agtzG0Gy3Niwak2Dlj6Di5cp2MDhPBYK93pOapogj17D/0TiFEsyO1RdPWFifOb+fEeQu/GdFAPF07MnPwx4zoMU+aF1akvUdfZgevZGDHu2mI0Rijej5J3w6Tanz8x7MXeXXLScx123BSNyXlKq9tOUlFDev1CPGLmx6BcaOtyZpCx44d0TSNoUOHAjBkyBDOnz+Pu/vVdxRnzpzJCy+8gJOTE1u3bmXOnDncd999+Pr6Eh4ezscff8xjjz1GaWnlYjILFy6ka9euN8wwePDgqrmtUFlkpKSkVBUds2fPJi0tjbFjx6JpGl5eXlWLbQUEBLBw4UKSkpIYNmwYkyZV/2G0YcMGJk6cWO1rkydPZt68eSxYsAAXFxcOHz7MBx98gLe3NytXrqw6zsnJidGjR1NRUcGHH35Y22/pTdM0jW3Hl5FfklXrc5Jzovkmej5TByylRR0X6TS0G1O5Q0n852AuqWvcpmdwQGl/O4YOE1HspdPcmBR7N4xdZqK1vx019T9omT8C8svxt7TLR1AzIzG0DdU7ihCA1Ba/sJXaoqzCRGTCJzd9HUunYGCQ/70Ed5mLnVFuaFgje6MTIT0fp3ubEWw/8Q5XTPWbNjG8+yMM6DitxsejknJ4efMJzKplNC9+cTKrgFX7U3j4ts56RxHNmKJpdWvL/X6vdqE/f39/kpOTr/r61KlTWbx4MQEBAQ32XNfaq/1aDiZ9zb5zf6/Xc7g5ejNlwP/i06Jbnc/VClMwH38fyq7U67kbnWJE8Q2pnC4iQ/Z1oRVnoSZvQLsoaz9UY3TCOPANFGfZykw0Paktmp+mqi00TeNM5l6iL1xvuqn1c3HwYHK/12jv0VfvKKKJlJtLiDj1Aacy/1un84Z0mcNtXR+o8fGYtFzmrztCaYVl3qxxMBr494OD6ehR+22ohW2xwDH3orlLuxzLTwn/rPf5haWXWBv9DEmX6v4GU3HrhHHAa+DqV+/nbyyK92CMg97E2H2uNC90pDj7Yuz9BMYBr6PINnS/MpdgPv0lmmaZBY8QwjIVleZQUl6gdwxd+bTozqwhy6V5YWPsjU7ccetCRnR/FKWWb8kCO9173ebFsfN5PLf+qMU2LwDKzCpv7jitdwzRjMkIDFEnNxqBUViaw5r9j2Iqy73p51IUA6E9n6K/3111PlerKEY99Rla7rGbznHTHNwxdH8Ag1fNe3ML/ahZu1ETvgZzsd5RmgVD53sx+NU8p1aIxiC1hW0qqzCRa0onK/ccx3L/pXccXfT0Hc24Ps9jLztn2bTkSwfZeuyvlF5nB57+flMY3evpGh+Pzy7g8W9iKSytaIyITe71ib2ZeEvjbkErLJOMwBAN6ocT7zRI8wJA01R2xn/E7jNfUMc+W+UCjrc+i+I7qkGy1JfSZgTGwKXSvGjGDL4jMQ5aiuLRT+8ozYKaHI5WlKZ3DCGElVM1M3nFWWAR+yM0BoXh3R5hYt9XpHkh8PcezP2Dl+Phcu0RxLe0u4PQnk/VeH7CpUL+9G2c1TQvAD7cdY684htvBCBsjzQwRIM5lr6F5JzoBr9uTMq3fHf0dSrMpXU6T1GMGHs8iKHzvTTG3tvX5eCB4dbnMPZ8WBbptACKoyfGvs9j6PEwGG18zqVWjvn03+vcNBRCiLooLLmEqtnmmxMHO1emBPyVoM736R1FNCMerh24f/CndPauvtPRL6N0atquODXXxJNr46zuzX6uqZyPfzyndwzRDEkDQzSI/OJsdp+99h73DeHchT18G/N8vUZ3GPwmYej9eJNto6n4jsQ46H8xePZvkucTDcfgO6JyNIat/7crTELL2q13CiGElSo3F1Ncnqd3DF14uFS+Se3SOljvKKIZcrR3466ANwjyvx+Abj7DueOWP6Mo137Ldj6vmCe+iSWnqKwpYzaZzccyiU1vpgvzC93IGhiiTmpaA2N9zAukXj7c6M/f0rkt0wYsxdO1Y53P1fLOYj75ETTWYmGOnhi6P4jBU6YiWAM1ex9qwldQYdI7ij7sW2AMegvFTkYQicYntYXt0NC4XJhKhfrrludZuQk2sQZGR89AJvV7FSd7N72jCAuQdvkI7dz7YKzhBtyFglLm/TuGjLySaz5uLXq1acG/5gyqcQSKsD12N3uBr+Iadvjb7ICw6z5++fJlZsyYAcCFCxcwGo14eXkBsH379msWQKtWrcLZ2ZmZM2cSFhbGqFGj8PX1BWDFihXMmTMHF5f6DRvPy8tj8ODBxMfHoygK0dHRTJo0ibi4ONq1a0d+fj6DBg0iPj4eg+Hq7um+fftYvnw5a9asue7zlJeXs2zZMr777jvc3NxwcHBgwYIFjBkzhsDAQHbs2IGXlxcTJ05k69at9Xotv//e1NaRtM1N0rwAyC/OJOzg09zV/3U61PEuudKqO8aARZXbrBZnNWguxeNWDL2ekOkiVsTQZhhKq16VTa/CFL3jNL3yAtTkcIzdZuudRNggqS2st7YoLr1SrXlhK7q2HsbEfn/BziCNOlE7ftepcy8XlfHE2lirb15A5eKk35/MkgU9RRWLm0Li6elJZGQkkZGRzJ07l0cffbTq85ru3jzwwAPMnDkTqPxFmpX165vXlStXUlxct90HzGZz1cetWrWiTZs2nDlzBoDo6Gj69u1LdHTlWhCHDh1iwIAB1yww6mLZsmVkZ2eze/duIiIiWL16NYWFhVcdV98CA67+3tRGXnEWexpx6si1lFYUsOHwS5w8/0Odz1Wc22AMWAQtezRYHqX9HRhufU6aF1ZIcfLC2P8VlNZDbnywFdIyd6IVpesdQ4hGJ7VF09QWZrWCwtJL9b6WperpG8qkfq9K80I0iLzicp5cG0vKZdsZIbp8TyKlFeYbHyhsgsU1MH5PVVXGjh0LwPHjx/Hx8SE9vbLgDgoKwmQy8fbbb/PZZ5+xefNm4uLiePzxxwkNDWXlypVkZWUxffp0pk2bBkBkZCQTJkxgzJgxPPTQQ1W/yAMDA1myZAljxoxh06ZN1TIEBQVVFRXR0dE8+uij1T4fPHgwZrOZxYsXc/vttxMSEsLq1aurzi8oKGDWrFkMHTqUBQsWoKrV9242mUx89dVXvPnmmzg6OgLg4+PDlClTrvp++Pv7V3386aefVj3fW2+9BUBqairDhg3jueeeY8SIEdxzzz0UFxdf9b2pTeGlaRo7TrxNuQ7bT5q1crafWEZUQt2HnCr2bhj7vYjSeujNhVDsMfSch7Hr/SiK8eauJZotxeiIsfcTGPzvockXg9WbZkY995XeKYRoclJbVNdQtcXFK6loqFdd35r1aTeeO25diNFw04OehaCwtIKnvo3j3KWat1u1RtkFpXx9SHZIE5UsvoFhMBgoLS2loKCAAwcOEBAQwP79+0lLS8Pb27va8M0777yTgIAAPv/8cyIjI5k3bx6+vr5s2LCB8PBwcnJy+OCDD1i3bh0RERH079+fL774oup8Dw8PIiIiqgqSX/y2yEhJSeGuu+4iLi4OqCwygoKCWLNmDS1btmTHjh3s2LGDr776ipSUymHpsbGxLF26lL1795KcnMyWLVuqXT8pKYn27dvTokWLWn9fIiMjSUpKYvv27URGRnL06FGioqIASExM5MEHH2TPnj20atWK77777qrvjbOz8w2f43jGVtJzj9Q6U2PYn7iabceXYVbrtm2UYrDH0OtRFL876/fEDu4Y+y/E0GZY/c4XFsfQcTKGW+aDjW13p+WdQr14UO8YQjQpqS2u7WZqi20/fIdiZ127JNzIre0ncnufBRjkJodoAKqq8ef/HONUdiOt5dbMrT6QwmUrXaxU1I1VtIODgoI4ePAgUVFRzJ8/n507d6JpGsHBdVvhOSYmhjNnzjB58mSgcm7ooEGDqh6fOnXqNc8bPHgwH3/8MSkpKfj5+eHk5ISmaRQWFnL06FEGDhzIqlWrOHnyJJs3bwYq74wkJibi4ODAgAEDqu5uTJ8+nQMHDnDnnfV8Y/2zXbt2sWvXLkaPHg1AUVERiYmJtG/fno4dO9K3b18A+vXrR1pa3TuaJeWF7Dv395vK2FBOZf5AYclFJvd/vU4LYymKgrHz3ajOPqhnV4FWy6FpLbpg7PM0iqNH/QILi2XwGoAS8CrmEx9BSbbecZqMmhiG4tkfxeiodxQhmozUFlerb22haSoFJRdu6rktTe+24xjb+9kad48Qoq4MBoVHh3fh2Pk4TOW2N52iqMzMyp+S+PO4nnpHETqzigZGcHAw+/fvJz09nQkTJvDpp5+iKArjxo2r03U0TSMkJIQVK669pkNNi3F16dKFvLw8duzYUVWU9O/fn7CwMPz8/HBzc0PTNJYuXVr1S/8X+/btu2pV3d9/3rlzZzIyMigoKKj1nRJN03j66aeZO3duta+npqZWDRUFMBqNlJTUfQGgqIRVzWoLtLTcOL6JfoqpA96klXPdFiE1+I4ERy/Uk5+C+frzCRWfYRh6PIAi81htluLaHuOA11Djl6PlHtc7TtMozUFN24LRf7reSYRoMlJbXPu11Ke2KC7Lx6zazjpRPdqEcnufF6R5IRpc33at+PDu/jy9Lo6SctuajgWw8eh5/meQH34e9VsgWVgHq/jJGhwczLp16+jcuTMGgwF3d3ciIiIYMuTqhffc3NyqLVD1288DAwM5ePAgiYmJQOWdhYSEhFplCAwMZOXKlQQFBQEwaNAgVqxYweDBgwEIDQ1l1apVlJdXDp9MSEigqKhy/lpsbCwpKSmoqsrGjRurzvmFi4sLs2bN4pVXXqGsrHLo1KVLl66aL/tboaGh/Pvf/656bZmZmVy8ePG6r+H335uaXCpM5mh6zc+tl8tFqYQd/BNZefF1PtfgcQvGgFfA0avmYzpNxdhrnjQvBIq9a+XCrW1G6B2lyWgZ29HKb/zzQQhrIbXF1epTW7i4upBzpWF3/mrOuvkM545b/4zBINNGROMY0MGd96f1w9HOKt7G1YlZ1fjnfhvcGU5Uc9MjMG60NVlT6NixI5qmMXRo5aKMQ4YM4fz587i7u1917MyZM3nhhRdwcnJi69atzJkzh/vuuw9fX1/Cw8P5+OOPeeyxxygtLQVg4cKFdO3a9YYZBg8eXDW3FSqLjJSUlKqiY/bs2aSlpTF27Fg0TcPLy6tqsa2AgAAWLlxIUlISw4YNY9KkSVddf+HChbz55psMHz4cJycnXFxcePHFF2vMExoaytmzZ6uu5eLiwvLlyzEaa/6F+vvvTU3rYOw6/RlqbadbNDFTWS7fHnqOCX1fppvP8Dqdq7h2wDjgVczHP4TCpGqPGTrfi8Hv6v8uwnYpihFDjz+iGuzRMnfqHafxmUtQM7Zj9J+hdxJhA6S2qGQNtcVd08bzxqvv4OjkyFfffoGTk/VORWvbqg8T+r4iC3aKRhfUyZPXJvTm5c0n9I7S5LaezOLh2/xp1+rG6/UJ66RomqbV5YSMjIwatxQT1u9SXhrbkl7QO8YNKRgY0WMegZ3uqfO5mrkUNf5ztJxYAAxdZ2NoX7chw8K2mBP+jZaxTe8Yjc/ojHHwe7JlsGhwUltYp7IKE7mmG6+zlZWbwLHcuu8q1py4ObZm1pDluDp66h1F2JAv9iby96hkvWM0uWn92vHy+F56xxA6sb2xR6LeNE3jQv5ZvWPUiobK7jNfsPPUR3UeLaIYHTH0eRql3TgM3R+U5oW4IWPX++u/o40lMRejZmzXO4UQwkIUleboHaFJ2BkcuSvgDWleiCY3b1hnQru31jtGk/vuRCZZ+XVfw09YB2lgiFozlV2mXLWsHxZH0jexKW4R5ebiOp2nKAaM3WZjaDuqcYIJq2PsfDdKh4l6x2h0WsYPaOW2tf+8EKLuyipMlN1gYWxrMf6WF2nTsrveMYQNMigKiyf2pltr2xoZWW7WWH1A1sKwVdLAELWiamaKynL1jlEvSZcOsDb6GQpLLukdRVg5Y5eZKO1v1ztG4zKbZBSGEOKGCm1k9MWQzrPp4TtK7xjChrk42PHetH64O9vrHaVJbTqWycXCUr1jCB1IA0PUiqk0F62ZLtxZGxcKzhEW/RSXChL1jiKsnLHr/6C0HX3jAy2YlvEDWoWMwhBCXFtZhYlyGxh90c1nOEO7zr3xgUI0snatnHlrSl+MBuXGB1uJMrPKvw/deI0dYX2kgSFuSNXMmMqu6B3jphWUXOCbQ8+QknNI7yjCyhm6zUHxCtQ7RuMxm1DTd+idQgjRTBWWWv+IR2+3Loy/5c8oipTSonkY6OfOn8f21DtGk9p49DzFZZZ7g1XUj/zUFTdkKs1Fwzp+OJRVFLEx9mWOpW/RO4qwYopiwNBrHrj66R2l0Wjnd6CZZeimEKK60oqiOq87ZWmc7VtxV8AbONjJNo6ieZnavx0zB3bQO0aTKSitYPPxTL1jiCZ20xtVt44+3BA5qlwMGnjdxy9fvsyMGTMAuHDhAkajES8vLwC2b99+zW3YVq1ahbOzMzNnziQsLIxRo0bh6+sLwIoVK5gzZw4uLi71znzp0iVmz55NWVkZS5cuJTg4uF7XqaiooG/fvsyaNYtFixbV+fzAwEB27NhR9f24kaysLF5++WX+8Y9/XPXY1KlTWbx4Mf3697WK0Re/pWpm/nvqfa4Un2d4t4dRFNsZbieajmJ0wnjLfMyxr0N5gd5xGl6FCe3CTyhtQ/VOIqyQ1BaWW1skpsbz19eW8f5nf73qsQdnPcWChU9yS1/L3v5wbJ/naeXsq3cMIa5p/qhuxKTlcu6ibUz1/OZwOvcMaC/1vA2xuBEYnp6eREZGEhkZydy5c3n00UerPq9pD/kHHniAmTNnAhAWFkZWVlbVYytXrqS4uG53Cszm6qMR9uzZQ+/evdm5c2etC4zfXwPgxx9/pEuXLmzatAlN0+qUqSaapqGq6jUf8/X1vWbz4resafTF7x1KDmPrsb9SYS7TO4qwUopTa4x9ngLFqHeURqGe36l3BCEahNQWdVNTbVFaUYSnt9s1mxfWopfvWLr5DNM7hhA1sjcaeG1CH5tZDyM118SB5Mt6xxBNyOIaGL+nqipjx44F4Pjx4/j4+JCeng5AUFAQJpOJt99+m88++4zNmzcTFxfH448/TmhoKCtXriQrK4vp06czbdo0ACIjI5kwYQJjxozhoYceorCwEKi8A7FkyRLGjBnDpk2bqp7/2LFjLFmyhG3bthEaGkpxcTEbNmwgJCSEkSNHsmTJkqpj/f39efXVVxk1ahTR0dFXvZYNGzYwb948OnToUO3xwMBA3nrrLcaMGUNISAhnz54FKu8Y3XPPPYwYMYJnn322qjBJTU1l6NChPPnkk4wcOZKMjAwWL17MyJEjCQkJYePGjVXHjRw5EoDi4mLmzZvHsGHDmDt3LiUlJT+vfWGZO4/U1tns3VwsSNA7hrBiSqueGLr9Qe8YjaMoFS3vrN4phGhwUlvUr7YoKs0hIz2TaRMqf+aVlJTywvzXuGv8bOY//jKlpZY97czVwZPQXk/qHUOIG+rVpgV/DPbXO0aT+TYuQ+8IoglZfAPDYDBQWlpKQUEBBw4cICAggP3795OWloa3t3e14Zt33nknAQEBfP7550RGRjJv3jx8fX3ZsGED4eHh5OTk8MEHH7Bu3ToiIiLo378/X3zxRdX5Hh4eREREVBUkAH379uWll15iypQpREZGkpeXxxtvvMH69evZuXMncXFxbN26FQCTyURgYCC7du266m5KSUkJu3fv5vbbb2fatGmEh4dXe9zLy4uIiAjmzp3L8uXLAXj33XcZMmQIe/bsYeLEiVXFFUBiYiIPPvgge/bsIS4ujuPHjxMZGcm3337L66+/TnZ2drXr/zIUdt++fbz44oscOXKEkrICNK49esNajOjxKG3de+sdQ1g5Q9tRKO3G6h2jUaiZMgpDWB+pLepeWyxevJjzmdV3BPhmTThOzk5s2v4VT8z/IyePn7nJ/zL6GtvnOZzsW+odQ4haeTC4Ez183PSO0ST2JlzifJ51r70jfmXxDQyovBty8OBBoqKimD9/PlFRUezfv7/O80VjYmI4c+YMkydPJjQ0lLVr11b7xT116tQbXiM2NpbbbrsNb29v7OzsmDFjBlFRUQAYjUYmT558zfN++OEHhg0bhrOzM5MnT+b777+vNhR00qRJAPTv35/U1FQAoqKiuPvuuwEYN24c7u7uVcf7+fkxaNAgAA4ePMj06dMxGo34+PgwdOhQYmNjqz3/b691yy230KdPH0oqrHDe/m/0aTeewE536x1D2AhD11ko7n30jtHgtIvRaNa4xoeweVJb1K22GDRkAMePxld/7dFHmDzldgB69upGj55dbvham6s+bW+nS+uhescQotYqp5L0tompJKoGm4/JYp624qYX8WwOgoOD2b9/P+np6UyYMIFPP/0URVEYN25cna6jaRohISGsWLHimo/fzGJcAI6OjhiN154Lv2HDBg4cOEBgYOXWi7m5uezZs4dRo0YBVM3BNRqN15zj2tBZVc0MVjz6ok3Lnozp/YzeMYQNURQjht5PYj78GljTFoNaOVrWbhS/SXonEaJBSW1R+6xmtRxVrahHesvg6uhNSM8n9I4hRJ318GnBw0P9WbEvSe8ojW7rySzmDessi3naAKsYgREcHMy6devo3LkzBoMBd3d3IiIiGDJkyFXHurm5Vc09/f3ngYGBHDx4kMTERACKiopISKjb+ggDBw4kKiqKnJwczGYzGzZs4LbbbrvuOb8MUY2NjSUmJoaYmBiWLft/9u47Pqoy7f/4Z1pm0nsjJJDQQaRLQsdgwbIi+KjrimVZXVxF3HV5rOtP8VkLFhQLwu5acF1REVwQBBViB2migPRQAyG9J9PO+f0xEogESJnkzJy53q/XviCZU77jmnjPde77up86barnr2VlZbF48WIAVq9eTVlZ47uFDB06lI8++gi3201RURHr1q1jwIABZ7zWjh072LljV1Pfst8xGS1c0uc+zMbGG7MJ0VYMljCM3X+vdQyvU47loKr6LXiKwCRji6aPLY4c28+mDVvo26/hksxBQ/qxYulnAOzZncvuXblNfcs+ZVyvP2OzhGsdQ4gWuWVoJ3q04VISV20VP7/0JzY/fDm1+ftx19Wwa9697Jx7D7vm3Yu99Php5xxe9io7597D3gWP4q6rAWD/+8+w4+W7qD7s+QxStmMdxT80fZnq0fI6Nh/R186JonGtnoFxrq3J2kNaWhqqqpKV5ZnaN3ToUI4ePdpg2uMJ1113HTNmzMBms7FixQomT57M9ddfT1JSEkuWLGHOnDlMnTq1vtHUAw88QJcuXZqcJTExkYcffpiJEyeiqirjxo1j/PjxZz1n+fLljBgxAqvVWv+9Sy+9lJkzZ5614dVf//pX/vjHPzJy5EiGDBlCx46N7/t8+eWXs3HjRsaOHYvBYOCRRx4hMTGxfrooeLqpT58+neHDh9Olawa9z+ve5Pfsb4Z1uZXYsE5axxAByhjdBzX5QlQ99Y6oK0Qt3Yohpp/WSYROyNiiIV8eW4wZOwZFcfGX++4gLj6WvCMnp3Ff97ur+duJU++UAAAgAElEQVR9T/CbS24ko0snvxxb9O5wCRnxLdvCVghfYDYZefSy3kxesAGX4p2diE5lDLLR7dYnOLLcM8vMYDKTfv0DBEXGUb5rA/lfvkenCXfXH199eBfO6nJ63vECJT9+QcG6pcQPGY/BaKLL5EfJz3mXkJSulG79is7/M6NZWZZvy2dQarRX35/wPQa1mXtq5eXlnXFLMaEPZTVHsZ+h/0V+6T62li5o50TekxzZm2uHvIBRp9taCv+guutwb3oI6vSzlMQQOxBTn+laxxB+SsYW/svurKKstnU7APjq2CLYEsktwxdgswRGI0Shb/O+yeWfaw+02fX3v/c0SaOvJTgpvf57FXt/oGz7t6RddVf990q25OAoLyRp9LXUFeVxeOkrZNzwMIeWvkzy2Bso2vAJ1tgO2OJTCc84v1kZQoNMrPzTCGwWGefrmS6WkAjvcStO7K6qcx/oh0zGIC7u879SvBCaM5hsGLv/QesYXqWWbEV1SQdwIQJNrbNc6whtZmjGjVK8ELpx4wVpRIdY2u1+isvJ0c8WkDCsYaNiW2InKnN/RFVVKvZsxlVbhckWQnBSBkc/e4vYwZdQc2Q3quLm4Iezqdj7wxnucLpqh5s1uwu9/VaEj5EChmig1lEOeH96mS8Y3nUKMaGpWscQAgBjVC99ba2qOlGLN2udQgjRjjwPPaq1jtEmImxJ9O3Y+O4uQvij0CAzU7I6t9v9Dn74PAlZv8EW33AZWkhyBmHpfT39MUqOYgmPASBp1DVk3PAQpVu/JmHkJIo3f06nSX+mePPnzbrv8u2yG4neSQFD1FNVlVqnPpvfdIg6jwFpV2sdQ4gGjOn/A7YErWN4jVq4XusIQoh2pOeHHsO63irNvoXuTOyXQkqkrc3vc/SzBVhjkonpP7bR15PHXE/Pqc8TnNiJqD4nGxI7K0tw11YRnJCGu9aznP3En0218VAppTWOlocXPk8KGKKe3VX1y/ap+mI2Wrm4zwxZOiJ8jsFkw9R9itYxvEYt3S7LSIQIECoqtc4KrWO0ibiwDHomXah1DCG8zmIyMnVEhtevu/tfD1CxexMHFj3H0c/f5ujqt6nYt4Wdr/2FI5/8E4BjOe9iL/HMjtj52l/YNf+v1BzNJXZAdv118r98n6TR/wNARLdB/PzSn4joPrhZWRQVvtqrnx5j4nTSxFPUO1vzzhN8tdHW2Yzs9kcGd75W6xhCnJF7zwLUY6u1juEVxh63Y0wcrnUM4WdkbOF/vNG88wRfG1tMGPAk6XEXaB1DiDahqCqTF2xgd4E+e94BjOgSy+yJsjOaXskMDAGAorp1uY41wpZE/7QJ5z5QCA0ZO00AU9tP6WwPatEGrSMIIdqBXpt3dozuJ8ULoWtGg4G7RjV9G2d/tOFgKTUOl9YxRBsxt/YCdbecfR/y5rK9+clZXy8pKWHSpEkAFBQUYDKZiI2NBWDVqlWNPsF58803CQ4O5rrrrmPhwoWMGTOGpKQkAObNm8fkyZMJCQlpceaioiJuvPFGHA4HTzzxBJmZzd8v/KmnniIrK4vRo0czYcIEjh8/jtVqJTQ0lBdffJGuXbs26TrTpk3j4osv5sorr2zW/e3OKkBpdm5fN6zLLbKGVfg8Q1AExo7jUQ4u0TpKq6kl21BdtRjMwVpHEX5Mxha+PbZwKy5dPvQAGNHtNq0jCNHmstJjGZwWzcZDpVpHaRN2l8La/SVk99BPnzFxUqsLGO0tJiaGnJwcAGbNmkVoaCh33nnnWc+55ZZb6v++cOFCevbsWT/ImD9/Ptdcc02zBhlutxuT6WQ/ha+//ppevXoxe/bsFl/j/vvvb/D63Llz6d+/PwsWLOCxxx7j7bffbvK1W6JOh+tY48Iy6JEsa1iFfzCkXAJHV4O//yz+shuJQZaRCD8iY4vm8Sw31V/zzq4JI0mO7KV1DCHaxV2junDLvzdqHaPN5OwplAKGTvn9EhJFURg3zrMV4bZt20hISODIkSMADBkyhJqaGmbNmsUrr7zCsmXL2LJlC3fccQdjx45l/vz55OfnM3HiRK6+2rNDRU5ODuPHjyc7O5spU6ZQVeVZHzZo0CBmzpxJdnY2S5curb//1q1bmTlzJitXrmTs2LHU1tayePFiRo8ezahRo5g5c2b9sZ07d+aRRx5hzJgxbNjQcJr1tGnTWLZs2WnvLysri/3793Po0CGuvPJKsrOzyc7OZv16T7d/VVW5//77ycrKYtKkSRQVNb9pjVtx4XDrr/He8K5TpHGn8BsGczDGtKu0juEVsoxE+DsZW5x9bOGZtak/WV1u1jqCEO2mT3IEI7vEah2jzXyXW4zLrb/Z5UIHBQyj0YjdbqeyspLvv/+e/v37s27dOg4fPkxcXFyDpx9XXnkl/fv3Z+7cueTk5HD77beTlJTE4sWLWbJkCcXFxcyePZtFixaxevVq+vXrx2uvvVZ/fnR0NKtXr64fkAD07duX++67j6uuuoqcnBzKy8t5/PHH+fDDD1mzZg1btmxhxYoVANTU1DBo0CC++OKLJk8FXbVqFb169SIuLo4PPviA1atX849//IOHHnoIgOXLl7N3716++eYbXnnlldMGL03hmX2hrycpKdHnkxHf/Om2QmjJkDxGF9uqqmU7UHW4o5EIHDK2OPPYQlHdunzo0TG6P3Fh6VrHEKJd/c+AjlpHaDOVdhc/5umzV0+g87slJI0ZMmQI69evZ+3atUyfPp01a9agqmqz14tu2rSJ3bt3c8UVVwDgdDoZPPjk1j0TJpy7GeQPP/zAsGHDiIuLA2DSpEmsXbuWyy67DJPJVH/tc7njjjuw2Wykpqby5JNP4nK5uP/++9m+fTtGo5Hc3FwA1q1bx8SJEzGZTCQlJTFixIhmvWeAOmfz9lf2ByO7yhpW4X8MRjPGzhNRdr527oN9mbsOKvdDRNPW1wvhi2Rs0fjYwjP7Ql8PPQD6p+pjBpwQzTG0cwypUcEcLtNfURJgw6FSBqVFax1DeJkuChiZmZmsW7eOI0eOMH78eF5++WUMBgMXXXRRs66jqiqjR49m3rx5jb7emmZcAFartcHa1LM5sU71hFmzZhEfH09OTg6KopCamtqqLCe4FScupc4r1/IVXeKHkxzVW+sYQrSIIX4oHF4B1Ye0jtIqatnPGKSAIfyYjC0aZ3fpb/lIqDWOjPhhWscQot0ZDQYmDUjhhZy9WkdpExsOljK1+c92hY/z+yUk4BlkLFq0iPT0dIxGI1FRUaxevZqhQ4eedmxYWFj92tNffz1o0CDWr19f/wSiurqaffv2NSvLwIEDWbt2LcXFxbjdbhYvXsywYa3/j2JlZSWJiYkYjUY++OAD3G7P9OzMzEw++ugj3G43x48f59tvv23WdfXWRdyAkeFdp2gdQ4gWMxiMGNOv1TpGq6llO7SOIESryNji9LGFqirYXTWtvq+vOT/lckxGXTzTE6LZrjwvGatZFx8JT/NzfoVsp6pDrf5tfa6tydpDWloaqqqSlZUFwNChQzl69ChRUVGnHXvdddcxY8YMbDYbK1asYPLkyVx//fUkJSWxZMkS5syZw9SpU7Hb7QA88MADdOnS9L2SExMTefjhh5k4cSKqqjJu3DjGj2/9dnC33nort956K++//z4XXnhh/RObyy+/nG+++YYRI0aQkpLSYFpqUzh0VsDokjCM2LBOWscQolWMMX1RQtP8ehaGWrEXVXFiMFq0jiL8kIwtGvKVsYWneKGvpnhGg4nzOl6mdQwhNBNhs3BJr0SWbj2mdRSvcykqPxwpZ3iGfpuVBiKDqqrNWsiYl5fX6H7owv+oqkph5V7UZgxG8kv3sbV0QRumap1JA58hLXag1jGEaDXl2Jcoe17XOkarmM5/AENUT61jCD8gYwv/UFGbT63T+03xtBxbdE8czeXnP6LJvYXwFTuPVzJ5gT53EPvd4FTuGdtN6xjCi/Q5X0g0idNd26ziha+LDkmV4oXQDUNCJphatzZea0rZz1pHEEJ4kS6Xj3T8jdYRhNBcz8RwzkuO0DpGm9h4qFTrCMLLpIARwPTW/6JfqgxChH4YTFYMSSO1jtEq0gdDCP1wue0oqlPrGF4VG9qJ1Jj+5z5QiACg1y1V9xRWUVmnr99dgU4KGAFMT/0vzEYbvZMv1jqGEF5lTL5Q6witU5mL6rZrnUII4QV6e+gB0LfjlVpHEMJnZPeIJ9Kmv2a2igo7jldqHUN4kRQwApRn+1T9fLDolTwOqyVM6xhCeJUhJAlD9Hlax2g51YVamat1CiGEF+ixgNE9cZTWEYTwGVaziVFd47WO0SZ+zq/QOoLwIilgBCiHztaxyvIRoVeG5GytI7RO5X6tEwghWklVVVzuOq1jeFVSZC9CrbIzgRCnGtU1TusIbeLnYzIDQ0+kgBGgHG79FDA6RJ1HfHjTt6MTwp8YYvuBNUbrGC2mVh3UOoIQopVcil1XTb8BusQP0zqCED5naKcYgkz6+3i447jMwNCTVi90uuzNrd7IUW/FLX3P+npJSQmTJk0CoKCgAJPJRGysp4K+atWqRrdhe/PNNwkODua6665j4cKFjBkzhqSkJADmzZvH5MmT6/c+b4mioiJuvPFGHA4HTzzxBJmZmc2+xlNPPUVWVhajR49mwoQJHD9+HKvVSmhoKC+++CJdu3Zl0KBBfPrpp/XvtzWcOnqS0k86iAsdMxhMGJPHohz4UOsoLSIFDNESMrbwrbGFnsYMJ2TEZ2kdQQifExxk4oJO0XyTW6x1FK/Kr7BTUu0gJlS269YDv+vUEhMTQ05ODgCzZs0iNDSUO++886zn3HLLLfV/X7hwIT179qwfZMyfP59rrrmmWYMMt9uNyWSq//rrr7+mV69ezJ49u8XXuP/++xu8PnfuXPr378+CBQt47LHHePvtt5t87XNRVBduxeG162nJZLSQIU9RhM4Z4i8APy1gUJuP6rZjMFm1TiLEGcnY4uz0VsCIDE4mLixd6xhC+KRRXeN0V8AAzyyM4Rn6XCITaPx+jpCiKIwbNw6Abdu2kZCQwJEjRwAYMmQINTU1zJo1i1deeYVly5axZcsW7rjjDsaOHcv8+fPJz89n4sSJXH311QDk5OQwfvx4srOzmTJlClVVVQAMGjSImTNnkp2dzdKlS+vvv3XrVmbOnMnKlSsZO3YstbW1LF68mNGjRzNq1ChmzpxZf2znzp155JFHGDNmDBs2bGjwPqZNm8ayZctOe39ZWVns339yDfk///lPsrOzGT16NHv27AGgtLSUm266idGjRzN+/Hi2b98OeAZh06dPZ8KECQwePJh//OMfADhddSz7aBW/nXg711x5K489/Axut7t1/0doJC1mIEHmYK1jCNGmDMFJENJB6xhNYzBBSAcM8UMxdr4GY597wOD3/6kRAUbGFg3HFpOuuoFdO/cC8OqLr/O3+5/k1humcenYa3nnrUX11/GXsYXMvhDizEZ00eeHfOmDoR9+P6o0Go3Y7XYqKyv5/vvv6d+/P+vWrePw4cPExcU1ePpx5ZVX0r9/f+bOnUtOTg633347SUlJLF68mCVLllBcXMzs2bNZtGgRq1evpl+/frz22mv150dHR7N69er6AQlA3759ue+++7jqqqvIycmhvLycxx9/nA8//JA1a9awZcsWVqxYAUBNTQ2DBg3iiy++aPJU0FWrVtGrV6/6r2NjY1m9ejU333wzr776KuApVPTt25cvv/ySBx98kLvuuqv++D179vDee++xatUqnn32WZxOJzt2bmfV8jUseO9VFi17A5PRyPKln7Xs/wCNyewLESgMsQO0jnA6SziGqD4YUi7F2P02TANnYho+D/PgJzH1+hPGtCsxxvbHYLRonVSIZpGxxcmxRc4XOdx97208NOPv9cfv33eIeW88x7sfzmfuS2/gdLrI3XvAb8YWXeKHax1BCJ8VH2alT3KE1jG8LrdYfzspBSq/W0LSmCFDhrB+/XrWrl3L9OnTWbNmDaqqNnu96KZNm9i9ezdXXHEFAE6nk8GDB9e/PmHChHNe44cffmDYsGHExXmql5MmTWLt2rVcdtllmEym+mufyx133IHNZiM1NZUnn3yy/vuXX345AP369WP58uUAfP/997z++usAjBw5ktLSUiorPVXGiy66CKvVitVqJS4ujsLCQr7++mt+3r6L3068DQB7nZ2Y2OgG91cUKDxSg9OhkJgagsVqxO1S2ftjKa+8tJkufaO49KaMBuds+aqArxYfwhJk4rczehEVb2P56/vY80MpF/2uM30y4zi6v4qdG4q58NpOTfrncC4Z8c1fEyyEPzLGDsR9eLk2NzeYPbMqQjtiCE2F0FQMYakYgqK0ySNEO5CxhWds4XLXMTRrIGWlFVRVej4AjBqbRZA1iCBrEDGx0RQXlbDuu03nHFv4Aqs5jA5Rfrw9tRDtYFSXOLYf01fjy4Ml+tnAINDpooCRmZnJunXrOHLkCOPHj+fll1/GYDBw0UUXNes6qqoyevRo5s2b1+jrrWnGBWC1WhusTT2bE+tUf+1EIzGTydSkqZmnNh4zmUy4XC5cipPfXH0p98yYesbzDAaISwmmvNBe/72yQjtpPSO485mBpx3vdit8+eEh7nx2IId3V/DpOwe49p6eFBypYdrsgbzz9M/0yYzj648OM/HO7ufM3RSJET0Is+pzmpsQpwnPAEsEONt4QBEU7SlShKViCPX8j5BkDIam/e4SQi9kbOHRWP+LoKCTs6pMRiNutxsV9ZxjC1+QHjcUk1EXw18h2syornHM/SZX6xhedai0BlVVMRgMWkcRreT3S0jAM8hYtGgR6enpGI1GoqKiWL16NUOHDj3t2LCwsPq1p7/+etCgQaxfv57cXM8PbHV1Nfv27WtWloEDB7J27VqKi4txu90sXryYYcPadplDZmYmH37oafD37bffEhMTQ3h4eKPHKoqToVkD+GzllxQXlwJQXlbB0bz8BscZDGAynfwBV1VwORWO7K7g1Rmb2b+9vMHxRXm1JKaFYrYYSe8TxbH9nn+mBsDlVDFbjOzaVELGeVFYgrzzQUi2QBOBxGAwYog9/YNHixmDIDwdQ9IojF1+h/H8+zFlvYI58wVMfe/FlH4txoQsz6wLKV6IACRjC8/YwumuZcO6H4iOjiQsPPTMx2cNOufYwhd0jrtA6whC+Lyu8WEkhuur+bbdpZBfoa+GxIGq1SXoc21N1h7S0tJQVZWsLE9TpqFDh3L06FGiok6f3nzdddcxY8YMbDYbK1asYPLkyVx//fUkJSWxZMkS5syZw9SpU7HbPTMPHnjgAbp06dLkLImJiTz88MNMnDgRVVUZN24c48eP984bPYMZM2Ywffp0Ro8eTUhICC+99NIZj3UqDrp0S2faX/7AH2/5C4qiYDabeejRv9AhJemM5yluFaddoWPXCG58oA//euQn/vzykPrXaypdWENOfshRFBWA84bFs/C5HWRf34mvPzrMqKtTWTRnF13Oj2LAmMRWvW/pfyECjSFmAGr+V809C2xxJ5d+nJhVEZyAQYPmmoqiUFhYSHh4eKufPAv9krFFQ1qOLa64ZBE2m5X/e+bBsx7fkrGFFpIiemodQQi/0DspguOVhVrH8KoDJTUkR0rzf39nUFVVbc4JeXl5je6HLvxDtb2YKntRk48vya8jPDoIs8XI8cPVEJHP1tIFzLlnI3c+NxCTyfMBKP9gNV8sOsT193qagr04fSPTXzy5xnfDp8eIjLOy5asCJt3Vnfdf2Mlv/9q7xe8jwpbIlJH/afH5Qvgj1W3HvfZOUJyNH2AKhl/6VNQXKkI7YjjHTj333Xcf3333HZ07d+b111/HYvFMD9+9ezfXXnstO3fupKioiLCwMMrLy5kwYQIGg4GPPvqIiIgI/va3vzFlyhQ6d+7c4LpVVVUcO3aM/Pz8+j8LCgpwu9389re/5fzzz/fGPxahAzK28E1uxUVRVfNmi7REfuk+tpYuaPP7BJlD+dOYjzQp3grhb95Yd4BXv9bXMpJ7L+zG9YNStY4hWkkWAQYYl+Jo0XkGIxiNBpxOBXutG5dDrS9eAMSnBHP8UDUup8Lh3ZUkp4fVv+awu9m/vZxr/9yTtSuOAlBb5WrV+5DZFyIQGUxWDFHnoZZsgeDEU4oUv/xpi2v22s4ff/yRf/3rXzidTrZv384777zDLbfcAkBCQgKVlZW4XC6GDRvGTz/9xLvvvsv69esBWLhwIZdccglvvvkmAwcOpLi4mPz8/PqCRVVVFRERESQmJpKYmEhWZiZxRoiuKsWmtux3kRCi/TjdtVpH8KqE8G5SvBCiiXomNr4c3Z9JI099kAJGgHGf6cltIwrzanHa3TgdCmFRFiLjrKz7ppS5L/zAJTelA7D+02MkdAyhc+9IRl2dyqszNmO2GPntjJOzK7757xFGTOgIwKDsRF7682a6D2xdZ/KO0fLkVgQmY/dbwBSCweSdp9UvvfQSBoOB8vJyhg4dyvPPP19fwJg1axbJycmkpqZy9OhR5s+fz4oVK+jbty91dXX885//5OWXX0ZRFLZt20ZhYSGJiYn06dOH0f3PJ7amAtOxQzgP7sP5w2qcRw6A00El4Bo2Flu/wWeLJoTQWEsfeviqxIhuWkcQwm/00mEB40iZvoqygUoKGAGmOYOR+JTTp533GBzLPS+d/NBxwcXJ9X8fMCax0b4Wp26Zel5WPOdlxTc5w5kkRHhnJxMh/I23ty5dv349AwYMAODaa6/l8ccfBzxbPX7yySdkZ2ezatUqOnbsyHPPPUdiYiIHDhzAZDIxePBg1n73HVMmXMnBb79kQub5JOz4Bueh/ah1tVSd5b7OIwe9+j6EEN6nNOOhhz9IjOihdQQh/EZUSBDJETaO6ajxZVGV/dwHCZ8nBYwAoqhuVPXcW6/6Opslgshg32oKJoS/cjgcGAwGtm/fzqFDh6irq+PZZ5+loqKCY8eO4XK5MJlM9OnRnYrCAj64+w+MuXsGOGo59t2X9DEovPefdzBgoGzrD8zun96k+7qOHkZ1uzCY5D9DQviq5sza9AcJMgNDiGbpmRSuqwJGYbW+ZpUFKhk5BhCXWx8/tIky+0KIFrHb7ac11XQ6nWzevJkff/yRLVu2EB0VyQ0jMwkvLWT520EkbN9I8LFDVH+SR1SNA8cbc/h0QCqfHy/jvq0H+degLkzeuJdX+6cz/ccDTQ/jcuLKz8OS0uncxwohNOFWW9evypdYzaFEBXfQOoYQfqV3Yjg5u/WzE0l5rROnW8Fikl44/kwKGAHErZO1rFLAEOLsFEWhuLi4QbGioKAAg8FAQkICSUlJZKSlMaRjErbrJ3LP7JeZc/8McguLuSQhnBn/czVP9e1Ef9XO01+sA2CLonB9ahwAblXlmd1HuTwpikiLGbei8tiOI4SamzcgcB3aLwUMIXyWqqsZGNLAU4jm65kUoXUEryusstNBtlL1a60uYCz+t3erchNvPHt/hJKSEiZNmgRAQUEBJpOJ2NhYAFatWtXsbdgeffRRVq9eTXZ2NnfddRc33ngjDoeDJ554gszMzJa9CR+ll2ZcCeFSwBDihJqamtNmVdjtdmJiYjy7fyTE0yMmkqi0BDhyAOfBrTi//ghX/hFURWEc0DnIyPZj+URZzDzYM4XffLsLgPt7pLC6sJxih5P0UBsz+6QBngJGrVvh0d6pGI1G4qwWjtQ6eLx387Ymcx49jAwhRGNkbKE9t+ICVK1jeI30vxCi+fS4E0lhlUMKGH7O72ZgxMTEkJOTA3g65IeGhnLnnXe2+Hpvv/02u3fvxmQysWTJEnr16sXs2bObfL7b7cZkMrX4/u1J0clUUJmBIQJdcXExS5cupaqqiuDgYBISEkhMTGRAeidiEqIwHj2A8+BuXBtW4sw7BC4nFWe53sfDezX4es3oPgDYzEa+HnPeaccHGY18dcr3v2rkmKZwFxe06DwhvE3GFo1k0NHsC4C48AytIwjhd6KCLSSGWzleqZ/ml9LI0//5/Vw6RVEYN24cANu2bSMhIYEjR44AMGTIEGpqapg2bRrLli2rP6dz584ATJ48merqasaNG8ecOXOYOXMmK1euZOzYsdTW1pKTk8P48ePJzs5mypQpVFV5euoPGjSImTNnkp2dzdKlS9v3DbeCovh/A89gSyQRwafvdCJEIImKiuI33Ttxc4dIrq44zAWfv0/K038h6JE7qHr6firefo3arz7DeXAfuHz3Q4i7pEjrCEI0SsYW+up/ARBmjdM6ghB+KT7MqnUEryqqlgKGv/O7GRi/ZjQasdvtVFZW8v3339O/f3/WrVvH0KFDiYuLIyQk5Iznvv3223Tu3Ln+qUtCQgJbtmzhqaeeori4mNmzZ7No0SJCQ0OZM2cOr732Gn/9618BiI6OZvXq1e3yHr1FDzMwZPtUIcBkMuF46xVq8vx7K1JFChjCR8nYQn8zMKSAIUTL6K2AUWX3/89Dgc7vCxjgeRqyfv161q5dy/Tp01mzZg2qqrZqnemmTZvYvXs3V1xxBQBOp5PBgwfXvz5hwoRW525vig62UI0La9oWjULonSW9Ky4vFTC2lFXz6M+HMRsMJNkszO6XjsVoAGBlfimvH/As9ThUY+e29ERu6ZzAHzbto8zp4qX+6XQMtrLgYAF9IkIYFB3W5Pu6S/TT2VzoT6CPLRSdFTBCrTFaRxDCL8WFNa8HkK+rcfj/56FAp4sCRmZmJuvWrePIkSOMHz+el19+GYPBwEUXXQSA2WxGURTAMy3U6Tz3f5RVVWX06NHMmzev0dfP9vTFN6m6KGCE287eiE2IQGGKTfDatZJtQSwc2h2bychTO/P49HgZlydHA3BpUjSXJnn+ft26XVySFMX2ihoGRYWSGRvOimNl/DY1jt2VddzUqXmZZAmJ8GWBPrbQ0wwMiymYILPv/LMVwp/EheprBka1FDD8nt/3wADPIATZdPQAACAASURBVGPRokWkp6djNBqJiopi9erVDB06FIDU1FR+/PFHAFauXNmkQcagQYNYv349ubm5AFRXV7Nv3762exNtTFEV9NBNPNQaq3UEIXyCKcZ706ETbRZsv+yJbjEa+GXyRQMFdicORaVjsJVgkxG7olLjUgg2GfnngeP8Ib35BRXVXodSU93a+EK0iUAfW+ipB0aYjB2EaDG9LSGpcejnd1ugavUMjHNtTdYe0tLSUFWVrKwsAIYOHcrRo0eJiooC4MYbb+Tmm29mzJgxXHjhhU16whEXF8ecOXOYOnUqdrun2csDDzxAly5d2u6NtCFF0ccPa2iQTAEVAsAU4/3fvUdq7XxdVMHdXZNPe21lfinjf5mJ0S0sGJdawn+PlnB7RiJL8kr4qbyGebnHublTAj0jmr49mVJZjjEk1GvvQeiDjC20p6cZGPLwQ4iWkyUkwtcYVFVt1mP5vLy8Zu+HLrTncNVQWnO41dfJL93H1tIFXkjUMr8f/jaRIR00u78QvqJuy/cUPtTybR5/rdLp5taNe3m6bye6hNlOe/3673fz7Pmd6Bjc8EnMoz8f5u6uyfx9xxGe6tuJv20/xFN9OzX5vokv/pugrj1bnV/4Nxlb+BZVVSmo3N1u92vrsUWPpAu5rO9DbXZ9IfRsT2EVN7y5XusYXjM4LZq51w3QOoZoBV0sIRHnpof+FyBPUYQ4wZszMFyKyl1bcrmnW3KjxYtCuxO7opxWvNhRUUOSzUJMkJkKl+d3zIk/m0qpLG95cCFEm1BRtI7gVTJ2EKLl4kL1VVyWJST+TwoYAUIPgxGrOQyzSV/r8IRoKW/2wPjvsRJ+KKtmzt5jXLtuF0uPlnD/1pM7nKzML+OyxOjTznvjYCG3/NK4s1uYjUlrdzKhQ/OWeUkBQwjf08zJuT5PemAI0XKRwRbMjTXH8lN2l/9/Jgp0utiFRJybtwYjqqrdD70MQIQ4yRgWgSHIiuqwt/pak1JimZTS8OfrN6cUIiZ3any2x6xTlor8b48U/rdHSrPvrVRWNPscIUTbau+HHm09tggJOr0AK4RoGqPBQGxoEMcrWz/e8AWKvuqzAanZMzAsFkuTOm0L/XG7FCodxzS7v0wBFaIhoxdnYWhFqanSOoLwATK28DHtOAOjPcYWZqO+psAL0d6CTPqZtK/obIZZIGr2DIz4+HgKCwtxOBxtkUe0kfKqQgoqW75Vm6p6BhgHa9Z4MVXzhFplBxIhTmWKicOdn6d1jNZx66M/j2gdGVv4llpHOfmlbb+9a3uNLYwGU5teXwi96xgdjMHLq0hy/v4HKvMPEhQWwbhH38Fs9fTgUlwOPvt/N2KvKCU0vgPZj7xFTfFxVj82GQyQ/f/+TUhMAl8+PZU+E+8grlu/Zt03OeL0Xl/CvzS7gGEwGEhISGiLLKIN5e3/StPdQ7whyCxbLQpxKmNImNYRWk1VpIAhZGzhaw4VH2frXv8eM5zKaJQV00K0xpxr+nv1eu+//z6bqaGktoqLLrqItJ2LeemllwB48MEHKezWiW++OUzPnj25RNnKnqI9ZNx6EwAhhd8wYfgECpIi+PLpqV7NJfyDfuYDibPSw37u8gRFiF8x6eBnwi3NtITwNU6lTusIXiXjByF8y5IlS4iIiGDkyJHU1NSQk5NT/9rq1avp2rUrF154IdXV1bz11luEhoaydOlSPvjgAxRF4Y477uDiiy9m7dq1Gr4LoRUpSQcIRZUChhB6Y9BBAUNmYAjhe1xufTTrO8Egz+uEaJWyGgcuL3a/3LMvF7vDyZJPPufuqbezauVyiqo8v3cKiopQdu5ixWc5vPzCc6z4eBlDho/mlVdfJTQ0jL25B0jq0JE33nyL/7y7kDlz5zFg0JBm3T80yExwkP+PoQKVFDAChFvx/z2PpYAhxK+YdPAr3O3/v5uE0BunW18zMECa9gnRGncv+pEdxyu9dr2fj5ZisoYwfu635BUaKa91MH7utwAcLa2mwFFGl4HDcVYUExSVwH2rDmA5/xKC0vuy4t0niek3hvJKB12uup+rb7qdXne93Lz3M7orky9I89r7Ee1LB6Nf0RRabn/qLQaDPEER4lSRN/2J8Kt/p3WMVjHpYCcVIfRGbzMwFFVmegnRGm4v79xhi0uhdOvXbP7blaguJ5bIk9u1WyLjqT6wHUOQDdVpxxbfEWOQjfwv3kNd8x8ie2ehuJzYi49xcMkcXNXN347d6OWGpKJ9SQEjQJhNsoWYEHqzboeZA/v8+2e753lGhsSf+zghRPvRWw8MRQcPcYTQktuLy0cAjEHBp2zXrGIwW9j27K2c99c3MJqDwGjAYDCgGo04K4sp+HYJsYMvoWTLGuylx4m74DKKNnxCbd4eQlK7N/v+Jqlg+DUpYAQIs9H/twxSZK28EA3U1bqoqfbOEoza2kpeeO0P5B/fx/9Of5eU5G6nHbNy9T/Y/ONnPPiX96mtrWTu69MwGAxM/f1LBNvCWPrJHIYNnURcTEqT7+t0yAcLIXyOl5+2ak1RZamaEK1x27DOlNQ4sbsU7C6350+ngt2lUPfL13Uud/337Kd+75RjT8zkcJQXYo1Jpu99C9j79mNUH9pBv4cWAuCqLCGkQzd63/0qe15/iLrCw5isIbhqKghL7wuKm6Of/JPwrgPp9vu/s//dJ5v9fsxSwPBrUsAIEBaTVesIrSZTQIVoSPHiZ/+gIBt33TaXD5c92+jrdXXV5B3bU//1jt1rGZF5jefvu76jU+p5AM0qXgBe31deCNF6JqN/z+z6NUUHfcCE0FJ2j0SvXMflVqhzKVzxSSTl4cCHD9Mj0sLBUCsdf1jAPTOfYfJcMx06d6byvYcIrj5OdHwM02fcy1O3T6Km6Dhjb7qbPZu+ozhvPz8+8hsGXjOVbglhjRZXzrT0Jcgsy9L9mRQwAoRZChhC6I7ixSmdJpOF8LCYM76+5uu3GTviBhYufgKAoKBgauuqUBQ3oSGRfPbFG/xm/LRm39coT0GE8Dl6W3Zqd1VrHUEIAZhNRsJMRpIS4ujeNYP58+fz73//m1mzZrHkP28CkBQXze+uvpxp06YxY8YMduzYwT0X9eWe/bsB6N69O8uXL+eaa67hy082ctttt/HOzS80er8TBZM65y+FjV+KHMkR/j8zPZBJASNA6GIJiQ62ghXCm7xZwDib2tpK8o7t4bKLptZ/r1f3TN5b8iQGg5GU5O7Ex6ayfvNyjh7bw/hxtxMdldSka5vkKYgQPkdvMzCq7cVaRxDCbymKmy2Hl2AyWjGbgjAbrVhMVsxGK2aTFbMx6Jc/T7xuw2wKOuvugVdffTUPPvggAAsWLGD06NH1r2VnZ/PBBx8wbdo0Pv74Y/785z/Xv/bII48wfvx4AOrq6qitraW6+swFyhMFkzCrfOTVE/l/M0Do4WlKraP5XYaF0LO62vaZlbT6K8/si1OZTBZuuOYRABYs/BsTr7yX5ate5YpL/sTqL9/m6iv+3NilTmO2yAwMIXyNWW8FDIcUMIRoqUp7IV/untvs84wG88kCx6+KG+auVoy2WkLCbEREhnD3E9l06pLMu6ueYPxN3fn3u28QFh5CSloSY67qQW7hWhSXgbffeYu1mz4lyGLF7XYyduxYXnnllTZ418KXSQEjQFh0MAOjyl6kdQQhfIq3GnieS2HRIXIPbAGgoOggKz6bx2UX/RGAn7Z/Qe8ewwBwOOtwu13YHTVNvrbFIjMwhPA1eitgVMkMDCFarKUzmBTVhcPlwkHjMyT+9EKv+r/vKf2Ue17rzff7/w3AX/7Rp/615T/NrP/73a915d0NfwLgnvm9uevC3BZlE/5NChgBQg89MKrtJVpHEMJnKIqK0WjAbDbgcrV+KcniZc/xzbpFOF12jh/fz8hh17L/wI/89pq/YTKZcThqSevYm6rqMsaOuIHnX7kFgKjIBG793dMsW/kStXVVzHvzHq6f+FCT7ysFDCF8jx7GDKeSJSRCtJyv/vxYTMFaRxAakQJGgLBZwrWO0Gq++gtUCC0YjQZ+9wfPVqdOh0JtjYvaWhe1NW7qfvnT8z03db967de7lxzJ20lZeQHP/30tKz6bR3xsR4YMvJxhF1zNlm1riIyI56br/4+333uE6yc+2GAHErM5iJLSYwDcfvPzzX4fliApYAjha6zmMK0jeFWVPAARosV8dQZTkFkKGIFKChgBItQaq3WEVnOrTuqcFdgsEVpHEcKnWIKMWIKCiIhq2rRve93J4kZtjYs331zBZZdfQp/+0biMl7Dik4VEx0ykttZF7oEf6NvL01yrT88R7N3/Ax2SunplBxKAIOuZm3wJIbQRZA7VOoJX1dhLUFT3WZsKCiEa56sPEINMIVpHEBqRAkaACLZEYjJYcPv5Th5V9mIpYAjRSlabCavNRNQvX9tCHfTu3ZURY5NJSq3m2+9dXHtzFwC+2WTkmt/1pnu3DCITu/Lll4f5/ZQJ/P2p+1HcMLhbf6rtGWzdsYoDB3dy8djbmrwDCYAtWD5QCOFrrDorYKgo1DrKCbWeeatoIUTjfHUJd5BZChiBSgoYAcJgMBBijaayrkDrKK1SbS8mLixd6xhC6EpUVBQVFZ5dfsrLy4mJOTnIj46OxuGsISbOhsVqp0u3ZAZckMiixW8AMGXKFGY9P4vHHnuMd599geefn8202x5vMMOjrsZdv4SltsZ1colLrQubTQoYQvgavS0hAc8DEClgCNF8vtpEX3pgBC4pYASQMGusDgoYvlkFFsKfDRs2jOeff56bbrqJVatWMXz48Aavff7554waNYpVq1Zx66231r/28ccfc/HFFwNQU1OD0+mkpqaa0DALoWGWdn8fQgjvMJuCMBktuBX/nrV5Ks80+G5axxDC7/jqEhI99PcTLSPd0wJIqDVO6wit5qtVYCH8Wf/+/UlMTGTkyJFs376dSZMm8cc/erZJveKKKzh06BAjR47EZrORlZUFgNvt5sMPP+Taa68lNjYWRVGYNGkSN910k5ZvRQjhJVazvj4clNce1TqCEH5HUd1U1OVrHaNREbZErSMIjcgMjAASpoNGnhW1x7WOIIRPcJcVYwgOxWi1eeV6zzzzTIOv582bB4DZbObNN9887XiTycQbb7xR//Xrr7/ulRxCCN8QbounxqGfWY/HK3ZrHUEIv1NafQSnu07rGI2KCJYCRqCSAkYA0cNOJAWVe7SOIIRPyL/jWpSKcgzBIRgjojFFRWOMjMYUFeP5MzIaY1SM589Tvm8wy699IcS5RQYnc7xil9YxvEYKGEI0ny//DoiwNb1huNAXGckGkDAdLCEpqszFrTgxGWV9vQhcruNHUSrKAVBra3DX1uA+ntekcw2h4Z5ix6nFjcgYjFG/FDlOFEOiYjCGR2IwykpDIQJRZHCy1hG8qqT6EA5XLUFmafwnRFMVVPjug0OZgRG4pIARQKJCUrSO0Gpu1UlR1QESI6QRlwhcjr07W3yuWl2Jq7oS8g6d+2CjCWN4hKe4caLIEfFL8SMqGmPkL0WQE6+H6WvNvBCBTG8FDFAprNxLSnRfrYMI4TeOV/rqzCUD4bYErUMIjUgBI4DEhnbSOoJXFFTskgKGCGiOPT+3z40UN0p5KUp5KS5yz3282YIpMqrBkpUTMzxCx12BKcb/Z4EJESj0V8DwLCORAoYQTaOobgoq9modo1Gh1hiZjR3ApIARQKyWMMKscX6/k8fxij3I8EMEMsfeHVpHaJzLibu4EHdxIb/efDE4c5QUMITwI5Eh+itgFPjs02QhfE9p9WFcio828JQdSAKaLG4OMDE6mIXhyw2FhGgPzj0+WsA4C1O0FC+E8CfhtgSMBpPWMbxKGnkK0XS+/PMiBYzAJgWMABMb1lnrCK1WVLUfl+LQOoYQmnDl56FUVWgdo1kMQVaM4RFaxxBCNIPRYNLdGvOS6sM4XDVaxxDCL/hyASNcGngGNClgBBg99MFQVBfFVQe0jiGEJlrTwFMrRpl9IYRfitBdHwyVgkrfXNMvhK/x5RnPsoVqYJMCRoDRwwwM8O1fqkK0pXZr4OlFplgpYAjhj/TYyDOv9CetIwjh8xyuWgoqfXkLVX3NDhPNIwWMAKOHHhieqqtB6xhCaKJu03daR2g2c7w8KRHCH+mxgJFbuFbrCEL4vEMlm3Arv27H7TtkBkZgk11IAozNEka4LYHKugKtozSZwWAkObI36XGZZMRnEheWrnUkITThOn4U537ffSJyJuY0+ZkVwh/psYCRX7GTansxodZYraMI4bP2FfruwxKz0UZ0SEetYwgNSQEjACVH9vb5AobVHEbn2CGkx2eSHncBNos0ABSidv3XWkdoEUtaF60jCCFaIDY0TesIbSK3cC19O16hdQwhfJKiutlfuE7rGGeUENEVo1FfOySJ5pECRgDqENWH3ce/0DrGaWJC0zyzLOIy6RB1nvxyEuJXatd9pXWEFrF0kgKGEP4oNqwzQaYQHG597dyxTwoYQpzRsbKfqXWWax3jjJIiemgdQWhMChgBqEPUeVpHAMBksJASfT4Z8Zmkx2USFdKhaSfa7VBQBCUlcP55YJB+GEL/lOoq7Fs3ah2j2QxBVszJMtVTCH9kMBhJjOzB4ZIftI7iVYdKNuF012IxBWsdRQif4+t9YhIjemodQWhMChgBKD68CxZTME53bbvfOyQomvS4oaTHZdIpdjBB5iYOHsoroKDQ87/yU6rCnVIhKqptwgrhQ+o2fgdut9Yxms2c2hmDUfpFC+GvkiN7666A4VacHCzeTNeE4VpHEcLn+HL/C4CkSClgBDopYAQgo8FEUmQvDpdsboe7GUgI70p63FAy4rNIjOiBoSkzJtxuKCr2FCwKC6HO3vhxxwulgCECQu33X2odoUUsaRlaRxBCtEJyZC+tI7SJ3MLvpIAhxK+UVB+mtOaw1jHOyGaJaPqMbaFbUsAIUClR57VZAcNstJEWO5CMuEzS44YSZotr2om1tSdnWRSXgKKc+5yCAujRrXWBhfBxqstF7cZvtY7RItL/Qgj/lhzZW+sIbSK3cB2K6sZokH5bQpyQ6+uzL6T/hUAKGAGrQ1Qfr14vwpboWRoSn0lq9ADMpqBzn6SqUFp2cpZFZVXzb1xZBdU1EBrS/HOF8BP2bZtRq1vw8+EDpIAhhH8LDookKjiFsto8raN4Va2zjGNlP5MS3VfrKEL4DN/vfyEFDCEFjICVHNkbg8GIqjZhlkMjDAYjyZG9PbuGxGcSF5betBOdTigs8hQtiorA4WzR/RvIOwrdu7b+OkL4qOrPP9Y6QotJAUMI/5cU1Ut3BQyAn499KgUMIX5RWn2EvLKtWsc4K+l/IUAKGAEryBxCUkQPjpXvaPI5VnMYnWIHkxGfSefYCwgOimzaiVVVJ5eGlJZ5Zl5406HD0DUDpFGg0CF3WQk1X3+mdYwWMQSHYEpI1jqGEKKVOkT2Zuexz7WO4XU7j61mZLfbsVnCtY4ihOZ+OrJM6wjnJAUMAVLACGidYy84ZwEjJjStfteQlKi+GI1NWCuqKFBS6ulPUVAENW28f7zDAfnHoYN8UBL6U/3pf8HlhZlKGrCkZTStaa8Qwqcl6bSRp0ux8/PRVQzsdI3WUYTQlNNdx/ajK7WOcVbhtgRCgqK1jiF8gBQwAljnuAtYm/tWg++ZDBZSovuSHp9JRlxW0zv92u2nLA0pBperDRKfxcHDUsAQuqO63VSt+FDrGC1m7d1f6whCCC+ID+uC2WjDpdRpHcXrfjyyjAFpEzEYZBanCFy78nOwu3y711ZShMy+EB5SwAhgiRE9CAnybEHaOW4oGXGZdIodTJC5iQ0xyytOLg0pL2/DpE1QWgqVlRAu00CFftRt/BZ3Yb7WMVrM2m+w1hGEEF5gNJpIjOhOXtlPWkfxurKaIxwq2UynWPl9JQLXj4f/q3WEc+oY00/rCMJHSAEjgBkMBq6/4GUibElNm+btdntmV5zYNaTO3vYhm+PgYThPn9u9icBUtfwDrSO0nMmEtc8ArVMIIbykQ1QfXRYwAH48vFQKGCJgHSv7mYLKPVrHOKeMuCytIwgfIQWMABcZfI5lF7W1J2dZFJd4+lv4qryj0KMbWCxaJxGi1Zx5h6jb5NvbmZ1NULfeGENCtY4hhPCSjPgsNhx4V+sYbSK3cC0VtceJCE7UOooQ7e7HI74/+yIuLEN+PkU9KWCIhlQVyspOFi0qfXs9XAMGA1RVQ3SU1kmEaLXqT/y39wWA9Xx5mimEniRH9iIkKIYaR4nWUbxORWFr3scM7zpF6yhCtKsaRxm787/UOsY5ZcTL7AtxkhQwBDidngachUWepSGOc+94sH7XLqbPn4vFZCYlNpYF987AYvb86/Rjbi53vPISFrOZiJAQFt73ADaLhQn/N5OSykr+87/30SkhkVc/XsaALl3I6tXKZR82G3TuBGkdwSz/Sgv/p9TWUPXZUq1jtIpNChhC6IrBYCQjPottecu1jtImth5ZwdCMyZiNQVpHEaLdbM/7BLfq+zudSQFDnEpaLge6klL4PAe2/ORZgtGE4gVAanwca554mq9mPUvnxET+u+7kVPfeaWl899xsvnz6GQZ17cqS775lS24uWT178czv/8Cib76hoqaa7YcOtq54ERYG558HY0ZCRmcpXgjdqPzvu6hVlVrHaDmzhaDe0mxLCL3pGj9c6whtptZZxo5jn2sdQ4h243Lb2XL4I61jnFNIULTsQCIakE98gS4ywrP0QlWbdVpyTGz934PMFoynNAG1nFJIqLU76NGxIyFWK3UOB9X2OkJtNmZ/tIQ/T5jYsswx0ZCRDgnxLTtfCB/mLi+jctECrWO0irVnX4xWm9YxhBBelho7AIspGKe7VusobWLdvrfolZSN2WTVOooQbW7L4f9SZS/SOsY5pccNbdpmAyJgyAyMQGcyQVzsuY87g4MFx/n0h01cOTSzwfdXbtzIgGl38sXWn+ia3IFeaWm4FDf/+SKHkX36UOdwsGnvHqa+PIetB/Y37WaJCTBsKGReIMULoVsV77+OWlutdYxWke1ThdAnszGIzrFDmn2eoqi8+8zPvPSXTbz0500cP1RNbZWTt5/YxqszNvP+CztPO6ex17etLeSFaRv55M1cAJwON+/N3tG6N3WKKnuRXzyRFqK16pxVrN//H61jNIksHxG/JjMwBCQmehp2NlNFTTWTn32GN/98b4NZFwCXDh7MpYMHM2vRB8z7ZAX3X3sdT9x8KwD3zH+Nh6/7LTNe/yfzp03nrrmvMG/a9MZvYjRCSgfPEpFQ2dFA6Jur4BhVH/vx1qm/kAaeQuhXl4Th7Cn4qlnnHN1XhcupMO35QeRuLePLDw9jsRoZe20nOnYNb/SclQv2n/b65jXHmTZ7IAv+vh2Arz86wsirUlv+Zhqxfv9/OC/lMmyWxnMJoQcbDyzE7vL9paomo4VOsYO0jiF8jBQwBCTGw7bmLSNxud1c//RT/L8bfkePjg0HD3anA6vF0wQrMjQEu/NkX42f9ueSEhtLXGQkZdWep8wn/mzAYoa0NOicBtaWTeVUVVWmnAm/Uv7v18Dl+820zsZgtWHt0VfrGEKINpIel4nRYEZRXU0+JzLOiqp6/rtcU+UkNNLC/m1lOOxuivJqGXV1Kn2HN5xZmbe38rTXzRYjbrcKBqgqd1BR7KBDRphX35/dVcXGAwsZ0e02r15XCF9RVVfED4cWax2jSVKjPcvWhDiVLCEREBQEsTHNOuXdL3P4ftdOHl/4H8bcP4P3vvqSP770IgArN25i9H0zGHP/DD7dvJkpF19af95Ly5Yy7cqrAOidmsaIGffyuzFjT17YZoNePWDsaOjRrUXFC9XpoGrVRxyffiPuMv1t9yb0ybF/DzVrVmgdo9VsQ0ZgsFi0jiGEaCM2Sxgdo89v1jmhkRZMZgNPTfmeJa/sZviVKRzcVUHWZSn84fHz+fSd/Tgd7gbnNPb6qImpvPvMDvqNjOeLRYfIvKwDi1/ZzWfvNHEpahNtPrSYyrrmz0wVwh+sy12AS7FrHaNJZPmIaIzMwBAeKR2gqLjJh0++cByTLxzX4HvXjRoNwFVZWVyV1fgvnH/cfU/93/9+8y38/eZbPF+EhXmWiXRI9iwbaQGluoqq5YuoXLYQpcTTlKhi4b+InjqjRdcToj2Vv/VKs5vp+qKQURdrHUEI0ca6JAznUMnmJh+/a1MJRpOBB17P5PDuCpbO30tUvI20HhEAJHQMobzITlyHkPpzGnu9Y9dwbn74PArzaig8Ukvu1jIGXZjI3p/KKDhcTUKqd5aauhUH63IXcFHve71yPSF8RUn1IbYd/UTrGE2WEZ957oNEwJEZGMIjMcHT0LO9xUTD4IEwajh0TGlR8cJVVEDZv17k6C2XU/7Wy/XFC4CqTz7ElX/Em4mF8Dr7th+o2/CN1jFazRASSvAQ/W6zKITw6NLc7VRVCI3wzMwKjbBQW+2iQ0YYhXk1KG6VomO1RMQ0nHF5tte//PAwoyel4qhz43arKC4Fe23DGRyttT1vJcVVB716TSG09u3e11FVResYTZIU0ZNwW4LWMYQPkhkYwsNshqREyDvaPvdLSvTMuIiKavElnIdyqfjwbWq+WHnmvgEuF6Xznyf+kedbfB8h2pLqclE671mtY3hFcNYYDEGy/aAQehduiycxogfHK3Y16fjug6LZ8NkxXr53My6nwlV/7EZohJn3X9iJ066QOb4DQTYTOzYU47QrnD8instvzTjtdYD928tJTg/FFmLm/BHx/Pup7YSEW8i+vrNX36OKwnf7XufKfo959bpCaOVY+Q72FnytdYwm693h0nMfJAKSQVV1MGdZeEdRMazf2HbX99KOIvbtW6hY9JbniXUT//WNuXcmoRde1uJ7CtFWyv8zn4p35msdwyviHptD8OBhWscQQrSDHw8vZc3OF7WO0eYmDZxFmuyCIPycnBhsXAAAIABJREFUorp5b8N08su9t+1wWzIbrdw+6n2sFu826RX6IEtIxEmxMRDcBp1+LWbokgFjR0HfPi0qXqiqSs3aLzj+199T8L9/oG79183qF1A67xncxdKQS/gWR+4uKhb+S+sYXmGMiMI24AKtYwgh2knPpAsxG21ax2hzn/78LHZXI7ulCeFHNh9c5DfFC4CuCSOkeCHOSAoY4iSDAVJTvHc9L+4okj/1Gor/7684dvzUoihqVSUlL/29RecK0RZUp5OS5x8Ft3fXbWsleEQ2BpOsShQiUFgtYXRLHKl1jDZXWVfA17v1MUtOBKbiqoN8t+8NrWM0Sx9ZPiLOQkaboqGOKbBnX+t2Q2ijHUVaq27DN1R/vozQcVd65XpCtEbFe6/j3L9H6xheI7uPCBF4+qZczo5jn2kdo81tzfuYbokj6RQ7WOsoQjSLorhZtf1p3MoZesX5oAhbIqkxA7SOIXyYFDBEQzYbxMdBQQuWW8REQ0Y6JMS3+PauogKq/vsuVSsXo9Z4f8pm6bxnsfa/AHNcotevLURTOfbupOK917WO4TWm2ASsfWSwIUSgSYnuS0xoGiXVh7SO0uY++/k5Jmf+Q6a1C7+y6eD7TW626yv6pIzHYDBoHUP4MFlCIk6Xltq845MSYdhQyLygxcUL56Fcimc/xrEpV1G5+O02KV4AqDXVlM6RpSRCO6rTQcnsR0HRx9IRgOCR4zC0cLaVEMK/nZcSGA2yK+sK+GrPPK1jCNFkRVX7WbvvLa1jNIvRYA6Y3ymi5WQGhjhdfJyn0Wb1WYoI3tpRZNsPVHy4oFk7irRW3abvqPr0v4RdfFW73E+IU1W8+y+cB/ZqHcOrQseM1zqCEEIjfTpcynd738Sl1Gkdpc1ty1tBt4SRdI6ThsXCt7kVF59un4Vb9Z+lIwBdEoYTZo3VOobwcfLITJzOYID0To2/5s0dRe79PQX33dbsHUW8oWz+czgP7GvXewpRt2U9FR+8qXUMrwrq2Zegbr20jiGE0IjNEk7P5GytY7Sbz35+jjpnldYxhDirjQfe43jFbq1jNFu/jr/ROoLwA1LAEI1L6QBBQSe/bosdRXa2bEcRb1Brayh8/C+4y8s0yyACizPvEMVP3q+rpSMA4RNu0DqCEEJjA1InaB2h3VTZi/jy/7d359FR1Xcfxz939slk3wMkBAgQNsGwIygIigtU1ApWq3WpVbEq1iIqrQuiFe1j1Wq1tvXx0frUDVdwQXBHBUEgQBJ2AgnZJvsks957nz9i7dO6QTKT752Zz+scDsEDhzfnBJx85t772/WodAbRd2po34fP9z8tnXHM0l0FyE8fI51BUYC3kNC3M5uB/vlATZ0hTxQJB7W2Go33LkHWXY9CsfCvAkWO1uGB+65fQfO0SaeElTkrF84pJ0tnEJGwzKSB6Jc2GlXN26RTekVZzRrkpBRjTD5vRSVj6Qy04PWtt0HTQ9Ipx+w4Xn1BR4lftdF3GzQQGFzU7V/+9Ykib70M3RuZh3L2lL90M1qe+D3SFt4snUIxSldVNN6/FKHDB6VTwi5x7gIoZrN0BhEZwJj8eXEzYADAB7seQbqrAAU87pEMQtWCWFV6J9p8tdIpx8xpTcHIvqdJZ1CU4C0k9N26ecXFN04UMeh48U+e1S/Bs/ol6QyKUa3/8yh8X6yXzgg7xZmAxNnxc9k4EX2/QdknIMWZJ53Ra3Rdw+rSZWjpPCKdQgSga1Srbpa7PbsnxvY/D1azUzqDogQHDAob/44taLjzBtQuXIDOtW8Aoeh58nHz4/fDV7pJOoNiTMe61WhfGX33oR4N18w5MCUmSWcQkUGYFDMmDrxIOqNX+YJteG3rb+APGfuNGop9Ww+/htKqVdIZ3eK0pmBMAd8QoaPHAYN6xAgnioSFpqLxniUI1VZJl1CM8FdsR9PDy6UzIsNkQuJZP5GuICKDGZY3C2kJ+dIZvaqpoxJvbb8Hmh5bD2im6HGo8Ut8sOsR6YxuK+HVF3SMOGBQtwUP7TfEiSLhorW3wr3sxph70CL1vlB9DdzLfx1VVyEdC8f4qbD2ia8vUojoh5kUMyYNvFg6o9cdcH+OT/c+KZ1Bcail8whWlS6DrmvSKd3itKZgTBydYkThwQGDus2c3Qeap106I6yClfvQcNu10Dp5xjt1T8hdh/pbroLW3CidEjFJZ/HoVCL6dkNzpyPDVSid0eu+OPgcymvWSmdQHPGHOr66hSl6X4uX9D8PNguvvqBjwwGDus3kcMTkFzKBXTvRcNv10Lyd0ikUZdQmNxpuXQi1tlo6JWKsA4bAMXqcdAYRGZSimDB50M+kM0S8W/Z7HGnZKZ1BcUDVQnhr+91o6qiUTuk2Xn1B3cUBg3okcc55MCUmS2eEXaB8G9zLboDm80mnUJRQW5tRv3QhQtXR+2LiaCT/5HLpBCIyuKLsachK6v4x7NFK1YJ4ZcstqGvbJZ1CMUzTVLy9414ccG+QTukRXn1B3cUBg3rElOBC4twF0hkR4S/dDPedvBKDfpja7EbDLVchdGi/dEpE2YaORMIJM6UziMjgFEWJ26swAqEOrNy8BPXte6VTKAZpuoo1Zfdjd9370ik94rAm8+oL6jYOGNRjiWedD8Xpks6ICH/pZjT89lpoHXwmBn27kLsO9UuuRLByn3RKxKVcdp10AhFFiUFZU5CbXCydIcIfasfLm2+C23NAOoViiK5rWFf+IMpr3pVO6bGxvPqCeoADBvWYOSkFyefF7jstgfJtaFi6EGp7q3QKGUyo7gjql/wi5m8bAQDHhGlwjCyRziCiKDJ50CXSCWK8wVas3LyYIwaFha5reK/iIeyoflM6pce6rr44WzqDohgHDAqLpLMvhDmnj3RGxAT2lKHh5isRaqiVTiGDCBzci/qbrojpB3Z+zWRC6iW/lK4goihTmDkefVJHSmeI6Qw048VNv0J92x7pFIpimqZizc77UVq1SjolLCYOuJBXX1CPcMCgsFBsdqReeq10RkQFD+5F3Q0/g79sm3QKCev89H3U33gpVHeddEqvcM08E9b+g6QziCgKnVAU3w/+9QXb8NLmG1HTUiadQlFI1UJ4a8c9KKtZI50SFpmJA3n1BfUYBwwKm4Rpp8A2Yox0RkRpzY2ov+VKeN55VTqFBOiahtZ//AWNdy+G7vNK5/QKxW5H8k+vks4goijVL+04FOfNks4Q5Q91YOWXN6GqmW+A0NELqQGsKr0Tu+s+kE4JEwUzhy2CyWSWDqEoxwGDwirtihsBRZHOiKxQCM0PL0fz4/dDD4Wka6iXaN5ONN57C9r+/mfplF6VOGcBLJk50hlEFMVOGnI1HNYk6QxRQdWLlzcvQdmR2HgnnSKrw9+IlzbfiP0Nn0qnhM2IPrPRJ3WEdAbFAA4YFFa2wcOQMHOOdEav8LzxPBp++0uobS3SKRRhodpq1C++HN7166RTepUpKQXJ8y+VziCiKJdgS8XUoiukM8SpehDv7FyBD3b9CZqmSueQQdW2VuDZDQtR0xo7tx05rMmYNvgX0hkUIzhgUNil/uwaKM4E6Yxe4S/dhLobfobAQZ73Hqt8pZtQd8PFCB6Iv4ewJc2/FKbE+H7XlIjCY2TfM9A3dZR0hiFsObQSr2y5Bb5gm3QKGUx5zVq8sGkROvxu6ZSwmlr0czhtKdIZFCM4YFDYmdMzkfzj2D1W9T+ptdWov/FSdH7Ey0Jjia5paH/1f9Gw9BpobfF3hK4lfwCS5s6XziCiGKEoCmYOuwFmxSqdYgiHmjbjfzdcg0bPQekUMgBNV/HR7j/j7R2/g6oFpXPCKi9lGEb2PUM6g2KIouu6Lh1BsUcP+FFz5Y+h1tdIp/Qq59SZSLt6Ccyp6dIp1AOhmio0PXQX/Ns3S6fIMJmQff/fYC/mu6VEFF7r9z6JjQeelc4wDKvZidNH3YpBWVOkU0iIL9iON7ffjcrGL6RTwk5RTLhg4mPITiqSTqEYwiswKCIUmx2pl10vndHrvJ+sQ+3V5/FqjCilaxraX38OtdecH7/jBYDEuQs4XhBRREwc8FOkOPtIZxhGUPXi9a23YcN+jjrxqKnjEP6x8ZcxOV4AwJj8eRwvKOx4BQZFlHv5Yng/e186Q4RzygykLVwCc1qmdAodheCRw2h+cBn8O7dIp4gy5/ZF7qPPw+RwSKcQUYyqbNyEl79cIp1hOEXZ0zBz2CIk2FKlU6gX7Kp9H2vL/4BAqEM6JSJc9gxcMuUp2Czx8Vw86j0cMCii1NZm1C5cAK2lSTpFhCkpBalXLYZr+mnSKfQddFWF543n0fr0o9D9fukccVn3PAbH6PHSGUQU497afg8qauPrZKej4bSmYuaw6zE450TpFIqQDn8T3qt4CHvrP5FOiagzRi3F0NyTpTMoBnHAoIjr/OwDNC7/tXSGKOekk5B2zS0wp/NqDCMJVlei6cFlCJRtk04xBNfss5F+3VLpDCKKA52BZjy1/lL4Q+3SKYY0JOckzCi+Fgm2NOkUCqOKmnV4f9cjMX8CTVH2NMwdfYd0BsUoDhjUKxofuAOd61ZJZ4hSHE4knX0hks7+KUyuROmcuKY2u9H23JPwvP0yEApJ5xiCOTMHuY89D1MCPzeJqHeU17yLt3fcK51hWE5rCk4uvg5DcqdLp1APdfgbsa78IexrWC+dEnHJjhxcOOkJOKx8PUGRwQGDeoXW4UHtNedDbaiVThFnSk5B8vzLkHjmj6HY7NI5cUXr8KB95TNof/VZ6H6fdI6hZN7+IJwTpkpnEFGcWbPzfuw88rZ0hqENzj4RM4qvg8vOqzGiUfmRd/H+rkfj4mojk2LGeeP+gD6pI6RTKIZxwKBe49v2BRqWLgT4KQeg6x3v5AuvhGvmGVDMFumcmKb5ffCsfhHtLzwFrb1VOsdwEqafjozFd0lnEFEcCqo+/GPDNWjsOCidYmgOazJmFF+LYj5TIGp4/G6sK3sQ+92fSaf0mhOKLseEARdIZ1CM44BBvar58fvheeN56QxDseQXIuXihUiYwhcl4aarIXSsXYW2Z5+A2lgvnWNIptQM5D72PMzJfOo9Eclo9FTiHxsXIqjyyrgfkp82BicM/jnyUoZJp9B3CIQ68eWhldh88AUE1E7pnF5TkD4W55SsgKIo0ikU4zhgUK/S/D7UXXchQlWV0imGYxsyAknnXgTnpOlQLLwioyc0nw+dH72D9pVP83Pt+5jMyFr+KByjx0mXEFGcKzuyBu/sXCGdETWKsqdiyqDLkJHYXzqFvhLSAthetQob9j8Lb7BFOqdXJdjS8NNJT8BlT5dOoTjAAYN6nb9iB+oXXw5oqnSKIZnSMpB42tlwzZ4HS1audE5UCR4+CM9bK9Gx9g3oHR7pHMNLufRaJP/4Z9IZREQAgHd23oeyI+9IZ0QNBSYM73MqJg28GMnOHOmcuKXpKipq1uGzfU+hzVcnnSNAwTkl96J/Bt8Mod7BAYNEtD3/JFqf/pN0hrGZTHBOmIbEM8+DfcwEKCaTdJEh6aEQvJ9/CM+bL8G/7QvpnKjhnDwDmb+5XzqDiOhrfB5G95gVK0bnn4UJAy6A05YinRNX9jV8ivV7/hbXn7Nj+8/HiUOulM6gOMIBg8S4770F3o/flc6ICpY++Ug8/VwkzJrDZxV8JeSuQ8fbr8LzzivQmtzSOVHF0rcAOQ8+zSNTichw+DyM7rOZEzC2cD6Ozz8bdh5hGVGHm7Zi/d6/oaa1TDpFVG7KMMwf9yDMJt76TL2HAwaJ0Xw+1P/6MgQP7JZOiR5WGxyjx8M58UQ4JkyFJTO+LhkNVh+Cb+PH8G74CP6dW3kbUjcodgeyH3gKtsIi6RQiom+188g7WLPzPumMqGU1O1CcOwvH5c9FdhL/rQ+XQKgTFbXrsO3w63B79kvniLNbXLhw0p+R4syTTqE4wwGDRIXqa1B3/UXQ2uLrYUfhYi0qhnPCiXBOPBG2omLpnLDT1RAC5dvh3fgxvBs/QujwQemkqJe+eDlc00+TziAi+l7v7FiBspo10hlRLy9lOEb3+xEG55wEi9kmnROV3J4DKD38Bspr3o2rU0W+jwIT5o6+A4OyT5BOoTjEAYPE+bZvRsPShYDKd9N7wpyRDceEaXBOPBH2EaOj9vYAta0F/tLN8G74CL5Nn0Bra5VOihmJc+Yj7eqbpDOIiH5QUPXh+S+uR0P7XumUmOCwJmNkn9NxXL85SEnoI51jeKoWxN76T7Dt8GuobtkunWM40wZfiXGF86UzKE5xwCBDaF/1Iloe4/Fp4WTp2x+2omLYiobBWjQMtkFDYXIZa9RQW1sQ2FuO4N5yBPZWILC3HGp9jXRWTLIVH4fsFU/wiF4iihoenxv/2PhLePwN0ikxREFh5niM6jsH/TPGwmp2SAcZSqOnEhW1a7Gj+i10BpqlcwxpZN8zccrwX0lnUBzjgEGG0fTHu9Hx9ivSGTHN0qcAtsHDYB00FLYBQ2DOyIIpPRPmpMg9tVzXNGjtrVCb3FDddQju343A3nIE9pRDbaiN2O9L/2JKTUfOQ3+HJTNbOoWI6Ji42/fj+U2LEAh1SKfEHIvJjoKMEgzMnIyBWZPgsmdIJ/U6VQvhSMsO7G/4DPvdn6Gls1o6ydDy00twzvH3wmQyS6dQHOOAQYahh0Kov/UqBHZulU6JP1YbzOmZXd/SMmHOyII5LQPm9EworqSud+3NZihmM/DPJ01rIeihEKCq0NUQtPa2rpGiqQFakxtqs7vrx82NQCgk++eLY4rDiazfPQ77kBHSKURE3VLZuAmvbrkVms5bTSMpJ3koBmZNxqCsKchKGiSdEzG+oAeVjV9gX8OnOOjeCH/II50UFdJdBVgw/o9w8IQbEsYBgwxFbWlC3aKLoDbUSacQRT+zGZm3PQDnOD5ki4ii2/aq1Vhb/oB0RtxIcmRjYNZk9M8Yh5zkIUi0Z0ondVtIDcDt2Y8jLTux3/0ZqptLOYYdowRbOs6f8DBPHCFD4IBBhhM4uBcNN18JrZ0PbyTqifRFt8N1ylzpDCKisPh031PYsP8Z6Yy45LKlIzt5MLKThyAnqev7JEeWdNY3hFQ/Gjz7Ud+2G3Vte1DfthuNHQc5WPSAzeLCeeMe4JG8ZBgcMMiQAnvKUH/r1dA7ec8rUXekXHQ1ks+/XDqDiCis1pU/iNKqN6QzCECCLQ3ZyYORkzQEmYkD4LJnINGeAZc9AxazPWK/r65r8AZb4fE3osPfhFZvzVeDRddYoetaxH7veGNWrJh3/D0oyCiRTiH6GgcMMix/2VY0/PZa6D6vdApRVEn80flIu/LX0hlERGGn6xpWb1+OPXUfSqfQ97BbXHDZM+Gyp8Nly4DLno5EewYSbGkwm6wwmSwwKWaYFDMUxQzoGjRdhaZr0PQQNF2FP+hBh78RHYFGePxNXR/7G9EZaOYVFb1CwRmjlmJo7gzpEKJ/wwGDDM23dSPcd94APeCXTiGKCq5T5iLt+tugKIp0ChFRRKhaEK9uWYpDTZulU4hi1klDF6Kk4FzpDKJvMEkHEH0fx5gJyLhlBWCxSKcQGZ5z6iykXfsbjhdEFNPMJivmjr4TucnF0ilEMYnjBRkZBwwyPOeEqci46W6AZ04TfSfHuCnIWLy866hbIqIYZ7M4cU7JCvRJHSmdQhRDFJxcvIjjBRkaBwyKCgknzET6DbcDJn7KEv0nR8kkZNx6HxReqUREccRuTcQ5JSvQP2OcdApR1FMUE04dsRij83l6GRkbn4FBUcXz1stofuQe6Qwiw3BOOwUZNy6DYrVKpxARiVC1IN7cvhx76z+RTiGKSibFjNNG3sIHdlJU4IBBUcez+iU0P34foPGYLIpvrjPORdrVS6DwyiQiinOapuKdsvtQUbNWOoUoqpgVK8447jcoyp4qnUJ0VDhgUFTqXP8emn7/W55OQnErecFlSLl4oXQGEZFh6LqO9yoeRmnV69IpRFHBbLJh7ug7MCBzonQK0VHjgEFRy1+2De5lv4LW3iqdQtR7FAWpP78BSfMukC4hIjKkj/f8BZsOPiedQWRoVrMDPxqzHAXpx0unEB0TDhgU1YJVB9Fw23VQ645IpxBFntmM9Ot/C9fMOdIlRESGtvHAs1i/90npDCJDsllcmDfmbvRNGyWdQnTMOGBQ1FOb3Gi4YxGC+yqkU4giRrHZkXHz7+CceKJ0ChFRVNh66FW8v+sRAHypS/RPCbZUnDXmbuSmFEunEHULBwyKCZq3E433LIHvy8+kU4jCTnElIvO2B+AYWSKdQkQUVcqOvIu1Zf8FVQ9KpxCJy04qwtzRy5DszJFOIeo2DhgUM3Q1hKaH70bn2jekU4jCxtInHxlL74etsEg6hYgoKtW0lOGN0jvQ4W+UTiESMzRnBk4dsRgWs106hahHOGBQzGl95nG0PfdX6QyiHnNMPBEZNy6DyZUonUJEFNU6/E1YVXonjrTskE4h6lUKTJhSdBkmDPiJdApRWHDAoJjU+claND10F/TODukUomNnMiHlwiuRtOAyKIoiXUNEFBNULYQPdz2KbTxmleKE3eLC6SOXYkAWj0ml2MEBg2JWqKYK7t/dzId7UlQxJacg46a74Th+knQKEVFM2ln9NtZVPAhV43MxKHalJfTDj8bchXRXgXQKUVhxwKCYpgcDaPnrH+BZ9aJ0CtEPsg4ejsxbV8CSnSedQkQU02pbK7Cq9E60++qlU4jCrjBjAs4YtRR2K29BpdjDAYPiAm8pIaNzzZ6HtKtvgmK1SacQEcWFzkALVpcuQ1XzNukUorAZV7gAU4t+DkUxSacQRQQHDIobvKWEjEix2ZF61WIkzp4nnUJEFHc0TcWHux/D1sOvSKcQ9YjN4sKsYYswNPdk6RSiiOKAQXGFt5T0vteONOH2ssPYOms0Fm07gA8a2rCoKA+XFGb/28871OnHr0sPAgBagir6J9jxl7GDsGJXNda723BdUR5m5aSios2L9xtacfWgXIE/TXhZBwxB+g23wzZoqHQKEVFcq6h5D+9VPAR/yCOdQnTM8tNLMHvEYiQ5sn/4JxNFOYt0AFFvUqw2pF29BPZRY9H08HLoHXyhEkmqrmN1TTP6OKwAgJuH9sUJGUnoCGnf+LkFCXa8MKnrC/kHdh9BfkLXOeX7PT6snFyMRdsOYFZOKp6srMey4fm994eIBIsVyQsuQ/L8S6FY+M8wEZG04ryT0S/tOKwt/wMOuD+XziE6KhaTA9OGXIHR/c7iqWUUN3hzFMWlhKmzkPf4S3CeMFM6Jaa9dqQJZ+alQUHX/1RzHUf3fIe19S2YnZPa9QMFCGoabCYFHzW0YUJaIhzm6P2nyzp4OHIeegYpF1zB8YKIyEASHZmYd/zdmD1iCewWPvyQjC0vZQQumvwExuTP43hBcSV6vwog6iFzeiYyb12BzNv/AHNW9N+OYDSqrmNVTTPm5qUd06/b3e5FjsOGZKsZADA7JxU3llbi8sIcvHakCcOTnbh1RyVeP9IUieyIUWx2pFzyS+T813/DVlgknUNERN9heJ9TcfHkv2FAJo+zJuMxm6yYOvgKLBj/IFIT+krnEPU6DhgU95wTpiH3sReQOO8CwGSWzokZL1c3YU5eGkzH+K7A6tpmnJn7r9HjnL4ZeKxkIMrbvZjXNx1PVzbgzuEF+LChLdzJEWMbdhxy/vgsks+7BIqZn2NEREbHqzHIiLKTBuOCiY9jfOH5PGWE4hY/84kAmJwJSLviV8h54ClYBxVL58SEPR4vVlY34qKNe3Cw04fbdh46ql/3bl0rTv3n7SNf8akaNjV7MC0zGa1BFQDQFlLD3hxuit2B1F/ciOz7/gprv0LpHCIiOka8GoOMwKSYMXHgRTh/wiPITCyUziESxVNIiP6DrqrwvP4cWv/+OHSfVzonJpz5STlWTx2Geyuq8W59CzRdx/SsFNw+PB+P7qvF3Lw0FCTYscfjxe8qqvHkuH+/xeKxfbWYkZWC4mQn1tS14JG9NZiamYybhhr30knHuClIu+omWPL6SacQEVEYlB1Zgw92PcqTSqhXZSYOwCnDFyM3hSeWEQEcMIi+U6i+Fs2PrYBv48fSKRRFrEXDkHrZdXCMHi+dQkREYebxufHh7sewu+4D6RSKcQ5rEqYMuhSj+s2BSeHtp0T/xAGD6Ad4N32K1qceQfDAbukUMjBzTh+kXLwQCSfN5tPAiYhiXHXLDny460+oa9slnUIxRlFMOK7fXEwZdAkc1mTpHCLD4YBBdBR0XUfnB2+j9ZnHodZVS+eQgZiSUpC84FIkzpkPxXp0x8QSEVH003Ud5TVrsX7vX+Hxu6VzKAbkp43B9KHXIDNpoHQKkWFxwCA6BnowCM9bK9H2/JPQWqLrGE8KL8VmR+Lc+UiefxlMiUnSOUREJCSo+rDp4PPYXPkigiqfnUXHLsNViKmDr8DALD4sluiHcMAg6gbN54Nn9QtoX/kMtNZm6RzqTYqChBmnI+WihbBk50rXEBGRQXQGmrFh/7PYXrUKqh6UzqEokGjPxORBl2B4n1P5nAuio8QBg6gHNJ8XnlUvoP3lv3PIiHGK3Y6EGWcgad6FsOYXSucQEZFBtXpr8dm+p1BRsw46NOkcMiC7xYVxheejpOBcWMx26RyiqMIBgygMNJ8XHW+9DM/qFxGqqZLOoTAypWYgcc55SDzjxzCnpErnEBFRlHB7DuDzfU9jb8Mn0HUOGQQk2rNQUnAORvY7E3aLSzqHKCpxwCAKI13X4dv8GTyrXoBv86eAxhcs0cpaWITEeRfANf00PpyTiIi6rdVbgy2HXsbO6rcRUDulc0hAZuJAjO0/H0NzZ8BsskjnEEU1DhhEERKqrYbnzZfQseZ1aO2t0jl0NBQFjrGTkTTvQjiOnyhdQ0REMcQf9GBH9ZvYcvgVtPvqpXOoF+Snl2Bc//kozBwvnUIUMzhgEEWY5veh86M18Kx6EcG95dI59C2UBBfQiE5PAAAFaklEQVQSTjwVSWf9BNYCHl1GRESRo2kq9tR/hC8PrURtK18XxBqTYsaQnOkY2/88ZCcPls4hijkcMIh6kb9iOzyrXoD30/eg+/3SOXFNsdnhGDcFCdNPg3P8VCg2PkSLiIh615GWndhc+SL2NaznczKinNXsxMi+Z6Ck4FwkO3Okc4hiFgcMIgGazwffpk/gXf8evF+sh+7tkE6KDyYz7KPHwXXSaXCeMAOmhETpIiIioq+ek/EKKmrWwhvkbafRQ0Hf1JEozpuFITnT4bDydQVRpHHAIBKmB/zwffk5Oj99D97PP4Le0S6dFHNsxaOQcNJsJEw7Bea0DOkcIiKib6VpKg41bUZF7XvY1/ApAiG+wWFEGa5CFOfNRHHuTF5tQdTLOGAQGYgeCsG3dSO869fB+/mH0NpapJOik9UGe/EoOEomIWHaKbDk9ZMuIiIiOiYhNYAD7g3YVfse9rs/h6oFpJPiWqI9E0NzT0Zx3kxkJxVJ5xDFLQ4YRAalqyr8O76Eb8sG+HduQWB3GRAKSmcZk8kE66BiOEaPh2PMeNiGj4HJ7pCuIiIiCotAqBP7GtZjV+37qGzcDE0PSSfFBZvFhcHZ01CcNwv5aaOhKCbpJKK4xwGDKEroAT/8u3cisGML/Du3wl9eGtfPzrD0K4RjzHjYR0+AY9RYmJKSpZOIiIgizhtoxZ76j7G79n1Ut+zgmBFmSY5sFKSXoDBzAgZmTobFbJNOIqL/hwMGUZTSVRXBA3vg3/El/Du3wF+2DVpLk3RWRChOF6wDB8M2cChsQ4bDftx4WDKzpbOIiIhEBVUvqpt34HDzVlQ1bUVd+26eZnKM7JYk5KePQUF6CQrSS5Dm4m2nREbGAYMohoTcdQgdPohgdeW/vq+qhOquA6Lhr7rFAktePqz5hbDmD4B14BBYBw6FJa8fFEWRriMiIjI0f6gD1c3bUdW8FYebtqKhfR90cND4/8wmG/qkjvx6sMhJHsxbQ4iiCAcMojig+XwIVVciVF2JYFUlQlUHEaqpgtrWAq29DXqnJ/IDh6LAlJQCU1o6zKmZMKdldH2clgFLbj9Y8wfA0icfisUS2Q4iIqI44Qu2o7q5FIe/GjTcngMA4uulv93iQlZSEfJShqMgvQR9UkfythCiKMYBg4igqyo0Tzs0Tyu0tlZo7W3f+FhXVUAxQTGZgK++KSYzoCiA2dx1hYTJ3PXfrVaYUrvGCXNqRtdYkZoGxcxxgoiISEog5IXbs7/rW/t+NHj2w+05EDPHtSbas5CVNBBZSUXITipCVlIRUpx5vIqTKIZwwCAiIiIiimNt3jo0dx5Gc0cVmjurvvr4MNp9DYa7BcVmccFlS0daQj+kJ/ZHuqsAGa6u722WBOk8IoowDhhERERERPQNIS0Ab6AF3kArvMHWb3zfGWiBL9j21Y9b4A22HcNDRBUoUACl6zaPBFvat3xLRYI9DS5b+tf/jbd/EMU3DhhERERERNRjuq4jpPnw9TgB5avbN7p+/PXHvKWDiLqJAwYRERERERERGR7PDCIiIiIiIiIiw+OAQURERERERESGxwGDiIiIiIiIiAyPAwYRERERERERGR4HDCIiIiIiIiIyPA4YRERERERERGR4HDCIiIiIiIiIyPA4YBARERERERGR4XHAICIiIiIiIiLD44BBRERERERERIbHAYOIiIiIiIiIDI8DBhEREREREREZHgcMIiIiIiIiIjI8DhhEREREREREZHgcMIiIiIiIiIjI8DhgEBEREREREZHhccAgIiIiIiIiIsPjgEFEREREREREhscBg4iIiIiIiIgMjwMGERERERERERkeBwwiIiIiIiIiMrz/AyACAIueezpDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# PLOT TWEET PER DEVICE TYPE PER AUTHOR\n",
        "i=1;\n",
        "fig = plt.figure(figsize=(15,15))\n",
        "for id, username in authors.items():\n",
        "   data_dict=df[df.user_id==id].groupby(['tweet_device']).count()\n",
        "   explode_value = np.repeat(0.05, data_dict.index.size)\n",
        "\n",
        "   fig.add_subplot(3,2,i)\n",
        "   # Creating plot per auther\n",
        "   plt.pie(data_dict['tweet'], autopct='%1.1f%%', shadow=False, pctdistance=0.85, explode= explode_value, textprops={'size': 'smaller'})\n",
        "   # draw circle\n",
        "   centre_circle = plt.Circle((0, 0), 0.70, fc='white')\n",
        "   fg = plt.gcf()\n",
        "  \n",
        "   # Adding Circle in Pie chart\n",
        "   fg.gca().add_artist(centre_circle)\n",
        "   plt.legend(data_dict.index, loc=\"best\")\n",
        "   plt.title(\"Number of tweets by \"+username+\" per device\")\n",
        "   plt.axis('equal')\n",
        "   i+=1\n",
        "# show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfFTPfXtuxxL"
      },
      "source": [
        "## Feature Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Vq6U6rn89G"
      },
      "source": [
        "## Lexical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8GzCCH5cF8mU"
      },
      "outputs": [],
      "source": [
        "#Dictionary words\n",
        "dictionary = nltk_words.words();\n",
        "english_words = set(word.strip().lower() for word in dictionary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NhyBVWsphSyF"
      },
      "outputs": [],
      "source": [
        "# characters or numbers appearing 3 or more consecutive times in a string  \n",
        "# Compile the ReGex //\"\\\\b([a-zA-Z0-9])\\\\1\\\\1+\\\\b\"\n",
        "repeating_re = re.compile(r\"(.)\\1{2,}\")\n",
        "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KtzP6sK_qyFP"
      },
      "outputs": [],
      "source": [
        "### Lexical and syntactic Feature Extraction\n",
        "def lexical_feature_extration(tweet):\n",
        "  tk_no_puntuation = tokenizer.tokenize(tweet) #puntuations are removed\n",
        "  tk_punctuation = tweet.split(\" \") #puntuations remained\n",
        "  \n",
        "  # number of words per tweet\n",
        "  num_words = len(tk_punctuation)\n",
        "\n",
        "  # number of sentences\n",
        "  sentences = nltk.sent_tokenize(tweet)\n",
        "  num_sentences = len(sentences)\n",
        "\n",
        "  #number of begining words capitalized, #number of punctuation per sentence, #number of uppercase letters\n",
        "  num__beginning_sent_capital = 0\n",
        "  num_punct_sent = 0\n",
        "  num_uppers_sent = 0\n",
        "  for s in sentences:\n",
        "    if s[0].isupper():\n",
        "      num__beginning_sent_capital +=1\n",
        "    for char in s:\n",
        "      if char in string.punctuation:\n",
        "          num_punct_sent +=1\n",
        "      if char.isupper():\n",
        "        num_uppers_sent +=1\n",
        "\n",
        "  # number of words for per sentences\n",
        "  num_sent_words = [len(s.split(\" \")) for s in sentences]\n",
        "  word_per_sent = sum(num_sent_words)/num_sentences\n",
        "\n",
        "  #Frequency of dictionary words\n",
        "  freq_dict_words = sum([1 if word.lower() in english_words else 0 for word in tk_no_puntuation])\n",
        "\n",
        "  #Frequency of word extensions\n",
        "  freq_words_ex = sum([1 if re.search(repeating_re, word) else 0 for word in tk_no_puntuation])\n",
        "\n",
        "  #lexical diversity\n",
        "  #print(tk_punctuation)\n",
        "  lex_diversity = len(tk_no_puntuation)/len(set(tk_no_puntuation)) if len(tk_no_puntuation)>0 else 0\n",
        "\n",
        "  return pd.Series([num_words,num_sentences,word_per_sent,freq_dict_words,freq_words_ex,lex_diversity,\n",
        "                    num__beginning_sent_capital,num_punct_sent,num_uppers_sent]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "XygqH1vdwP39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 956
        },
        "outputId": "f1e5320c-8435-409b-9d41-eda0aa128144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3641: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_single_column(loc, value, pi)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    user_id  retweet_count  reply_count  like_count  quote_count  \\\n",
              "0  27699224              0            1          15            0   \n",
              "1  27699224              2            4          66            0   \n",
              "2  27699224              7            3          67            1   \n",
              "3  27699224              0            1          23            1   \n",
              "4  27699224              0            0          20            0   \n",
              "\n",
              "         tweet_device                                              tweet  \\\n",
              "0  Twitter for iPhone  FYI for other authorsthis raised $, which is a...   \n",
              "1  Twitter for iPhone  Twenty years from now, this is gonna read like...   \n",
              "2  Twitter for iPhone  If you donate $ or more to @WCKitchen and DM m...   \n",
              "3     Twitter Web App  Our long international nightmare is just begin...   \n",
              "4  Twitter for iPhone                                         Nostalgia.   \n",
              "\n",
              "              tweet_id                tweet_time    username  ...  \\\n",
              "0  1498672192766328838  2022-03-01T14:51:09.000Z  @askanyone  ...   \n",
              "1  1498655705351479296  2022-03-01T13:45:38.000Z  @askanyone  ...   \n",
              "2  1498048242336120832  2022-02-27T21:31:48.000Z  @askanyone  ...   \n",
              "3  1496922333512351744  2022-02-24T18:57:50.000Z  @askanyone  ...   \n",
              "4  1495551477057732609  2022-02-21T00:10:32.000Z  @askanyone  ...   \n",
              "\n",
              "   num_sentences  word_per_sent  freq_dict_words  freq_words_ex  \\\n",
              "0            2.0           18.5             32.0            0.0   \n",
              "1            1.0           18.0             16.0            0.0   \n",
              "2            1.0           37.0             32.0            0.0   \n",
              "3            1.0            7.0              7.0            0.0   \n",
              "4            1.0            1.0              1.0            0.0   \n",
              "\n",
              "   lex_diversity  num__beginning_sent_capital  num_punct_sent  \\\n",
              "0       1.058824                          2.0             6.0   \n",
              "1       1.058824                          1.0             2.0   \n",
              "2       1.058824                          1.0             4.0   \n",
              "3       1.000000                          1.0             1.0   \n",
              "4       1.000000                          1.0             1.0   \n",
              "\n",
              "   num_uppers_sent  mimicry_by_length  mimicry_by_word  \n",
              "0              5.0           2.211111              3.0  \n",
              "1              1.0           0.520231              2.0  \n",
              "2             19.0           3.392157              0.0  \n",
              "3              1.0           5.100000              0.0  \n",
              "4              1.0           0.135135              0.0  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cd9f11b-4b69-4a8a-b808-2f284ce64c30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>reply_count</th>\n",
              "      <th>like_count</th>\n",
              "      <th>quote_count</th>\n",
              "      <th>tweet_device</th>\n",
              "      <th>tweet</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_time</th>\n",
              "      <th>username</th>\n",
              "      <th>...</th>\n",
              "      <th>num_sentences</th>\n",
              "      <th>word_per_sent</th>\n",
              "      <th>freq_dict_words</th>\n",
              "      <th>freq_words_ex</th>\n",
              "      <th>lex_diversity</th>\n",
              "      <th>num__beginning_sent_capital</th>\n",
              "      <th>num_punct_sent</th>\n",
              "      <th>num_uppers_sent</th>\n",
              "      <th>mimicry_by_length</th>\n",
              "      <th>mimicry_by_word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>FYI for other authorsthis raised $, which is a...</td>\n",
              "      <td>1498672192766328838</td>\n",
              "      <td>2022-03-01T14:51:09.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18.5</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.211111</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>27699224</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Twenty years from now, this is gonna read like...</td>\n",
              "      <td>1498655705351479296</td>\n",
              "      <td>2022-03-01T13:45:38.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.520231</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>27699224</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>67</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>If you donate $ or more to @WCKitchen and DM m...</td>\n",
              "      <td>1498048242336120832</td>\n",
              "      <td>2022-02-27T21:31:48.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.058824</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>3.392157</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>Our long international nightmare is just begin...</td>\n",
              "      <td>1496922333512351744</td>\n",
              "      <td>2022-02-24T18:57:50.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>27699224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>Nostalgia.</td>\n",
              "      <td>1495551477057732609</td>\n",
              "      <td>2022-02-21T00:10:32.000Z</td>\n",
              "      <td>@askanyone</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.135135</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cd9f11b-4b69-4a8a-b808-2f284ce64c30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cd9f11b-4b69-4a8a-b808-2f284ce64c30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cd9f11b-4b69-4a8a-b808-2f284ce64c30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "## Apply lexical and syntactic feature extraction\n",
        "df2[['num_words','num_sentences','word_per_sent','freq_dict_words','freq_words_ex', 'lex_diversity','num__beginning_sent_capital','num_punct_sent', 'num_uppers_sent']] = df2['tweet'].apply(lexical_feature_extration)\n",
        "\n",
        "#add columns mimicry_by_length and mimicry_by_word to list\n",
        "df2['mimicry_by_length'] = np.nan\n",
        "df2['mimicry_by_word'] = np.nan\n",
        "\n",
        "#mimicry by length code\n",
        "#get each authors tweet\n",
        "for username in authors.values():\n",
        "  #print(df[df.user_id==id]);\n",
        "  author_data = df2[df2.username==username]\n",
        "  #sort it\n",
        "  author_data.sort_values(by=\"tweet_time\", ascending=False)\n",
        "  author_tweets = author_data['tweet']\n",
        "  tweet_index_list = author_tweets.keys()\n",
        "  #get mimicry length and mimicry by word\n",
        "  mimicry_length = []\n",
        "  for i in range(len(tweet_index_list)-1):\n",
        "      currentKey = tweet_index_list[i]\n",
        "      nextKey = tweet_index_list[i+1]\n",
        "      #mimicry by length\n",
        "      df2.loc[currentKey,'mimicry_by_length'] = len(author_tweets[currentKey])/len(author_tweets[nextKey])\n",
        "      #mimicry by word\n",
        "      current_tweet_words = set(tokenizer.tokenize(author_tweets[currentKey]))\n",
        "      next_tweet_words = set(tokenizer.tokenize(author_tweets[nextKey]))\n",
        "      df2.loc[currentKey,'mimicry_by_word'] = len(current_tweet_words.intersection(next_tweet_words))\n",
        "      \n",
        "  df2.loc[tweet_index_list[-1],'mimicry_by_length'] = 0\n",
        "  df2.loc[tweet_index_list[-1],'mimicry_by_word'] = 0\n",
        "  \n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZlFUMHO5ORM"
      },
      "source": [
        "### Performing Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6fALk5N55UyC"
      },
      "outputs": [],
      "source": [
        "def balanceData(balanceType, trainX, trainY):\n",
        "    # [\"None\", \"SMOTE\", \"RandomOver\", \"RandomUnder\"]\n",
        "    if balanceType == \"None\":\n",
        "        x_train_res = trainX\n",
        "        y_train_res = trainY\n",
        "    if balanceType == \"SMOTE\":\n",
        "        sm = SMOTE(random_state=12)\n",
        "        x_train_res, y_train_res = sm.fit_resample(trainX, trainY)\n",
        "    if balanceType == \"RandomOver\":\n",
        "        sm = RandomOverSampler(random_state=12)\n",
        "        x_train_res, y_train_res = sm.fit_sample(trainX, trainY)\n",
        "    if balanceType == \"RandomUnder\":\n",
        "        sm = RandomUnderSampler(random_state=12)\n",
        "        x_train_res, y_train_res = sm.fit_sample(trainX, trainY)\n",
        "\n",
        "    return x_train_res, y_train_res\n",
        "        \n",
        "def initNeuralNetModel(trainX, trainY,numFeatures):\n",
        "    train_Y = np_utils.to_categorical(trainY)\n",
        "    inputShape = (numFeatures,)\n",
        "    class_weight1 = {0: 1.,1: 20.}\n",
        "    y_ints = [y.argmax() for y in train_Y]\n",
        "    train_classes = np.unique(y_ints)\n",
        "    num_classes = len(train_classes)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, input_shape=inputShape))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dense(32))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Dense(num_classes))\n",
        "    model.add(Activation(tf.nn.softmax))\n",
        "\n",
        "    #opt = RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    # opt = RMSprop(0.001)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def doNeuralNetAnalysis(model, trainX, trainY, testX, testY, numFeatures):\n",
        "    print(\"Doing analysis with fully connected neural network\")\n",
        "    train_Y = np_utils.to_categorical(trainY)\n",
        "    test_Y = np_utils.to_categorical(testY)\n",
        "    inputShape = (numFeatures,)\n",
        "    class_weight1 = {0: 1.,1: 20.}\n",
        "    y_ints = [y.argmax() for y in train_Y]\n",
        "    train_classes = np.unique(y_ints)\n",
        "    chanDim = 1\n",
        "    num_classes = len(train_classes)\n",
        "\n",
        "    # initialize our initial learning rate and # of epochs to train for\n",
        "    INIT_LR = 0.01\n",
        "    EPOCHS = 4\n",
        "\n",
        "    # compile the model using SGD as our optimizer and categorical\n",
        "    # cross-entropy loss (you'll want to use binary_crossentropy\n",
        "    # for 2-class classification)\n",
        "    print(\"[INFO] training network...\")\n",
        "    # opt = SGD(lr=INIT_LR)\n",
        "    # model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "    #              metrics=[\"accuracy\"])\n",
        "    # model.compile(loss='binary_crossentropy',\n",
        "    #              optimizer=opt,\n",
        "    #              metrics=[sensitivity, specificity])\n",
        "    class_weights = compute_class_weight(class_weight = \"balanced\",classes=train_classes, y = y_ints)\n",
        "    class_weights = dict(zip(np.unique(train_classes), class_weights))\n",
        "    #print(class_weights)\n",
        "\n",
        "    # train the neural network\n",
        "    model.fit(trainX, train_Y, validation_data=(testX, test_Y),\n",
        "              epochs=EPOCHS, batch_size=32,\n",
        "                  class_weight=class_weights, verbose=0)\n",
        "\n",
        "    # evaluate the network\n",
        "    print(\"[INFO] evaluating network...\")\n",
        "    #preds = model.predict(testX, verbose=0)\n",
        "    #predictions = preds.argmax(axis=1)\n",
        "    #print(classification_report(testY, predictions,target_names=[\"0\", \"1\"])\n",
        "    #print(confusion_matrix(testY, predictions))\n",
        "    return model\n",
        "\n",
        "def getClassifierCode(classifierType):\n",
        "    #[\"ANN\", \"SVM\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Naive Bayes\"]\n",
        "    code = \"\"\n",
        "    if classifierType == \"ANN\":\n",
        "        return \"ann\"\n",
        "    if classifierType == \"SVM\":\n",
        "        return \"svm\"\n",
        "    if classifierType == \"Decision Tree\":\n",
        "        return \"dt\"\n",
        "    if classifierType == \"Random Forest\":\n",
        "        return \"rf\"\n",
        "    if classifierType == \"Naive Bayes\":\n",
        "        return \"NB\"\n",
        "    if classifierType == \"Logistic Regression\":\n",
        "      return \"LR\"   \n",
        "\n",
        "    return code\n",
        "\n",
        "def getBalanceCode(balanceType):\n",
        "    #[\"None\", \"SMOTE\", \"RandomOver\", \"RandomUnder\"]\n",
        "    code = \"\"\n",
        "    if balanceType == \"None\":\n",
        "        code = '-'\n",
        "    if balanceType == \"SMOTE\":\n",
        "        code = 's'\n",
        "    if balanceType == \"RandomOver\":\n",
        "        code = 'ro'\n",
        "    if balanceType == \"RandomUnder\":\n",
        "        code = 'ru'\n",
        "    return code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aCPuapH78r8"
      },
      "source": [
        "#### Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sIbW2GPfFD0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f4f6e2-c40f-4037-921f-994d07e30e03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'retweet_count', 'reply_count', 'like_count', 'quote_count',\n",
              "       'tweet_device', 'tweet', 'tweet_id', 'tweet_time', 'username',\n",
              "       'tweet_device_code', 'username_code', 'num_words', 'num_sentences',\n",
              "       'word_per_sent', 'freq_dict_words', 'freq_words_ex', 'lex_diversity',\n",
              "       'num__beginning_sent_capital', 'num_punct_sent', 'num_uppers_sent',\n",
              "       'mimicry_by_length', 'mimicry_by_word'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "### Need to perform grouping\n",
        "df2.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "NGpU1ffE362O"
      },
      "outputs": [],
      "source": [
        "# We did not consider the non-stylometric feature 'retweet_count', 'reply_count', 'like_count', 'quote_count','tweet_device_code'\n",
        "data = df2[['num_words', 'num_sentences','word_per_sent','freq_dict_words','freq_words_ex','lex_diversity','mimicry_by_length','mimicry_by_word','num__beginning_sent_capital', 'num_punct_sent', 'num_uppers_sent']]\n",
        "labels = df2['username_code']\n",
        "numFeatures = 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KVrC9H4MHbqy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abd6553-e6dd-42a5-853d-50efb08f66d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of Features and the scores\n",
            "\n",
            "  num_words    num_sentences    word_per_sent    freq_dict_words    freq_words_ex    lex_diversity    mimicry_by_length    mimicry_by_word    num__beginning_sent_capital    num_punct_sent    num_uppers_sent\n",
            "-----------  ---------------  ---------------  -----------------  ---------------  ---------------  -------------------  -----------------  -----------------------------  ----------------  -----------------\n",
            "    60.2809          15.5724          59.1764            89.1407          1.79416          8.77267              3.97884            45.2046                        21.7228           11.6433            44.7265\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  num_words    num_sentences    word_per_sent    freq_dict_words    freq_words_ex    lex_diversity    mimicry_by_length    mimicry_by_word    num__beginning_sent_capital    num_punct_sent    num_uppers_sent\n",
            "-----------  ---------------  ---------------  -----------------  ---------------  ---------------  -------------------  -----------------  -----------------------------  ----------------  -----------------\n",
            "         37                2             18.5                 32                0          1.05882             2.21111                   3                              2                 6                  5\n",
            "         18                1             18                   16                0          1.05882             0.520231                  2                              1                 2                  1\n",
            "         37                1             37                   32                0          1.05882             3.39216                   0                              1                 4                 19\n",
            "          7                1              7                    7                0          1                   5.1                       0                              1                 1                  1\n",
            "          1                1              1                    1                0          1                   0.135135                  0                              1                 1                  1\n",
            "The number of row, columns  (4401, 11)\n"
          ]
        }
      ],
      "source": [
        "### FEATURE RANKING\n",
        "### https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
        "## ANOVA F-value\n",
        "\n",
        "# feature extraction\n",
        "test = SelectKBest(score_func=f_classif, k=\"all\")\n",
        "fit = test.fit(data, labels)\n",
        "# summarize scores\n",
        "np.set_printoptions(precision=3)\n",
        "print(\"List of Features and the scores\\n\")\n",
        "\n",
        "print(tabulate([fit.scores_], headers=data.columns))\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "features = fit.transform(data)\n",
        "# summarize selected features\n",
        "print(tabulate(features[0:5,:], headers = data.columns))\n",
        "print(\"The number of row, columns \",data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dRt-ywW6Ue0P"
      },
      "outputs": [],
      "source": [
        "# Open all files for writing everytime the program is ran from the beginning\n",
        "filenames = ['output.csv','pca-output.csv']\n",
        "#Header\n",
        "header = ['Experiment-Number','Grouping-Number','Balance-Code','Classifier-Code','Split-Number','Accuracy','Total-F1','cm']\n",
        "for outputFilename in filenames:\n",
        "  # open the file using open() function\n",
        "  with open(path+outputFilename, 'w', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(header)\n",
        "\n",
        "test_header = ['Experiment-Number','Grouping-Number','Balance-Code','Classifier-Code','Accuracy','Total-F1','cm']\n",
        "for outputFilename in filenames:\n",
        "  name = path+\"test-\"+outputFilename\n",
        "  with open(name, 'w', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(test_header)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "bxEXfw47-fM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a09ee0-364a-4550-9f05-2f8fb3a3ae45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.10      0.15       173\n",
            "           1       0.50      0.44      0.47       151\n",
            "           2       0.27      0.04      0.07       150\n",
            "           3       0.29      0.28      0.29       138\n",
            "           4       0.50      0.40      0.44       128\n",
            "           5       0.24      0.75      0.36       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.36      0.34      0.30       880\n",
            "weighted avg       0.36      0.32      0.29       880\n",
            "\n",
            "[[ 17  18   1  28  13  96]\n",
            " [  5  67   1   7  12  59]\n",
            " [  9  11   6  32  15  77]\n",
            " [ 10  16   8  39   5  60]\n",
            " [  3  15   3  16  51  40]\n",
            " [  6   7   3  13   6 105]]\n",
            "Accuracy: 0.32386363636363635\n",
            "Total f1 over classes: 1.7855532678907267\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.19      0.25       173\n",
            "           1       0.39      0.50      0.44       151\n",
            "           2       0.29      0.13      0.18       150\n",
            "           3       0.31      0.20      0.24       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.29      0.41      0.34       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.30       880\n",
            "weighted avg       0.32      0.32      0.30       880\n",
            "\n",
            "[[33 38 14 14 42 32]\n",
            " [10 76  3  4 30 28]\n",
            " [20 18 20 17 37 38]\n",
            " [13 27 19 27 28 24]\n",
            " [ 6 17  7 11 67 20]\n",
            " [ 8 19  7 15 34 57]]\n",
            "Accuracy: 0.3181818181818182\n",
            "Total f1 over classes: 1.813416568059178\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.56      0.36       173\n",
            "           1       0.48      0.21      0.29       151\n",
            "           2       0.20      0.17      0.19       150\n",
            "           3       0.38      0.24      0.29       138\n",
            "           4       0.55      0.09      0.15       128\n",
            "           5       0.32      0.51      0.40       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.37      0.30      0.28       880\n",
            "weighted avg       0.36      0.31      0.28       880\n",
            "\n",
            "[[97 11 25  9  0 31]\n",
            " [74 31 16  5  3 22]\n",
            " [57  6 26 21  2 38]\n",
            " [50  9 19 33  3 24]\n",
            " [46  7 22  7 11 35]\n",
            " [37  0 19 11  1 72]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.6804751659821464\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.34      0.33       173\n",
            "           1       0.47      0.50      0.49       151\n",
            "           2       0.27      0.23      0.25       150\n",
            "           3       0.29      0.27      0.28       138\n",
            "           4       0.52      0.46      0.49       128\n",
            "           5       0.43      0.53      0.47       140\n",
            "\n",
            "    accuracy                           0.39       880\n",
            "   macro avg       0.39      0.39      0.39       880\n",
            "weighted avg       0.38      0.39      0.38       880\n",
            "\n",
            "[[58 29 26 24 14 22]\n",
            " [31 76 11  9 12 12]\n",
            " [36 15 35 28  9 27]\n",
            " [25 23 27 37  9 17]\n",
            " [ 8 17 13 11 59 20]\n",
            " [18  2 19 17 10 74]]\n",
            "Accuracy: 0.38522727272727275\n",
            "Total f1 over classes: 2.3114001076538897\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.02      0.03       173\n",
            "           1       0.38      0.19      0.25       151\n",
            "           2       0.33      0.06      0.10       150\n",
            "           3       0.50      0.03      0.05       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.12      0.01      0.01       140\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.27      0.20      0.12       880\n",
            "weighted avg       0.27      0.18      0.12       880\n",
            "\n",
            "[[  3  15   0   1 151   3]\n",
            " [  8  28   1   0 114   0]\n",
            " [  2   8   9   2 126   3]\n",
            " [  3   7  10   4 113   1]\n",
            " [  1   9   1   1 116   0]\n",
            " [  4   6   6   0 123   1]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.7172912895337177\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.05      0.09       173\n",
            "           1       0.39      0.62      0.48       152\n",
            "           2       0.18      0.08      0.11       149\n",
            "           3       0.28      0.31      0.29       139\n",
            "           4       0.29      0.54      0.38       128\n",
            "           5       0.31      0.35      0.33       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.31      0.33      0.28       880\n",
            "weighted avg       0.31      0.31      0.27       880\n",
            "\n",
            "[[ 9 42  9 28 54 31]\n",
            " [ 2 95  7 15 24  9]\n",
            " [ 3 31 12 35 40 28]\n",
            " [ 2 31 18 43 21 24]\n",
            " [ 5 22  6 13 69 13]\n",
            " [ 2 23 15 20 31 48]]\n",
            "Accuracy: 0.31363636363636366\n",
            "Total f1 over classes: 1.681050105617537\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.17      0.22       173\n",
            "           1       0.39      0.57      0.47       152\n",
            "           2       0.21      0.09      0.13       149\n",
            "           3       0.33      0.23      0.27       139\n",
            "           4       0.28      0.52      0.36       128\n",
            "           5       0.29      0.31      0.30       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.30      0.32      0.29       880\n",
            "weighted avg       0.30      0.31      0.29       880\n",
            "\n",
            "[[30 35  7 14 63 24]\n",
            " [13 87  9  8 23 12]\n",
            " [21 23 14 23 40 28]\n",
            " [18 24 20 32 19 26]\n",
            " [ 9 23  1 13 67 15]\n",
            " [15 30 15  7 29 43]]\n",
            "Accuracy: 0.31022727272727274\n",
            "Total f1 over classes: 1.7445086033501562\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.60      0.34       173\n",
            "           1       0.34      0.61      0.43       152\n",
            "           2       0.24      0.05      0.08       149\n",
            "           3       0.43      0.22      0.29       139\n",
            "           4       0.44      0.11      0.17       128\n",
            "           5       0.40      0.12      0.19       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.35      0.28      0.25       880\n",
            "weighted avg       0.34      0.30      0.26       880\n",
            "\n",
            "[[104  52   4   2   3   8]\n",
            " [ 46  92   5   3   4   2]\n",
            " [ 83  38   7  14   3   4]\n",
            " [ 56  31  10  30   7   5]\n",
            " [ 72  23   3  10  14   6]\n",
            " [ 75  36   0  10   1  17]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.5054643058304507\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.26      0.26       173\n",
            "           1       0.41      0.47      0.44       152\n",
            "           2       0.24      0.19      0.22       149\n",
            "           3       0.32      0.30      0.31       139\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.40      0.42      0.41       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.35      0.35      0.35       880\n",
            "weighted avg       0.34      0.35      0.34       880\n",
            "\n",
            "[[45 38 26 21 16 27]\n",
            " [24 72 16 15 12 13]\n",
            " [38 25 29 28 10 19]\n",
            " [24 17 27 42 14 15]\n",
            " [19 12  6 16 60 15]\n",
            " [24 13 15 10 18 59]]\n",
            "Accuracy: 0.3488636363636364\n",
            "Total f1 over classes: 2.0997030787736715\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.02      0.03       173\n",
            "           1       0.50      0.19      0.28       152\n",
            "           2       0.24      0.03      0.05       149\n",
            "           3       0.38      0.04      0.07       139\n",
            "           4       0.16      0.98      0.28       128\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.19       880\n",
            "   macro avg       0.25      0.21      0.12       880\n",
            "weighted avg       0.25      0.19      0.11       880\n",
            "\n",
            "[[  3   4   1   0 165   0]\n",
            " [  0  29   4   0 119   0]\n",
            " [  4  12   4   7 122   0]\n",
            " [  0   8   7   5 119   0]\n",
            " [  1   2   0   0 125   0]\n",
            " [  6   3   1   1 128   0]]\n",
            "Accuracy: 0.18863636363636363\n",
            "Total f1 over classes: 0.6981964723018249\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.16      0.21       172\n",
            "           1       0.43      0.36      0.39       152\n",
            "           2       0.32      0.17      0.23       149\n",
            "           3       0.23      0.22      0.22       139\n",
            "           4       0.35      0.53      0.42       129\n",
            "           5       0.31      0.55      0.40       139\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.31       880\n",
            "weighted avg       0.32      0.32      0.31       880\n",
            "\n",
            "[[28 25 15 30 27 47]\n",
            " [28 54  5 21 17 27]\n",
            " [ 8 16 26 28 34 37]\n",
            " [12 14 23 30 28 32]\n",
            " [ 8 11  3  9 68 30]\n",
            " [12  6 10 12 22 77]]\n",
            "Accuracy: 0.3215909090909091\n",
            "Total f1 over classes: 1.8599494126811547\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.17      0.22       172\n",
            "           1       0.41      0.54      0.46       152\n",
            "           2       0.35      0.15      0.21       149\n",
            "           3       0.30      0.20      0.24       139\n",
            "           4       0.30      0.57      0.39       129\n",
            "           5       0.34      0.46      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.32       880\n",
            "weighted avg       0.34      0.34      0.32       880\n",
            "\n",
            "[[29 42  9 21 35 36]\n",
            " [17 82  2 13 21 17]\n",
            " [10 20 22 19 47 31]\n",
            " [12 21 17 28 40 21]\n",
            " [ 8 18  4  7 74 18]\n",
            " [10 19  8  6 32 64]]\n",
            "Accuracy: 0.3397727272727273\n",
            "Total f1 over classes: 1.9211296193794758\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.51      0.35       172\n",
            "           1       0.38      0.23      0.29       152\n",
            "           2       0.20      0.17      0.19       149\n",
            "           3       0.34      0.27      0.30       139\n",
            "           4       0.67      0.22      0.33       129\n",
            "           5       0.39      0.50      0.43       139\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.37      0.32      0.31       880\n",
            "weighted avg       0.36      0.32      0.31       880\n",
            "\n",
            "[[88 19 21 17  0 27]\n",
            " [70 35 17 14  2 14]\n",
            " [57 12 26 27  4 23]\n",
            " [43  7 25 37  5 22]\n",
            " [31 17 22  7 28 24]\n",
            " [38  1 21  7  3 69]]\n",
            "Accuracy: 0.3215909090909091\n",
            "Total f1 over classes: 1.8856593762680565\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.28      0.27       172\n",
            "           1       0.40      0.49      0.44       152\n",
            "           2       0.29      0.21      0.25       149\n",
            "           3       0.26      0.22      0.24       139\n",
            "           4       0.47      0.43      0.45       129\n",
            "           5       0.47      0.53      0.50       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.36      0.36       880\n",
            "weighted avg       0.35      0.36      0.35       880\n",
            "\n",
            "[[48 40 30 24  8 22]\n",
            " [30 75 10 13 15  9]\n",
            " [37 20 32 27 17 16]\n",
            " [33 23 19 31 15 18]\n",
            " [15 24  8  9 56 17]\n",
            " [26  7 10 14  9 73]]\n",
            "Accuracy: 0.35795454545454547\n",
            "Total f1 over classes: 2.1415156637201265\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       172\n",
            "           1       0.42      0.25      0.31       152\n",
            "           2       0.29      0.03      0.05       149\n",
            "           3       0.33      0.03      0.05       139\n",
            "           4       0.15      0.89      0.26       129\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.20      0.20      0.11       880\n",
            "weighted avg       0.20      0.18      0.11       880\n",
            "\n",
            "[[  0  15   1   1 154   1]\n",
            " [  1  38   3   1 107   2]\n",
            " [  1  15   4   5 123   1]\n",
            " [  0   7   4   4 122   2]\n",
            " [  1  11   1   1 115   0]\n",
            " [  0   4   1   0 134   0]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.6762904693035308\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.13      0.19       173\n",
            "           1       0.37      0.70      0.48       152\n",
            "           2       0.52      0.11      0.18       149\n",
            "           3       0.32      0.30      0.31       138\n",
            "           4       0.40      0.57      0.47       128\n",
            "           5       0.35      0.43      0.38       140\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.38      0.37      0.33       880\n",
            "weighted avg       0.37      0.36      0.33       880\n",
            "\n",
            "[[ 23  60   3  27  25  35]\n",
            " [ 10 106   1   7  17  11]\n",
            " [ 13  30  16  32  27  31]\n",
            " [ 16  32   6  41  22  21]\n",
            " [  3  30   0   8  73  14]\n",
            " [ 10  32   5  13  20  60]]\n",
            "Accuracy: 0.3625\n",
            "Total f1 over classes: 2.0037344370511256\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.13      0.17       173\n",
            "           1       0.42      0.55      0.47       152\n",
            "           2       0.33      0.17      0.23       149\n",
            "           3       0.33      0.26      0.29       138\n",
            "           4       0.31      0.58      0.41       128\n",
            "           5       0.31      0.38      0.34       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.31       880\n",
            "\n",
            "[[22 45 19 18 39 30]\n",
            " [19 83  2  9 20 19]\n",
            " [ 7 22 26 28 37 29]\n",
            " [14 14 18 36 33 23]\n",
            " [ 6 19  2  9 74 18]\n",
            " [16 16 12  9 34 53]]\n",
            "Accuracy: 0.3340909090909091\n",
            "Total f1 over classes: 1.9089318915608897\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.17      0.20       173\n",
            "           1       0.51      0.28      0.36       152\n",
            "           2       0.00      0.00      0.00       149\n",
            "           3       0.33      0.20      0.25       138\n",
            "           4       0.26      0.66      0.38       128\n",
            "           5       0.28      0.52      0.36       140\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.27      0.30      0.26       880\n",
            "weighted avg       0.27      0.29      0.25       880\n",
            "\n",
            "[[30 16  2  9 58 58]\n",
            " [36 42  1  8 38 27]\n",
            " [23  9  0 27 49 41]\n",
            " [17  4  2 27 51 37]\n",
            " [ 5  8  1  5 84 25]\n",
            " [18  3  0  6 40 73]]\n",
            "Accuracy: 0.2909090909090909\n",
            "Total f1 over classes: 1.5421941766787435\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.27      0.27       173\n",
            "           1       0.46      0.58      0.51       152\n",
            "           2       0.28      0.17      0.22       149\n",
            "           3       0.26      0.25      0.26       138\n",
            "           4       0.50      0.49      0.49       128\n",
            "           5       0.45      0.54      0.49       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[46 37 22 25  9 34]\n",
            " [27 88 12 11  6  8]\n",
            " [29 26 26 38 13 17]\n",
            " [30 13 22 35 19 19]\n",
            " [14 17  7 12 63 15]\n",
            " [23 10  3 12 17 75]]\n",
            "Accuracy: 0.3784090909090909\n",
            "Total f1 over classes: 2.237326233433326\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.03      0.06       173\n",
            "           1       0.41      0.20      0.27       152\n",
            "           2       0.52      0.10      0.17       149\n",
            "           3       0.50      0.07      0.12       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.38      0.02      0.04       140\n",
            "\n",
            "    accuracy                           0.20       880\n",
            "   macro avg       0.38      0.22      0.15       880\n",
            "weighted avg       0.38      0.20      0.15       880\n",
            "\n",
            "[[  6  12   3   0 149   3]\n",
            " [  4  30   3   1 113   1]\n",
            " [  1  11  15   8 114   0]\n",
            " [  2   7   2   9 117   1]\n",
            " [  2   8   2   0 116   0]\n",
            " [  4   6   4   0 123   3]]\n",
            "Accuracy: 0.2034090909090909\n",
            "Total f1 over classes: 0.9222186492920346\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.16      0.21       149\n",
            "           1       0.31      0.57      0.40       154\n",
            "           2       0.27      0.08      0.12       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.34      0.47      0.39       138\n",
            "           5       0.25      0.30      0.27       140\n",
            "\n",
            "    accuracy                           0.30       881\n",
            "   macro avg       0.29      0.30      0.27       881\n",
            "weighted avg       0.29      0.30      0.27       881\n",
            "\n",
            "[[24 47  5 13 23 37]\n",
            " [13 88  0  9 26 18]\n",
            " [14 35 12 40 29 27]\n",
            " [ 9 43 13 29 21 28]\n",
            " [ 7 32  4 11 65 19]\n",
            " [ 9 38 10 13 28 42]]\n",
            "Accuracy: 0.29511918274687854\n",
            "Total f1 over classes: 1.6243243723435907\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.17      0.22       149\n",
            "           1       0.35      0.47      0.40       154\n",
            "           2       0.38      0.20      0.26       157\n",
            "           3       0.22      0.17      0.20       143\n",
            "           4       0.27      0.47      0.34       138\n",
            "           5       0.25      0.27      0.26       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.30      0.29      0.28       881\n",
            "\n",
            "[[26 34 10 16 33 30]\n",
            " [15 72  3 14 29 21]\n",
            " [18 20 31 27 42 19]\n",
            " [11 30 18 25 37 22]\n",
            " [11 22  4 16 65 20]\n",
            " [10 27 16 14 35 38]]\n",
            "Accuracy: 0.2917139614074915\n",
            "Total f1 over classes: 1.6783504111932954\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.17      0.19       149\n",
            "           1       0.41      0.26      0.32       154\n",
            "           2       0.50      0.01      0.02       157\n",
            "           3       0.35      0.19      0.25       143\n",
            "           4       0.25      0.60      0.35       138\n",
            "           5       0.26      0.47      0.33       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.33      0.28      0.24       881\n",
            "weighted avg       0.33      0.28      0.24       881\n",
            "\n",
            "[[25 17  0  1 49 57]\n",
            " [21 40  0 14 50 29]\n",
            " [28 13  2 25 48 41]\n",
            " [17 13  0 27 46 40]\n",
            " [11 13  1  7 83 23]\n",
            " [13  2  1  3 55 66]]\n",
            "Accuracy: 0.2758229284903519\n",
            "Total f1 over classes: 1.4644314190388168\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.32      0.29       149\n",
            "           1       0.37      0.39      0.38       154\n",
            "           2       0.32      0.25      0.28       157\n",
            "           3       0.27      0.23      0.25       143\n",
            "           4       0.48      0.45      0.46       138\n",
            "           5       0.35      0.41      0.38       140\n",
            "\n",
            "    accuracy                           0.34       881\n",
            "   macro avg       0.34      0.34      0.34       881\n",
            "weighted avg       0.34      0.34      0.34       881\n",
            "\n",
            "[[47 30 18 14  8 32]\n",
            " [28 60 14 17 12 23]\n",
            " [35 20 39 30 14 19]\n",
            " [31 25 21 33 16 17]\n",
            " [15 15 13 17 62 16]\n",
            " [23 14 17 12 17 57]]\n",
            "Accuracy: 0.33825198637911463\n",
            "Total f1 over classes: 2.031053525300125\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.01      0.01       149\n",
            "           1       0.34      0.20      0.25       154\n",
            "           2       0.19      0.03      0.04       157\n",
            "           3       0.29      0.03      0.05       143\n",
            "           4       0.17      0.89      0.28       138\n",
            "           5       0.00      0.00      0.00       140\n",
            "\n",
            "    accuracy                           0.19       881\n",
            "   macro avg       0.18      0.19      0.11       881\n",
            "weighted avg       0.19      0.19      0.11       881\n",
            "\n",
            "[[  1  10   0   0 137   1]\n",
            " [  2  31   2   1 118   0]\n",
            " [  3  14   4   9 126   1]\n",
            " [  2  12   9   4 115   1]\n",
            " [  0  12   3   0 123   0]\n",
            " [  1  11   3   0 125   0]]\n",
            "Accuracy: 0.18501702610669693\n",
            "Total f1 over classes: 0.6415673873671472\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.16      0.21       173\n",
            "           1       0.38      0.47      0.42       151\n",
            "           2       0.23      0.13      0.17       150\n",
            "           3       0.23      0.33      0.27       138\n",
            "           4       0.30      0.47      0.36       128\n",
            "           5       0.28      0.21      0.24       140\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.29      0.30      0.28       880\n",
            "weighted avg       0.29      0.29      0.28       880\n",
            "\n",
            "[[28 32 12 44 37 20]\n",
            " [15 71 10 12 27 16]\n",
            " [20 13 20 48 29 20]\n",
            " [13 25 20 46 22 12]\n",
            " [ 5 18 14 22 60  9]\n",
            " [10 30 10 32 28 30]]\n",
            "Accuracy: 0.2897727272727273\n",
            "Total f1 over classes: 1.6737183884292248\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.19      0.25       173\n",
            "           1       0.39      0.50      0.44       151\n",
            "           2       0.29      0.13      0.18       150\n",
            "           3       0.31      0.20      0.24       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.29      0.41      0.34       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.30       880\n",
            "weighted avg       0.32      0.32      0.30       880\n",
            "\n",
            "[[33 38 14 14 42 32]\n",
            " [10 76  3  4 30 28]\n",
            " [20 18 20 17 37 38]\n",
            " [13 27 19 27 28 24]\n",
            " [ 6 17  7 11 67 20]\n",
            " [ 8 19  7 15 34 57]]\n",
            "Accuracy: 0.3181818181818182\n",
            "Total f1 over classes: 1.813416568059178\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.56      0.36       173\n",
            "           1       0.48      0.21      0.29       151\n",
            "           2       0.20      0.17      0.19       150\n",
            "           3       0.38      0.24      0.29       138\n",
            "           4       0.55      0.09      0.15       128\n",
            "           5       0.32      0.51      0.40       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.37      0.30      0.28       880\n",
            "weighted avg       0.36      0.31      0.28       880\n",
            "\n",
            "[[97 11 25  9  0 31]\n",
            " [74 31 16  5  3 22]\n",
            " [57  6 26 21  2 38]\n",
            " [50  9 19 33  3 24]\n",
            " [46  7 22  7 11 35]\n",
            " [37  0 19 11  1 72]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.6804751659821464\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.31      0.30       173\n",
            "           1       0.45      0.47      0.46       151\n",
            "           2       0.25      0.21      0.23       150\n",
            "           3       0.30      0.26      0.28       138\n",
            "           4       0.50      0.48      0.49       128\n",
            "           5       0.42      0.51      0.46       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.37       880\n",
            "\n",
            "[[53 25 30 23 15 27]\n",
            " [35 71 13  9 12 11]\n",
            " [38 22 32 23  8 27]\n",
            " [23 21 25 36 14 19]\n",
            " [11 16 11 13 61 16]\n",
            " [20  3 17 17 11 72]]\n",
            "Accuracy: 0.3693181818181818\n",
            "Total f1 over classes: 2.219536617911622\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.02      0.03       173\n",
            "           1       0.38      0.19      0.25       151\n",
            "           2       0.33      0.06      0.10       150\n",
            "           3       0.50      0.03      0.05       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.12      0.01      0.01       140\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.27      0.20      0.12       880\n",
            "weighted avg       0.27      0.18      0.12       880\n",
            "\n",
            "[[  3  15   0   1 151   3]\n",
            " [  8  28   1   0 114   0]\n",
            " [  2   8   9   2 126   3]\n",
            " [  3   7  10   4 113   1]\n",
            " [  1   9   1   1 116   0]\n",
            " [  4   6   6   0 123   1]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.7172912895337177\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.15      0.20       173\n",
            "           1       0.38      0.60      0.47       152\n",
            "           2       0.24      0.13      0.17       149\n",
            "           3       0.30      0.24      0.27       139\n",
            "           4       0.35      0.49      0.41       128\n",
            "           5       0.34      0.45      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.32      0.34      0.32       880\n",
            "weighted avg       0.32      0.34      0.31       880\n",
            "\n",
            "[[26 40 12 26 34 35]\n",
            " [13 91  9  8 16 15]\n",
            " [16 31 19 23 32 28]\n",
            " [14 29 23 34 12 27]\n",
            " [ 6 25  6 14 63 14]\n",
            " [10 23 10  9 25 62]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.896416516504155\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.17      0.22       173\n",
            "           1       0.39      0.57      0.47       152\n",
            "           2       0.21      0.09      0.13       149\n",
            "           3       0.33      0.23      0.27       139\n",
            "           4       0.28      0.52      0.36       128\n",
            "           5       0.29      0.31      0.30       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.30      0.32      0.29       880\n",
            "weighted avg       0.30      0.31      0.29       880\n",
            "\n",
            "[[30 35  7 14 63 24]\n",
            " [13 87  9  8 23 12]\n",
            " [21 23 14 23 40 28]\n",
            " [18 24 20 32 19 26]\n",
            " [ 9 23  1 13 67 15]\n",
            " [15 30 15  7 29 43]]\n",
            "Accuracy: 0.31022727272727274\n",
            "Total f1 over classes: 1.7445086033501562\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.60      0.34       173\n",
            "           1       0.34      0.61      0.43       152\n",
            "           2       0.24      0.05      0.08       149\n",
            "           3       0.43      0.22      0.29       139\n",
            "           4       0.44      0.11      0.17       128\n",
            "           5       0.40      0.12      0.19       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.35      0.28      0.25       880\n",
            "weighted avg       0.34      0.30      0.26       880\n",
            "\n",
            "[[104  52   4   2   3   8]\n",
            " [ 46  92   5   3   4   2]\n",
            " [ 83  38   7  14   3   4]\n",
            " [ 56  31  10  30   7   5]\n",
            " [ 72  23   3  10  14   6]\n",
            " [ 75  36   0  10   1  17]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.5054643058304507\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.30      0.29       173\n",
            "           1       0.43      0.47      0.45       152\n",
            "           2       0.25      0.20      0.22       149\n",
            "           3       0.31      0.29      0.30       139\n",
            "           4       0.47      0.47      0.47       128\n",
            "           5       0.42      0.46      0.44       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.36      0.36       880\n",
            "\n",
            "[[52 35 21 21 18 26]\n",
            " [24 72 16 14 11 15]\n",
            " [36 24 30 30 10 19]\n",
            " [25 17 26 41 15 15]\n",
            " [15 10 12 17 60 14]\n",
            " [28  8 15 11 13 64]]\n",
            "Accuracy: 0.3625\n",
            "Total f1 over classes: 2.179806779600148\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.02      0.03       173\n",
            "           1       0.50      0.19      0.28       152\n",
            "           2       0.24      0.03      0.05       149\n",
            "           3       0.38      0.04      0.07       139\n",
            "           4       0.16      0.98      0.28       128\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.19       880\n",
            "   macro avg       0.25      0.21      0.12       880\n",
            "weighted avg       0.25      0.19      0.11       880\n",
            "\n",
            "[[  3   4   1   0 165   0]\n",
            " [  0  29   4   0 119   0]\n",
            " [  4  12   4   7 122   0]\n",
            " [  0   8   7   5 119   0]\n",
            " [  1   2   0   0 125   0]\n",
            " [  6   3   1   1 128   0]]\n",
            "Accuracy: 0.18863636363636363\n",
            "Total f1 over classes: 0.6981964723018249\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.12      0.17       172\n",
            "           1       0.43      0.41      0.42       152\n",
            "           2       0.39      0.11      0.17       149\n",
            "           3       0.41      0.13      0.20       139\n",
            "           4       0.36      0.57      0.44       129\n",
            "           5       0.27      0.73      0.39       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.36      0.34      0.30       880\n",
            "weighted avg       0.36      0.33      0.29       880\n",
            "\n",
            "[[ 20  33   8   6  23  82]\n",
            " [  6  63   1   4  20  58]\n",
            " [ 16  16  16  12  38  51]\n",
            " [  9  18  12  18  34  48]\n",
            " [  6  11   1   4  74  33]\n",
            " [  9   7   3   0  19 101]]\n",
            "Accuracy: 0.33181818181818185\n",
            "Total f1 over classes: 1.7869099804636206\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.17      0.22       172\n",
            "           1       0.41      0.54      0.46       152\n",
            "           2       0.35      0.15      0.21       149\n",
            "           3       0.30      0.20      0.24       139\n",
            "           4       0.30      0.57      0.39       129\n",
            "           5       0.34      0.46      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.32       880\n",
            "weighted avg       0.34      0.34      0.32       880\n",
            "\n",
            "[[29 42  9 21 35 36]\n",
            " [17 82  2 13 21 17]\n",
            " [10 20 22 19 47 31]\n",
            " [12 21 17 28 40 21]\n",
            " [ 8 18  4  7 74 18]\n",
            " [10 19  8  6 32 64]]\n",
            "Accuracy: 0.3397727272727273\n",
            "Total f1 over classes: 1.9211296193794758\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.51      0.35       172\n",
            "           1       0.38      0.23      0.29       152\n",
            "           2       0.20      0.17      0.19       149\n",
            "           3       0.34      0.27      0.30       139\n",
            "           4       0.67      0.22      0.33       129\n",
            "           5       0.39      0.50      0.43       139\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.37      0.32      0.31       880\n",
            "weighted avg       0.36      0.32      0.31       880\n",
            "\n",
            "[[88 19 21 17  0 27]\n",
            " [70 35 17 14  2 14]\n",
            " [57 12 26 27  4 23]\n",
            " [43  7 25 37  5 22]\n",
            " [31 17 22  7 28 24]\n",
            " [38  1 21  7  3 69]]\n",
            "Accuracy: 0.3215909090909091\n",
            "Total f1 over classes: 1.8856593762680565\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.28      0.27       172\n",
            "           1       0.39      0.47      0.43       152\n",
            "           2       0.27      0.20      0.23       149\n",
            "           3       0.27      0.22      0.25       139\n",
            "           4       0.45      0.44      0.45       129\n",
            "           5       0.47      0.53      0.50       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.35      0.36      0.35       880\n",
            "weighted avg       0.35      0.35      0.35       880\n",
            "\n",
            "[[48 41 32 22  6 23]\n",
            " [30 72 12 12 16 10]\n",
            " [33 20 30 28 20 18]\n",
            " [30 24 19 31 18 17]\n",
            " [20 21  8  7 57 16]\n",
            " [25  7 10 14  9 74]]\n",
            "Accuracy: 0.35454545454545455\n",
            "Total f1 over classes: 2.1166599689977907\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       172\n",
            "           1       0.42      0.25      0.31       152\n",
            "           2       0.29      0.03      0.05       149\n",
            "           3       0.33      0.03      0.05       139\n",
            "           4       0.15      0.89      0.26       129\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.20      0.20      0.11       880\n",
            "weighted avg       0.20      0.18      0.11       880\n",
            "\n",
            "[[  0  15   1   1 154   1]\n",
            " [  1  38   3   1 107   2]\n",
            " [  1  15   4   5 123   1]\n",
            " [  0   7   4   4 122   2]\n",
            " [  1  11   1   1 115   0]\n",
            " [  0   4   1   0 134   0]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.6762904693035308\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.45      0.37       173\n",
            "           1       0.49      0.44      0.47       152\n",
            "           2       0.42      0.15      0.22       149\n",
            "           3       0.37      0.27      0.31       138\n",
            "           4       0.46      0.54      0.50       128\n",
            "           5       0.33      0.46      0.39       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.40      0.38      0.37       880\n",
            "weighted avg       0.40      0.38      0.37       880\n",
            "\n",
            "[[77 22  5 15 15 39]\n",
            " [35 67  5  6 16 23]\n",
            " [41 14 22 26 16 30]\n",
            " [45  9 13 37 13 21]\n",
            " [14 17  0  9 69 19]\n",
            " [34  7  7  7 20 65]]\n",
            "Accuracy: 0.38295454545454544\n",
            "Total f1 over classes: 2.246601008678517\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.13      0.17       173\n",
            "           1       0.42      0.55      0.47       152\n",
            "           2       0.33      0.17      0.23       149\n",
            "           3       0.33      0.26      0.29       138\n",
            "           4       0.31      0.58      0.41       128\n",
            "           5       0.31      0.38      0.34       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.31       880\n",
            "\n",
            "[[22 45 19 18 39 30]\n",
            " [19 83  2  9 20 19]\n",
            " [ 7 22 26 28 37 29]\n",
            " [14 14 18 36 33 23]\n",
            " [ 6 19  2  9 74 18]\n",
            " [16 16 12  9 34 53]]\n",
            "Accuracy: 0.3340909090909091\n",
            "Total f1 over classes: 1.9089318915608897\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.17      0.20       173\n",
            "           1       0.51      0.28      0.36       152\n",
            "           2       0.00      0.00      0.00       149\n",
            "           3       0.33      0.20      0.25       138\n",
            "           4       0.26      0.66      0.38       128\n",
            "           5       0.28      0.52      0.36       140\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.27      0.30      0.26       880\n",
            "weighted avg       0.27      0.29      0.25       880\n",
            "\n",
            "[[30 16  2  9 58 58]\n",
            " [36 42  1  8 38 27]\n",
            " [23  9  0 27 49 41]\n",
            " [17  4  2 27 51 37]\n",
            " [ 5  8  1  5 84 25]\n",
            " [18  3  0  6 40 73]]\n",
            "Accuracy: 0.2909090909090909\n",
            "Total f1 over classes: 1.5421941766787435\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.28      0.28       173\n",
            "           1       0.47      0.55      0.50       152\n",
            "           2       0.31      0.19      0.23       149\n",
            "           3       0.28      0.27      0.27       138\n",
            "           4       0.47      0.48      0.47       128\n",
            "           5       0.43      0.54      0.48       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[49 35 25 24 11 29]\n",
            " [25 83 14 11 10  9]\n",
            " [26 24 28 37  8 26]\n",
            " [33 12 17 37 20 19]\n",
            " [17 14  4 15 61 17]\n",
            " [25  9  3  9 19 75]]\n",
            "Accuracy: 0.3784090909090909\n",
            "Total f1 over classes: 2.243463177276358\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.03      0.06       173\n",
            "           1       0.41      0.20      0.27       152\n",
            "           2       0.52      0.10      0.17       149\n",
            "           3       0.50      0.07      0.12       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.38      0.02      0.04       140\n",
            "\n",
            "    accuracy                           0.20       880\n",
            "   macro avg       0.38      0.22      0.15       880\n",
            "weighted avg       0.38      0.20      0.15       880\n",
            "\n",
            "[[  6  12   3   0 149   3]\n",
            " [  4  30   3   1 113   1]\n",
            " [  1  11  15   8 114   0]\n",
            " [  2   7   2   9 117   1]\n",
            " [  2   8   2   0 116   0]\n",
            " [  4   6   4   0 123   3]]\n",
            "Accuracy: 0.2034090909090909\n",
            "Total f1 over classes: 0.9222186492920346\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.44      0.33       149\n",
            "           1       0.41      0.31      0.35       154\n",
            "           2       0.38      0.11      0.18       157\n",
            "           3       0.32      0.22      0.26       143\n",
            "           4       0.41      0.49      0.44       138\n",
            "           5       0.28      0.40      0.33       140\n",
            "\n",
            "    accuracy                           0.32       881\n",
            "   macro avg       0.34      0.33      0.31       881\n",
            "weighted avg       0.34      0.32      0.31       881\n",
            "\n",
            "[[66 11  4 10 13 45]\n",
            " [44 47  3  9 28 23]\n",
            " [55 13 18 27 21 23]\n",
            " [32 22 13 32 12 32]\n",
            " [17 15  6 13 67 20]\n",
            " [40  7  4  9 24 56]]\n",
            "Accuracy: 0.3246311010215664\n",
            "Total f1 over classes: 1.8885977504424438\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.17      0.22       149\n",
            "           1       0.35      0.47      0.40       154\n",
            "           2       0.38      0.20      0.26       157\n",
            "           3       0.22      0.17      0.20       143\n",
            "           4       0.27      0.47      0.34       138\n",
            "           5       0.25      0.27      0.26       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.30      0.29      0.28       881\n",
            "\n",
            "[[26 34 10 16 33 30]\n",
            " [15 72  3 14 29 21]\n",
            " [18 20 31 27 42 19]\n",
            " [11 30 18 25 37 22]\n",
            " [11 22  4 16 65 20]\n",
            " [10 27 16 14 35 38]]\n",
            "Accuracy: 0.2917139614074915\n",
            "Total f1 over classes: 1.6783504111932954\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.17      0.19       149\n",
            "           1       0.41      0.26      0.32       154\n",
            "           2       0.50      0.01      0.02       157\n",
            "           3       0.35      0.19      0.25       143\n",
            "           4       0.25      0.60      0.35       138\n",
            "           5       0.26      0.47      0.33       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.33      0.28      0.24       881\n",
            "weighted avg       0.33      0.28      0.24       881\n",
            "\n",
            "[[25 17  0  1 49 57]\n",
            " [21 40  0 14 50 29]\n",
            " [28 13  2 25 48 41]\n",
            " [17 13  0 27 46 40]\n",
            " [11 13  1  7 83 23]\n",
            " [13  2  1  3 55 66]]\n",
            "Accuracy: 0.2758229284903519\n",
            "Total f1 over classes: 1.4644314190388168\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.27      0.25       149\n",
            "           1       0.36      0.40      0.38       154\n",
            "           2       0.31      0.24      0.27       157\n",
            "           3       0.22      0.20      0.21       143\n",
            "           4       0.48      0.43      0.45       138\n",
            "           5       0.36      0.42      0.39       140\n",
            "\n",
            "    accuracy                           0.32       881\n",
            "   macro avg       0.33      0.33      0.32       881\n",
            "weighted avg       0.32      0.32      0.32       881\n",
            "\n",
            "[[40 30 15 22 12 30]\n",
            " [30 61 14 17 12 20]\n",
            " [32 23 37 33 13 19]\n",
            " [28 26 27 28 17 17]\n",
            " [13 17 11 18 60 19]\n",
            " [27 14 16 12 12 59]]\n",
            "Accuracy: 0.32349602724177073\n",
            "Total f1 over classes: 1.9411478832951112\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.01      0.01       149\n",
            "           1       0.34      0.20      0.25       154\n",
            "           2       0.19      0.03      0.04       157\n",
            "           3       0.29      0.03      0.05       143\n",
            "           4       0.17      0.89      0.28       138\n",
            "           5       0.00      0.00      0.00       140\n",
            "\n",
            "    accuracy                           0.19       881\n",
            "   macro avg       0.18      0.19      0.11       881\n",
            "weighted avg       0.19      0.19      0.11       881\n",
            "\n",
            "[[  1  10   0   0 137   1]\n",
            " [  2  31   2   1 118   0]\n",
            " [  3  14   4   9 126   1]\n",
            " [  2  12   9   4 115   1]\n",
            " [  0  12   3   0 123   0]\n",
            " [  1  11   3   0 125   0]]\n",
            "Accuracy: 0.18501702610669693\n",
            "Total f1 over classes: 0.6415673873671472\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.33      0.34       173\n",
            "           1       0.34      0.60      0.43       151\n",
            "           2       0.18      0.05      0.07       150\n",
            "           3       0.25      0.26      0.26       138\n",
            "           4       0.47      0.43      0.45       128\n",
            "           5       0.29      0.31      0.30       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.31      0.33      0.31       880\n",
            "weighted avg       0.31      0.33      0.31       880\n",
            "\n",
            "[[57 51  5 26 12 22]\n",
            " [21 91  3  7 10 19]\n",
            " [35 23  7 41 12 32]\n",
            " [18 42 11 36 12 19]\n",
            " [12 27  6 14 55 14]\n",
            " [21 34  6 19 17 43]]\n",
            "Accuracy: 0.32840909090909093\n",
            "Total f1 over classes: 1.8480746428463477\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.19      0.25       173\n",
            "           1       0.39      0.50      0.44       151\n",
            "           2       0.29      0.13      0.18       150\n",
            "           3       0.31      0.20      0.24       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.29      0.41      0.34       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.30       880\n",
            "weighted avg       0.32      0.32      0.30       880\n",
            "\n",
            "[[33 38 14 14 42 32]\n",
            " [10 76  3  4 30 28]\n",
            " [20 18 20 17 37 38]\n",
            " [13 27 19 27 28 24]\n",
            " [ 6 17  7 11 67 20]\n",
            " [ 8 19  7 15 34 57]]\n",
            "Accuracy: 0.3181818181818182\n",
            "Total f1 over classes: 1.813416568059178\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.56      0.36       173\n",
            "           1       0.48      0.21      0.29       151\n",
            "           2       0.20      0.17      0.19       150\n",
            "           3       0.38      0.24      0.29       138\n",
            "           4       0.55      0.09      0.15       128\n",
            "           5       0.32      0.51      0.40       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.37      0.30      0.28       880\n",
            "weighted avg       0.36      0.31      0.28       880\n",
            "\n",
            "[[97 11 25  9  0 31]\n",
            " [74 31 16  5  3 22]\n",
            " [57  6 26 21  2 38]\n",
            " [50  9 19 33  3 24]\n",
            " [46  7 22  7 11 35]\n",
            " [37  0 19 11  1 72]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.6804751659821464\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.32      0.31       173\n",
            "           1       0.44      0.44      0.44       151\n",
            "           2       0.25      0.19      0.22       150\n",
            "           3       0.29      0.28      0.29       138\n",
            "           4       0.49      0.48      0.48       128\n",
            "           5       0.40      0.49      0.44       140\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.36      0.36       880\n",
            "\n",
            "[[55 28 23 25 16 26]\n",
            " [38 67 12 10 11 13]\n",
            " [33 21 29 28 10 29]\n",
            " [24 19 22 39 14 20]\n",
            " [11 17 12 12 61 15]\n",
            " [18  2 19 20 13 68]]\n",
            "Accuracy: 0.3625\n",
            "Total f1 over classes: 2.1753499067018636\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.02      0.03       173\n",
            "           1       0.38      0.19      0.25       151\n",
            "           2       0.33      0.06      0.10       150\n",
            "           3       0.50      0.03      0.05       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.12      0.01      0.01       140\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.27      0.20      0.12       880\n",
            "weighted avg       0.27      0.18      0.12       880\n",
            "\n",
            "[[  3  15   0   1 151   3]\n",
            " [  8  28   1   0 114   0]\n",
            " [  2   8   9   2 126   3]\n",
            " [  3   7  10   4 113   1]\n",
            " [  1   9   1   1 116   0]\n",
            " [  4   6   6   0 123   1]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.7172912895337177\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.38      0.34       173\n",
            "           1       0.41      0.61      0.49       152\n",
            "           2       0.26      0.12      0.17       149\n",
            "           3       0.28      0.21      0.24       139\n",
            "           4       0.41      0.47      0.43       128\n",
            "           5       0.38      0.32      0.35       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.34      0.35      0.34       880\n",
            "weighted avg       0.34      0.35      0.33       880\n",
            "\n",
            "[[65 35  7 27 20 19]\n",
            " [32 92  5  8  9  6]\n",
            " [37 31 18 17 29 17]\n",
            " [28 29 26 29  6 21]\n",
            " [19 24  4 12 60  9]\n",
            " [34 16  9 11 24 45]]\n",
            "Accuracy: 0.35113636363636364\n",
            "Total f1 over classes: 2.0107055239873968\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.17      0.22       173\n",
            "           1       0.39      0.57      0.47       152\n",
            "           2       0.21      0.09      0.13       149\n",
            "           3       0.33      0.23      0.27       139\n",
            "           4       0.28      0.52      0.36       128\n",
            "           5       0.29      0.31      0.30       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.30      0.32      0.29       880\n",
            "weighted avg       0.30      0.31      0.29       880\n",
            "\n",
            "[[30 35  7 14 63 24]\n",
            " [13 87  9  8 23 12]\n",
            " [21 23 14 23 40 28]\n",
            " [18 24 20 32 19 26]\n",
            " [ 9 23  1 13 67 15]\n",
            " [15 30 15  7 29 43]]\n",
            "Accuracy: 0.31022727272727274\n",
            "Total f1 over classes: 1.7445086033501562\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.60      0.34       173\n",
            "           1       0.34      0.61      0.43       152\n",
            "           2       0.24      0.05      0.08       149\n",
            "           3       0.43      0.22      0.29       139\n",
            "           4       0.44      0.11      0.17       128\n",
            "           5       0.40      0.12      0.19       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.35      0.28      0.25       880\n",
            "weighted avg       0.34      0.30      0.26       880\n",
            "\n",
            "[[104  52   4   2   3   8]\n",
            " [ 46  92   5   3   4   2]\n",
            " [ 83  38   7  14   3   4]\n",
            " [ 56  31  10  30   7   5]\n",
            " [ 72  23   3  10  14   6]\n",
            " [ 75  36   0  10   1  17]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.5054643058304507\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.30      0.29       173\n",
            "           1       0.39      0.45      0.42       152\n",
            "           2       0.27      0.23      0.25       149\n",
            "           3       0.30      0.28      0.29       139\n",
            "           4       0.46      0.42      0.44       128\n",
            "           5       0.43      0.46      0.44       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.36      0.36      0.36       880\n",
            "weighted avg       0.35      0.35      0.35       880\n",
            "\n",
            "[[52 41 25 21 13 21]\n",
            " [27 69 19 15 12 10]\n",
            " [34 26 34 26 10 19]\n",
            " [27 18 24 39 14 17]\n",
            " [17 11  9 19 54 18]\n",
            " [24 11 15 11 14 64]]\n",
            "Accuracy: 0.35454545454545455\n",
            "Total f1 over classes: 2.1359394051882092\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.02      0.03       173\n",
            "           1       0.50      0.19      0.28       152\n",
            "           2       0.24      0.03      0.05       149\n",
            "           3       0.38      0.04      0.07       139\n",
            "           4       0.16      0.98      0.28       128\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.19       880\n",
            "   macro avg       0.25      0.21      0.12       880\n",
            "weighted avg       0.25      0.19      0.11       880\n",
            "\n",
            "[[  3   4   1   0 165   0]\n",
            " [  0  29   4   0 119   0]\n",
            " [  4  12   4   7 122   0]\n",
            " [  0   8   7   5 119   0]\n",
            " [  1   2   0   0 125   0]\n",
            " [  6   3   1   1 128   0]]\n",
            "Accuracy: 0.18863636363636363\n",
            "Total f1 over classes: 0.6981964723018249\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.35      0.34       172\n",
            "           1       0.41      0.51      0.45       152\n",
            "           2       0.33      0.20      0.25       149\n",
            "           3       0.33      0.25      0.28       139\n",
            "           4       0.43      0.59      0.50       129\n",
            "           5       0.42      0.37      0.40       139\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[61 41 18 22 17 13]\n",
            " [31 78  6 12 17  8]\n",
            " [28 23 30 26 21 21]\n",
            " [27 19 21 35 23 14]\n",
            " [13 16  3  5 76 16]\n",
            " [31 15 12  7 22 52]]\n",
            "Accuracy: 0.37727272727272726\n",
            "Total f1 over classes: 2.218973315091173\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.17      0.22       172\n",
            "           1       0.41      0.54      0.46       152\n",
            "           2       0.35      0.15      0.21       149\n",
            "           3       0.30      0.20      0.24       139\n",
            "           4       0.30      0.57      0.39       129\n",
            "           5       0.34      0.46      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.32       880\n",
            "weighted avg       0.34      0.34      0.32       880\n",
            "\n",
            "[[29 42  9 21 35 36]\n",
            " [17 82  2 13 21 17]\n",
            " [10 20 22 19 47 31]\n",
            " [12 21 17 28 40 21]\n",
            " [ 8 18  4  7 74 18]\n",
            " [10 19  8  6 32 64]]\n",
            "Accuracy: 0.3397727272727273\n",
            "Total f1 over classes: 1.9211296193794758\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.51      0.35       172\n",
            "           1       0.38      0.23      0.29       152\n",
            "           2       0.20      0.17      0.19       149\n",
            "           3       0.34      0.27      0.30       139\n",
            "           4       0.67      0.22      0.33       129\n",
            "           5       0.39      0.50      0.43       139\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.37      0.32      0.31       880\n",
            "weighted avg       0.36      0.32      0.31       880\n",
            "\n",
            "[[88 19 21 17  0 27]\n",
            " [70 35 17 14  2 14]\n",
            " [57 12 26 27  4 23]\n",
            " [43  7 25 37  5 22]\n",
            " [31 17 22  7 28 24]\n",
            " [38  1 21  7  3 69]]\n",
            "Accuracy: 0.3215909090909091\n",
            "Total f1 over classes: 1.8856593762680565\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       172\n",
            "           1       0.40      0.50      0.44       152\n",
            "           2       0.30      0.23      0.27       149\n",
            "           3       0.27      0.24      0.25       139\n",
            "           4       0.49      0.43      0.45       129\n",
            "           5       0.46      0.50      0.48       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.36      0.36       880\n",
            "weighted avg       0.36      0.36      0.36       880\n",
            "\n",
            "[[46 38 30 27  8 23]\n",
            " [29 76 11 12 14 10]\n",
            " [31 23 35 31 16 13]\n",
            " [33 25 18 34 12 17]\n",
            " [18 20  7 10 55 19]\n",
            " [23 10 14 14  8 70]]\n",
            "Accuracy: 0.35909090909090907\n",
            "Total f1 over classes: 2.1587023754743484\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       172\n",
            "           1       0.42      0.25      0.31       152\n",
            "           2       0.29      0.03      0.05       149\n",
            "           3       0.33      0.03      0.05       139\n",
            "           4       0.15      0.89      0.26       129\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.20      0.20      0.11       880\n",
            "weighted avg       0.20      0.18      0.11       880\n",
            "\n",
            "[[  0  15   1   1 154   1]\n",
            " [  1  38   3   1 107   2]\n",
            " [  1  15   4   5 123   1]\n",
            " [  0   7   4   4 122   2]\n",
            " [  1  11   1   1 115   0]\n",
            " [  0   4   1   0 134   0]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.6762904693035308\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.21      0.26       173\n",
            "           1       0.38      0.65      0.48       152\n",
            "           2       0.30      0.05      0.08       149\n",
            "           3       0.32      0.41      0.36       138\n",
            "           4       0.48      0.49      0.49       128\n",
            "           5       0.35      0.46      0.39       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.36      0.38      0.34       880\n",
            "weighted avg       0.36      0.37      0.34       880\n",
            "\n",
            "[[36 53  4 32 12 36]\n",
            " [13 99  5 13 11 11]\n",
            " [16 29  7 50 16 31]\n",
            " [12 33  4 57 12 20]\n",
            " [ 7 25  0 10 63 23]\n",
            " [15 24  3 17 17 64]]\n",
            "Accuracy: 0.3704545454545455\n",
            "Total f1 over classes: 2.0631637563618317\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.13      0.17       173\n",
            "           1       0.42      0.55      0.47       152\n",
            "           2       0.33      0.17      0.23       149\n",
            "           3       0.33      0.26      0.29       138\n",
            "           4       0.31      0.58      0.41       128\n",
            "           5       0.31      0.38      0.34       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.31       880\n",
            "\n",
            "[[22 45 19 18 39 30]\n",
            " [19 83  2  9 20 19]\n",
            " [ 7 22 26 28 37 29]\n",
            " [14 14 18 36 33 23]\n",
            " [ 6 19  2  9 74 18]\n",
            " [16 16 12  9 34 53]]\n",
            "Accuracy: 0.3340909090909091\n",
            "Total f1 over classes: 1.9089318915608897\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.17      0.20       173\n",
            "           1       0.51      0.28      0.36       152\n",
            "           2       0.00      0.00      0.00       149\n",
            "           3       0.33      0.20      0.25       138\n",
            "           4       0.26      0.66      0.38       128\n",
            "           5       0.28      0.52      0.36       140\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.27      0.30      0.26       880\n",
            "weighted avg       0.27      0.29      0.25       880\n",
            "\n",
            "[[30 16  2  9 58 58]\n",
            " [36 42  1  8 38 27]\n",
            " [23  9  0 27 49 41]\n",
            " [17  4  2 27 51 37]\n",
            " [ 5  8  1  5 84 25]\n",
            " [18  3  0  6 40 73]]\n",
            "Accuracy: 0.2909090909090909\n",
            "Total f1 over classes: 1.5421941766787435\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.28      0.28       173\n",
            "           1       0.46      0.57      0.51       152\n",
            "           2       0.28      0.18      0.22       149\n",
            "           3       0.26      0.25      0.25       138\n",
            "           4       0.53      0.49      0.51       128\n",
            "           5       0.45      0.54      0.49       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.38      0.38      0.38       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[49 39 26 22  7 30]\n",
            " [26 86 13 12  7  8]\n",
            " [33 22 27 40  8 19]\n",
            " [32 16 21 34 17 18]\n",
            " [18 13  6 12 63 16]\n",
            " [25  9  5 10 16 75]]\n",
            "Accuracy: 0.3795454545454545\n",
            "Total f1 over classes: 2.2604126810005134\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.03      0.06       173\n",
            "           1       0.41      0.20      0.27       152\n",
            "           2       0.52      0.10      0.17       149\n",
            "           3       0.50      0.07      0.12       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.38      0.02      0.04       140\n",
            "\n",
            "    accuracy                           0.20       880\n",
            "   macro avg       0.38      0.22      0.15       880\n",
            "weighted avg       0.38      0.20      0.15       880\n",
            "\n",
            "[[  6  12   3   0 149   3]\n",
            " [  4  30   3   1 113   1]\n",
            " [  1  11  15   8 114   0]\n",
            " [  2   7   2   9 117   1]\n",
            " [  2   8   2   0 116   0]\n",
            " [  4   6   4   0 123   3]]\n",
            "Accuracy: 0.2034090909090909\n",
            "Total f1 over classes: 0.9222186492920346\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.21      0.24       149\n",
            "           1       0.35      0.53      0.42       154\n",
            "           2       0.20      0.03      0.05       157\n",
            "           3       0.24      0.31      0.27       143\n",
            "           4       0.48      0.45      0.47       138\n",
            "           5       0.30      0.41      0.35       140\n",
            "\n",
            "    accuracy                           0.32       881\n",
            "   macro avg       0.31      0.33      0.30       881\n",
            "weighted avg       0.31      0.32      0.30       881\n",
            "\n",
            "[[31 39  2 30  6 41]\n",
            " [16 82  2 19 15 20]\n",
            " [26 27  5 55 17 27]\n",
            " [15 36  8 45 10 29]\n",
            " [ 7 28  3 18 62 20]\n",
            " [16 24  5 19 18 58]]\n",
            "Accuracy: 0.32122587968217936\n",
            "Total f1 over classes: 1.7999097151727061\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.17      0.22       149\n",
            "           1       0.35      0.47      0.40       154\n",
            "           2       0.38      0.20      0.26       157\n",
            "           3       0.22      0.17      0.20       143\n",
            "           4       0.27      0.47      0.34       138\n",
            "           5       0.25      0.27      0.26       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.30      0.29      0.28       881\n",
            "\n",
            "[[26 34 10 16 33 30]\n",
            " [15 72  3 14 29 21]\n",
            " [18 20 31 27 42 19]\n",
            " [11 30 18 25 37 22]\n",
            " [11 22  4 16 65 20]\n",
            " [10 27 16 14 35 38]]\n",
            "Accuracy: 0.2917139614074915\n",
            "Total f1 over classes: 1.6783504111932954\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.17      0.19       149\n",
            "           1       0.41      0.26      0.32       154\n",
            "           2       0.50      0.01      0.02       157\n",
            "           3       0.35      0.19      0.25       143\n",
            "           4       0.25      0.60      0.35       138\n",
            "           5       0.26      0.47      0.33       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.33      0.28      0.24       881\n",
            "weighted avg       0.33      0.28      0.24       881\n",
            "\n",
            "[[25 17  0  1 49 57]\n",
            " [21 40  0 14 50 29]\n",
            " [28 13  2 25 48 41]\n",
            " [17 13  0 27 46 40]\n",
            " [11 13  1  7 83 23]\n",
            " [13  2  1  3 55 66]]\n",
            "Accuracy: 0.2758229284903519\n",
            "Total f1 over classes: 1.4644314190388168\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.32      0.29       149\n",
            "           1       0.37      0.39      0.38       154\n",
            "           2       0.32      0.23      0.27       157\n",
            "           3       0.24      0.23      0.23       143\n",
            "           4       0.51      0.46      0.49       138\n",
            "           5       0.36      0.41      0.38       140\n",
            "\n",
            "    accuracy                           0.34       881\n",
            "   macro avg       0.34      0.34      0.34       881\n",
            "weighted avg       0.34      0.34      0.34       881\n",
            "\n",
            "[[48 26 14 21  9 31]\n",
            " [33 60 14 18 10 19]\n",
            " [34 23 36 34 12 18]\n",
            " [29 27 20 33 16 18]\n",
            " [14 15 11 17 64 17]\n",
            " [25 12 17 15 14 57]]\n",
            "Accuracy: 0.33825198637911463\n",
            "Total f1 over classes: 2.0369309750191165\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.01      0.01       149\n",
            "           1       0.34      0.20      0.25       154\n",
            "           2       0.19      0.03      0.04       157\n",
            "           3       0.29      0.03      0.05       143\n",
            "           4       0.17      0.89      0.28       138\n",
            "           5       0.00      0.00      0.00       140\n",
            "\n",
            "    accuracy                           0.19       881\n",
            "   macro avg       0.18      0.19      0.11       881\n",
            "weighted avg       0.19      0.19      0.11       881\n",
            "\n",
            "[[  1  10   0   0 137   1]\n",
            " [  2  31   2   1 118   0]\n",
            " [  3  14   4   9 126   1]\n",
            " [  2  12   9   4 115   1]\n",
            " [  0  12   3   0 123   0]\n",
            " [  1  11   3   0 125   0]]\n",
            "Accuracy: 0.18501702610669693\n",
            "Total f1 over classes: 0.6415673873671472\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.18      0.22       173\n",
            "           1       0.42      0.42      0.42       151\n",
            "           2       0.11      0.02      0.03       150\n",
            "           3       0.25      0.46      0.33       138\n",
            "           4       0.47      0.34      0.40       128\n",
            "           5       0.28      0.49      0.36       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.30      0.32      0.29       880\n",
            "weighted avg       0.30      0.31      0.29       880\n",
            "\n",
            "[[31 33  6 49  9 45]\n",
            " [17 63  3 20 15 33]\n",
            " [21 11  3 59  8 48]\n",
            " [15 20  8 64  7 24]\n",
            " [14 11  5 31 44 23]\n",
            " [16 12  3 31 10 68]]\n",
            "Accuracy: 0.31022727272727274\n",
            "Total f1 over classes: 1.7500164289669846\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.19      0.25       173\n",
            "           1       0.39      0.50      0.44       151\n",
            "           2       0.29      0.13      0.18       150\n",
            "           3       0.31      0.20      0.24       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.29      0.41      0.34       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.30       880\n",
            "weighted avg       0.32      0.32      0.30       880\n",
            "\n",
            "[[33 38 14 14 42 32]\n",
            " [10 76  3  4 30 28]\n",
            " [20 18 20 17 37 38]\n",
            " [13 27 19 27 28 24]\n",
            " [ 6 17  7 11 67 20]\n",
            " [ 8 19  7 15 34 57]]\n",
            "Accuracy: 0.3181818181818182\n",
            "Total f1 over classes: 1.813416568059178\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.56      0.36       173\n",
            "           1       0.48      0.21      0.29       151\n",
            "           2       0.20      0.17      0.19       150\n",
            "           3       0.38      0.24      0.29       138\n",
            "           4       0.55      0.09      0.15       128\n",
            "           5       0.32      0.51      0.40       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.37      0.30      0.28       880\n",
            "weighted avg       0.36      0.31      0.28       880\n",
            "\n",
            "[[97 11 25  9  0 31]\n",
            " [74 31 16  5  3 22]\n",
            " [57  6 26 21  2 38]\n",
            " [50  9 19 33  3 24]\n",
            " [46  7 22  7 11 35]\n",
            " [37  0 19 11  1 72]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.6804751659821464\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.35      0.34       173\n",
            "           1       0.45      0.46      0.46       151\n",
            "           2       0.26      0.22      0.24       150\n",
            "           3       0.27      0.24      0.25       138\n",
            "           4       0.48      0.43      0.45       128\n",
            "           5       0.40      0.49      0.44       140\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.36      0.36       880\n",
            "\n",
            "[[61 27 25 22 12 26]\n",
            " [32 70 11 11 13 14]\n",
            " [38 17 33 25 11 26]\n",
            " [26 21 25 33 13 20]\n",
            " [14 17 12 11 55 19]\n",
            " [19  2 20 19 11 69]]\n",
            "Accuracy: 0.36477272727272725\n",
            "Total f1 over classes: 2.1812265803006734\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.02      0.03       173\n",
            "           1       0.38      0.19      0.25       151\n",
            "           2       0.33      0.06      0.10       150\n",
            "           3       0.50      0.03      0.05       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.12      0.01      0.01       140\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.27      0.20      0.12       880\n",
            "weighted avg       0.27      0.18      0.12       880\n",
            "\n",
            "[[  3  15   0   1 151   3]\n",
            " [  8  28   1   0 114   0]\n",
            " [  2   8   9   2 126   3]\n",
            " [  3   7  10   4 113   1]\n",
            " [  1   9   1   1 116   0]\n",
            " [  4   6   6   0 123   1]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.7172912895337177\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.42      0.38       173\n",
            "           1       0.35      0.73      0.47       152\n",
            "           2       0.31      0.17      0.22       149\n",
            "           3       0.50      0.21      0.29       139\n",
            "           4       0.43      0.44      0.43       128\n",
            "           5       0.28      0.17      0.21       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.37      0.36      0.34       880\n",
            "weighted avg       0.37      0.36      0.34       880\n",
            "\n",
            "[[ 73  57  11   4  17  11]\n",
            " [ 23 111   4   3   5   6]\n",
            " [ 34  40  26  12  18  19]\n",
            " [ 24  38  23  29  12  13]\n",
            " [ 17  32   9   5  56   9]\n",
            " [ 36  42  11   5  22  23]]\n",
            "Accuracy: 0.3613636363636364\n",
            "Total f1 over classes: 2.0153411549093874\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.17      0.22       173\n",
            "           1       0.39      0.57      0.47       152\n",
            "           2       0.21      0.09      0.13       149\n",
            "           3       0.33      0.23      0.27       139\n",
            "           4       0.28      0.52      0.36       128\n",
            "           5       0.29      0.31      0.30       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.30      0.32      0.29       880\n",
            "weighted avg       0.30      0.31      0.29       880\n",
            "\n",
            "[[30 35  7 14 63 24]\n",
            " [13 87  9  8 23 12]\n",
            " [21 23 14 23 40 28]\n",
            " [18 24 20 32 19 26]\n",
            " [ 9 23  1 13 67 15]\n",
            " [15 30 15  7 29 43]]\n",
            "Accuracy: 0.31022727272727274\n",
            "Total f1 over classes: 1.7445086033501562\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.60      0.34       173\n",
            "           1       0.34      0.61      0.43       152\n",
            "           2       0.24      0.05      0.08       149\n",
            "           3       0.43      0.22      0.29       139\n",
            "           4       0.44      0.11      0.17       128\n",
            "           5       0.40      0.12      0.19       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.35      0.28      0.25       880\n",
            "weighted avg       0.34      0.30      0.26       880\n",
            "\n",
            "[[104  52   4   2   3   8]\n",
            " [ 46  92   5   3   4   2]\n",
            " [ 83  38   7  14   3   4]\n",
            " [ 56  31  10  30   7   5]\n",
            " [ 72  23   3  10  14   6]\n",
            " [ 75  36   0  10   1  17]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.5054643058304507\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.29      0.28       173\n",
            "           1       0.41      0.46      0.43       152\n",
            "           2       0.23      0.21      0.22       149\n",
            "           3       0.35      0.34      0.35       139\n",
            "           4       0.44      0.41      0.43       128\n",
            "           5       0.41      0.42      0.42       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.36      0.36      0.35       880\n",
            "weighted avg       0.35      0.35      0.35       880\n",
            "\n",
            "[[51 36 29 19 14 24]\n",
            " [26 70 20 14 12 10]\n",
            " [36 25 31 26 12 19]\n",
            " [25 16 23 47 13 15]\n",
            " [18 14 11 18 53 14]\n",
            " [29  9 18  9 16 58]]\n",
            "Accuracy: 0.3522727272727273\n",
            "Total f1 over classes: 2.129117578659812\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.02      0.03       173\n",
            "           1       0.50      0.19      0.28       152\n",
            "           2       0.24      0.03      0.05       149\n",
            "           3       0.38      0.04      0.07       139\n",
            "           4       0.16      0.98      0.28       128\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.19       880\n",
            "   macro avg       0.25      0.21      0.12       880\n",
            "weighted avg       0.25      0.19      0.11       880\n",
            "\n",
            "[[  3   4   1   0 165   0]\n",
            " [  0  29   4   0 119   0]\n",
            " [  4  12   4   7 122   0]\n",
            " [  0   8   7   5 119   0]\n",
            " [  1   2   0   0 125   0]\n",
            " [  6   3   1   1 128   0]]\n",
            "Accuracy: 0.18863636363636363\n",
            "Total f1 over classes: 0.6981964723018249\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.36      0.33       172\n",
            "           1       0.41      0.49      0.45       152\n",
            "           2       0.31      0.17      0.22       149\n",
            "           3       0.30      0.29      0.29       139\n",
            "           4       0.48      0.37      0.42       129\n",
            "           5       0.32      0.42      0.37       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.36      0.35      0.35       880\n",
            "weighted avg       0.35      0.35      0.35       880\n",
            "\n",
            "[[62 39 17 26  8 20]\n",
            " [34 75  4 15  5 19]\n",
            " [30 18 25 29 13 34]\n",
            " [26 21 17 40 11 24]\n",
            " [21 15  9 10 48 26]\n",
            " [30 14  8 14 14 59]]\n",
            "Accuracy: 0.35113636363636364\n",
            "Total f1 over classes: 2.079803245152723\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.17      0.22       172\n",
            "           1       0.41      0.54      0.46       152\n",
            "           2       0.35      0.15      0.21       149\n",
            "           3       0.30      0.20      0.24       139\n",
            "           4       0.30      0.57      0.39       129\n",
            "           5       0.34      0.46      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.32       880\n",
            "weighted avg       0.34      0.34      0.32       880\n",
            "\n",
            "[[29 42  9 21 35 36]\n",
            " [17 82  2 13 21 17]\n",
            " [10 20 22 19 47 31]\n",
            " [12 21 17 28 40 21]\n",
            " [ 8 18  4  7 74 18]\n",
            " [10 19  8  6 32 64]]\n",
            "Accuracy: 0.3397727272727273\n",
            "Total f1 over classes: 1.9211296193794758\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.51      0.35       172\n",
            "           1       0.38      0.23      0.29       152\n",
            "           2       0.20      0.17      0.19       149\n",
            "           3       0.34      0.27      0.30       139\n",
            "           4       0.67      0.22      0.33       129\n",
            "           5       0.39      0.50      0.43       139\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.37      0.32      0.31       880\n",
            "weighted avg       0.36      0.32      0.31       880\n",
            "\n",
            "[[88 19 21 17  0 27]\n",
            " [70 35 17 14  2 14]\n",
            " [57 12 26 27  4 23]\n",
            " [43  7 25 37  5 22]\n",
            " [31 17 22  7 28 24]\n",
            " [38  1 21  7  3 69]]\n",
            "Accuracy: 0.3215909090909091\n",
            "Total f1 over classes: 1.8856593762680565\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.30      0.29       172\n",
            "           1       0.39      0.51      0.44       152\n",
            "           2       0.25      0.21      0.23       149\n",
            "           3       0.26      0.21      0.23       139\n",
            "           4       0.50      0.45      0.47       129\n",
            "           5       0.48      0.49      0.48       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.36      0.36       880\n",
            "weighted avg       0.35      0.36      0.35       880\n",
            "\n",
            "[[51 40 34 22  5 20]\n",
            " [26 77 14 13 12 10]\n",
            " [35 22 32 31 16 13]\n",
            " [30 26 27 29 11 16]\n",
            " [19 22  8  6 58 16]\n",
            " [23 12 11 11 14 68]]\n",
            "Accuracy: 0.35795454545454547\n",
            "Total f1 over classes: 2.144805153918653\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       172\n",
            "           1       0.42      0.25      0.31       152\n",
            "           2       0.29      0.03      0.05       149\n",
            "           3       0.33      0.03      0.05       139\n",
            "           4       0.15      0.89      0.26       129\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.20      0.20      0.11       880\n",
            "weighted avg       0.20      0.18      0.11       880\n",
            "\n",
            "[[  0  15   1   1 154   1]\n",
            " [  1  38   3   1 107   2]\n",
            " [  1  15   4   5 123   1]\n",
            " [  0   7   4   4 122   2]\n",
            " [  1  11   1   1 115   0]\n",
            " [  0   4   1   0 134   0]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.6762904693035308\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.75      0.40       173\n",
            "           1       0.64      0.24      0.35       152\n",
            "           2       0.42      0.12      0.19       149\n",
            "           3       0.39      0.21      0.27       138\n",
            "           4       0.50      0.42      0.46       128\n",
            "           5       0.39      0.34      0.37       140\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.43      0.35      0.34       880\n",
            "weighted avg       0.43      0.36      0.34       880\n",
            "\n",
            "[[129   7   5   6   7  19]\n",
            " [ 94  37   4   1   6  10]\n",
            " [ 68   6  18  25  12  20]\n",
            " [ 74   2   8  29  12  13]\n",
            " [ 50   3   3   5  54  13]\n",
            " [ 58   3   5   9  17  48]]\n",
            "Accuracy: 0.35795454545454547\n",
            "Total f1 over classes: 2.0342083568689926\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.13      0.17       173\n",
            "           1       0.42      0.55      0.47       152\n",
            "           2       0.33      0.17      0.23       149\n",
            "           3       0.33      0.26      0.29       138\n",
            "           4       0.31      0.58      0.41       128\n",
            "           5       0.31      0.38      0.34       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.31       880\n",
            "\n",
            "[[22 45 19 18 39 30]\n",
            " [19 83  2  9 20 19]\n",
            " [ 7 22 26 28 37 29]\n",
            " [14 14 18 36 33 23]\n",
            " [ 6 19  2  9 74 18]\n",
            " [16 16 12  9 34 53]]\n",
            "Accuracy: 0.3340909090909091\n",
            "Total f1 over classes: 1.9089318915608897\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.17      0.20       173\n",
            "           1       0.51      0.28      0.36       152\n",
            "           2       0.00      0.00      0.00       149\n",
            "           3       0.33      0.20      0.25       138\n",
            "           4       0.26      0.66      0.38       128\n",
            "           5       0.28      0.52      0.36       140\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.27      0.30      0.26       880\n",
            "weighted avg       0.27      0.29      0.25       880\n",
            "\n",
            "[[30 16  2  9 58 58]\n",
            " [36 42  1  8 38 27]\n",
            " [23  9  0 27 49 41]\n",
            " [17  4  2 27 51 37]\n",
            " [ 5  8  1  5 84 25]\n",
            " [18  3  0  6 40 73]]\n",
            "Accuracy: 0.2909090909090909\n",
            "Total f1 over classes: 1.5421941766787435\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       173\n",
            "           1       0.45      0.57      0.50       152\n",
            "           2       0.25      0.15      0.19       149\n",
            "           3       0.29      0.28      0.28       138\n",
            "           4       0.54      0.50      0.52       128\n",
            "           5       0.45      0.54      0.49       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[46 38 19 28  7 35]\n",
            " [28 86 13 10  7  8]\n",
            " [38 25 22 39  6 19]\n",
            " [28 15 20 39 20 16]\n",
            " [15 15  6 12 64 16]\n",
            " [24 11  7  8 14 76]]\n",
            "Accuracy: 0.3784090909090909\n",
            "Total f1 over classes: 2.2460476076818345\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.03      0.06       173\n",
            "           1       0.41      0.20      0.27       152\n",
            "           2       0.52      0.10      0.17       149\n",
            "           3       0.50      0.07      0.12       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.38      0.02      0.04       140\n",
            "\n",
            "    accuracy                           0.20       880\n",
            "   macro avg       0.38      0.22      0.15       880\n",
            "weighted avg       0.38      0.20      0.15       880\n",
            "\n",
            "[[  6  12   3   0 149   3]\n",
            " [  4  30   3   1 113   1]\n",
            " [  1  11  15   8 114   0]\n",
            " [  2   7   2   9 117   1]\n",
            " [  2   8   2   0 116   0]\n",
            " [  4   6   4   0 123   3]]\n",
            "Accuracy: 0.2034090909090909\n",
            "Total f1 over classes: 0.9222186492920346\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.77      0.36       149\n",
            "           1       0.53      0.19      0.28       154\n",
            "           2       0.21      0.06      0.10       157\n",
            "           3       0.35      0.18      0.24       143\n",
            "           4       0.49      0.33      0.40       138\n",
            "           5       0.35      0.31      0.33       140\n",
            "\n",
            "    accuracy                           0.30       881\n",
            "   macro avg       0.36      0.31      0.28       881\n",
            "weighted avg       0.36      0.30      0.28       881\n",
            "\n",
            "[[114   6   4   4   5  16]\n",
            " [ 99  29   4   5   8   9]\n",
            " [ 83   2  10  29  14  19]\n",
            " [ 70   9  14  26   6  18]\n",
            " [ 50   8   7   8  46  19]\n",
            " [ 70   1   9   2  15  43]]\n",
            "Accuracy: 0.30419977298524403\n",
            "Total f1 over classes: 1.696068691743517\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.17      0.22       149\n",
            "           1       0.35      0.47      0.40       154\n",
            "           2       0.38      0.20      0.26       157\n",
            "           3       0.22      0.17      0.20       143\n",
            "           4       0.27      0.47      0.34       138\n",
            "           5       0.25      0.27      0.26       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.30      0.29      0.28       881\n",
            "\n",
            "[[26 34 10 16 33 30]\n",
            " [15 72  3 14 29 21]\n",
            " [18 20 31 27 42 19]\n",
            " [11 30 18 25 37 22]\n",
            " [11 22  4 16 65 20]\n",
            " [10 27 16 14 35 38]]\n",
            "Accuracy: 0.2917139614074915\n",
            "Total f1 over classes: 1.6783504111932954\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.17      0.19       149\n",
            "           1       0.41      0.26      0.32       154\n",
            "           2       0.50      0.01      0.02       157\n",
            "           3       0.35      0.19      0.25       143\n",
            "           4       0.25      0.60      0.35       138\n",
            "           5       0.26      0.47      0.33       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.33      0.28      0.24       881\n",
            "weighted avg       0.33      0.28      0.24       881\n",
            "\n",
            "[[25 17  0  1 49 57]\n",
            " [21 40  0 14 50 29]\n",
            " [28 13  2 25 48 41]\n",
            " [17 13  0 27 46 40]\n",
            " [11 13  1  7 83 23]\n",
            " [13  2  1  3 55 66]]\n",
            "Accuracy: 0.2758229284903519\n",
            "Total f1 over classes: 1.4644314190388168\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.32      0.29       149\n",
            "           1       0.37      0.43      0.40       154\n",
            "           2       0.36      0.26      0.30       157\n",
            "           3       0.25      0.22      0.23       143\n",
            "           4       0.50      0.48      0.49       138\n",
            "           5       0.35      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.35       881\n",
            "   macro avg       0.35      0.35      0.35       881\n",
            "weighted avg       0.35      0.35      0.35       881\n",
            "\n",
            "[[47 31 13 20  9 29]\n",
            " [27 66 11 16 15 19]\n",
            " [34 24 41 31 10 17]\n",
            " [27 28 23 31 14 20]\n",
            " [14 16 13 14 66 15]\n",
            " [29 12 14 12 18 55]]\n",
            "Accuracy: 0.3473325766174801\n",
            "Total f1 over classes: 2.081703885369906\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.01      0.01       149\n",
            "           1       0.34      0.20      0.25       154\n",
            "           2       0.19      0.03      0.04       157\n",
            "           3       0.29      0.03      0.05       143\n",
            "           4       0.17      0.89      0.28       138\n",
            "           5       0.00      0.00      0.00       140\n",
            "\n",
            "    accuracy                           0.19       881\n",
            "   macro avg       0.18      0.19      0.11       881\n",
            "weighted avg       0.19      0.19      0.11       881\n",
            "\n",
            "[[  1  10   0   0 137   1]\n",
            " [  2  31   2   1 118   0]\n",
            " [  3  14   4   9 126   1]\n",
            " [  2  12   9   4 115   1]\n",
            " [  0  12   3   0 123   0]\n",
            " [  1  11   3   0 125   0]]\n",
            "Accuracy: 0.18501702610669693\n",
            "Total f1 over classes: 0.6415673873671472\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.14      0.19       173\n",
            "           1       0.38      0.54      0.45       151\n",
            "           2       0.00      0.00      0.00       150\n",
            "           3       0.27      0.38      0.32       138\n",
            "           4       0.45      0.45      0.45       128\n",
            "           5       0.27      0.50      0.35       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.28      0.34      0.29       880\n",
            "weighted avg       0.28      0.33      0.29       880\n",
            "\n",
            "[[24 41  1 36 19 52]\n",
            " [13 82  1 13 15 27]\n",
            " [11 23  0 47 15 54]\n",
            " [ 8 31  1 53  9 36]\n",
            " [11 20  0 20 58 19]\n",
            " [11 20  2 25 12 70]]\n",
            "Accuracy: 0.3261363636363636\n",
            "Total f1 over classes: 1.7610481360775838\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.19      0.25       173\n",
            "           1       0.39      0.50      0.44       151\n",
            "           2       0.29      0.13      0.18       150\n",
            "           3       0.31      0.20      0.24       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.29      0.41      0.34       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.30       880\n",
            "weighted avg       0.32      0.32      0.30       880\n",
            "\n",
            "[[33 38 14 14 42 32]\n",
            " [10 76  3  4 30 28]\n",
            " [20 18 20 17 37 38]\n",
            " [13 27 19 27 28 24]\n",
            " [ 6 17  7 11 67 20]\n",
            " [ 8 19  7 15 34 57]]\n",
            "Accuracy: 0.3181818181818182\n",
            "Total f1 over classes: 1.813416568059178\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.56      0.36       173\n",
            "           1       0.48      0.21      0.29       151\n",
            "           2       0.20      0.17      0.19       150\n",
            "           3       0.38      0.24      0.29       138\n",
            "           4       0.55      0.09      0.15       128\n",
            "           5       0.32      0.51      0.40       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.37      0.30      0.28       880\n",
            "weighted avg       0.36      0.31      0.28       880\n",
            "\n",
            "[[97 11 25  9  0 31]\n",
            " [74 31 16  5  3 22]\n",
            " [57  6 26 21  2 38]\n",
            " [50  9 19 33  3 24]\n",
            " [46  7 22  7 11 35]\n",
            " [37  0 19 11  1 72]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.6804751659821464\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.34      0.33       173\n",
            "           1       0.45      0.49      0.47       151\n",
            "           2       0.23      0.20      0.22       150\n",
            "           3       0.31      0.25      0.28       138\n",
            "           4       0.52      0.48      0.50       128\n",
            "           5       0.42      0.51      0.46       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.38       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[58 28 29 21 12 25]\n",
            " [33 74 10 10 12 12]\n",
            " [39 21 30 23  9 28]\n",
            " [28 21 22 35 13 19]\n",
            " [ 8 16 14 11 62 17]\n",
            " [17  4 23 13 11 72]]\n",
            "Accuracy: 0.37613636363636366\n",
            "Total f1 over classes: 2.252483956012928\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.14      0.02      0.03       173\n",
            "           1       0.38      0.19      0.25       151\n",
            "           2       0.33      0.06      0.10       150\n",
            "           3       0.50      0.03      0.05       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.12      0.01      0.01       140\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.27      0.20      0.12       880\n",
            "weighted avg       0.27      0.18      0.12       880\n",
            "\n",
            "[[  3  15   0   1 151   3]\n",
            " [  8  28   1   0 114   0]\n",
            " [  2   8   9   2 126   3]\n",
            " [  3   7  10   4 113   1]\n",
            " [  1   9   1   1 116   0]\n",
            " [  4   6   6   0 123   1]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.7172912895337177\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.29      0.29       173\n",
            "           1       0.42      0.59      0.49       152\n",
            "           2       0.30      0.11      0.17       149\n",
            "           3       0.31      0.36      0.33       139\n",
            "           4       0.44      0.45      0.44       128\n",
            "           5       0.32      0.35      0.33       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.35      0.36      0.34       880\n",
            "weighted avg       0.34      0.35      0.34       880\n",
            "\n",
            "[[50 32 10 37 19 25]\n",
            " [30 89  7 12  5  9]\n",
            " [30 23 17 33 21 25]\n",
            " [22 28  9 50  7 23]\n",
            " [14 20  3 14 57 20]\n",
            " [24 18 11 16 22 48]]\n",
            "Accuracy: 0.3534090909090909\n",
            "Total f1 over classes: 2.052866724947564\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.17      0.22       173\n",
            "           1       0.39      0.57      0.47       152\n",
            "           2       0.21      0.09      0.13       149\n",
            "           3       0.33      0.23      0.27       139\n",
            "           4       0.28      0.52      0.36       128\n",
            "           5       0.29      0.31      0.30       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.30      0.32      0.29       880\n",
            "weighted avg       0.30      0.31      0.29       880\n",
            "\n",
            "[[30 35  7 14 63 24]\n",
            " [13 87  9  8 23 12]\n",
            " [21 23 14 23 40 28]\n",
            " [18 24 20 32 19 26]\n",
            " [ 9 23  1 13 67 15]\n",
            " [15 30 15  7 29 43]]\n",
            "Accuracy: 0.31022727272727274\n",
            "Total f1 over classes: 1.7445086033501562\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.60      0.34       173\n",
            "           1       0.34      0.61      0.43       152\n",
            "           2       0.24      0.05      0.08       149\n",
            "           3       0.43      0.22      0.29       139\n",
            "           4       0.44      0.11      0.17       128\n",
            "           5       0.40      0.12      0.19       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.35      0.28      0.25       880\n",
            "weighted avg       0.34      0.30      0.26       880\n",
            "\n",
            "[[104  52   4   2   3   8]\n",
            " [ 46  92   5   3   4   2]\n",
            " [ 83  38   7  14   3   4]\n",
            " [ 56  31  10  30   7   5]\n",
            " [ 72  23   3  10  14   6]\n",
            " [ 75  36   0  10   1  17]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.5054643058304507\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.29      0.29       173\n",
            "           1       0.42      0.46      0.44       152\n",
            "           2       0.23      0.19      0.21       149\n",
            "           3       0.34      0.32      0.33       139\n",
            "           4       0.45      0.45      0.45       128\n",
            "           5       0.42      0.45      0.44       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.36      0.36       880\n",
            "weighted avg       0.35      0.36      0.35       880\n",
            "\n",
            "[[50 33 30 18 15 27]\n",
            " [27 70 19 11 12 13]\n",
            " [37 23 29 27 15 18]\n",
            " [21 15 25 45 16 17]\n",
            " [18 13 11 17 57 12]\n",
            " [24 12 13 14 13 63]]\n",
            "Accuracy: 0.3568181818181818\n",
            "Total f1 over classes: 2.1495127657803224\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.21      0.02      0.03       173\n",
            "           1       0.50      0.19      0.28       152\n",
            "           2       0.24      0.03      0.05       149\n",
            "           3       0.38      0.04      0.07       139\n",
            "           4       0.16      0.98      0.28       128\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.19       880\n",
            "   macro avg       0.25      0.21      0.12       880\n",
            "weighted avg       0.25      0.19      0.11       880\n",
            "\n",
            "[[  3   4   1   0 165   0]\n",
            " [  0  29   4   0 119   0]\n",
            " [  4  12   4   7 122   0]\n",
            " [  0   8   7   5 119   0]\n",
            " [  1   2   0   0 125   0]\n",
            " [  6   3   1   1 128   0]]\n",
            "Accuracy: 0.18863636363636363\n",
            "Total f1 over classes: 0.6981964723018249\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.38      0.35       172\n",
            "           1       0.43      0.49      0.46       152\n",
            "           2       0.36      0.21      0.27       149\n",
            "           3       0.28      0.19      0.23       139\n",
            "           4       0.39      0.40      0.39       129\n",
            "           5       0.36      0.47      0.41       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.36      0.35       880\n",
            "weighted avg       0.36      0.36      0.35       880\n",
            "\n",
            "[[66 33 11 20 13 29]\n",
            " [32 74  2 16 10 18]\n",
            " [33 21 32 18 20 25]\n",
            " [31 18 26 27 16 21]\n",
            " [23 15  9  6 51 25]\n",
            " [24 11  9  8 21 66]]\n",
            "Accuracy: 0.35909090909090907\n",
            "Total f1 over classes: 2.1039000331224638\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.17      0.22       172\n",
            "           1       0.41      0.54      0.46       152\n",
            "           2       0.35      0.15      0.21       149\n",
            "           3       0.30      0.20      0.24       139\n",
            "           4       0.30      0.57      0.39       129\n",
            "           5       0.34      0.46      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.32       880\n",
            "weighted avg       0.34      0.34      0.32       880\n",
            "\n",
            "[[29 42  9 21 35 36]\n",
            " [17 82  2 13 21 17]\n",
            " [10 20 22 19 47 31]\n",
            " [12 21 17 28 40 21]\n",
            " [ 8 18  4  7 74 18]\n",
            " [10 19  8  6 32 64]]\n",
            "Accuracy: 0.3397727272727273\n",
            "Total f1 over classes: 1.9211296193794758\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.51      0.35       172\n",
            "           1       0.38      0.23      0.29       152\n",
            "           2       0.20      0.17      0.19       149\n",
            "           3       0.34      0.27      0.30       139\n",
            "           4       0.67      0.22      0.33       129\n",
            "           5       0.39      0.50      0.43       139\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.37      0.32      0.31       880\n",
            "weighted avg       0.36      0.32      0.31       880\n",
            "\n",
            "[[88 19 21 17  0 27]\n",
            " [70 35 17 14  2 14]\n",
            " [57 12 26 27  4 23]\n",
            " [43  7 25 37  5 22]\n",
            " [31 17 22  7 28 24]\n",
            " [38  1 21  7  3 69]]\n",
            "Accuracy: 0.3215909090909091\n",
            "Total f1 over classes: 1.8856593762680565\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.33      0.31       172\n",
            "           1       0.39      0.47      0.42       152\n",
            "           2       0.29      0.23      0.26       149\n",
            "           3       0.28      0.24      0.26       139\n",
            "           4       0.49      0.45      0.47       129\n",
            "           5       0.47      0.49      0.48       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[57 37 30 22  6 20]\n",
            " [31 71 13 14 14  9]\n",
            " [35 20 35 29 17 13]\n",
            " [31 24 23 33 10 18]\n",
            " [17 22  7  9 58 16]\n",
            " [25  9 12 12 13 68]]\n",
            "Accuracy: 0.3659090909090909\n",
            "Total f1 over classes: 2.1999012060811864\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       172\n",
            "           1       0.42      0.25      0.31       152\n",
            "           2       0.29      0.03      0.05       149\n",
            "           3       0.33      0.03      0.05       139\n",
            "           4       0.15      0.89      0.26       129\n",
            "           5       0.00      0.00      0.00       139\n",
            "\n",
            "    accuracy                           0.18       880\n",
            "   macro avg       0.20      0.20      0.11       880\n",
            "weighted avg       0.20      0.18      0.11       880\n",
            "\n",
            "[[  0  15   1   1 154   1]\n",
            " [  1  38   3   1 107   2]\n",
            " [  1  15   4   5 123   1]\n",
            " [  0   7   4   4 122   2]\n",
            " [  1  11   1   1 115   0]\n",
            " [  0   4   1   0 134   0]]\n",
            "Accuracy: 0.18295454545454545\n",
            "Total f1 over classes: 0.6762904693035308\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.27      0.31       173\n",
            "           1       0.44      0.53      0.48       152\n",
            "           2       0.41      0.19      0.26       149\n",
            "           3       0.34      0.36      0.35       138\n",
            "           4       0.43      0.60      0.50       128\n",
            "           5       0.37      0.45      0.40       140\n",
            "\n",
            "    accuracy                           0.39       880\n",
            "   macro avg       0.39      0.40      0.38       880\n",
            "weighted avg       0.39      0.39      0.38       880\n",
            "\n",
            "[[47 37 12 27 19 31]\n",
            " [17 81  4 15 18 17]\n",
            " [25 18 28 32 23 23]\n",
            " [15 17 15 50 20 21]\n",
            " [ 9 15  0 10 77 17]\n",
            " [16 15  9 13 24 63]]\n",
            "Accuracy: 0.3931818181818182\n",
            "Total f1 over classes: 2.30601010767823\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.13      0.17       173\n",
            "           1       0.42      0.55      0.47       152\n",
            "           2       0.33      0.17      0.23       149\n",
            "           3       0.33      0.26      0.29       138\n",
            "           4       0.31      0.58      0.41       128\n",
            "           5       0.31      0.38      0.34       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.31       880\n",
            "\n",
            "[[22 45 19 18 39 30]\n",
            " [19 83  2  9 20 19]\n",
            " [ 7 22 26 28 37 29]\n",
            " [14 14 18 36 33 23]\n",
            " [ 6 19  2  9 74 18]\n",
            " [16 16 12  9 34 53]]\n",
            "Accuracy: 0.3340909090909091\n",
            "Total f1 over classes: 1.9089318915608897\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.17      0.20       173\n",
            "           1       0.51      0.28      0.36       152\n",
            "           2       0.00      0.00      0.00       149\n",
            "           3       0.33      0.20      0.25       138\n",
            "           4       0.26      0.66      0.38       128\n",
            "           5       0.28      0.52      0.36       140\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.27      0.30      0.26       880\n",
            "weighted avg       0.27      0.29      0.25       880\n",
            "\n",
            "[[30 16  2  9 58 58]\n",
            " [36 42  1  8 38 27]\n",
            " [23  9  0 27 49 41]\n",
            " [17  4  2 27 51 37]\n",
            " [ 5  8  1  5 84 25]\n",
            " [18  3  0  6 40 73]]\n",
            "Accuracy: 0.2909090909090909\n",
            "Total f1 over classes: 1.5421941766787435\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.24      0.24       173\n",
            "           1       0.45      0.55      0.49       152\n",
            "           2       0.25      0.17      0.21       149\n",
            "           3       0.27      0.27      0.27       138\n",
            "           4       0.55      0.50      0.52       128\n",
            "           5       0.48      0.56      0.52       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.38       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[42 40 23 26  9 33]\n",
            " [25 83 16 10  9  9]\n",
            " [33 24 26 40  9 17]\n",
            " [33 15 25 37 15 13]\n",
            " [17 14  8 13 64 12]\n",
            " [28  8  5 10 10 79]]\n",
            "Accuracy: 0.37613636363636366\n",
            "Total f1 over classes: 2.255828366562742\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.03      0.06       173\n",
            "           1       0.41      0.20      0.27       152\n",
            "           2       0.52      0.10      0.17       149\n",
            "           3       0.50      0.07      0.12       138\n",
            "           4       0.16      0.91      0.27       128\n",
            "           5       0.38      0.02      0.04       140\n",
            "\n",
            "    accuracy                           0.20       880\n",
            "   macro avg       0.38      0.22      0.15       880\n",
            "weighted avg       0.38      0.20      0.15       880\n",
            "\n",
            "[[  6  12   3   0 149   3]\n",
            " [  4  30   3   1 113   1]\n",
            " [  1  11  15   8 114   0]\n",
            " [  2   7   2   9 117   1]\n",
            " [  2   8   2   0 116   0]\n",
            " [  4   6   4   0 123   3]]\n",
            "Accuracy: 0.2034090909090909\n",
            "Total f1 over classes: 0.9222186492920346\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.25      0.26       149\n",
            "           1       0.40      0.40      0.40       154\n",
            "           2       0.29      0.14      0.19       157\n",
            "           3       0.23      0.24      0.24       143\n",
            "           4       0.35      0.48      0.40       138\n",
            "           5       0.31      0.39      0.34       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.31      0.32      0.30       881\n",
            "weighted avg       0.31      0.31      0.30       881\n",
            "\n",
            "[[37 19 10 24 19 40]\n",
            " [18 61  4 16 32 23]\n",
            " [31 15 22 44 28 17]\n",
            " [17 26 21 34 21 24]\n",
            " [11 18  6 16 66 21]\n",
            " [22 15 13 12 23 55]]\n",
            "Accuracy: 0.31214528944381387\n",
            "Total f1 over classes: 1.8273080630453529\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.17      0.22       149\n",
            "           1       0.35      0.47      0.40       154\n",
            "           2       0.38      0.20      0.26       157\n",
            "           3       0.22      0.17      0.20       143\n",
            "           4       0.27      0.47      0.34       138\n",
            "           5       0.25      0.27      0.26       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.30      0.29      0.28       881\n",
            "\n",
            "[[26 34 10 16 33 30]\n",
            " [15 72  3 14 29 21]\n",
            " [18 20 31 27 42 19]\n",
            " [11 30 18 25 37 22]\n",
            " [11 22  4 16 65 20]\n",
            " [10 27 16 14 35 38]]\n",
            "Accuracy: 0.2917139614074915\n",
            "Total f1 over classes: 1.6783504111932954\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.17      0.19       149\n",
            "           1       0.41      0.26      0.32       154\n",
            "           2       0.50      0.01      0.02       157\n",
            "           3       0.35      0.19      0.25       143\n",
            "           4       0.25      0.60      0.35       138\n",
            "           5       0.26      0.47      0.33       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.33      0.28      0.24       881\n",
            "weighted avg       0.33      0.28      0.24       881\n",
            "\n",
            "[[25 17  0  1 49 57]\n",
            " [21 40  0 14 50 29]\n",
            " [28 13  2 25 48 41]\n",
            " [17 13  0 27 46 40]\n",
            " [11 13  1  7 83 23]\n",
            " [13  2  1  3 55 66]]\n",
            "Accuracy: 0.2758229284903519\n",
            "Total f1 over classes: 1.4644314190388168\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.34      0.30       149\n",
            "           1       0.35      0.42      0.38       154\n",
            "           2       0.33      0.24      0.28       157\n",
            "           3       0.23      0.19      0.21       143\n",
            "           4       0.50      0.44      0.47       138\n",
            "           5       0.37      0.43      0.40       140\n",
            "\n",
            "    accuracy                           0.34       881\n",
            "   macro avg       0.34      0.34      0.34       881\n",
            "weighted avg       0.34      0.34      0.34       881\n",
            "\n",
            "[[50 28 15 15  9 32]\n",
            " [29 64 11 19 11 20]\n",
            " [36 24 38 29 13 17]\n",
            " [26 32 25 27 15 18]\n",
            " [15 19 10 17 61 16]\n",
            " [23 16 15 12 14 60]]\n",
            "Accuracy: 0.340522133938706\n",
            "Total f1 over classes: 2.0347222360464796\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.01      0.01       149\n",
            "           1       0.34      0.20      0.25       154\n",
            "           2       0.19      0.03      0.04       157\n",
            "           3       0.29      0.03      0.05       143\n",
            "           4       0.17      0.89      0.28       138\n",
            "           5       0.00      0.00      0.00       140\n",
            "\n",
            "    accuracy                           0.19       881\n",
            "   macro avg       0.18      0.19      0.11       881\n",
            "weighted avg       0.19      0.19      0.11       881\n",
            "\n",
            "[[  1  10   0   0 137   1]\n",
            " [  2  31   2   1 118   0]\n",
            " [  3  14   4   9 126   1]\n",
            " [  2  12   9   4 115   1]\n",
            " [  0  12   3   0 123   0]\n",
            " [  1  11   3   0 125   0]]\n",
            "Accuracy: 0.18501702610669693\n",
            "Total f1 over classes: 0.6415673873671472\n"
          ]
        }
      ],
      "source": [
        "# Deal with data imbalance ofter stratified k fold split for cross validation\n",
        "balanceTypes = [\"None\", \"SMOTE\", \"RandomOver\", \"RandomUnder\"]\n",
        "analysisTypes = [\"ANN\", \"SVM\", \"Logistic Regression\", \"Decision Tree\", \"Random Forest\", \"Naive Bayes\"]\n",
        "resultsList = []\n",
        "testResultList = []\n",
        "\n",
        "def perform_experiment(groupingCode, experimentNumber, data, labels, outputFilename):  \n",
        "  #Split the overall dataset into  training and testing\n",
        "  training_data, testing_data = train_test_split(data, test_size=0.2, random_state=34)\n",
        "  #training_data = data.sample(frac=0.8, random_state=25)\n",
        "  training_labels = labels[training_data.index]\n",
        "  # This test data will be used to evaluate the model\n",
        "  #testing_data = data.drop(training_data.index)\n",
        "  testing_labels = labels[testing_data.index]\n",
        "  #print(testing_labels)\n",
        "\n",
        "  print(f\"No. of training examples: {training_data.shape[0]}\")\n",
        "  print(f\"No. of testing examples: {testing_data.shape[0]}\")\n",
        "\n",
        "  models=[initNeuralNetModel(training_data, training_labels,numFeatures),\n",
        "          SVC(kernel='rbf',gamma=\"auto\"),\n",
        "          LogisticRegression(random_state=34, C=1, multi_class='auto', solver='lbfgs',max_iter=100),\n",
        "          DecisionTreeClassifier(criterion=\"gini\", random_state=34, max_depth=5, min_samples_leaf=5),\n",
        "          RandomForestClassifier(n_estimators=100), GaussianNB()]\n",
        "\n",
        "  # Running classifiers for balance type = SMOTE\n",
        "  balanceType = \"SMOTE\"\n",
        "  resultsList = []\n",
        "  testResultList = []\n",
        "  # Using 5 splits for k-fold cross validation.\n",
        "  skf = StratifiedKFold(n_splits=4,random_state=25, shuffle=True)\n",
        "  split = -1\n",
        "  for train, test in skf.split(training_data, training_labels):\n",
        "      split = split + 1\n",
        "      trainX = np.take(training_data, train, axis=0)\n",
        "      trainY = np.take(training_labels, train, axis=0)\n",
        "      testX = np.take(training_data, test, axis=0)\n",
        "      testY = np.take(training_labels, test, axis=0)\n",
        "      #print(\"trainX shape:\", trainX.shape)\n",
        "      #print(\"trainY shape\", trainY.shape)\n",
        "\n",
        "      # deal with the imbalance on the training set alone (so duplication doesn't bleed across test/train split)\n",
        "      trainX, trainY = balanceData(balanceType, trainX, trainY)\n",
        "\n",
        "      #print(\"trainX shape after balancing:\", trainX.shape)\n",
        "      #print(\"trainY shape after balancing\", trainY.shape)\n",
        "      #trainY = trainY.reshape((trainY.shape[0],))\n",
        "\n",
        "      for analysisType in analysisTypes:\n",
        "          print(\"Doing analysis with {}\".format(analysisType))\n",
        "          if analysisType == \"All\":\n",
        "              #print(\"Doing analysis with Linear Regression\")\n",
        "              #print(\"But it's not actually implemented...\")\n",
        "              preditions = testY + 1\n",
        "          else:\n",
        "              model = None\n",
        "              if analysisType == \"ANN\":\n",
        "                models[0] = doNeuralNetAnalysis(models[0], trainX, trainY,\n",
        "                                                testX, testY, numFeatures)\n",
        "                preds = models[0].predict(testX, verbose=0)\n",
        "                predictions = preds.argmax(axis=1)\n",
        "                #predictions = doNeuralNetAnalysis(trainX, trainY, testX, testY, numFeatures)\n",
        "              elif analysisType == \"SVM\":\n",
        "                  #svclassifier = SVC(kernel='linear')\n",
        "                  #svclassifier = SVC(kernel='poly', degree=8)\n",
        "                  #model = SVC(kernel='rbf', gamma=\"auto\")\n",
        "                  models[1].fit(trainX, trainY)\n",
        "                  predictions = models[1].predict(testX)\n",
        "                  #svclassifier = SVC(kernel='sigmoid')\n",
        "              elif analysisType == \"Logistic Regression\":\n",
        "                  #model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
        "                  models[2].fit(trainX, trainY)\n",
        "                  predictions = models[2].predict(testX)   \n",
        "              elif analysisType == \"Decision Tree\":\n",
        "                  #model = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=3, min_samples_leaf=5)\n",
        "                  models[3].fit(trainX, trainY)\n",
        "                  predictions = models[3].predict(testX)\n",
        "              elif analysisType == \"Random Forest\":\n",
        "                  #model = RandomForestClassifier(n_estimators=100)\n",
        "                  models[4].fit(trainX, trainY)\n",
        "                  predictions = models[4].predict(testX)\n",
        "              elif analysisType == \"Naive Bayes\":\n",
        "                  #model = GaussianNB()\n",
        "                  models[5].fit(trainX, trainY)\n",
        "                  predictions = models[5].predict(testX)\n",
        "              \n",
        "              #scores = cross_val_score(model, data, labels, cv=5)\n",
        "              print(classification_report(testY, predictions))\n",
        "              cm = confusion_matrix(testY, predictions)\n",
        "              print(cm)\n",
        "              accuracy = accuracy_score(testY, predictions)\n",
        "              print(f\"Accuracy: {accuracy}\")\n",
        "              f1s = f1_score(testY, predictions, average=None)\n",
        "              total_f1s = np.sum(f1s)\n",
        "              print(\"Total f1 over classes: {}\".format(total_f1s))\n",
        "              balanceCode = getBalanceCode(balanceType)\n",
        "              classifierCode = getClassifierCode(analysisType)\n",
        "              turple = [experimentNumber, groupingCode, balanceCode, classifierCode, split, accuracy, total_f1s,cm.reshape([1,36]).tolist()]\n",
        "              #print(turple)\n",
        "              resultsList.append(turple)\n",
        "\n",
        "  # we use the test dataset\n",
        "  for i in range(len(models)):\n",
        "      predictions = []\n",
        "      print(\"Doing test analysis with {}\".format(analysisTypes[i]))\n",
        "      if analysisTypes[i] == \"ANN\":\n",
        "        preds = models[0].predict(testing_data, verbose=0)\n",
        "        predictions = preds.argmax(axis=1)\n",
        "      else:\n",
        "         predictions = models[i].predict(testing_data)\n",
        "\n",
        "      #print(predictions)\n",
        "      print(classification_report(testing_labels, predictions))\n",
        "      cm = confusion_matrix(testing_labels, predictions)\n",
        "      print(cm)\n",
        "      accuracy = accuracy_score(testing_labels, predictions)\n",
        "      print(f\"Accuracy: {accuracy}\")\n",
        "      f1s = f1_score(testing_labels, predictions, average=None)\n",
        "      total_f1s = np.sum(f1s)\n",
        "      print(\"Total f1 over classes: {}\".format(total_f1s))\n",
        "      #featureCode = getFeatureCode(dataFiles, addBorders)\n",
        "      balanceCode = getBalanceCode(balanceType)\n",
        "      classifierCode = getClassifierCode(analysisTypes[i])\n",
        "      turple = [experimentNumber, groupingCode, balanceCode, classifierCode,\n",
        "                accuracy, total_f1s,cm.reshape([1,36]).tolist()]\n",
        "      #print(turple)\n",
        "      testResultList.append(turple)\n",
        "\n",
        "  #print(\"****************************************************************\")\n",
        "  #print(\"EXPERIMENT VALIDATION RESULT\")\n",
        "  #print(tabulate(resultsList, headers = header))\n",
        "  with open(path+outputFilename, 'a+', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(resultsList)\n",
        "\n",
        "\n",
        "  #print(\"****************************************************************\")\n",
        "  #print(\"EXPERIMENT TEST RESULT\")\n",
        "  #print(tabulate(resultsList, headers = header))\n",
        "  name = path+\"test-\"+outputFilename\n",
        "  with open(name, 'a+', newline='') as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(testResultList)     \n",
        "\n",
        "perform_experiment('G-1', 1,data, labels,\"output.csv\")\n",
        "perform_experiment('G-1', 2,data, labels,\"output.csv\")\n",
        "perform_experiment('G-1', 3,data, labels,\"output.csv\")\n",
        "perform_experiment('G-1', 4,data, labels,\"output.csv\")\n",
        "perform_experiment('G-1', 5,data, labels,\"output.csv\")          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnIYJOr0HVsn"
      },
      "source": [
        "### Performing PCA and using it for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5Rl97bA9LO3S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec88b92-2363-4638-a2e4-5e29efc32592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained Variance: [7.448e-01 9.613e-02 6.432e-02 6.106e-02 1.481e-02 1.053e-02 6.517e-03\n",
            " 1.538e-03 2.309e-04 2.986e-05 2.337e-05]\n",
            "Shape of Transformed data:  (4401, 11)\n",
            "PCA data frame has row,columns: (4401, 11)\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.14      0.20       173\n",
            "           1       0.35      0.58      0.44       151\n",
            "           2       0.28      0.13      0.18       150\n",
            "           3       0.32      0.21      0.25       138\n",
            "           4       0.29      0.53      0.38       128\n",
            "           5       0.31      0.34      0.32       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.31      0.32      0.30       880\n",
            "weighted avg       0.31      0.32      0.29       880\n",
            "\n",
            "[[25 52  5 17 40 34]\n",
            " [14 88  3  5 27 14]\n",
            " [13 19 20 22 42 34]\n",
            " [10 38 23 29 26 12]\n",
            " [ 7 21 10  7 68 15]\n",
            " [ 9 34 10 10 29 48]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.7723192940433234\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.23      0.28       173\n",
            "           1       0.38      0.50      0.43       151\n",
            "           2       0.22      0.13      0.16       150\n",
            "           3       0.30      0.18      0.23       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.31      0.39      0.35       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.31      0.32      0.30       880\n",
            "weighted avg       0.31      0.32      0.30       880\n",
            "\n",
            "[[39 41 17 14 41 21]\n",
            " [14 75  6  3 30 23]\n",
            " [23 17 19 18 38 35]\n",
            " [14 29 22 25 26 22]\n",
            " [ 6 16 10 12 66 18]\n",
            " [12 20 11 12 31 54]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.806021440982625\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.44      0.32       173\n",
            "           1       0.43      0.32      0.37       151\n",
            "           2       0.22      0.01      0.03       150\n",
            "           3       0.41      0.15      0.22       138\n",
            "           4       0.29      0.52      0.37       128\n",
            "           5       0.28      0.35      0.31       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.31      0.30      0.27       880\n",
            "weighted avg       0.31      0.30      0.27       880\n",
            "\n",
            "[[76 21  2  3 40 31]\n",
            " [47 48  2  4 35 15]\n",
            " [60  8  2 11 33 36]\n",
            " [46 16  2 21 25 28]\n",
            " [29  9  0  7 67 16]\n",
            " [41 10  1  5 34 49]]\n",
            "Accuracy: 0.2988636363636364\n",
            "Total f1 over classes: 1.615709221606018\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.39      0.38       173\n",
            "           1       0.42      0.44      0.43       151\n",
            "           2       0.28      0.22      0.25       150\n",
            "           3       0.26      0.23      0.25       138\n",
            "           4       0.50      0.48      0.49       128\n",
            "           5       0.35      0.42      0.38       140\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.36      0.36       880\n",
            "weighted avg       0.36      0.36      0.36       880\n",
            "\n",
            "[[68 30 18 21 14 22]\n",
            " [28 67 13 10 10 23]\n",
            " [35 12 33 29 10 31]\n",
            " [26 22 26 32 14 18]\n",
            " [ 7 17  9 17 61 17]\n",
            " [25 11 19 14 12 59]]\n",
            "Accuracy: 0.36363636363636365\n",
            "Total f1 over classes: 2.1700330575844546\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.66      0.41       173\n",
            "           1       0.41      0.19      0.26       151\n",
            "           2       0.33      0.09      0.15       150\n",
            "           3       0.38      0.13      0.19       138\n",
            "           4       0.29      0.61      0.40       128\n",
            "           5       0.38      0.17      0.24       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.35      0.31      0.27       880\n",
            "weighted avg       0.35      0.32      0.28       880\n",
            "\n",
            "[[115  10   4   5  34   5]\n",
            " [ 77  29   4   2  34   5]\n",
            " [ 63   8  14  11  39  15]\n",
            " [ 65   7  13  18  29   6]\n",
            " [ 23  10   4   5  78   8]\n",
            " [ 49   6   4   6  51  24]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.6425951665895142\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.27      0.30       173\n",
            "           1       0.39      0.57      0.46       152\n",
            "           2       0.26      0.07      0.11       149\n",
            "           3       0.26      0.32      0.29       139\n",
            "           4       0.36      0.41      0.38       128\n",
            "           5       0.37      0.43      0.40       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.34      0.32       880\n",
            "\n",
            "[[46 39  7 28 30 23]\n",
            " [16 86  7 11 14 18]\n",
            " [21 30 11 43 20 24]\n",
            " [21 29 13 44 14 18]\n",
            " [15 19  3 18 53 20]\n",
            " [17 18  2 25 17 60]]\n",
            "Accuracy: 0.3409090909090909\n",
            "Total f1 over classes: 1.9405672166332406\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.20      0.23       173\n",
            "           1       0.38      0.55      0.45       152\n",
            "           2       0.19      0.07      0.10       149\n",
            "           3       0.32      0.22      0.26       139\n",
            "           4       0.28      0.55      0.37       128\n",
            "           5       0.32      0.29      0.31       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.29      0.31      0.29       880\n",
            "weighted avg       0.29      0.31      0.28       880\n",
            "\n",
            "[[35 35  5 17 61 20]\n",
            " [17 83  6  8 24 14]\n",
            " [29 23 10 21 45 21]\n",
            " [25 26 18 31 17 22]\n",
            " [10 24  1 12 70 11]\n",
            " [21 28 12  7 30 41]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.7158815620959298\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.40      0.30       173\n",
            "           1       0.41      0.24      0.31       152\n",
            "           2       0.33      0.01      0.01       149\n",
            "           3       0.35      0.32      0.33       139\n",
            "           4       0.25      0.59      0.35       128\n",
            "           5       0.38      0.19      0.25       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.33      0.29      0.26       880\n",
            "weighted avg       0.33      0.29      0.26       880\n",
            "\n",
            "[[70 18  1 20 54 10]\n",
            " [59 37  1  9 37  9]\n",
            " [45 15  1 27 56  5]\n",
            " [48  6  0 44 31 10]\n",
            " [23  8  0 13 75  9]\n",
            " [48  6  0 13 46 26]]\n",
            "Accuracy: 0.2875\n",
            "Total f1 over classes: 1.5527357311573426\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.32      0.31       173\n",
            "           1       0.44      0.53      0.48       152\n",
            "           2       0.30      0.27      0.28       149\n",
            "           3       0.34      0.29      0.32       139\n",
            "           4       0.47      0.52      0.49       128\n",
            "           5       0.42      0.38      0.40       139\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.38      0.38      0.38       880\n",
            "weighted avg       0.38      0.38      0.38       880\n",
            "\n",
            "[[55 31 30 20 17 20]\n",
            " [19 80 14 16 12 11]\n",
            " [39 26 40 16 14 14]\n",
            " [24 17 27 41 12 18]\n",
            " [12 11  9 19 66 11]\n",
            " [28 17 15  7 19 53]]\n",
            "Accuracy: 0.3806818181818182\n",
            "Total f1 over classes: 2.28388078269713\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.54      0.35       173\n",
            "           1       0.52      0.31      0.39       152\n",
            "           2       0.21      0.04      0.07       149\n",
            "           3       0.28      0.13      0.18       139\n",
            "           4       0.25      0.48      0.33       128\n",
            "           5       0.30      0.19      0.24       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.30      0.28      0.26       880\n",
            "weighted avg       0.30      0.29      0.26       880\n",
            "\n",
            "[[93 11  2 12 42 13]\n",
            " [57 47  4  6 29  9]\n",
            " [69 12  6 14 32 16]\n",
            " [53 11 13 18 30 14]\n",
            " [39  7  2  9 61 10]\n",
            " [54  3  2  6 47 27]]\n",
            "Accuracy: 0.2863636363636364\n",
            "Total f1 over classes: 1.5439079128519548\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.47      0.38       172\n",
            "           1       0.39      0.48      0.43       152\n",
            "           2       0.33      0.07      0.11       149\n",
            "           3       0.32      0.27      0.29       139\n",
            "           4       0.43      0.51      0.47       129\n",
            "           5       0.43      0.44      0.43       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.35       880\n",
            "weighted avg       0.37      0.37      0.35       880\n",
            "\n",
            "[[80 35  4 22 14 17]\n",
            " [35 73  2 11 14 17]\n",
            " [46 22 10 32 22 17]\n",
            " [40 19  8 37 20 15]\n",
            " [21 18  2  6 66 16]\n",
            " [32 18  4  6 18 61]]\n",
            "Accuracy: 0.3715909090909091\n",
            "Total f1 over classes: 2.1120984468591106\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.28      0.31       172\n",
            "           1       0.40      0.53      0.46       152\n",
            "           2       0.37      0.15      0.21       149\n",
            "           3       0.29      0.20      0.24       139\n",
            "           4       0.31      0.54      0.39       129\n",
            "           5       0.34      0.38      0.36       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.33       880\n",
            "weighted avg       0.34      0.34      0.33       880\n",
            "\n",
            "[[48 41  8 22 30 23]\n",
            " [26 81  4 11 15 15]\n",
            " [13 21 22 20 47 26]\n",
            " [20 21 17 28 32 21]\n",
            " [13 19  1  8 70 18]\n",
            " [19 21  7  7 32 53]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 1.967262416761295\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.20      0.24       172\n",
            "           1       0.48      0.19      0.27       152\n",
            "           2       0.40      0.03      0.05       149\n",
            "           3       0.41      0.12      0.18       139\n",
            "           4       0.27      0.27      0.27       129\n",
            "           5       0.22      0.84      0.35       139\n",
            "\n",
            "    accuracy                           0.27       880\n",
            "   macro avg       0.35      0.27      0.23       880\n",
            "weighted avg       0.35      0.27      0.23       880\n",
            "\n",
            "[[ 34  10   0   3  21 104]\n",
            " [ 27  29   2   5  21  68]\n",
            " [ 16  10   4  10  25  84]\n",
            " [ 14   4   3  16  20  82]\n",
            " [  9   7   1   3  35  74]\n",
            " [ 12   0   0   2   8 117]]\n",
            "Accuracy: 0.26704545454545453\n",
            "Total f1 over classes: 1.3636809431542438\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       172\n",
            "           1       0.40      0.49      0.44       152\n",
            "           2       0.34      0.24      0.28       149\n",
            "           3       0.24      0.22      0.23       139\n",
            "           4       0.45      0.44      0.45       129\n",
            "           5       0.42      0.51      0.46       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[58 32 29 22  8 23]\n",
            " [27 74  7 17 11 16]\n",
            " [22 24 36 30 22 15]\n",
            " [27 20 22 30 16 24]\n",
            " [14 23  3 11 57 21]\n",
            " [21 10 10 14 13 71]]\n",
            "Accuracy: 0.3704545454545455\n",
            "Total f1 over classes: 2.196213305550919\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.57      0.37       172\n",
            "           1       0.42      0.30      0.35       152\n",
            "           2       0.43      0.06      0.11       149\n",
            "           3       0.26      0.25      0.26       139\n",
            "           4       0.28      0.43      0.34       129\n",
            "           5       0.35      0.14      0.20       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.34      0.29      0.27       880\n",
            "weighted avg       0.34      0.30      0.27       880\n",
            "\n",
            "[[98 21  1 30 18  4]\n",
            " [64 46  2 17 17  6]\n",
            " [52 15  9 27 36 10]\n",
            " [53 10  5 35 26 10]\n",
            " [37 15  2 15 55  5]\n",
            " [60  2  2 11 45 19]]\n",
            "Accuracy: 0.29772727272727273\n",
            "Total f1 over classes: 1.6138333733361845\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.33      0.31       173\n",
            "           1       0.48      0.49      0.49       152\n",
            "           2       0.43      0.29      0.35       149\n",
            "           3       0.38      0.30      0.34       138\n",
            "           4       0.46      0.50      0.48       128\n",
            "           5       0.41      0.52      0.46       140\n",
            "\n",
            "    accuracy                           0.40       880\n",
            "   macro avg       0.41      0.41      0.40       880\n",
            "weighted avg       0.40      0.40      0.40       880\n",
            "\n",
            "[[57 33 18 23 14 28]\n",
            " [32 75  5 11  9 20]\n",
            " [33 16 43 20 18 19]\n",
            " [38 11 19 42 16 12]\n",
            " [11 16  3  7 64 27]\n",
            " [24  6 11  8 18 73]]\n",
            "Accuracy: 0.4022727272727273\n",
            "Total f1 over classes: 2.416424092885654\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.23      0.24       173\n",
            "           1       0.41      0.53      0.47       152\n",
            "           2       0.33      0.14      0.20       149\n",
            "           3       0.32      0.24      0.28       138\n",
            "           4       0.31      0.53      0.40       128\n",
            "           5       0.33      0.36      0.35       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[39 42 15 15 32 30]\n",
            " [26 81  2  9 20 14]\n",
            " [18 20 21 30 34 26]\n",
            " [27 14 16 33 30 18]\n",
            " [13 22  2  7 68 16]\n",
            " [25 17  7  8 32 51]]\n",
            "Accuracy: 0.33295454545454545\n",
            "Total f1 over classes: 1.9227326522057968\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.40      0.28       173\n",
            "           1       0.41      0.47      0.44       152\n",
            "           2       0.23      0.18      0.20       149\n",
            "           3       0.29      0.13      0.18       138\n",
            "           4       0.42      0.32      0.36       128\n",
            "           5       0.36      0.26      0.30       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.32      0.29      0.29       880\n",
            "weighted avg       0.32      0.30      0.29       880\n",
            "\n",
            "[[70 41 32  6  6 18]\n",
            " [50 72  9  2 10  9]\n",
            " [55 20 27 25  4 18]\n",
            " [50 15 29 18 14 12]\n",
            " [54 15  4  7 41  7]\n",
            " [46 14 18  4 22 36]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.7647514493547083\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.26      0.27       173\n",
            "           1       0.43      0.53      0.48       152\n",
            "           2       0.30      0.23      0.27       149\n",
            "           3       0.31      0.25      0.27       138\n",
            "           4       0.47      0.47      0.47       128\n",
            "           5       0.40      0.51      0.45       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.36      0.38      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[45 37 23 22 13 33]\n",
            " [20 81 12 10  9 20]\n",
            " [38 20 35 27 13 16]\n",
            " [21 15 28 34 20 20]\n",
            " [10 20  8 11 60 19]\n",
            " [25 15  9  7 13 71]]\n",
            "Accuracy: 0.3704545454545455\n",
            "Total f1 over classes: 2.1996898760448396\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.61      0.37       173\n",
            "           1       0.51      0.30      0.37       152\n",
            "           2       0.47      0.06      0.11       149\n",
            "           3       0.30      0.22      0.25       138\n",
            "           4       0.29      0.41      0.34       128\n",
            "           5       0.31      0.19      0.23       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.36      0.30      0.28       880\n",
            "weighted avg       0.36      0.30      0.28       880\n",
            "\n",
            "[[106  13   0  14  24  16]\n",
            " [ 72  45   3  10  15   7]\n",
            " [ 65   9   9  30  22  14]\n",
            " [ 56   6   3  30  29  14]\n",
            " [ 50   9   1   8  52   8]\n",
            " [ 57   6   3   9  39  26]]\n",
            "Accuracy: 0.30454545454545456\n",
            "Total f1 over classes: 1.6670181045982373\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.36      0.30       149\n",
            "           1       0.43      0.39      0.41       154\n",
            "           2       0.32      0.20      0.25       157\n",
            "           3       0.28      0.21      0.24       143\n",
            "           4       0.39      0.43      0.41       138\n",
            "           5       0.33      0.39      0.36       140\n",
            "\n",
            "    accuracy                           0.33       881\n",
            "   macro avg       0.33      0.33      0.33       881\n",
            "weighted avg       0.33      0.33      0.33       881\n",
            "\n",
            "[[54 20 12 14 14 35]\n",
            " [38 60  7 13 19 17]\n",
            " [44 11 32 29 26 15]\n",
            " [32 21 19 30 15 26]\n",
            " [20 18 13  8 60 19]\n",
            " [26 10 18 13 18 55]]\n",
            "Accuracy: 0.33030646992054485\n",
            "Total f1 over classes: 1.9658452343403803\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       149\n",
            "           1       0.35      0.44      0.39       154\n",
            "           2       0.33      0.13      0.19       157\n",
            "           3       0.23      0.17      0.19       143\n",
            "           4       0.28      0.44      0.34       138\n",
            "           5       0.27      0.29      0.28       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.29      0.29      0.28       881\n",
            "\n",
            "[[40 32  6 12 30 29]\n",
            " [26 67  4 11 26 20]\n",
            " [31 18 21 30 39 18]\n",
            " [21 28 16 24 31 23]\n",
            " [18 22  4 16 61 17]\n",
            " [19 26 12 11 32 40]]\n",
            "Accuracy: 0.28717366628830876\n",
            "Total f1 over classes: 1.6550484557028389\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.45      0.28       149\n",
            "           1       0.34      0.36      0.35       154\n",
            "           2       0.25      0.23      0.24       157\n",
            "           3       0.28      0.13      0.17       143\n",
            "           4       0.33      0.22      0.26       138\n",
            "           5       0.24      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.26       881\n",
            "   macro avg       0.27      0.25      0.25       881\n",
            "weighted avg       0.27      0.26      0.25       881\n",
            "\n",
            "[[67 26 22  5 12 17]\n",
            " [53 56 14 10 12  9]\n",
            " [60 20 36 21  8 12]\n",
            " [41 27 30 18 10 17]\n",
            " [60 18 14  8 30  8]\n",
            " [54 16 27  3 20 20]]\n",
            "Accuracy: 0.2576617480136209\n",
            "Total f1 over classes: 1.4834904925750796\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.36      0.32       149\n",
            "           1       0.41      0.47      0.44       154\n",
            "           2       0.34      0.24      0.28       157\n",
            "           3       0.27      0.25      0.26       143\n",
            "           4       0.44      0.39      0.41       138\n",
            "           5       0.37      0.41      0.39       140\n",
            "\n",
            "    accuracy                           0.35       881\n",
            "   macro avg       0.35      0.35      0.35       881\n",
            "weighted avg       0.35      0.35      0.35       881\n",
            "\n",
            "[[53 23 14 16 11 32]\n",
            " [28 73 11 14 15 13]\n",
            " [30 24 38 34 16 15]\n",
            " [26 20 24 36 15 22]\n",
            " [12 22 12 22 54 16]\n",
            " [32 17 12  9 13 57]]\n",
            "Accuracy: 0.3530079455164586\n",
            "Total f1 over classes: 2.104660790254653\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.64      0.35       149\n",
            "           1       0.43      0.32      0.37       154\n",
            "           2       0.18      0.02      0.03       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.29      0.37      0.33       138\n",
            "           5       0.26      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.28      0.28      0.25       881\n",
            "weighted avg       0.28      0.28      0.25       881\n",
            "\n",
            "[[95 11  0 14 20  9]\n",
            " [59 50  1 13 22  9]\n",
            " [70 16  3 32 21 15]\n",
            " [51 16  7 28 30 11]\n",
            " [45 12  4 15 51 11]\n",
            " [70 10  2 10 29 19]]\n",
            "Accuracy: 0.2792281498297389\n",
            "Total f1 over classes: 1.4838868218580543\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.16      0.21       173\n",
            "           1       0.33      0.54      0.41       151\n",
            "           2       0.25      0.26      0.25       150\n",
            "           3       0.31      0.19      0.24       138\n",
            "           4       0.41      0.38      0.40       128\n",
            "           5       0.34      0.43      0.38       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.32      0.33      0.31       880\n",
            "weighted avg       0.32      0.32      0.31       880\n",
            "\n",
            "[[28 50 34 13 21 27]\n",
            " [17 82 20  3 12 17]\n",
            " [16 27 39 19 16 33]\n",
            " [15 38 33 26  8 18]\n",
            " [12 28 11  9 49 19]\n",
            " [10 22 21 13 14 60]]\n",
            "Accuracy: 0.32272727272727275\n",
            "Total f1 over classes: 1.884570134240136\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.23      0.28       173\n",
            "           1       0.38      0.50      0.43       151\n",
            "           2       0.22      0.13      0.16       150\n",
            "           3       0.30      0.18      0.23       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.31      0.39      0.35       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.31      0.32      0.30       880\n",
            "weighted avg       0.31      0.32      0.30       880\n",
            "\n",
            "[[39 41 17 14 41 21]\n",
            " [14 75  6  3 30 23]\n",
            " [23 17 19 18 38 35]\n",
            " [14 29 22 25 26 22]\n",
            " [ 6 16 10 12 66 18]\n",
            " [12 20 11 12 31 54]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.806021440982625\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.44      0.32       173\n",
            "           1       0.43      0.32      0.37       151\n",
            "           2       0.22      0.01      0.03       150\n",
            "           3       0.41      0.15      0.22       138\n",
            "           4       0.29      0.52      0.37       128\n",
            "           5       0.28      0.35      0.31       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.31      0.30      0.27       880\n",
            "weighted avg       0.31      0.30      0.27       880\n",
            "\n",
            "[[76 21  2  3 40 31]\n",
            " [47 48  2  4 35 15]\n",
            " [60  8  2 11 33 36]\n",
            " [46 16  2 21 25 28]\n",
            " [29  9  0  7 67 16]\n",
            " [41 10  1  5 34 49]]\n",
            "Accuracy: 0.2988636363636364\n",
            "Total f1 over classes: 1.615709221606018\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.34      0.34       173\n",
            "           1       0.42      0.44      0.43       151\n",
            "           2       0.26      0.20      0.23       150\n",
            "           3       0.29      0.27      0.28       138\n",
            "           4       0.54      0.52      0.53       128\n",
            "           5       0.37      0.47      0.42       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.37       880\n",
            "\n",
            "[[59 32 19 20 14 29]\n",
            " [29 67 16 10 10 19]\n",
            " [39 14 30 31 10 26]\n",
            " [21 22 24 37 12 22]\n",
            " [10 14 10 12 66 16]\n",
            " [20 11 16 16 11 66]]\n",
            "Accuracy: 0.3693181818181818\n",
            "Total f1 over classes: 2.2147593819928324\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.66      0.41       173\n",
            "           1       0.41      0.19      0.26       151\n",
            "           2       0.33      0.09      0.15       150\n",
            "           3       0.38      0.13      0.19       138\n",
            "           4       0.29      0.61      0.40       128\n",
            "           5       0.38      0.17      0.24       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.35      0.31      0.27       880\n",
            "weighted avg       0.35      0.32      0.28       880\n",
            "\n",
            "[[115  10   4   5  34   5]\n",
            " [ 77  29   4   2  34   5]\n",
            " [ 63   8  14  11  39  15]\n",
            " [ 65   7  13  18  29   6]\n",
            " [ 23  10   4   5  78   8]\n",
            " [ 49   6   4   6  51  24]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.6425951665895142\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.29      0.29       173\n",
            "           1       0.42      0.62      0.50       152\n",
            "           2       0.22      0.07      0.11       149\n",
            "           3       0.40      0.19      0.26       139\n",
            "           4       0.32      0.62      0.42       128\n",
            "           5       0.44      0.37      0.40       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.35      0.36      0.33       880\n",
            "weighted avg       0.35      0.36      0.33       880\n",
            "\n",
            "[[51 36  9 10 53 14]\n",
            " [22 94  5  4 19  8]\n",
            " [39 27 11 16 39 17]\n",
            " [23 29 15 27 27 18]\n",
            " [20 13  1  5 79 10]\n",
            " [19 23  9  6 30 52]]\n",
            "Accuracy: 0.3568181818181818\n",
            "Total f1 over classes: 1.9924783611562153\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.20      0.23       173\n",
            "           1       0.38      0.55      0.45       152\n",
            "           2       0.19      0.07      0.10       149\n",
            "           3       0.32      0.22      0.26       139\n",
            "           4       0.28      0.55      0.37       128\n",
            "           5       0.32      0.29      0.31       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.29      0.31      0.29       880\n",
            "weighted avg       0.29      0.31      0.28       880\n",
            "\n",
            "[[35 35  5 17 61 20]\n",
            " [17 83  6  8 24 14]\n",
            " [29 23 10 21 45 21]\n",
            " [25 26 18 31 17 22]\n",
            " [10 24  1 12 70 11]\n",
            " [21 28 12  7 30 41]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.7158815620959298\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.40      0.30       173\n",
            "           1       0.41      0.24      0.31       152\n",
            "           2       0.33      0.01      0.01       149\n",
            "           3       0.35      0.32      0.33       139\n",
            "           4       0.25      0.59      0.35       128\n",
            "           5       0.38      0.19      0.25       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.33      0.29      0.26       880\n",
            "weighted avg       0.33      0.29      0.26       880\n",
            "\n",
            "[[70 18  1 20 54 10]\n",
            " [59 37  1  9 37  9]\n",
            " [45 15  1 27 56  5]\n",
            " [48  6  0 44 31 10]\n",
            " [23  8  0 13 75  9]\n",
            " [48  6  0 13 46 26]]\n",
            "Accuracy: 0.2875\n",
            "Total f1 over classes: 1.5527357311573426\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.29      0.30       173\n",
            "           1       0.41      0.51      0.45       152\n",
            "           2       0.30      0.26      0.28       149\n",
            "           3       0.33      0.29      0.31       139\n",
            "           4       0.47      0.51      0.49       128\n",
            "           5       0.42      0.42      0.42       139\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[51 38 28 26 15 15]\n",
            " [25 77 12 13 13 12]\n",
            " [31 26 38 20 16 18]\n",
            " [19 23 26 41 11 19]\n",
            " [11 12  8 15 65 17]\n",
            " [26 14 15  9 17 58]]\n",
            "Accuracy: 0.375\n",
            "Total f1 over classes: 2.248845442102382\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.54      0.35       173\n",
            "           1       0.52      0.31      0.39       152\n",
            "           2       0.21      0.04      0.07       149\n",
            "           3       0.28      0.13      0.18       139\n",
            "           4       0.25      0.48      0.33       128\n",
            "           5       0.30      0.19      0.24       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.30      0.28      0.26       880\n",
            "weighted avg       0.30      0.29      0.26       880\n",
            "\n",
            "[[93 11  2 12 42 13]\n",
            " [57 47  4  6 29  9]\n",
            " [69 12  6 14 32 16]\n",
            " [53 11 13 18 30 14]\n",
            " [39  7  2  9 61 10]\n",
            " [54  3  2  6 47 27]]\n",
            "Accuracy: 0.2863636363636364\n",
            "Total f1 over classes: 1.5439079128519548\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.37      0.37       172\n",
            "           1       0.39      0.58      0.47       152\n",
            "           2       0.32      0.19      0.24       149\n",
            "           3       0.34      0.18      0.23       139\n",
            "           4       0.43      0.39      0.41       129\n",
            "           5       0.36      0.52      0.42       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.36       880\n",
            "weighted avg       0.37      0.37      0.36       880\n",
            "\n",
            "[[64 43 19 12 10 24]\n",
            " [25 88  8  6  8 17]\n",
            " [25 27 28 21 20 28]\n",
            " [27 23 21 25 14 29]\n",
            " [16 22  6  4 50 31]\n",
            " [21 21  5  6 14 72]]\n",
            "Accuracy: 0.3715909090909091\n",
            "Total f1 over classes: 2.1375219887988717\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.28      0.31       172\n",
            "           1       0.40      0.53      0.46       152\n",
            "           2       0.37      0.15      0.21       149\n",
            "           3       0.29      0.20      0.24       139\n",
            "           4       0.31      0.54      0.39       129\n",
            "           5       0.34      0.38      0.36       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.33       880\n",
            "weighted avg       0.34      0.34      0.33       880\n",
            "\n",
            "[[48 41  8 22 30 23]\n",
            " [26 81  4 11 15 15]\n",
            " [13 21 22 20 47 26]\n",
            " [20 21 17 28 32 21]\n",
            " [13 19  1  8 70 18]\n",
            " [19 21  7  7 32 53]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 1.967262416761295\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.20      0.24       172\n",
            "           1       0.48      0.19      0.27       152\n",
            "           2       0.40      0.03      0.05       149\n",
            "           3       0.41      0.12      0.18       139\n",
            "           4       0.27      0.27      0.27       129\n",
            "           5       0.22      0.84      0.35       139\n",
            "\n",
            "    accuracy                           0.27       880\n",
            "   macro avg       0.35      0.27      0.23       880\n",
            "weighted avg       0.35      0.27      0.23       880\n",
            "\n",
            "[[ 34  10   0   3  21 104]\n",
            " [ 27  29   2   5  21  68]\n",
            " [ 16  10   4  10  25  84]\n",
            " [ 14   4   3  16  20  82]\n",
            " [  9   7   1   3  35  74]\n",
            " [ 12   0   0   2   8 117]]\n",
            "Accuracy: 0.26704545454545453\n",
            "Total f1 over classes: 1.3636809431542438\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.30      0.31       172\n",
            "           1       0.41      0.49      0.44       152\n",
            "           2       0.35      0.25      0.29       149\n",
            "           3       0.24      0.23      0.24       139\n",
            "           4       0.46      0.45      0.45       129\n",
            "           5       0.42      0.51      0.46       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[52 35 29 25  7 24]\n",
            " [29 74  7 15 12 15]\n",
            " [25 21 37 33 19 14]\n",
            " [25 21 18 32 19 24]\n",
            " [12 21  3 12 58 23]\n",
            " [21  9 11 16 11 71]]\n",
            "Accuracy: 0.36818181818181817\n",
            "Total f1 over classes: 2.193567431205824\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.57      0.37       172\n",
            "           1       0.42      0.30      0.35       152\n",
            "           2       0.43      0.06      0.11       149\n",
            "           3       0.26      0.25      0.26       139\n",
            "           4       0.28      0.43      0.34       129\n",
            "           5       0.35      0.14      0.20       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.34      0.29      0.27       880\n",
            "weighted avg       0.34      0.30      0.27       880\n",
            "\n",
            "[[98 21  1 30 18  4]\n",
            " [64 46  2 17 17  6]\n",
            " [52 15  9 27 36 10]\n",
            " [53 10  5 35 26 10]\n",
            " [37 15  2 15 55  5]\n",
            " [60  2  2 11 45 19]]\n",
            "Accuracy: 0.29772727272727273\n",
            "Total f1 over classes: 1.6138333733361845\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.21      0.25       173\n",
            "           1       0.44      0.57      0.50       152\n",
            "           2       0.43      0.22      0.29       149\n",
            "           3       0.34      0.34      0.34       138\n",
            "           4       0.42      0.59      0.49       128\n",
            "           5       0.37      0.44      0.40       140\n",
            "\n",
            "    accuracy                           0.39       880\n",
            "   macro avg       0.38      0.40      0.38       880\n",
            "weighted avg       0.38      0.39      0.37       880\n",
            "\n",
            "[[36 40 13 30 27 27]\n",
            " [17 87  4 14 13 17]\n",
            " [18 20 33 26 31 21]\n",
            " [19 18 17 47 18 19]\n",
            " [ 7 15  3  6 76 21]\n",
            " [23 16  6 15 18 62]]\n",
            "Accuracy: 0.3875\n",
            "Total f1 over classes: 2.272301607369834\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.23      0.24       173\n",
            "           1       0.41      0.53      0.47       152\n",
            "           2       0.33      0.14      0.20       149\n",
            "           3       0.32      0.24      0.28       138\n",
            "           4       0.31      0.53      0.40       128\n",
            "           5       0.33      0.36      0.35       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[39 42 15 15 32 30]\n",
            " [26 81  2  9 20 14]\n",
            " [18 20 21 30 34 26]\n",
            " [27 14 16 33 30 18]\n",
            " [13 22  2  7 68 16]\n",
            " [25 17  7  8 32 51]]\n",
            "Accuracy: 0.33295454545454545\n",
            "Total f1 over classes: 1.9227326522057968\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.40      0.28       173\n",
            "           1       0.41      0.47      0.44       152\n",
            "           2       0.23      0.18      0.20       149\n",
            "           3       0.29      0.13      0.18       138\n",
            "           4       0.42      0.32      0.36       128\n",
            "           5       0.36      0.26      0.30       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.32      0.29      0.29       880\n",
            "weighted avg       0.32      0.30      0.29       880\n",
            "\n",
            "[[70 41 32  6  6 18]\n",
            " [50 72  9  2 10  9]\n",
            " [55 20 27 25  4 18]\n",
            " [50 15 29 18 14 12]\n",
            " [54 15  4  7 41  7]\n",
            " [46 14 18  4 22 36]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.7647514493547083\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.25      0.28       173\n",
            "           1       0.42      0.53      0.47       152\n",
            "           2       0.31      0.23      0.27       149\n",
            "           3       0.30      0.28      0.29       138\n",
            "           4       0.48      0.48      0.48       128\n",
            "           5       0.39      0.49      0.43       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[44 42 23 19 12 33]\n",
            " [21 80 12 12 11 16]\n",
            " [23 20 35 37 12 22]\n",
            " [23 13 28 38 18 18]\n",
            " [12 18  4 13 62 19]\n",
            " [23 17 10  9 13 68]]\n",
            "Accuracy: 0.3715909090909091\n",
            "Total f1 over classes: 2.2123665925416627\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.61      0.37       173\n",
            "           1       0.51      0.30      0.37       152\n",
            "           2       0.47      0.06      0.11       149\n",
            "           3       0.30      0.22      0.25       138\n",
            "           4       0.29      0.41      0.34       128\n",
            "           5       0.31      0.19      0.23       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.36      0.30      0.28       880\n",
            "weighted avg       0.36      0.30      0.28       880\n",
            "\n",
            "[[106  13   0  14  24  16]\n",
            " [ 72  45   3  10  15   7]\n",
            " [ 65   9   9  30  22  14]\n",
            " [ 56   6   3  30  29  14]\n",
            " [ 50   9   1   8  52   8]\n",
            " [ 57   6   3   9  39  26]]\n",
            "Accuracy: 0.30454545454545456\n",
            "Total f1 over classes: 1.6670181045982373\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.30      0.30       149\n",
            "           1       0.39      0.48      0.43       154\n",
            "           2       0.33      0.18      0.23       157\n",
            "           3       0.20      0.17      0.19       143\n",
            "           4       0.37      0.47      0.41       138\n",
            "           5       0.35      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       881\n",
            "   macro avg       0.32      0.33      0.32       881\n",
            "weighted avg       0.32      0.33      0.32       881\n",
            "\n",
            "[[45 24 13 23 14 30]\n",
            " [24 74  9 11 19 17]\n",
            " [27 23 28 35 30 14]\n",
            " [20 27 21 25 28 22]\n",
            " [16 25  5 10 65 17]\n",
            " [16 17  9 22 22 54]]\n",
            "Accuracy: 0.33030646992054485\n",
            "Total f1 over classes: 1.9292807696342806\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       149\n",
            "           1       0.35      0.44      0.39       154\n",
            "           2       0.33      0.13      0.19       157\n",
            "           3       0.23      0.17      0.19       143\n",
            "           4       0.28      0.44      0.34       138\n",
            "           5       0.27      0.29      0.28       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.29      0.29      0.28       881\n",
            "\n",
            "[[40 32  6 12 30 29]\n",
            " [26 67  4 11 26 20]\n",
            " [31 18 21 30 39 18]\n",
            " [21 28 16 24 31 23]\n",
            " [18 22  4 16 61 17]\n",
            " [19 26 12 11 32 40]]\n",
            "Accuracy: 0.28717366628830876\n",
            "Total f1 over classes: 1.6550484557028389\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.45      0.28       149\n",
            "           1       0.34      0.36      0.35       154\n",
            "           2       0.25      0.23      0.24       157\n",
            "           3       0.28      0.13      0.17       143\n",
            "           4       0.33      0.22      0.26       138\n",
            "           5       0.24      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.26       881\n",
            "   macro avg       0.27      0.25      0.25       881\n",
            "weighted avg       0.27      0.26      0.25       881\n",
            "\n",
            "[[67 26 22  5 12 17]\n",
            " [53 56 14 10 12  9]\n",
            " [60 20 36 21  8 12]\n",
            " [41 27 30 18 10 17]\n",
            " [60 18 14  8 30  8]\n",
            " [54 16 27  3 20 20]]\n",
            "Accuracy: 0.2576617480136209\n",
            "Total f1 over classes: 1.4834904925750796\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.32      0.29       149\n",
            "           1       0.40      0.46      0.43       154\n",
            "           2       0.34      0.24      0.28       157\n",
            "           3       0.23      0.20      0.22       143\n",
            "           4       0.43      0.39      0.41       138\n",
            "           5       0.34      0.39      0.36       140\n",
            "\n",
            "    accuracy                           0.33       881\n",
            "   macro avg       0.33      0.33      0.33       881\n",
            "weighted avg       0.33      0.33      0.33       881\n",
            "\n",
            "[[47 26 14 18 12 32]\n",
            " [27 71  9 16 13 18]\n",
            " [28 20 38 39 16 16]\n",
            " [29 25 23 29 16 21]\n",
            " [14 21 11 16 54 22]\n",
            " [30 15 18  8 14 55]]\n",
            "Accuracy: 0.3337116912599319\n",
            "Total f1 over classes: 1.9874176576405846\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.64      0.35       149\n",
            "           1       0.43      0.32      0.37       154\n",
            "           2       0.18      0.02      0.03       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.29      0.37      0.33       138\n",
            "           5       0.26      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.28      0.28      0.25       881\n",
            "weighted avg       0.28      0.28      0.25       881\n",
            "\n",
            "[[95 11  0 14 20  9]\n",
            " [59 50  1 13 22  9]\n",
            " [70 16  3 32 21 15]\n",
            " [51 16  7 28 30 11]\n",
            " [45 12  4 15 51 11]\n",
            " [70 10  2 10 29 19]]\n",
            "Accuracy: 0.2792281498297389\n",
            "Total f1 over classes: 1.4838868218580543\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.12      0.17       173\n",
            "           1       0.39      0.52      0.45       151\n",
            "           2       0.23      0.45      0.31       150\n",
            "           3       0.34      0.14      0.20       138\n",
            "           4       0.40      0.38      0.39       128\n",
            "           5       0.38      0.41      0.39       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.34      0.33      0.32       880\n",
            "weighted avg       0.34      0.33      0.31       880\n",
            "\n",
            "[[20 39 66  9 17 22]\n",
            " [10 78 32  2 15 14]\n",
            " [13 18 67 10 17 25]\n",
            " [ 7 29 56 19 13 14]\n",
            " [ 7 19 27  9 48 18]\n",
            " [11 15 40  7 10 57]]\n",
            "Accuracy: 0.32840909090909093\n",
            "Total f1 over classes: 1.894979091934466\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.23      0.28       173\n",
            "           1       0.38      0.50      0.43       151\n",
            "           2       0.22      0.13      0.16       150\n",
            "           3       0.30      0.18      0.23       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.31      0.39      0.35       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.31      0.32      0.30       880\n",
            "weighted avg       0.31      0.32      0.30       880\n",
            "\n",
            "[[39 41 17 14 41 21]\n",
            " [14 75  6  3 30 23]\n",
            " [23 17 19 18 38 35]\n",
            " [14 29 22 25 26 22]\n",
            " [ 6 16 10 12 66 18]\n",
            " [12 20 11 12 31 54]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.806021440982625\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.44      0.32       173\n",
            "           1       0.43      0.32      0.37       151\n",
            "           2       0.22      0.01      0.03       150\n",
            "           3       0.41      0.15      0.22       138\n",
            "           4       0.29      0.52      0.37       128\n",
            "           5       0.28      0.35      0.31       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.31      0.30      0.27       880\n",
            "weighted avg       0.31      0.30      0.27       880\n",
            "\n",
            "[[76 21  2  3 40 31]\n",
            " [47 48  2  4 35 15]\n",
            " [60  8  2 11 33 36]\n",
            " [46 16  2 21 25 28]\n",
            " [29  9  0  7 67 16]\n",
            " [41 10  1  5 34 49]]\n",
            "Accuracy: 0.2988636363636364\n",
            "Total f1 over classes: 1.615709221606018\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.40      0.39       173\n",
            "           1       0.46      0.47      0.46       151\n",
            "           2       0.32      0.23      0.27       150\n",
            "           3       0.29      0.28      0.29       138\n",
            "           4       0.50      0.51      0.50       128\n",
            "           5       0.34      0.42      0.38       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.38      0.39      0.38       880\n",
            "weighted avg       0.38      0.38      0.38       880\n",
            "\n",
            "[[69 25 17 22 17 23]\n",
            " [26 71 12 10 11 21]\n",
            " [37 15 35 25 13 25]\n",
            " [20 19 23 39 12 25]\n",
            " [ 4 14  8 18 65 19]\n",
            " [24 11 15 19 12 59]]\n",
            "Accuracy: 0.3840909090909091\n",
            "Total f1 over classes: 2.294121876431262\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.66      0.41       173\n",
            "           1       0.41      0.19      0.26       151\n",
            "           2       0.33      0.09      0.15       150\n",
            "           3       0.38      0.13      0.19       138\n",
            "           4       0.29      0.61      0.40       128\n",
            "           5       0.38      0.17      0.24       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.35      0.31      0.27       880\n",
            "weighted avg       0.35      0.32      0.28       880\n",
            "\n",
            "[[115  10   4   5  34   5]\n",
            " [ 77  29   4   2  34   5]\n",
            " [ 63   8  14  11  39  15]\n",
            " [ 65   7  13  18  29   6]\n",
            " [ 23  10   4   5  78   8]\n",
            " [ 49   6   4   6  51  24]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.6425951665895142\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.24      0.27       173\n",
            "           1       0.38      0.59      0.46       152\n",
            "           2       0.28      0.17      0.21       149\n",
            "           3       0.33      0.24      0.28       139\n",
            "           4       0.31      0.51      0.38       128\n",
            "           5       0.46      0.33      0.38       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.33       880\n",
            "weighted avg       0.34      0.34      0.33       880\n",
            "\n",
            "[[42 43  8 18 49 13]\n",
            " [13 90 15  5 20  9]\n",
            " [25 32 26 22 33 11]\n",
            " [21 28 25 33 22 10]\n",
            " [12 23  6 10 65 12]\n",
            " [21 23 13 12 24 46]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 1.9895653570056373\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.20      0.23       173\n",
            "           1       0.38      0.55      0.45       152\n",
            "           2       0.19      0.07      0.10       149\n",
            "           3       0.32      0.22      0.26       139\n",
            "           4       0.28      0.55      0.37       128\n",
            "           5       0.32      0.29      0.31       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.29      0.31      0.29       880\n",
            "weighted avg       0.29      0.31      0.28       880\n",
            "\n",
            "[[35 35  5 17 61 20]\n",
            " [17 83  6  8 24 14]\n",
            " [29 23 10 21 45 21]\n",
            " [25 26 18 31 17 22]\n",
            " [10 24  1 12 70 11]\n",
            " [21 28 12  7 30 41]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.7158815620959298\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.40      0.30       173\n",
            "           1       0.41      0.24      0.31       152\n",
            "           2       0.33      0.01      0.01       149\n",
            "           3       0.35      0.32      0.33       139\n",
            "           4       0.25      0.59      0.35       128\n",
            "           5       0.38      0.19      0.25       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.33      0.29      0.26       880\n",
            "weighted avg       0.33      0.29      0.26       880\n",
            "\n",
            "[[70 18  1 20 54 10]\n",
            " [59 37  1  9 37  9]\n",
            " [45 15  1 27 56  5]\n",
            " [48  6  0 44 31 10]\n",
            " [23  8  0 13 75  9]\n",
            " [48  6  0 13 46 26]]\n",
            "Accuracy: 0.2875\n",
            "Total f1 over classes: 1.5527357311573426\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.32      0.32       173\n",
            "           1       0.41      0.49      0.44       152\n",
            "           2       0.30      0.26      0.28       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.46      0.50      0.48       128\n",
            "           5       0.40      0.40      0.40       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.37       880\n",
            "\n",
            "[[55 32 27 21 18 20]\n",
            " [29 74 12 13 10 14]\n",
            " [35 26 39 17 17 15]\n",
            " [17 21 28 38 13 22]\n",
            " [ 9 12 10 20 64 13]\n",
            " [27 17 12 12 16 55]]\n",
            "Accuracy: 0.3693181818181818\n",
            "Total f1 over classes: 2.2127369528825636\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.54      0.35       173\n",
            "           1       0.52      0.31      0.39       152\n",
            "           2       0.21      0.04      0.07       149\n",
            "           3       0.28      0.13      0.18       139\n",
            "           4       0.25      0.48      0.33       128\n",
            "           5       0.30      0.19      0.24       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.30      0.28      0.26       880\n",
            "weighted avg       0.30      0.29      0.26       880\n",
            "\n",
            "[[93 11  2 12 42 13]\n",
            " [57 47  4  6 29  9]\n",
            " [69 12  6 14 32 16]\n",
            " [53 11 13 18 30 14]\n",
            " [39  7  2  9 61 10]\n",
            " [54  3  2  6 47 27]]\n",
            "Accuracy: 0.2863636363636364\n",
            "Total f1 over classes: 1.5439079128519548\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.38      0.35       172\n",
            "           1       0.42      0.41      0.42       152\n",
            "           2       0.33      0.11      0.17       149\n",
            "           3       0.28      0.32      0.30       139\n",
            "           4       0.35      0.50      0.41       129\n",
            "           5       0.38      0.36      0.37       139\n",
            "\n",
            "    accuracy                           0.35       880\n",
            "   macro avg       0.35      0.35      0.34       880\n",
            "weighted avg       0.35      0.35      0.33       880\n",
            "\n",
            "[[65 28  8 31 19 21]\n",
            " [30 63  2 21 17 19]\n",
            " [32 19 17 38 29 14]\n",
            " [31 18 13 45 21 11]\n",
            " [22 13  2 11 64 17]\n",
            " [23 10 10 14 32 50]]\n",
            "Accuracy: 0.34545454545454546\n",
            "Total f1 over classes: 2.013245076900274\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.28      0.31       172\n",
            "           1       0.40      0.53      0.46       152\n",
            "           2       0.37      0.15      0.21       149\n",
            "           3       0.29      0.20      0.24       139\n",
            "           4       0.31      0.54      0.39       129\n",
            "           5       0.34      0.38      0.36       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.33       880\n",
            "weighted avg       0.34      0.34      0.33       880\n",
            "\n",
            "[[48 41  8 22 30 23]\n",
            " [26 81  4 11 15 15]\n",
            " [13 21 22 20 47 26]\n",
            " [20 21 17 28 32 21]\n",
            " [13 19  1  8 70 18]\n",
            " [19 21  7  7 32 53]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 1.967262416761295\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.20      0.24       172\n",
            "           1       0.48      0.19      0.27       152\n",
            "           2       0.40      0.03      0.05       149\n",
            "           3       0.41      0.12      0.18       139\n",
            "           4       0.27      0.27      0.27       129\n",
            "           5       0.22      0.84      0.35       139\n",
            "\n",
            "    accuracy                           0.27       880\n",
            "   macro avg       0.35      0.27      0.23       880\n",
            "weighted avg       0.35      0.27      0.23       880\n",
            "\n",
            "[[ 34  10   0   3  21 104]\n",
            " [ 27  29   2   5  21  68]\n",
            " [ 16  10   4  10  25  84]\n",
            " [ 14   4   3  16  20  82]\n",
            " [  9   7   1   3  35  74]\n",
            " [ 12   0   0   2   8 117]]\n",
            "Accuracy: 0.26704545454545453\n",
            "Total f1 over classes: 1.3636809431542438\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.31      0.32       172\n",
            "           1       0.41      0.49      0.45       152\n",
            "           2       0.31      0.22      0.26       149\n",
            "           3       0.23      0.20      0.21       139\n",
            "           4       0.45      0.43      0.44       129\n",
            "           5       0.38      0.49      0.43       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.35      0.36      0.35       880\n",
            "weighted avg       0.35      0.36      0.35       880\n",
            "\n",
            "[[54 31 30 22  7 28]\n",
            " [26 75  8 12 15 16]\n",
            " [21 23 33 33 17 22]\n",
            " [31 19 24 28 16 21]\n",
            " [15 23  3 11 55 22]\n",
            " [20 11  9 18 13 68]]\n",
            "Accuracy: 0.35568181818181815\n",
            "Total f1 over classes: 2.105313807201018\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.57      0.37       172\n",
            "           1       0.42      0.30      0.35       152\n",
            "           2       0.43      0.06      0.11       149\n",
            "           3       0.26      0.25      0.26       139\n",
            "           4       0.28      0.43      0.34       129\n",
            "           5       0.35      0.14      0.20       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.34      0.29      0.27       880\n",
            "weighted avg       0.34      0.30      0.27       880\n",
            "\n",
            "[[98 21  1 30 18  4]\n",
            " [64 46  2 17 17  6]\n",
            " [52 15  9 27 36 10]\n",
            " [53 10  5 35 26 10]\n",
            " [37 15  2 15 55  5]\n",
            " [60  2  2 11 45 19]]\n",
            "Accuracy: 0.29772727272727273\n",
            "Total f1 over classes: 1.6138333733361845\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.25      0.29       173\n",
            "           1       0.45      0.61      0.52       152\n",
            "           2       0.56      0.24      0.34       149\n",
            "           3       0.37      0.30      0.33       138\n",
            "           4       0.41      0.52      0.46       128\n",
            "           5       0.37      0.56      0.45       140\n",
            "\n",
            "    accuracy                           0.41       880\n",
            "   macro avg       0.42      0.41      0.40       880\n",
            "weighted avg       0.42      0.41      0.39       880\n",
            "\n",
            "[[43 41 10 22 21 36]\n",
            " [13 93  0 12 16 18]\n",
            " [18 21 36 25 19 30]\n",
            " [27 17 10 41 19 24]\n",
            " [ 9 22  2  4 66 25]\n",
            " [17 13  6  6 19 79]]\n",
            "Accuracy: 0.4068181818181818\n",
            "Total f1 over classes: 2.380642816250216\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.23      0.24       173\n",
            "           1       0.41      0.53      0.47       152\n",
            "           2       0.33      0.14      0.20       149\n",
            "           3       0.32      0.24      0.28       138\n",
            "           4       0.31      0.53      0.40       128\n",
            "           5       0.33      0.36      0.35       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[39 42 15 15 32 30]\n",
            " [26 81  2  9 20 14]\n",
            " [18 20 21 30 34 26]\n",
            " [27 14 16 33 30 18]\n",
            " [13 22  2  7 68 16]\n",
            " [25 17  7  8 32 51]]\n",
            "Accuracy: 0.33295454545454545\n",
            "Total f1 over classes: 1.9227326522057968\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.40      0.28       173\n",
            "           1       0.41      0.47      0.44       152\n",
            "           2       0.23      0.18      0.20       149\n",
            "           3       0.29      0.13      0.18       138\n",
            "           4       0.42      0.32      0.36       128\n",
            "           5       0.36      0.26      0.30       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.32      0.29      0.29       880\n",
            "weighted avg       0.32      0.30      0.29       880\n",
            "\n",
            "[[70 41 32  6  6 18]\n",
            " [50 72  9  2 10  9]\n",
            " [55 20 27 25  4 18]\n",
            " [50 15 29 18 14 12]\n",
            " [54 15  4  7 41  7]\n",
            " [46 14 18  4 22 36]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.7647514493547083\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.29      0.31       173\n",
            "           1       0.40      0.52      0.45       152\n",
            "           2       0.29      0.23      0.25       149\n",
            "           3       0.29      0.25      0.27       138\n",
            "           4       0.49      0.47      0.48       128\n",
            "           5       0.40      0.49      0.44       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.37      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[50 43 20 19 10 31]\n",
            " [22 79 15 13  8 15]\n",
            " [27 22 34 31 13 22]\n",
            " [20 21 29 34 17 17]\n",
            " [ 9 18 10 14 60 17]\n",
            " [23 17 11  7 14 68]]\n",
            "Accuracy: 0.3693181818181818\n",
            "Total f1 over classes: 2.1955716323752155\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.61      0.37       173\n",
            "           1       0.51      0.30      0.37       152\n",
            "           2       0.47      0.06      0.11       149\n",
            "           3       0.30      0.22      0.25       138\n",
            "           4       0.29      0.41      0.34       128\n",
            "           5       0.31      0.19      0.23       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.36      0.30      0.28       880\n",
            "weighted avg       0.36      0.30      0.28       880\n",
            "\n",
            "[[106  13   0  14  24  16]\n",
            " [ 72  45   3  10  15   7]\n",
            " [ 65   9   9  30  22  14]\n",
            " [ 56   6   3  30  29  14]\n",
            " [ 50   9   1   8  52   8]\n",
            " [ 57   6   3   9  39  26]]\n",
            "Accuracy: 0.30454545454545456\n",
            "Total f1 over classes: 1.6670181045982373\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.29      0.30       149\n",
            "           1       0.38      0.50      0.43       154\n",
            "           2       0.29      0.13      0.18       157\n",
            "           3       0.18      0.14      0.16       143\n",
            "           4       0.35      0.43      0.39       138\n",
            "           5       0.32      0.43      0.37       140\n",
            "\n",
            "    accuracy                           0.32       881\n",
            "   macro avg       0.31      0.32      0.30       881\n",
            "weighted avg       0.31      0.32      0.30       881\n",
            "\n",
            "[[43 22  6 24 14 40]\n",
            " [24 77  9  9 18 17]\n",
            " [21 28 21 35 29 23]\n",
            " [18 32 22 20 25 26]\n",
            " [18 24  5 11 60 20]\n",
            " [16 19 10 10 25 60]]\n",
            "Accuracy: 0.318955732122588\n",
            "Total f1 over classes: 1.8279486527888436\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       149\n",
            "           1       0.35      0.44      0.39       154\n",
            "           2       0.33      0.13      0.19       157\n",
            "           3       0.23      0.17      0.19       143\n",
            "           4       0.28      0.44      0.34       138\n",
            "           5       0.27      0.29      0.28       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.29      0.29      0.28       881\n",
            "\n",
            "[[40 32  6 12 30 29]\n",
            " [26 67  4 11 26 20]\n",
            " [31 18 21 30 39 18]\n",
            " [21 28 16 24 31 23]\n",
            " [18 22  4 16 61 17]\n",
            " [19 26 12 11 32 40]]\n",
            "Accuracy: 0.28717366628830876\n",
            "Total f1 over classes: 1.6550484557028389\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.45      0.28       149\n",
            "           1       0.34      0.36      0.35       154\n",
            "           2       0.25      0.23      0.24       157\n",
            "           3       0.28      0.13      0.17       143\n",
            "           4       0.33      0.22      0.26       138\n",
            "           5       0.24      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.26       881\n",
            "   macro avg       0.27      0.25      0.25       881\n",
            "weighted avg       0.27      0.26      0.25       881\n",
            "\n",
            "[[67 26 22  5 12 17]\n",
            " [53 56 14 10 12  9]\n",
            " [60 20 36 21  8 12]\n",
            " [41 27 30 18 10 17]\n",
            " [60 18 14  8 30  8]\n",
            " [54 16 27  3 20 20]]\n",
            "Accuracy: 0.2576617480136209\n",
            "Total f1 over classes: 1.4834904925750796\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.34      0.31       149\n",
            "           1       0.42      0.47      0.44       154\n",
            "           2       0.28      0.20      0.24       157\n",
            "           3       0.23      0.22      0.22       143\n",
            "           4       0.45      0.39      0.42       138\n",
            "           5       0.35      0.40      0.37       140\n",
            "\n",
            "    accuracy                           0.34       881\n",
            "   macro avg       0.34      0.34      0.33       881\n",
            "weighted avg       0.33      0.34      0.33       881\n",
            "\n",
            "[[51 23 15 16 11 33]\n",
            " [22 73 10 18 12 19]\n",
            " [33 22 32 41 16 13]\n",
            " [27 21 23 31 15 26]\n",
            " [ 9 24 13 23 54 15]\n",
            " [33 12 21  6 12 56]]\n",
            "Accuracy: 0.337116912599319\n",
            "Total f1 over classes: 2.007233334447839\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.64      0.35       149\n",
            "           1       0.43      0.32      0.37       154\n",
            "           2       0.18      0.02      0.03       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.29      0.37      0.33       138\n",
            "           5       0.26      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.28      0.28      0.25       881\n",
            "weighted avg       0.28      0.28      0.25       881\n",
            "\n",
            "[[95 11  0 14 20  9]\n",
            " [59 50  1 13 22  9]\n",
            " [70 16  3 32 21 15]\n",
            " [51 16  7 28 30 11]\n",
            " [45 12  4 15 51 11]\n",
            " [70 10  2 10 29 19]]\n",
            "Accuracy: 0.2792281498297389\n",
            "Total f1 over classes: 1.4838868218580543\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.12      0.18       173\n",
            "           1       0.40      0.42      0.41       151\n",
            "           2       0.23      0.23      0.23       150\n",
            "           3       0.42      0.14      0.22       138\n",
            "           4       0.31      0.43      0.36       128\n",
            "           5       0.29      0.59      0.39       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.33      0.32      0.30       880\n",
            "weighted avg       0.33      0.31      0.29       880\n",
            "\n",
            "[[21 29 29  3 42 49]\n",
            " [11 63 20  2 20 35]\n",
            " [ 9 14 35 11 23 58]\n",
            " [ 9 23 39 20 19 28]\n",
            " [ 7 21 11  7 55 27]\n",
            " [ 9  8 15  5 21 82]]\n",
            "Accuracy: 0.31363636363636366\n",
            "Total f1 over classes: 1.7812176553812558\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.23      0.28       173\n",
            "           1       0.38      0.50      0.43       151\n",
            "           2       0.22      0.13      0.16       150\n",
            "           3       0.30      0.18      0.23       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.31      0.39      0.35       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.31      0.32      0.30       880\n",
            "weighted avg       0.31      0.32      0.30       880\n",
            "\n",
            "[[39 41 17 14 41 21]\n",
            " [14 75  6  3 30 23]\n",
            " [23 17 19 18 38 35]\n",
            " [14 29 22 25 26 22]\n",
            " [ 6 16 10 12 66 18]\n",
            " [12 20 11 12 31 54]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.806021440982625\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.44      0.32       173\n",
            "           1       0.43      0.32      0.37       151\n",
            "           2       0.22      0.01      0.03       150\n",
            "           3       0.41      0.15      0.22       138\n",
            "           4       0.29      0.52      0.37       128\n",
            "           5       0.28      0.35      0.31       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.31      0.30      0.27       880\n",
            "weighted avg       0.31      0.30      0.27       880\n",
            "\n",
            "[[76 21  2  3 40 31]\n",
            " [47 48  2  4 35 15]\n",
            " [60  8  2 11 33 36]\n",
            " [46 16  2 21 25 28]\n",
            " [29  9  0  7 67 16]\n",
            " [41 10  1  5 34 49]]\n",
            "Accuracy: 0.2988636363636364\n",
            "Total f1 over classes: 1.615709221606018\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.35      0.36       173\n",
            "           1       0.41      0.44      0.42       151\n",
            "           2       0.27      0.19      0.22       150\n",
            "           3       0.30      0.29      0.29       138\n",
            "           4       0.51      0.54      0.52       128\n",
            "           5       0.35      0.45      0.40       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.36      0.37      0.37       880\n",
            "\n",
            "[[61 32 17 21 17 25]\n",
            " [23 66 10 14 15 23]\n",
            " [33 16 28 31 12 30]\n",
            " [21 23 22 40 11 21]\n",
            " [ 7 16 10 10 69 16]\n",
            " [22  8 17 18 12 63]]\n",
            "Accuracy: 0.3715909090909091\n",
            "Total f1 over classes: 2.2154442283140057\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.66      0.41       173\n",
            "           1       0.41      0.19      0.26       151\n",
            "           2       0.33      0.09      0.15       150\n",
            "           3       0.38      0.13      0.19       138\n",
            "           4       0.29      0.61      0.40       128\n",
            "           5       0.38      0.17      0.24       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.35      0.31      0.27       880\n",
            "weighted avg       0.35      0.32      0.28       880\n",
            "\n",
            "[[115  10   4   5  34   5]\n",
            " [ 77  29   4   2  34   5]\n",
            " [ 63   8  14  11  39  15]\n",
            " [ 65   7  13  18  29   6]\n",
            " [ 23  10   4   5  78   8]\n",
            " [ 49   6   4   6  51  24]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.6425951665895142\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.18      0.22       173\n",
            "           1       0.39      0.59      0.47       152\n",
            "           2       0.28      0.15      0.19       149\n",
            "           3       0.30      0.24      0.27       139\n",
            "           4       0.39      0.50      0.44       128\n",
            "           5       0.31      0.40      0.35       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.32      0.34      0.32       880\n",
            "weighted avg       0.32      0.34      0.32       880\n",
            "\n",
            "[[31 42 14 24 33 29]\n",
            " [12 90  9 12  9 20]\n",
            " [19 30 22 24 24 30]\n",
            " [17 29 17 34 15 27]\n",
            " [ 9 21  7  7 64 20]\n",
            " [18 21 10 13 21 56]]\n",
            "Accuracy: 0.3375\n",
            "Total f1 over classes: 1.9357956564330894\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.20      0.23       173\n",
            "           1       0.38      0.55      0.45       152\n",
            "           2       0.19      0.07      0.10       149\n",
            "           3       0.32      0.22      0.26       139\n",
            "           4       0.28      0.55      0.37       128\n",
            "           5       0.32      0.29      0.31       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.29      0.31      0.29       880\n",
            "weighted avg       0.29      0.31      0.28       880\n",
            "\n",
            "[[35 35  5 17 61 20]\n",
            " [17 83  6  8 24 14]\n",
            " [29 23 10 21 45 21]\n",
            " [25 26 18 31 17 22]\n",
            " [10 24  1 12 70 11]\n",
            " [21 28 12  7 30 41]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.7158815620959298\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.40      0.30       173\n",
            "           1       0.41      0.24      0.31       152\n",
            "           2       0.33      0.01      0.01       149\n",
            "           3       0.35      0.32      0.33       139\n",
            "           4       0.25      0.59      0.35       128\n",
            "           5       0.38      0.19      0.25       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.33      0.29      0.26       880\n",
            "weighted avg       0.33      0.29      0.26       880\n",
            "\n",
            "[[70 18  1 20 54 10]\n",
            " [59 37  1  9 37  9]\n",
            " [45 15  1 27 56  5]\n",
            " [48  6  0 44 31 10]\n",
            " [23  8  0 13 75  9]\n",
            " [48  6  0 13 46 26]]\n",
            "Accuracy: 0.2875\n",
            "Total f1 over classes: 1.5527357311573426\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.35      0.34       173\n",
            "           1       0.44      0.51      0.47       152\n",
            "           2       0.30      0.27      0.28       149\n",
            "           3       0.36      0.29      0.32       139\n",
            "           4       0.48      0.51      0.49       128\n",
            "           5       0.42      0.42      0.42       139\n",
            "\n",
            "    accuracy                           0.39       880\n",
            "   macro avg       0.39      0.39      0.39       880\n",
            "weighted avg       0.38      0.39      0.38       880\n",
            "\n",
            "[[60 34 29 16 15 19]\n",
            " [22 78 15 11 14 12]\n",
            " [34 23 40 19 17 16]\n",
            " [24 20 28 40  9 18]\n",
            " [12 11 10 16 65 14]\n",
            " [33 11 12  9 16 58]]\n",
            "Accuracy: 0.3875\n",
            "Total f1 over classes: 2.324759274329056\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.54      0.35       173\n",
            "           1       0.52      0.31      0.39       152\n",
            "           2       0.21      0.04      0.07       149\n",
            "           3       0.28      0.13      0.18       139\n",
            "           4       0.25      0.48      0.33       128\n",
            "           5       0.30      0.19      0.24       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.30      0.28      0.26       880\n",
            "weighted avg       0.30      0.29      0.26       880\n",
            "\n",
            "[[93 11  2 12 42 13]\n",
            " [57 47  4  6 29  9]\n",
            " [69 12  6 14 32 16]\n",
            " [53 11 13 18 30 14]\n",
            " [39  7  2  9 61 10]\n",
            " [54  3  2  6 47 27]]\n",
            "Accuracy: 0.2863636363636364\n",
            "Total f1 over classes: 1.5439079128519548\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.30      0.32       172\n",
            "           1       0.38      0.54      0.44       152\n",
            "           2       0.29      0.22      0.25       149\n",
            "           3       0.33      0.19      0.24       139\n",
            "           4       0.43      0.43      0.43       129\n",
            "           5       0.40      0.55      0.46       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[51 45 27 11 12 26]\n",
            " [23 82  8 10 12 17]\n",
            " [18 24 33 27 21 26]\n",
            " [23 23 28 27 15 23]\n",
            " [10 29  8  3 56 23]\n",
            " [23 14  8  4 14 76]]\n",
            "Accuracy: 0.3693181818181818\n",
            "Total f1 over classes: 2.1534503921040433\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.28      0.31       172\n",
            "           1       0.40      0.53      0.46       152\n",
            "           2       0.37      0.15      0.21       149\n",
            "           3       0.29      0.20      0.24       139\n",
            "           4       0.31      0.54      0.39       129\n",
            "           5       0.34      0.38      0.36       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.33       880\n",
            "weighted avg       0.34      0.34      0.33       880\n",
            "\n",
            "[[48 41  8 22 30 23]\n",
            " [26 81  4 11 15 15]\n",
            " [13 21 22 20 47 26]\n",
            " [20 21 17 28 32 21]\n",
            " [13 19  1  8 70 18]\n",
            " [19 21  7  7 32 53]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 1.967262416761295\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.20      0.24       172\n",
            "           1       0.48      0.19      0.27       152\n",
            "           2       0.40      0.03      0.05       149\n",
            "           3       0.41      0.12      0.18       139\n",
            "           4       0.27      0.27      0.27       129\n",
            "           5       0.22      0.84      0.35       139\n",
            "\n",
            "    accuracy                           0.27       880\n",
            "   macro avg       0.35      0.27      0.23       880\n",
            "weighted avg       0.35      0.27      0.23       880\n",
            "\n",
            "[[ 34  10   0   3  21 104]\n",
            " [ 27  29   2   5  21  68]\n",
            " [ 16  10   4  10  25  84]\n",
            " [ 14   4   3  16  20  82]\n",
            " [  9   7   1   3  35  74]\n",
            " [ 12   0   0   2   8 117]]\n",
            "Accuracy: 0.26704545454545453\n",
            "Total f1 over classes: 1.3636809431542438\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      0.32      0.33       172\n",
            "           1       0.39      0.47      0.43       152\n",
            "           2       0.31      0.23      0.26       149\n",
            "           3       0.24      0.23      0.24       139\n",
            "           4       0.44      0.45      0.44       129\n",
            "           5       0.44      0.50      0.47       139\n",
            "\n",
            "    accuracy                           0.36       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.36      0.36       880\n",
            "\n",
            "[[55 33 30 25  5 24]\n",
            " [28 72 10 16 15 11]\n",
            " [23 24 34 28 23 17]\n",
            " [25 20 23 32 18 21]\n",
            " [14 23  3 14 58 17]\n",
            " [20 11  8 16 14 70]]\n",
            "Accuracy: 0.36477272727272725\n",
            "Total f1 over classes: 2.1688642348955884\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.57      0.37       172\n",
            "           1       0.42      0.30      0.35       152\n",
            "           2       0.43      0.06      0.11       149\n",
            "           3       0.26      0.25      0.26       139\n",
            "           4       0.28      0.43      0.34       129\n",
            "           5       0.35      0.14      0.20       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.34      0.29      0.27       880\n",
            "weighted avg       0.34      0.30      0.27       880\n",
            "\n",
            "[[98 21  1 30 18  4]\n",
            " [64 46  2 17 17  6]\n",
            " [52 15  9 27 36 10]\n",
            " [53 10  5 35 26 10]\n",
            " [37 15  2 15 55  5]\n",
            " [60  2  2 11 45 19]]\n",
            "Accuracy: 0.29772727272727273\n",
            "Total f1 over classes: 1.6138333733361845\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.46      0.37       173\n",
            "           1       0.50      0.50      0.50       152\n",
            "           2       0.45      0.22      0.30       149\n",
            "           3       0.43      0.24      0.31       138\n",
            "           4       0.45      0.49      0.47       128\n",
            "           5       0.40      0.49      0.44       140\n",
            "\n",
            "    accuracy                           0.40       880\n",
            "   macro avg       0.42      0.40      0.40       880\n",
            "weighted avg       0.42      0.40      0.40       880\n",
            "\n",
            "[[80 28 10 13 15 27]\n",
            " [39 76  6  5  8 18]\n",
            " [44 16 33 15 20 21]\n",
            " [43 10 16 33 19 17]\n",
            " [23 16  1  6 63 19]\n",
            " [36  6  8  5 16 69]]\n",
            "Accuracy: 0.4022727272727273\n",
            "Total f1 over classes: 2.380369063925378\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.23      0.24       173\n",
            "           1       0.41      0.53      0.47       152\n",
            "           2       0.33      0.14      0.20       149\n",
            "           3       0.32      0.24      0.28       138\n",
            "           4       0.31      0.53      0.40       128\n",
            "           5       0.33      0.36      0.35       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[39 42 15 15 32 30]\n",
            " [26 81  2  9 20 14]\n",
            " [18 20 21 30 34 26]\n",
            " [27 14 16 33 30 18]\n",
            " [13 22  2  7 68 16]\n",
            " [25 17  7  8 32 51]]\n",
            "Accuracy: 0.33295454545454545\n",
            "Total f1 over classes: 1.9227326522057968\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.40      0.28       173\n",
            "           1       0.41      0.47      0.44       152\n",
            "           2       0.23      0.18      0.20       149\n",
            "           3       0.29      0.13      0.18       138\n",
            "           4       0.42      0.32      0.36       128\n",
            "           5       0.36      0.26      0.30       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.32      0.29      0.29       880\n",
            "weighted avg       0.32      0.30      0.29       880\n",
            "\n",
            "[[70 41 32  6  6 18]\n",
            " [50 72  9  2 10  9]\n",
            " [55 20 27 25  4 18]\n",
            " [50 15 29 18 14 12]\n",
            " [54 15  4  7 41  7]\n",
            " [46 14 18  4 22 36]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.7647514493547083\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.25      0.27       173\n",
            "           1       0.43      0.53      0.47       152\n",
            "           2       0.31      0.24      0.27       149\n",
            "           3       0.31      0.27      0.29       138\n",
            "           4       0.48      0.49      0.49       128\n",
            "           5       0.39      0.49      0.43       140\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.37      0.38      0.37       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[43 43 23 19 12 33]\n",
            " [17 80 12 13  9 21]\n",
            " [30 19 36 31 13 20]\n",
            " [19 16 26 37 20 20]\n",
            " [10 18  8 13 63 16]\n",
            " [27 11 12  7 14 69]]\n",
            "Accuracy: 0.37272727272727274\n",
            "Total f1 over classes: 2.2181556421888784\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.61      0.37       173\n",
            "           1       0.51      0.30      0.37       152\n",
            "           2       0.47      0.06      0.11       149\n",
            "           3       0.30      0.22      0.25       138\n",
            "           4       0.29      0.41      0.34       128\n",
            "           5       0.31      0.19      0.23       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.36      0.30      0.28       880\n",
            "weighted avg       0.36      0.30      0.28       880\n",
            "\n",
            "[[106  13   0  14  24  16]\n",
            " [ 72  45   3  10  15   7]\n",
            " [ 65   9   9  30  22  14]\n",
            " [ 56   6   3  30  29  14]\n",
            " [ 50   9   1   8  52   8]\n",
            " [ 57   6   3   9  39  26]]\n",
            "Accuracy: 0.30454545454545456\n",
            "Total f1 over classes: 1.6670181045982373\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.47      0.34       149\n",
            "           1       0.43      0.41      0.42       154\n",
            "           2       0.39      0.21      0.27       157\n",
            "           3       0.26      0.16      0.20       143\n",
            "           4       0.43      0.41      0.42       138\n",
            "           5       0.35      0.42      0.38       140\n",
            "\n",
            "    accuracy                           0.35       881\n",
            "   macro avg       0.35      0.35      0.34       881\n",
            "weighted avg       0.35      0.35      0.34       881\n",
            "\n",
            "[[70 16  5 12 10 36]\n",
            " [44 63 10  5 15 17]\n",
            " [51 15 33 27 17 14]\n",
            " [40 23 16 23 14 27]\n",
            " [25 19 11 10 56 17]\n",
            " [32  9 10 12 18 59]]\n",
            "Accuracy: 0.34506242905788875\n",
            "Total f1 over classes: 2.0315960295283286\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       149\n",
            "           1       0.35      0.44      0.39       154\n",
            "           2       0.33      0.13      0.19       157\n",
            "           3       0.23      0.17      0.19       143\n",
            "           4       0.28      0.44      0.34       138\n",
            "           5       0.27      0.29      0.28       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.29      0.29      0.28       881\n",
            "\n",
            "[[40 32  6 12 30 29]\n",
            " [26 67  4 11 26 20]\n",
            " [31 18 21 30 39 18]\n",
            " [21 28 16 24 31 23]\n",
            " [18 22  4 16 61 17]\n",
            " [19 26 12 11 32 40]]\n",
            "Accuracy: 0.28717366628830876\n",
            "Total f1 over classes: 1.6550484557028389\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.45      0.28       149\n",
            "           1       0.34      0.36      0.35       154\n",
            "           2       0.25      0.23      0.24       157\n",
            "           3       0.28      0.13      0.17       143\n",
            "           4       0.33      0.22      0.26       138\n",
            "           5       0.24      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.26       881\n",
            "   macro avg       0.27      0.25      0.25       881\n",
            "weighted avg       0.27      0.26      0.25       881\n",
            "\n",
            "[[67 26 22  5 12 17]\n",
            " [53 56 14 10 12  9]\n",
            " [60 20 36 21  8 12]\n",
            " [41 27 30 18 10 17]\n",
            " [60 18 14  8 30  8]\n",
            " [54 16 27  3 20 20]]\n",
            "Accuracy: 0.2576617480136209\n",
            "Total f1 over classes: 1.4834904925750796\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.33      0.30       149\n",
            "           1       0.37      0.43      0.40       154\n",
            "           2       0.33      0.24      0.28       157\n",
            "           3       0.26      0.24      0.25       143\n",
            "           4       0.40      0.34      0.37       138\n",
            "           5       0.31      0.36      0.33       140\n",
            "\n",
            "    accuracy                           0.32       881\n",
            "   macro avg       0.33      0.32      0.32       881\n",
            "weighted avg       0.33      0.32      0.32       881\n",
            "\n",
            "[[49 26 14 19  9 32]\n",
            " [27 66 13 12 16 20]\n",
            " [29 19 38 40 18 13]\n",
            " [26 21 18 35 15 28]\n",
            " [13 28 13 20 47 17]\n",
            " [32 18 20  7 13 50]]\n",
            "Accuracy: 0.32349602724177073\n",
            "Total f1 over classes: 1.9316611231116534\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.64      0.35       149\n",
            "           1       0.43      0.32      0.37       154\n",
            "           2       0.18      0.02      0.03       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.29      0.37      0.33       138\n",
            "           5       0.26      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.28      0.28      0.25       881\n",
            "weighted avg       0.28      0.28      0.25       881\n",
            "\n",
            "[[95 11  0 14 20  9]\n",
            " [59 50  1 13 22  9]\n",
            " [70 16  3 32 21 15]\n",
            " [51 16  7 28 30 11]\n",
            " [45 12  4 15 51 11]\n",
            " [70 10  2 10 29 19]]\n",
            "Accuracy: 0.2792281498297389\n",
            "Total f1 over classes: 1.4838868218580543\n",
            "No. of training examples: 3520\n",
            "No. of testing examples: 881\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.21      0.26       173\n",
            "           1       0.34      0.52      0.42       151\n",
            "           2       0.25      0.29      0.27       150\n",
            "           3       0.29      0.14      0.19       138\n",
            "           4       0.29      0.52      0.37       128\n",
            "           5       0.39      0.20      0.26       140\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.32      0.31      0.29       880\n",
            "weighted avg       0.32      0.31      0.29       880\n",
            "\n",
            "[[36 50 34  8 39  6]\n",
            " [13 79 16  4 30  9]\n",
            " [14 32 44 11 35 14]\n",
            " [11 30 44 19 28  6]\n",
            " [ 5 23 14 11 66  9]\n",
            " [24 15 27 13 33 28]]\n",
            "Accuracy: 0.3090909090909091\n",
            "Total f1 over classes: 1.7622497180332888\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.32      0.31       173\n",
            "           1       0.33      0.44      0.38       151\n",
            "           2       0.26      0.28      0.27       150\n",
            "           3       0.33      0.22      0.27       138\n",
            "           4       0.53      0.39      0.45       128\n",
            "           5       0.39      0.41      0.40       140\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.36      0.34      0.35       880\n",
            "weighted avg       0.35      0.34      0.34       880\n",
            "\n",
            "[[55 32 35 17  9 25]\n",
            " [30 67 17  8 13 16]\n",
            " [32 25 42 19 10 22]\n",
            " [28 24 32 31  7 16]\n",
            " [12 37 10  9 50 10]\n",
            " [25 17 25 10  6 57]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 2.073832288570799\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      0.23      0.28       173\n",
            "           1       0.38      0.50      0.43       151\n",
            "           2       0.22      0.13      0.16       150\n",
            "           3       0.30      0.18      0.23       138\n",
            "           4       0.28      0.52      0.37       128\n",
            "           5       0.31      0.39      0.35       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.31      0.32      0.30       880\n",
            "weighted avg       0.31      0.32      0.30       880\n",
            "\n",
            "[[39 41 17 14 41 21]\n",
            " [14 75  6  3 30 23]\n",
            " [23 17 19 18 38 35]\n",
            " [14 29 22 25 26 22]\n",
            " [ 6 16 10 12 66 18]\n",
            " [12 20 11 12 31 54]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.806021440982625\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.44      0.32       173\n",
            "           1       0.43      0.32      0.37       151\n",
            "           2       0.22      0.01      0.03       150\n",
            "           3       0.41      0.15      0.22       138\n",
            "           4       0.29      0.52      0.37       128\n",
            "           5       0.28      0.35      0.31       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.31      0.30      0.27       880\n",
            "weighted avg       0.31      0.30      0.27       880\n",
            "\n",
            "[[76 21  2  3 40 31]\n",
            " [47 48  2  4 35 15]\n",
            " [60  8  2 11 33 36]\n",
            " [46 16  2 21 25 28]\n",
            " [29  9  0  7 67 16]\n",
            " [41 10  1  5 34 49]]\n",
            "Accuracy: 0.2988636363636364\n",
            "Total f1 over classes: 1.615709221606018\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.39      0.38       173\n",
            "           1       0.45      0.47      0.46       151\n",
            "           2       0.28      0.21      0.24       150\n",
            "           3       0.28      0.27      0.27       138\n",
            "           4       0.52      0.55      0.53       128\n",
            "           5       0.37      0.44      0.40       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.38      0.39      0.38       880\n",
            "weighted avg       0.38      0.38      0.38       880\n",
            "\n",
            "[[67 30 15 18 17 26]\n",
            " [23 71 13 12 14 18]\n",
            " [35 13 31 32 11 28]\n",
            " [26 19 28 37 10 18]\n",
            " [ 5 16 10 12 70 15]\n",
            " [21 10 15 21 12 61]]\n",
            "Accuracy: 0.38295454545454544\n",
            "Total f1 over classes: 2.2846809099299796\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.66      0.41       173\n",
            "           1       0.41      0.19      0.26       151\n",
            "           2       0.33      0.09      0.15       150\n",
            "           3       0.38      0.13      0.19       138\n",
            "           4       0.29      0.61      0.40       128\n",
            "           5       0.38      0.17      0.24       140\n",
            "\n",
            "    accuracy                           0.32       880\n",
            "   macro avg       0.35      0.31      0.27       880\n",
            "weighted avg       0.35      0.32      0.28       880\n",
            "\n",
            "[[115  10   4   5  34   5]\n",
            " [ 77  29   4   2  34   5]\n",
            " [ 63   8  14  11  39  15]\n",
            " [ 65   7  13  18  29   6]\n",
            " [ 23  10   4   5  78   8]\n",
            " [ 49   6   4   6  51  24]]\n",
            "Accuracy: 0.3159090909090909\n",
            "Total f1 over classes: 1.6425951665895142\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.34      0.32       173\n",
            "           1       0.38      0.48      0.42       152\n",
            "           2       0.30      0.14      0.19       149\n",
            "           3       0.40      0.19      0.25       139\n",
            "           4       0.30      0.55      0.39       128\n",
            "           5       0.40      0.37      0.39       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.35      0.34      0.33       880\n",
            "weighted avg       0.35      0.34      0.33       880\n",
            "\n",
            "[[58 29  9  7 51 19]\n",
            " [37 73 10  1 22  9]\n",
            " [30 28 21 14 41 15]\n",
            " [21 29 21 26 22 20]\n",
            " [16 20  0  8 70 14]\n",
            " [26 14  9  9 29 52]]\n",
            "Accuracy: 0.3409090909090909\n",
            "Total f1 over classes: 1.9649354610104337\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.34      0.34       173\n",
            "           1       0.35      0.49      0.41       152\n",
            "           2       0.22      0.19      0.20       149\n",
            "           3       0.31      0.27      0.29       139\n",
            "           4       0.43      0.45      0.44       128\n",
            "           5       0.37      0.27      0.31       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.33      0.34      0.33       880\n",
            "weighted avg       0.33      0.34      0.33       880\n",
            "\n",
            "[[59 31 29 22 14 18]\n",
            " [16 74 23 12 12 15]\n",
            " [34 34 29 17 20 15]\n",
            " [26 26 22 38 15 12]\n",
            " [14 24 11 17 58  4]\n",
            " [27 24 20 15 16 37]]\n",
            "Accuracy: 0.3352272727272727\n",
            "Total f1 over classes: 1.9902409954670113\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.20      0.23       173\n",
            "           1       0.38      0.55      0.45       152\n",
            "           2       0.19      0.07      0.10       149\n",
            "           3       0.32      0.22      0.26       139\n",
            "           4       0.28      0.55      0.37       128\n",
            "           5       0.32      0.29      0.31       139\n",
            "\n",
            "    accuracy                           0.31       880\n",
            "   macro avg       0.29      0.31      0.29       880\n",
            "weighted avg       0.29      0.31      0.28       880\n",
            "\n",
            "[[35 35  5 17 61 20]\n",
            " [17 83  6  8 24 14]\n",
            " [29 23 10 21 45 21]\n",
            " [25 26 18 31 17 22]\n",
            " [10 24  1 12 70 11]\n",
            " [21 28 12  7 30 41]]\n",
            "Accuracy: 0.3068181818181818\n",
            "Total f1 over classes: 1.7158815620959298\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.40      0.30       173\n",
            "           1       0.41      0.24      0.31       152\n",
            "           2       0.33      0.01      0.01       149\n",
            "           3       0.35      0.32      0.33       139\n",
            "           4       0.25      0.59      0.35       128\n",
            "           5       0.38      0.19      0.25       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.33      0.29      0.26       880\n",
            "weighted avg       0.33      0.29      0.26       880\n",
            "\n",
            "[[70 18  1 20 54 10]\n",
            " [59 37  1  9 37  9]\n",
            " [45 15  1 27 56  5]\n",
            " [48  6  0 44 31 10]\n",
            " [23  8  0 13 75  9]\n",
            " [48  6  0 13 46 26]]\n",
            "Accuracy: 0.2875\n",
            "Total f1 over classes: 1.5527357311573426\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.30      0.30       173\n",
            "           1       0.44      0.54      0.49       152\n",
            "           2       0.32      0.28      0.30       149\n",
            "           3       0.35      0.28      0.31       139\n",
            "           4       0.47      0.55      0.51       128\n",
            "           5       0.42      0.42      0.42       139\n",
            "\n",
            "    accuracy                           0.39       880\n",
            "   macro avg       0.39      0.39      0.39       880\n",
            "weighted avg       0.38      0.39      0.38       880\n",
            "\n",
            "[[52 32 23 24 22 20]\n",
            " [22 82 11 12 11 14]\n",
            " [34 27 41 17 16 14]\n",
            " [20 20 30 39 11 19]\n",
            " [10 13  8 15 70 12]\n",
            " [30 12 14  6 19 58]]\n",
            "Accuracy: 0.3886363636363636\n",
            "Total f1 over classes: 2.322522714161627\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.54      0.35       173\n",
            "           1       0.52      0.31      0.39       152\n",
            "           2       0.21      0.04      0.07       149\n",
            "           3       0.28      0.13      0.18       139\n",
            "           4       0.25      0.48      0.33       128\n",
            "           5       0.30      0.19      0.24       139\n",
            "\n",
            "    accuracy                           0.29       880\n",
            "   macro avg       0.30      0.28      0.26       880\n",
            "weighted avg       0.30      0.29      0.26       880\n",
            "\n",
            "[[93 11  2 12 42 13]\n",
            " [57 47  4  6 29  9]\n",
            " [69 12  6 14 32 16]\n",
            " [53 11 13 18 30 14]\n",
            " [39  7  2  9 61 10]\n",
            " [54  3  2  6 47 27]]\n",
            "Accuracy: 0.2863636363636364\n",
            "Total f1 over classes: 1.5439079128519548\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.34      0.43      0.38       172\n",
            "           1       0.41      0.46      0.43       152\n",
            "           2       0.36      0.19      0.25       149\n",
            "           3       0.27      0.22      0.25       139\n",
            "           4       0.40      0.44      0.42       129\n",
            "           5       0.41      0.45      0.43       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[74 37  9 19  9 24]\n",
            " [36 70  6 14 14 12]\n",
            " [29 22 29 27 25 17]\n",
            " [32 17 24 31 17 18]\n",
            " [21 17  6  9 57 19]\n",
            " [26  9  7 14 21 62]]\n",
            "Accuracy: 0.36704545454545456\n",
            "Total f1 over classes: 2.154053632047102\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.31      0.29       172\n",
            "           1       0.34      0.52      0.41       152\n",
            "           2       0.27      0.22      0.24       149\n",
            "           3       0.24      0.21      0.22       139\n",
            "           4       0.48      0.35      0.41       129\n",
            "           5       0.39      0.34      0.36       139\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.32      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[53 39 31 25  5 19]\n",
            " [29 79  7 14  9 14]\n",
            " [34 29 33 30 11 12]\n",
            " [29 32 26 29 11 12]\n",
            " [13 36  9  9 45 17]\n",
            " [36 16 16 12 12 47]]\n",
            "Accuracy: 0.325\n",
            "Total f1 over classes: 1.9374426273331247\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.28      0.31       172\n",
            "           1       0.40      0.53      0.46       152\n",
            "           2       0.37      0.15      0.21       149\n",
            "           3       0.29      0.20      0.24       139\n",
            "           4       0.31      0.54      0.39       129\n",
            "           5       0.34      0.38      0.36       139\n",
            "\n",
            "    accuracy                           0.34       880\n",
            "   macro avg       0.34      0.35      0.33       880\n",
            "weighted avg       0.34      0.34      0.33       880\n",
            "\n",
            "[[48 41  8 22 30 23]\n",
            " [26 81  4 11 15 15]\n",
            " [13 21 22 20 47 26]\n",
            " [20 21 17 28 32 21]\n",
            " [13 19  1  8 70 18]\n",
            " [19 21  7  7 32 53]]\n",
            "Accuracy: 0.3431818181818182\n",
            "Total f1 over classes: 1.967262416761295\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.20      0.24       172\n",
            "           1       0.48      0.19      0.27       152\n",
            "           2       0.40      0.03      0.05       149\n",
            "           3       0.41      0.12      0.18       139\n",
            "           4       0.27      0.27      0.27       129\n",
            "           5       0.22      0.84      0.35       139\n",
            "\n",
            "    accuracy                           0.27       880\n",
            "   macro avg       0.35      0.27      0.23       880\n",
            "weighted avg       0.35      0.27      0.23       880\n",
            "\n",
            "[[ 34  10   0   3  21 104]\n",
            " [ 27  29   2   5  21  68]\n",
            " [ 16  10   4  10  25  84]\n",
            " [ 14   4   3  16  20  82]\n",
            " [  9   7   1   3  35  74]\n",
            " [ 12   0   0   2   8 117]]\n",
            "Accuracy: 0.26704545454545453\n",
            "Total f1 over classes: 1.3636809431542438\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.30      0.30       172\n",
            "           1       0.42      0.53      0.47       152\n",
            "           2       0.33      0.23      0.27       149\n",
            "           3       0.22      0.21      0.21       139\n",
            "           4       0.45      0.44      0.44       129\n",
            "           5       0.45      0.53      0.48       139\n",
            "\n",
            "    accuracy                           0.37       880\n",
            "   macro avg       0.36      0.37      0.36       880\n",
            "weighted avg       0.36      0.37      0.36       880\n",
            "\n",
            "[[51 32 29 29  6 25]\n",
            " [27 80  7 14 13 11]\n",
            " [24 24 34 31 20 16]\n",
            " [30 18 23 29 19 20]\n",
            " [13 24  4 12 57 19]\n",
            " [19 11  7 16 13 73]]\n",
            "Accuracy: 0.36818181818181817\n",
            "Total f1 over classes: 2.1817971094426976\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.57      0.37       172\n",
            "           1       0.42      0.30      0.35       152\n",
            "           2       0.43      0.06      0.11       149\n",
            "           3       0.26      0.25      0.26       139\n",
            "           4       0.28      0.43      0.34       129\n",
            "           5       0.35      0.14      0.20       139\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.34      0.29      0.27       880\n",
            "weighted avg       0.34      0.30      0.27       880\n",
            "\n",
            "[[98 21  1 30 18  4]\n",
            " [64 46  2 17 17  6]\n",
            " [52 15  9 27 36 10]\n",
            " [53 10  5 35 26 10]\n",
            " [37 15  2 15 55  5]\n",
            " [60  2  2 11 45 19]]\n",
            "Accuracy: 0.29772727272727273\n",
            "Total f1 over classes: 1.6138333733361845\n",
            "Doing analysis with ANN\n",
            "Doing analysis with fully connected neural network\n",
            "[INFO] training network...\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.32      0.36      0.34       173\n",
            "           1       0.48      0.54      0.51       152\n",
            "           2       0.43      0.22      0.29       149\n",
            "           3       0.36      0.34      0.35       138\n",
            "           4       0.44      0.53      0.48       128\n",
            "           5       0.42      0.44      0.43       140\n",
            "\n",
            "    accuracy                           0.40       880\n",
            "   macro avg       0.41      0.41      0.40       880\n",
            "weighted avg       0.41      0.40      0.40       880\n",
            "\n",
            "[[63 31 14 24 16 25]\n",
            " [30 82  3 10 12 15]\n",
            " [32 18 33 34 20 12]\n",
            " [33 11 11 47 20 16]\n",
            " [11 19  5  7 68 18]\n",
            " [31 10 10 10 17 62]]\n",
            "Accuracy: 0.4034090909090909\n",
            "Total f1 over classes: 2.401564348821176\n",
            "Doing analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.26      0.27       173\n",
            "           1       0.34      0.48      0.40       152\n",
            "           2       0.24      0.15      0.19       149\n",
            "           3       0.28      0.25      0.27       138\n",
            "           4       0.46      0.47      0.47       128\n",
            "           5       0.36      0.39      0.37       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.33      0.33       880\n",
            "weighted avg       0.32      0.33      0.32       880\n",
            "\n",
            "[[45 36 25 25 12 30]\n",
            " [24 73 13 14 15 13]\n",
            " [33 37 23 24 11 21]\n",
            " [28 23 21 35 19 12]\n",
            " [11 22  3 13 60 19]\n",
            " [24 23 12 14 13 54]]\n",
            "Accuracy: 0.32954545454545453\n",
            "Total f1 over classes: 1.9571495601255349\n",
            "Doing analysis with Logistic Regression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.23      0.24       173\n",
            "           1       0.41      0.53      0.47       152\n",
            "           2       0.33      0.14      0.20       149\n",
            "           3       0.32      0.24      0.28       138\n",
            "           4       0.31      0.53      0.40       128\n",
            "           5       0.33      0.36      0.35       140\n",
            "\n",
            "    accuracy                           0.33       880\n",
            "   macro avg       0.33      0.34      0.32       880\n",
            "weighted avg       0.33      0.33      0.32       880\n",
            "\n",
            "[[39 42 15 15 32 30]\n",
            " [26 81  2  9 20 14]\n",
            " [18 20 21 30 34 26]\n",
            " [27 14 16 33 30 18]\n",
            " [13 22  2  7 68 16]\n",
            " [25 17  7  8 32 51]]\n",
            "Accuracy: 0.33295454545454545\n",
            "Total f1 over classes: 1.9227326522057968\n",
            "Doing analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.22      0.40      0.28       173\n",
            "           1       0.41      0.47      0.44       152\n",
            "           2       0.23      0.18      0.20       149\n",
            "           3       0.29      0.13      0.18       138\n",
            "           4       0.42      0.32      0.36       128\n",
            "           5       0.36      0.26      0.30       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.32      0.29      0.29       880\n",
            "weighted avg       0.32      0.30      0.29       880\n",
            "\n",
            "[[70 41 32  6  6 18]\n",
            " [50 72  9  2 10  9]\n",
            " [55 20 27 25  4 18]\n",
            " [50 15 29 18 14 12]\n",
            " [54 15  4  7 41  7]\n",
            " [46 14 18  4 22 36]]\n",
            "Accuracy: 0.3\n",
            "Total f1 over classes: 1.7647514493547083\n",
            "Doing analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.29      0.30       173\n",
            "           1       0.42      0.55      0.48       152\n",
            "           2       0.28      0.21      0.24       149\n",
            "           3       0.31      0.27      0.29       138\n",
            "           4       0.48      0.49      0.48       128\n",
            "           5       0.43      0.50      0.46       140\n",
            "\n",
            "    accuracy                           0.38       880\n",
            "   macro avg       0.37      0.38      0.38       880\n",
            "weighted avg       0.37      0.38      0.37       880\n",
            "\n",
            "[[50 42 18 20 12 31]\n",
            " [22 83 11 11  8 17]\n",
            " [34 19 31 33 15 17]\n",
            " [19 17 29 37 21 15]\n",
            " [11 20 11 10 63 13]\n",
            " [25 15 10  7 13 70]]\n",
            "Accuracy: 0.3795454545454545\n",
            "Total f1 over classes: 2.25151902047575\n",
            "Doing analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.61      0.37       173\n",
            "           1       0.51      0.30      0.37       152\n",
            "           2       0.47      0.06      0.11       149\n",
            "           3       0.30      0.22      0.25       138\n",
            "           4       0.29      0.41      0.34       128\n",
            "           5       0.31      0.19      0.23       140\n",
            "\n",
            "    accuracy                           0.30       880\n",
            "   macro avg       0.36      0.30      0.28       880\n",
            "weighted avg       0.36      0.30      0.28       880\n",
            "\n",
            "[[106  13   0  14  24  16]\n",
            " [ 72  45   3  10  15   7]\n",
            " [ 65   9   9  30  22  14]\n",
            " [ 56   6   3  30  29  14]\n",
            " [ 50   9   1   8  52   8]\n",
            " [ 57   6   3   9  39  26]]\n",
            "Accuracy: 0.30454545454545456\n",
            "Total f1 over classes: 1.6670181045982373\n",
            "Doing test analysis with ANN\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.38      0.33       149\n",
            "           1       0.35      0.38      0.36       154\n",
            "           2       0.24      0.13      0.17       157\n",
            "           3       0.25      0.24      0.24       143\n",
            "           4       0.40      0.49      0.44       138\n",
            "           5       0.35      0.32      0.33       140\n",
            "\n",
            "    accuracy                           0.32       881\n",
            "   macro avg       0.31      0.32      0.31       881\n",
            "weighted avg       0.31      0.32      0.31       881\n",
            "\n",
            "[[57 29  9 20  8 26]\n",
            " [33 58  7 16 26 14]\n",
            " [39 17 20 40 27 14]\n",
            " [27 27 21 34 18 16]\n",
            " [18 18  6 14 67 15]\n",
            " [27 16 21 11 20 45]]\n",
            "Accuracy: 0.318955732122588\n",
            "Total f1 over classes: 1.8740528766493953\n",
            "Doing test analysis with SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.27      0.36      0.31       149\n",
            "           1       0.30      0.40      0.34       154\n",
            "           2       0.29      0.20      0.24       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.49      0.41      0.44       138\n",
            "           5       0.31      0.31      0.31       140\n",
            "\n",
            "    accuracy                           0.31       881\n",
            "   macro avg       0.32      0.31      0.31       881\n",
            "weighted avg       0.32      0.31      0.31       881\n",
            "\n",
            "[[54 31 13 15  8 28]\n",
            " [33 61 12 21 11 16]\n",
            " [38 31 32 25 14 17]\n",
            " [35 33 18 28  8 21]\n",
            " [10 28 15 14 56 15]\n",
            " [29 20 20 11 17 43]]\n",
            "Accuracy: 0.31101021566401815\n",
            "Total f1 over classes: 1.8603134592951966\n",
            "Doing test analysis with Logistic Regression\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.26      0.27      0.26       149\n",
            "           1       0.35      0.44      0.39       154\n",
            "           2       0.33      0.13      0.19       157\n",
            "           3       0.23      0.17      0.19       143\n",
            "           4       0.28      0.44      0.34       138\n",
            "           5       0.27      0.29      0.28       140\n",
            "\n",
            "    accuracy                           0.29       881\n",
            "   macro avg       0.29      0.29      0.28       881\n",
            "weighted avg       0.29      0.29      0.28       881\n",
            "\n",
            "[[40 32  6 12 30 29]\n",
            " [26 67  4 11 26 20]\n",
            " [31 18 21 30 39 18]\n",
            " [21 28 16 24 31 23]\n",
            " [18 22  4 16 61 17]\n",
            " [19 26 12 11 32 40]]\n",
            "Accuracy: 0.28717366628830876\n",
            "Total f1 over classes: 1.6550484557028389\n",
            "Doing test analysis with Decision Tree\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.20      0.45      0.28       149\n",
            "           1       0.34      0.36      0.35       154\n",
            "           2       0.25      0.23      0.24       157\n",
            "           3       0.28      0.13      0.17       143\n",
            "           4       0.33      0.22      0.26       138\n",
            "           5       0.24      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.26       881\n",
            "   macro avg       0.27      0.25      0.25       881\n",
            "weighted avg       0.27      0.26      0.25       881\n",
            "\n",
            "[[67 26 22  5 12 17]\n",
            " [53 56 14 10 12  9]\n",
            " [60 20 36 21  8 12]\n",
            " [41 27 30 18 10 17]\n",
            " [60 18 14  8 30  8]\n",
            " [54 16 27  3 20 20]]\n",
            "Accuracy: 0.2576617480136209\n",
            "Total f1 over classes: 1.4834904925750796\n",
            "Doing test analysis with Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.25      0.32      0.28       149\n",
            "           1       0.39      0.44      0.41       154\n",
            "           2       0.33      0.20      0.25       157\n",
            "           3       0.23      0.24      0.23       143\n",
            "           4       0.47      0.43      0.45       138\n",
            "           5       0.34      0.37      0.35       140\n",
            "\n",
            "    accuracy                           0.33       881\n",
            "   macro avg       0.33      0.33      0.33       881\n",
            "weighted avg       0.33      0.33      0.33       881\n",
            "\n",
            "[[47 29 14 18  8 33]\n",
            " [27 67  7 22 13 18]\n",
            " [39 22 31 39 13 13]\n",
            " [27 19 18 34 21 24]\n",
            " [12 20 10 21 60 15]\n",
            " [33 13 15 14 13 52]]\n",
            "Accuracy: 0.33030646992054485\n",
            "Total f1 over classes: 1.9783962870690746\n",
            "Doing test analysis with Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.64      0.35       149\n",
            "           1       0.43      0.32      0.37       154\n",
            "           2       0.18      0.02      0.03       157\n",
            "           3       0.25      0.20      0.22       143\n",
            "           4       0.29      0.37      0.33       138\n",
            "           5       0.26      0.14      0.18       140\n",
            "\n",
            "    accuracy                           0.28       881\n",
            "   macro avg       0.28      0.28      0.25       881\n",
            "weighted avg       0.28      0.28      0.25       881\n",
            "\n",
            "[[95 11  0 14 20  9]\n",
            " [59 50  1 13 22  9]\n",
            " [70 16  3 32 21 15]\n",
            " [51 16  7 28 30 11]\n",
            " [45 12  4 15 51 11]\n",
            " [70 10  2 10 29 19]]\n",
            "Accuracy: 0.2792281498297389\n",
            "Total f1 over classes: 1.4838868218580543\n"
          ]
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale data before applying PCA\n",
        "#scaling=StandardScaler()\n",
        " \n",
        "# Use fit and transform method\n",
        "#scaling.fit(data)\n",
        "#Scaled_data=scaling.transform(data)\n",
        "\n",
        "# Set the n_components=3\n",
        "principal=PCA(n_components=11)\n",
        "principal.fit(data)\n",
        "pca_data=principal.transform(data)\n",
        "\n",
        "# summarize components\n",
        "print(\"Explained Variance: %s\" % principal.explained_variance_ratio_)\n",
        "print(\"Shape of Transformed data: \",pca_data.shape)\n",
        "\n",
        "pca_df = pd.DataFrame(pca_data, columns = [\"pc\"+str(pci) for pci in range(11)],\n",
        "                      index = labels.index)\n",
        "print(\"PCA data frame has row,columns:\", pca_df.shape)\n",
        "\n",
        "\n",
        "perform_experiment('G-1', 1,pca_df, labels,\"pca-output.csv\")\n",
        "perform_experiment('G-1', 2,pca_df, labels,\"pca-output.csv\")\n",
        "perform_experiment('G-1', 3,pca_df, labels,\"pca-output.csv\")\n",
        "perform_experiment('G-1', 4,pca_df, labels,\"pca-output.csv\")\n",
        "perform_experiment('G-1', 5,pca_df, labels,\"pca-output.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zddk0hlsVRDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "8b401508-29ee-4bee-f2a0-2d27c1c491a9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def ElbowMethod(data):\n",
        "    X = data  # <your_data>\n",
        "    distorsions = []\n",
        "    for k in range(1,6):\n",
        "        kmeans = KMeans(n_clusters=k)\n",
        "        kmeans.fit(X)\n",
        "        distorsions.append(kmeans.inertia_)\n",
        "\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    plt.plot(range(1, 6), distorsions, 'bo-')\n",
        "    plt.grid(True)\n",
        "    plt.ylabel(\"Square Root Error\")\n",
        "    plt.xlabel(\"Number of Clusters\")\n",
        "    plt.title('Elbow curve')\n",
        "    plt.savefig(\"ElbowCurve.png\")\n",
        "    plt.show()\n",
        "\n",
        "ElbowMethod(data)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cj1Mv0-hWju8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d85383a7-fe76-4476-c150-98c39849180f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  [0 1 0 ... 1 0 0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ANALYSIS PART\n",
        "\n",
        "# Using the graph shown in Elbow Method, find the appropriate value of K and set it here.\n",
        "def Analysis(vector, K=2):\n",
        "    arr = (np.array(vector))\n",
        "\n",
        "    # mean normalization of the data . converting into normal distribution having mean=0 , -0.1<x<0.1\n",
        "    sc = StandardScaler()\n",
        "    x = sc.fit_transform(arr)\n",
        "\n",
        "    # Breaking into principle components\n",
        "    pca = PCA(n_components=2)\n",
        "    components = (pca.fit_transform(x))\n",
        "    # Applying kmeans algorithm for finding centroids\n",
        "\n",
        "    kmeans = KMeans(n_clusters=K)\n",
        "    kmeans.fit_transform(components)\n",
        "    print(\"labels: \", kmeans.labels_)\n",
        "    centers = kmeans.cluster_centers_\n",
        "\n",
        "    # lables are assigned by the algorithm if 2 clusters then lables would be 0 or 1\n",
        "    lables = kmeans.labels_\n",
        "    colors = [\"r.\", \"g.\", \"b.\", \"y.\", \"c.\",\"m.\",\"k.\"]\n",
        "    colors = colors[:K + 1]\n",
        "    #print(\"colors are: \",len(colors))\n",
        "\n",
        "    for i in range(len(components)):\n",
        "        plt.plot(components[i][0], components[i][1], colors[lables[i]], markersize=10)\n",
        "\n",
        "    plt.scatter(centers[:, 0], centers[:, 1], marker=\"x\", s=150, linewidths=10, zorder=15)\n",
        "    plt.xlabel(\"1st Principle Component\")\n",
        "    plt.ylabel(\"2nd Principle Component\")\n",
        "    title = \"Styles Clusters\"\n",
        "    plt.title(title)\n",
        "    plt.savefig(\"Results\" + \".png\")\n",
        "    plt.show()\n",
        "Analysis(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Analysis(data, K=6)"
      ],
      "metadata": {
        "id": "kfqzfsKQNhFy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "c6ac6c5c-3c16-42bf-c33b-cf4c5f4e651f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels:  [3 4 3 ... 1 5 5]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "fake_tweet_001.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}